IncidentId,CreatedDateTime,Title,IssueDescription,Subject,DaysToSolution,RootCauseSupportTopic,InitialSupportTopicPath,Symptomstxt,Causetxt,Resolutiontxt,RelatedICM_IDs,,,,,,,
1.20022E+14,11:13.6,Kerbaroes TGT error for the service account user,"Question: What time did the problem begin?\nAnswer: Sun, Feb 23, 2020, 12:00 AM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sun, Feb 23, 2020, 12:00 AM MST\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: No\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Tried to restart the credential services, but still getting the error while running the job from CRONTAB. When I run the same job manually, it is running fine.\n\nAnd also, credential service logs are out of date. I am not seeing the recent logs for  the credential services updating.\n\nQuestion: Additional details about the issue\nAnswer: Kerbaroes TGT for the service user is failing.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - No;\nDoes hdfs dfs -ls / work? - Yes;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - Tried to restart the credential services, but still getting the error while running the job from CRONTAB. When I run the same job manually, it is running fine.\n\nAnd also, credential service logs are out of date. I am not seeing the recent logs for  the credential services updating.;\nAdditional details about the issue - Kerbaroes TGT for the service user is failing.;\n\n- ProblemStartTime: 02/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kerbaroes TGT error for the service account user,0.161405439,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",VM reboots very often,"The logs indicate that the VM crash is caused by the guest OS send it looked like the VM is repeatedly panicking. The Vm in question is not hosted on the node that is was listed during the time period of this incident so you should not be seeing the issue. Host2020-02-24 04:18:00Microsoft-Windows-Hyper-V-Worker'31e20ea6- --- has encountered a fatal error. The guest operating system reported that it failed with the following error codes: ErrorCode0: 0x0, ErrorCode1: 0x818000040F120000, ErrorCode2: 0x7FCC0E690E40, ErrorCode3: 0x7FCC0F39B9F8, ErrorCode4: 0x7FCBF0D277A8. If the problem persists, contact Product Support for the guest operating system. (Virtual machine ID 68A7D101- ---)Host2020-02-24 04:18:21Microsoft-Windows-Hyper-V-Worker'31e20ea6- --- was reset by the guest operating system. (Virtual machine ID 68A7D101- ---) Please let us know if you have any questions or concerns.",The Vm in question is not hosted on the node that is was listed during the time period of this incident so you should not be seeing the issue.,177045841,,,,,,,
1.20022E+14,42:48.6,some pipelines are failing with no applicatoin ID assigned,"We're trying to determine where/why some of our pipeline activities are failing. We're using a self hosted IR and some of the pipeline activities that are failing are not making it to the HDI cluster to get an app ID assigned so troubleshooting has been a problem. We'd like to figure out how we can better monitor and troubleshoot issues like this. Also if there are tools that we can use to monitor the IR as well to see if possibly we're hitting a bottle neck in regards to resources or connections, concrurrent or otherwise.\n\nProblem start date and time\nFri, Feb 21, 2020, 12:00 AM EST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 02/21/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinerg/providers/Microsoft.DataFactory/factories/mpcosmuse2sephtsadf1\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",some pipelines are failing with no applicatoin ID assigned,2.112285165,Root Cause : HDInsight Service\Configuration\Spark,"Routing Azure Data Factory V2\Pipeline Activities\HDInsight (Hive, MapReduce, Pig, Spark, Streaming)",Out of memory exceptions in the livy logs and application's not being created from the service logs due to timeout.,"Based on the investigation done and the resolution, it appears the cluster did not have enough free memory to handle the workload as well as the velocity of jobs meant resources were not available right away for some jobs. This in turn caused some jobs to fail due to resource allocation, and others to fail as the job would timeout waiting for resources.","For the jobs failing due to out of memory, increasing the heap size seemed to have resolved these. For the remaining jobs, increasing the livy timeout seems to have resolved the issues customer was facing.",,,,,,,,
1.20022E+14,25:09.0,Node manager unhealthy ,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 26, 2020, 12:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Node manager unhealthy \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Node manager unhealthy \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Other, don't know or not applicable;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Node manager unhealthy ;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Node manager unhealthy ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 01/26/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHSP90ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Node manager unhealthy ,0.035312622,Root Cause : HDInsight Service\Configuration\HDInsight,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie",warnings in ambari,Node manager unhealthy,restarted nodemgr.,,,,,,,,
1.20022E+14,16:35.9,Cluster not scaling up,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 24, 2020, 10:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The following error is not enabling to scale up the cluster:\n\n{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The following error is not enabling to scale up the cluster:\n\n{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.;\n\n- ProblemStartTime: 02/24/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: TBDC-TIMS-CAS-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/853a7c3e-9554-4f69-a0cd-fa48a4362d54/resourceGroups/cas_prod_rg/providers/Microsoft.HDInsight/clusters/casdbcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster not scaling up,2.052211989,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,unable to scale,zombie nodes,"zombie nodes cleaned  Ambari server log will throw a lot of OutOfMemoryException, deadlocks etc... If that happens, scaling the DB will not help. You can run the modified version of the python script that will remove the nodes from the database directly.NOTE: Since we are using SQL statements instead of REST api, it is effective but shouldn't result in customer starting to play with the ambari db directly.  	  	 Get SSH credentials for a root user through ACIS action (user who can sudo)   	   		 If the customer has to run it, but says that don't have an user account with root privileges, you can create the user account through ACIS and share it with the customer 	  	 	 	 From the active headnode (""ping headnodehost"" to identify the active headnode)   	   		 cd /root 		wget https://healingscriptssa.blob.core.windows.net/clusterpatches/ambari_clean_zombienodes.sh  -O ambari_clean_zombienodes.sh 		chmod a+x ambari_clean_zombienodes.sh 		./ambari_clean_zombienodes.sh 		After script execution is complete it will automatically restart the ambari server",,,,,,,,
1.20022E+14,33:08.4,not possible to scale up,"can't scale up the cluster\n\nProblem start date and time\n{Namepii}, Feb 24, 2020, 12:00 PM PST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 02/24/2020 20:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-bpeng-Shared-HDInsight/providers/Microsoft.HDInsight/clusters/cccmstaging\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",not possible to scale up,0.033397823,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\General Guidance or Advisory,Issue : Scaling failure,"Cause: cluster is unable to retrieve the Actual Node count from Ambari , headnode1 was unresponsive and this is where Ambari-server was running.",Resolution : Restarting the headnode1 caused ambari-server to failover to hn0 and Ambari server to come back up to a healthy state. Which helped in the cluster scale up.  ,,,,,,,,
1.20022E+14,58:00.9,Overall cluster's performance is extremely slow,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: SELECT * FROM imdl_irdp.cur_esg_controversies_msci WHERE as_of_date = '2020-02-04' AND issuer_cusip in ('{ALPHANUMERICPII}')\n\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: There are multiple performance issues running with different tables. \n\n1. A simple where condition on a table, that is less than 1 GB is taking around 30 minutes.\n\n2. Inserting and updating the values (single row) into a transactional table is taking more than 10 minutes for every attempt.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - SELECT * FROM imdl_irdp.cur_esg_controversies_msci WHERE as_of_date = '2020-02-04' AND issuer_cusip in ('{ALPHANUMERICPII}')\n\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - There are multiple performance issues running with different tables. \n\n1. A simple where condition on a table, that is less than 1 GB is taking around 30 minutes.\n\n2. Inserting and updating the values (single row) into a transactional table is taking more than 10 minutes for every attempt.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Overall cluster's performance is extremely slow,0.079040279,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Slower query performance,"Customer is loading data from external tables to managed tables. They are using simple queries such as SELECT, INSERT and UPDATE for their incremental data. Everything seemed to be good except configuration needed to be adjusted to improve query performance. ","Setting hive.fetch.task.conversion=none (from more) resulted in faster performance for customer. With this change, queries can be converted to a single FETCH task, minimizing latency.Some additional information on this https://vcfvct.wordpress.com/2016/02/18/make-hive-query-faster-with-fetch-task/https://cwiki.apache.org/confluence/display/Hive/Configuration+Propertieshttps://stackoverflow.com/questions/7466454/how-does-hive-decide-when-to-use-map-reduce-and-when-not-to",180049259,,,,,,,
1.20023E+14,51:17.5,Creation of a HDinsight cluster creation with HDI 3.6 and spark 2.1 version along with Data lake Gen2 is being a problem,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Creation of HD Insight cluster with HDI 3.6 and sprak version 2.1 with Azure Data lake {Alphanumericpii} is being a problem.\n\nWe want to know if the above combination is possible ?\n\nPlese refer to the email that's attached with screenshots that are there. that was the combination tried and the errors we saw.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Creation of HD Insight cluster with HDI 3.6 and sprak version 2.1 with Azure Data lake {Alphanumericpii} is being a problem.\n\nWe want to know if the above combination is possible ?\n\nPlese refer to the email that's attached with screenshots that are there. that was the combination tried and the errors we saw.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/24/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: US_AUDIT_PREPROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Creation of a HDinsight cluster creation with HDI 3.6 and spark 2.1 version along with Data lake Gen2 is being a problem,0.028466968,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,120022523001923 - Creation of an HDinsight cluster creation with HDI 3.6 and spark 2.1 version along with Data lake Gen2 is a problem.,Product Group confirmed that this combination is not supported,Use HDInsight 4.0/Spark 2.4 ,177173517,,,,,,,
1.20023E+14,22:56.3,"Creation of hdinsight with ESP failing,","Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 12:00 PM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Feb 25, 2020, 1:00 PM EST\n\nQuestion: {Namepii} name\nAnswer: nhanpoc\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToJoinToDomain\\',\\r\\n \\'message\\': \\'Failed to join to domain domainservices.avidxchange.com. Output = Failed to join domain: failed to precreate account in ou {AlphanumericPII}: Insufficient access\\{uncpii} Error = \\'\\r\\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - nhanpoc;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToJoinToDomain\\',\\r\\n \\'message\\': \\'Failed to join to domain domainservices.avidxchange.com. Output = Failed to join domain: failed to precreate account in ou {AlphanumericPII}: Insufficient access\\{uncpii} Error = \\'\\r\\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]};\n\n- ProblemStartTime: 02/25/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AvidXchange Enterprise DevQA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb7f642a-16cf-48a7-8161-58002441290d/resourceGroups/{Namepii}-AADDS-POC/providers/Microsoft.HDInsight/clusters/nhanpoc\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Creation of hdinsight with ESP failing,",0.023294572,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,"1: User is unable to deploy a cluster and is getting an error message that reads: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.2: Username in Ambari showing incorrectly as opposed to what is in AADS. ","We had two issues to cover in this case.  1: User is unable to deploy a cluster and is getting an error message that reads: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.2: Username in Ambari showing incorrectly: User's name in AADS is showing as the username is cpollock-adm while in Ambari it shows up as cpollock- (e0e31a4f). ","For the first issue: We were advised by the product group team that this is a known issue with ESP clusters upon deletion some of the OU entries are not clearing properly. This will cause issues when attempting to deploy clusters with the same user name as before. As work around we suggested deploying clusters with different usernames, especially making sure that the first 6 characters of the cluster name are different from before. We expect this issue to be cleared soon with the fix available for the General Public in our next cluster OS update releases. For the second issue:  1. We found that according to this link: https://docs.microsoft.com/en-us/azure/active-directory-domain-services/synchronization. The SAMAccountName attribute is sourced from the mailNickname attribute in the Azure AD tenant.2. In this case the user's mailNickName attribute was empty, this prompted AADS to generate a generic username that was reflected in Ambari as cpollock- (e0e31a4f)3. To resolve this issue, had the user update the mailNickName property in AADS to what the SAMAccountName is in AADS then waited about an hour for the LDAP to resync with Ambari. 4. This cleared the username issue, it now reflected correctly as intended and the user is now able access HiveView. ",,,,,,,,
1.20023E+14,35:24.8,Show Server Error ,"Question: What time did the problem begin?\nAnswer: Wed, Feb 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Feb 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Is issue intermittent?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: No Not Able to Access the cluster \n\nQuestion: Additional details about the issue\nAnswer: {\n  'status': 500,\n  'message': 'Server Error'\n}\n\nGetting error while accessing the cluster \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs issue intermittent? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - No Not Able to Access the cluster ;\nAdditional details about the issue - {\n  'status': 500,\n  'message': 'Server Error'\n}\n\nGetting error while accessing the cluster ;\n\n- ProblemStartTime: 02/25/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05ue2piphdidm01\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Show Server Error ,0.05377525,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Ambari UI is not loading,"Ambari UI throwing 500, server error.",Ambari-Server status,"In our troubleshooting from the backend logs,  we have found issue with  ambari- server status, restarting the server resolved the issue. You have confirmed that the cluster is up and running.",,,,,,,,
1.20023E+14,36:23.8,Erroe while creating HDinsight cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 12:00 PM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We are getting error while trying to create a new HDinsight cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We are getting error while trying to create a new HDinsight cluster;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/25/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Enterprise Dev/Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Erroe while creating HDinsight cluster,0.047605914,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to create Hdinsight cluster,This is a transient issue. It looks like the over provision - a normal operation for HDI - wasn't successed during this time. ,Redeployed the lcluster,,,,,,,,
1.20023E+14,39:37.1,Health of cluster - heartbeat lost on all nodes,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 11:50 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: tried to restart HDFS components but it did not change the status.\n\nQuestion: Additional details about the issue\nAnswer: resource Health on Portal also showing unhealthy\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - tried to restart HDFS components but it did not change the status.;\nAdditional details about the issue - resource Health on Portal also showing unhealthy\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/25/2020 17:50:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: 9885 - Decision Support Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/816a4b01-2bf2-44ce-9e31-b1fec9095726/resourceGroups/DS3_DEVResourceGroup_Central/providers/Microsoft.HDInsight/clusters/d3ncsparkstrm02\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Health of cluster - heartbeat lost on all nodes,0.969697383,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Health of cluster - heartbeat lost on all nodes.,Heartbeat lost on one of the headnodes and Ambari agent is unable to determine the status of the worker nodes.,Rebooted both the head-nodes from the backend and kill the zombie process manually from client side.,,,,,,,,
1.20023E+14,16:14.1,Updating Error,"Question: What time did the problem begin?\nAnswer: Sat, Feb 8, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Feb 25, 2020, 12:00 AM PST\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: {Namepii} is not scaling ans stuck in Updating Error state\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - {Namepii} is not scaling ans stuck in Updating Error state;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.;\n\n- ProblemStartTime: 02/08/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DnI Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Updating Error,0.988517668,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Cluster stuck in Updating Error state when trying to scale up,"Symptoms. The script action fails. Text similar to the following error displays when you view the operation in Ambari:​from azure.storage.blob import BlobService​ImportError: cannot import name BlobService​"" style=""border-bottom-color:currentColor;border-bottom-style:none;border-bottom-width:0px;border-image-outset:0;border-image-repeat:stretch;border-image-slice:100%;border-image-source:none;border-image-width:1;border-left-color:currentColor;border-left-style:none;border-left-width:0px;border-right-color:currentColor;border-right-style:none;border-right-width:0px;border-top-color:currentColor;border-top-style:none;border-top-width:0px;box-sizing:inherit;direction:ltr;display:block;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;font-size:1em;line-height:19px;padding-bottom:0px;padding-left:0px;padding-right:0px;padding-top:0px;position:relative;"">Traceback (most recent call list):​  File ""/var/lib/ambari-agent/cache/custom_actions/scripts/run_customscriptaction.py"", line 21, in <module>​    from azure.storage.blob import BlobService​ImportError: cannot import name BlobService​Cause. This error occurs if you upgrade the Python Azure Storage client that's included with the HDInsight cluster. HDInsight expects Azure Storage client 0.20.0.","To resolve this error, manually connect to each cluster node by using ssh. Run the following command to reinstall the correct storage client version:sudo pip install azure-storage==0.20.0",177188729,,,,,,,
1.20023E+14,48:50.2,corrupted authorized_keys file for 'clusteruser' on headnode0,"one of our data analysists added their public key to the ssh user `clusteruser` authorized_keys, and seemingly corrupted the file, we are now completely unable to login to the headnode.\n\nWould appreciate your assistance in recovering access to the node. \n\nProblem start date and time\nWed, Feb 26, 2020, 12:00 AM EST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 02/26/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: rbeu-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f59599c2-4fd5-42ff-b526-0414953ff73e/resourceGroups/rbpoc-rbeu-weu-poc-rg/providers/Microsoft.HDInsight/clusters/rbpoc-rbeu-weu-poc\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",corrupted authorized_keys file for 'clusteruser' on headnode0,0.034870349,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,No access to the cluster's headnodes. ,"A user added their public key to the ssh user `clusteruser` authorized_keys, and seemingly corrupted the file, they are now completely unable to login to the headnode",User followed the steps provided here https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-the-ssh-user-password and he was able to reset the ssh user password and gain access to the cluster. ,,,,,,,,
1.20023E+14,21:05.0,HIVE service unable to start,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Here is the error message we got\n\nCaused by: java.lang.reflect.InvocationTargetException\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 20 more\nCaused by: MetaException(message:Hive Schema version 1.2.1000 does not match metastore's schema version 1.2.0 Metastore is not upgraded or corrupt)\n        at org.apache.hadoop.hive.metastore.RetryingHMSHandler. init ({AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient. init ({AlphanumericPII})\n        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient. init ({AlphanumericPII})\n        ... 25 more\nCaused by: MetaException(message:Hive Schema version 1.2.1000 does not match metastore's schema version 1.2.0 Metastore is not upgraded or corrupt)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hive.metastore.RetryingHMSHandler. init ({AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Here is the error message we got\n\nCaused by: java.lang.reflect.InvocationTargetException\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 20 more\nCaused by: MetaException(message:Hive Schema version 1.2.1000 does not match metastore's schema version 1.2.0 Metastore is not upgraded or corrupt)\n        at org.apache.hadoop.hive.metastore.RetryingHMSHandler. init ({AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient. init ({AlphanumericPII})\n        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient. init ({AlphanumericPII})\n        ... 25 more\nCaused by: MetaException(message:Hive Schema version 1.2.1000 does not match metastore's schema version 1.2.0 Metastore is not upgraded or corrupt)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hive.metastore.RetryingHMSHandler. init ({AlphanumericPII})\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Prod_DR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cca3be6-ea39-4394-9aab-242213bd98e5/resourceGroups/eaasedl-prd/providers/Microsoft.HDInsight/clusters/sparkeaasedlprd\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HIVE service unable to start,0.290624636,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Hive services unable to start,Hive metastore version not matching with hive version.,Updated the metastore version to the latest matching the hive version,,,,,,,,
1.20023E+14,13:52.5,Resource Manager Down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The resource manager on head nodes are down. Cannot be restarted.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The resource manager on head nodes are down. Cannot be restarted.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/JourneyAI/providers/Microsoft.HDInsight/clusters/sensei-dsnpalpha-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Resource Manager Down,0.010052228,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,"We determined that the HDInsight cluster sensei-dsnpalpha-hdi has a WASB storage account with secure transfer enabled breaking the cluster. We would recommend you recreate the cluster and enable secure transfer while deploy the new cluster or if you want to fix this cluster without secure transfer, please disable the secure transfer on storage account.",Resource Manager Down,"We determined that the HDInsight cluster sensei-dsnpalpha-hdi has a WASB storage account with secure transfer enabled breaking the cluster. We would recommend you recreate the cluster and enable secure transfer while deploy the new cluster or if you want to fix this cluster without secure transfer, please disable the secure transfer on storage account.",,,,,,,,
1.20023E+14,14:46.8,Need to stop Ambari View,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I want to stop Amabari VIew. so then no one can view it.\n\nWhen i stopp the serive it is getting turned on automatically.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I want to stop Amabari VIew. so then no one can view it.\n\nWhen i stopp the serive it is getting turned on automatically.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to stop Ambari View,0.049678281,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,You had an 'Allow_External' rules that applied for all users. We removed the allow_external rules as well as alter the denied rule. ,Customer wanted to block ambari view from the public. ,This was an NGS issue,,,,,,,,
1.20023E+14,30:32.6,HDI version,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 19, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: n/a\n\nQuestion: Additional details about the issue\nAnswer: We deployed two new spark hdinsight clusters recently, {AlphanumericPII} and {Alphanumericpii}) was created on 12/23/2020 in our daily subscriptioin and {AlphanumericPII} and {Alphanumericpii}) was created on 12/26/2020 in our staging subscription. In these two new clusters, the spark version is 2.3.2. But when we deployed same spark hdinsight cluster in our  production subscription on 01/16/2020, we found that spark version was changed back to 2.3.0. \n\nSince we have already made change to support spark 2.3.2 on daily and staging, we wondered if this could affect our spark apps on production cluster. Checking Azure HDInsight release history, there are two recent releases for {ALPHANUMERICPII} that were on 01/09/2020 and 12/17/2019, what is change between these two released? Is Spark version change as expected?\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - n/a;\nAdditional details about the issue - We deployed two new spark hdinsight clusters recently, {AlphanumericPII} and {Alphanumericpii}) was created on 12/23/2020 in our daily subscriptioin and {AlphanumericPII} and {Alphanumericpii}) was created on 12/26/2020 in our staging subscription. In these two new clusters, the spark version is 2.3.2. But when we deployed same spark hdinsight cluster in our  production subscription on 01/16/2020, we found that spark version was changed back to 2.3.0. \n\nSince we have already made change to support spark 2.3.2 on daily and staging, we wondered if this could affect our spark apps on production cluster. Checking Azure HDInsight release history, there are two recent releases for {ALPHANUMERICPII} that were on 01/09/2020 and 12/17/2019, what is change between these two released? Is Spark version change as expected?\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 01/19/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI version,0.026034554,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,"Issue:HDI Version:We deployed two new spark hdinsight clusters recently, one(HDI3.6 and Spark2.3) was created on 12/23/2020 in our daily subscriptioin and other(HDI3.6 and Spark2.3) was created on 12/26/2020 in our staging subscription. In these two new clusters, the spark version is 2.3.2. But when we deployed same spark hdinsight cluster in our  production subscription on 01/16/2020, we found that spark version was changed back to 2.3.0. Since we have already made change to support spark 2.3.2 on daily and staging, we wondered if this could affect our spark apps on production cluster. Checking Azure HDInsight release history, there are two recent releases for HDI3.6 that were on 01/09/2020 and 12/17/2019, what is change between these two released? Is Spark version change as expected?", Cause:              HDI product team confirmed that this is a labelling issue.  ,Fix:HDI Product group has fixed the issue and deployment should be completed by now.,177348164,,,,,,,
1.20023E+14,39:19.0,FD QA :  kpphv806llapfdqausc01 : Analyze and Querying from Hive View failing for table insght_mtrc & insght_prdctn.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Analyze query is not working and is timing out.\nQuery works from non-secure cluster from hive view, and beeline and but doesn’t work from LLAP hive view.\n\nSELECT DISTINCT INSGHT_IK,INSGHT_MTRC_VL_NB, ROWKEY, MTRC_TS\nFROM INSGHT_MTRC\nWHERE MTRC_TS  (GREATER THAN =) ='2020-02-25 {Alphanumericpii}' AND INSGHT_MTRC_VL_NB  (GREATER THAN =) =1\nORDER BY MTRC_TS DESC\n\nQuestion: Interactive query explain plan if available\nAnswer: +-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n|                                                                        Explain                                                                        |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n| Plan optimized by CBO.                                                                                                                                |\n|                                                                                                                                                       |\n| Vertex dependency in root stage                                                                                                                       |\n| Reducer 2  - Map 1 (SIMPLE_EDGE)                                                                                                                      |\n| Reducer 3  - Reducer 2 (SIMPLE_EDGE)                                                                                                                  |\n|                                                                                                                                                       |\n| {Alphanumericpii}                                                                                                                                               |\n|   Fetch Operator                                                                                                                                      |\n|     {alphanumericpii}                                                                                                                                          |\n|     {Alphanumericpii}                                                                                                                                           |\n|       Reducer 3 vectorized, llap                                                                                                                      |\n|       File Output Operator [{ALPHANUMERICPII}]                                                                                                                    |\n|         Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                               |\n|           {AlphanumericPII}']                                                                                                    |\n|         -Reducer 2 [SIMPLE_EDGE] vectorized, llap                                                                                                    |\n|           SHUFFLE [{ALPHANUMERICPII}]                                                                                                                             |\n|             Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                           |\n|               {AlphanumericPII}']                                                                                                |\n|               Group By Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                       |\n|                 {AlphanumericPII}, {AlphanumericPII}, {AlphanumericPII}, {AlphanumericPII}                                              |\n|                -Map 1 [SIMPLE_EDGE] vectorized, llap                                                                                                  |\n|                 SHUFFLE [{ALPHANUMERICPII}]                                                                                                                       |\n|                   {AlphanumericPII}, {alphanumericpii}, {alphanumericpii}, {alphanumericpii}                                                                                            |\n|                   Group By Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                   |\n|                     {AlphanumericPII}, rowkey, insght_mtrc_vl_nb, insght_ik                                       |\n|                     Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                   |\n|                       Output:['mtrc_ts','rowkey','insght_mtrc_vl_nb','insght_ik']                                                                     |\n|                       Filter Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                 |\n|                         predicate:(insght_mtrc_vl_nb = 1.0)                                                                                          |\n|                         TableScan [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                      |\n|                           insightdriven_tz@insght_mtrc,insght_mtrc,Tbl:COMPLETE,Col:NONE,Output:['rowkey','mtrc_ts','insght_mtrc_vl_nb','insght_ik']  |\n|                                                                                                                                                       |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Analyze query is not working and is timing out.\nQuery works from non-secure cluster from hive view \nQuery works when run from beeline \nQuery doesn’t work from LLAP hive view.\n\nThe following were tried \n1. Increasing timeout \n2. Turn off pushdown optimization \n\nERROR LOG \nrror log while running query in ambari hive view.\n \n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - Result fetch timed out\njava.util.concurrent.TimeoutException: deadline passed\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - Result fetch timed out\n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - java.util.concurrent.TimeoutException: deadline passed\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Analyze query is not working and is timing out.\nQuery works from non-secure cluster from hive view, and beeline and but doesn’t work from LLAP hive view.\n\nSELECT DISTINCT INSGHT_IK,INSGHT_MTRC_VL_NB, ROWKEY, MTRC_TS\nFROM INSGHT_MTRC\nWHERE MTRC_TS  (GREATER THAN =) ='2020-02-25 {Alphanumericpii}' AND INSGHT_MTRC_VL_NB  (GREATER THAN =) =1\nORDER BY MTRC_TS DESC;\nInteractive query explain plan if available - +-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n|                                                                        Explain                                                                        |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n| Plan optimized by CBO.                                                                                                                                |\n|                                                                                                                                                       |\n| Vertex dependency in root stage                                                                                                                       |\n| Reducer 2  - Map 1 (SIMPLE_EDGE)                                                                                                                      |\n| Reducer 3  - Reducer 2 (SIMPLE_EDGE)                                                                                                                  |\n|                                                                                                                                                       |\n| {Alphanumericpii}                                                                                                                                               |\n|   Fetch Operator                                                                                                                                      |\n|     {alphanumericpii}                                                                                                                                          |\n|     {Alphanumericpii}                                                                                                                                           |\n|       Reducer 3 vectorized, llap                                                                                                                      |\n|       File Output Operator [{ALPHANUMERICPII}]                                                                                                                    |\n|         Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                               |\n|           {AlphanumericPII}']                                                                                                    |\n|         -Reducer 2 [SIMPLE_EDGE] vectorized, llap                                                                                                    |\n|           SHUFFLE [{ALPHANUMERICPII}]                                                                                                                             |\n|             Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                           |\n|               {AlphanumericPII}']                                                                                                |\n|               Group By Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                       |\n|                 {AlphanumericPII}, {AlphanumericPII}, {AlphanumericPII}, {AlphanumericPII}                                              |\n|                -Map 1 [SIMPLE_EDGE] vectorized, llap                                                                                                  |\n|                 SHUFFLE [{ALPHANUMERICPII}]                                                                                                                       |\n|                   {AlphanumericPII}, {alphanumericpii}, {alphanumericpii}, {alphanumericpii}                                                                                            |\n|                   Group By Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                   |\n|                     {AlphanumericPII}, rowkey, insght_mtrc_vl_nb, insght_ik                                       |\n|                     Select Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                   |\n|                       Output:['mtrc_ts','rowkey','insght_mtrc_vl_nb','insght_ik']                                                                     |\n|                       Filter Operator [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                 |\n|                         predicate:(insght_mtrc_vl_nb = 1.0)                                                                                          |\n|                         TableScan [{ALPHANUMERICPII}] ({alphanumericpii} {alphanumericpii})                                                                                      |\n|                           insightdriven_tz@insght_mtrc,insght_mtrc,Tbl:COMPLETE,Col:NONE,Output:['rowkey','mtrc_ts','insght_mtrc_vl_nb','insght_ik']  |\n|                                                                                                                                                       |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------+--+\n;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Analyze query is not working and is timing out.\nQuery works from non-secure cluster from hive view \nQuery works when run from beeline \nQuery doesn’t work from LLAP hive view.\n\nThe following were tried \n1. Increasing timeout \n2. Turn off pushdown optimization \n\nERROR LOG \nrror log while running query in ambari hive view.\n \n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - Result fetch timed out\njava.util.concurrent.TimeoutException: deadline passed\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - Result fetch timed out\n26 Feb 2020 {Alphanumericpii} ERROR [{alphanumericpii}] [HIVE {Alphanumericpii} {ALPHANUMERICPII}] {AlphanumericPII} - java.util.concurrent.TimeoutException: deadline passed;\n\n- ProblemStartTime: 02/25/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpphv806llapfdqausc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD QA :  kpphv806llapfdqausc01 : Analyze and Querying from Hive View failing for table insght_mtrc & insght_prdctn.,26.58254673,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,FD QA : kpphv806llapfdqausc01 : Analyze and Querying from Hive View failing for table insght_mtrc & insght_prdctn.,"When The client (LLAP zkclient) sends a request to the server (Hbase ZK quorum) , it essentially expects a 'secure' response. The zookeeper connectivity from ESP to non ESP will not work because the clients will try to use secure connection which will not be supported."," To have query hbase tables from hive, they need to make sure either both the clusters (LLAP and HBase) are ESP or Non ESP.  ",179623156,,,,,,,
1.20023E+14,05:27.0,HDI ambari GUI went unreachable,"Question: What time did the problem begin?\nAnswer: Wed, Feb 26, 2020, 6:55 PM GMT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: none\n\nQuestion: Additional details about the issue\nAnswer: https://cortexaapsprdspark.azurehdinsight.net/\n\nThis site can’t be reached\n\ncortexaapsprdspark.azurehdinsight.net took too long to respond\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - none;\nAdditional details about the issue - https://cortexaapsprdspark.azurehdinsight.net/\n\nThis site can’t be reached\n\ncortexaapsprdspark.azurehdinsight.net took too long to respond;\n\n- ProblemStartTime: 02/26/2020 18:55:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: US_AUDIT_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c71ef53-4473-4862-af36-bae6e40451b2/resourceGroups/App-Cortex-AME-PRD-RG/providers/Microsoft.HDInsight/clusters/cortexaapsprdspark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI ambari GUI went unreachable,0.087592386,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,HDI ambari GUI went unreachable,HDI ambari GUI went unreachable,Support checked and found that customer is able to browse cluster thru internal endpoint while public endpoint access is lost as the source VM doesn’t have public IP assigned to it and it got changed. Informed customer that no VIP VM’s would carry dynamic IP provided by Host and would need to get a static IP to avoid connectivity lost. Customer confirmed to close the case.,,,,,,,,
1.20023E+14,26:39.2,Issues Containercustom built ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: hdfs dfs - abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/incidents/v1/offsets\n\nits takes 5-6 mins to list the dir\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Other, don't know or not applicable;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - hdfs dfs - abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/incidents/v1/offsets\n\nits takes 5-6 mins to list the dir;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/04af94d4-74f4-4642-b571-5b48a42b979f/resourceGroups/ITS-APPOPS-EDL-PROD-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/PHSP02ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Issues Containercustom built ,5.108053602,Root Cause : HDInsight Service\Transient error / Unknown,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie",slow listing of files,unknown,created copy of files,,,,,,,,
1.20023E+14,06:54.3,yarn memory usage 100% with jupyter nodes,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Additional details about the issue\nAnswer: Hello,\n   we are running our code in jupyter notebook ({alphanumericpii} notebook) and when we run 4 parallel notebook the yarn memory is used at 100%.\n\nYarn memory goes to 100% even if we run very simple pyspark code like the ones attached (files.zip. You can find it inside main issue.zip file).\n\nattached also the screen of the made tests and yarn usage (new_cluster_issues.docx. You can find it inside main issue.zip file).\n\nusing azure documentation (https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-resource-manager) we found a way to run multiple notebook and avoid yarn memory saturation.\nwe added on top of the notebook code:\n\n%%configure\n{'executorMemory': '{ALPHANUMERICPII}', 'executorCores': 4, '{AlphanumericPII}}\n\nis there any configuration that can be applied in the HDI spark cluster to assign to each notebook the max amount of memory/core/executors to use?\nthanks\nBR\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nAdditional details about the issue - Hello,\n   we are running our code in jupyter notebook ({alphanumericpii} notebook) and when we run 4 parallel notebook the yarn memory is used at 100%.\n\nYarn memory goes to 100% even if we run very simple pyspark code like the ones attached (files.zip. You can find it inside main issue.zip file).\n\nattached also the screen of the made tests and yarn usage (new_cluster_issues.docx. You can find it inside main issue.zip file).\n\nusing azure documentation (https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-resource-manager) we found a way to run multiple notebook and avoid yarn memory saturation.\nwe added on top of the notebook code:\n\n%%configure\n{'executorMemory': '{ALPHANUMERICPII}', 'executorCores': 4, '{AlphanumericPII}}\n\nis there any configuration that can be applied in the HDI spark cluster to assign to each notebook the max amount of memory/core/executors to use?\nthanks\nBR\n{Namepii};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2fa38a83-8c49-4cae-90fc-346d90c21eb8/resourceGroups/airetail-analytics/providers/Microsoft.HDInsight/clusters/airetail-spark-36-secure\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",yarn memory usage 100% with jupyter nodes,0.228468534,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Client tool issue\Notebooks,"When the client launch one Jupyter notebook in a HDInsight Spark cluster, it uses  excessive amount of resources (YARN Memory). When they trigger 4 Jupyter notebooks YARN Memory is already at 100% of its capacity.","Jupyter notebook is allocating resources in advance (without running anything) for future jobs, that’s why it shows an aggressive increase in the YARN memory usage, just for allocating resources (memory) in advance.","Decrease the values for spark.executor.memory through Ambari, select Spark2, then Configs tab and finally look for the ""spark.executor.memory"" config on the search bar, decrease the values on: * Custom spark2-defaults* Spark2-thrift-sparkconf",,,,,,,,
1.20023E+14,10:02.9,Not able to Delete HDID02SPRK,"Question: What time did the problem begin?\nAnswer: Wed, Feb 26, 2020, 4:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: Yes, we made changes to Peering as we were testing Global peering.\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Deleting HdInsgiht fails with Interal Server Error. I tried to delete each individual components as well with our any success. \n\nPlease help me delete {ALPHANUMERICPII} and all teh components associated with that.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - Yes, we made changes to Peering as we were testing Global peering.;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Deleting HdInsgiht fails with Interal Server Error. I tried to delete each individual components as well with our any success. \n\nPlease help me delete {ALPHANUMERICPII} and all teh components associated with that.;\n\n- ProblemStartTime: 02/26/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: NON_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acab600-1814-4101-95b7-c69a8fbe8dbc/resourceGroups/rg-nonprod-cus-cloudservices/providers/Microsoft.HDInsight/clusters/hdid02sprk\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to Delete HDID02SPRK,6.310950315,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Delete HDInsight cluster,Not able to Delete HDID02SPRK,NA,PG deleted the CLuster Manually https://icm.ad.msft.net/imp/v3/incidents/details/177468493/home,177468493,,,,,,,
1.20023E+14,52:17.7,ahd501dj pyspark fails to start with permissionmismatch error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Can you log in to Ranger using the cluster local admin credential?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII}: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: Operation failed: 'This request is not authorized to perform this operation using this permission.', 403, PUT, https://azuscvdls00501.dfs.core.windows.net/ahd501/user/kkotha/.sparkStaging/application_1582825186165_0006?action=setAccessControl&timeout=90, AuthorizationPermissionMismatch, 'This request is not authorized to perform this operation using this permission. {AlphanumericPII} {AlphanumericPII}'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - Yes;\nDoes the issue affect all users or a few users? - All users;\nDoes kinit for some or all users work from the Head node? - ;\nCan you log in to Ranger using the cluster local admin credential? - ;\nDoes authentication fail even for the cluster admin account? - ;\nAdditional details about the issue - {AlphanumericPII}: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: Operation failed: 'This request is not authorized to perform this operation using this permission.', 403, PUT, https://azuscvdls00501.dfs.core.windows.net/ahd501/user/kkotha/.sparkStaging/application_1582825186165_0006?action=setAccessControl&timeout=90, AuthorizationPermissionMismatch, 'This request is not authorized to perform this operation using this permission. {AlphanumericPII} {AlphanumericPII}';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ahd501dj pyspark fails to start with permissionmismatch error,49.12136971,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ranger in cluster with Enterprise Security Package,120022721001340 - ahd501dj pyspark fails to start with permissionmismatch error,Unknown,The issue is no longer happening. All of the users are able to access the pyspark shell without having the 'Storage Blob Data Owner' role. Customer said the only change was adding the service account users to the 'Storage Blob Data Owner' role but we don't know why that would resolve the original permissionmismatch error.Customer agreed we can archive the case and reopen if the same 403 permissions mismatch happens,"179,532,039,180,048,000",,,,,,,
1.20023E+14,18:56.3,Out of Memory Errors,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 25, 2020, 12:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: {alphanumericpii}\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: We were able to adjust the settings for various memory configurations on our other HDInsight (HDP-2.6.2.25) cluster that is attached to {Alphanumericpii} storage and resolve this issue.  \n\nWhen I looked online, I found some release notes for Hortonworks Data Platform (HDP) 3.1.3 that mention a fixed bug {ALPHANUMERICPII} “Hive throws OutOfMemoryError on ABFS during QueryResultsCacheoperation”. This seems like the issue we are seeing but I cannot be sure. From what I can tell, the “ABFS” portion of this seems to be related to the Data {Namepii} V2. When I look around I see multiple issues related to ABFS.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - {alphanumericpii};\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - We were able to adjust the settings for various memory configurations on our other HDInsight (HDP-2.6.2.25) cluster that is attached to {Alphanumericpii} storage and resolve this issue.  \n\nWhen I looked online, I found some release notes for Hortonworks Data Platform (HDP) 3.1.3 that mention a fixed bug {ALPHANUMERICPII} “Hive throws OutOfMemoryError on ABFS during QueryResultsCacheoperation”. This seems like the issue we are seeing but I cannot be sure. From what I can tell, the “ABFS” portion of this seems to be related to the Data {Namepii} V2. When I look around I see multiple issues related to ABFS.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/25/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Greenhouse\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5fcb9b33-e28e-4056-96dc-9ecc709cfd78/resourceGroups/ProductionCluster/providers/Microsoft.HDInsight/clusters/Greenhouse-Production\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Out of Memory Errors,0.980794859,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Hive,Out of Memory Errors.,Hive query with million rows throws OutOfMemoryError.,Need to optimize the DML hive query accordingly to the partition base so that Mapper vertices completed successfully. ,,,,,,,,
1.20023E+14,43:26.5,[Azure Government] consent test for fairfax,"[Azure Government] test ticket, ignore and close\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: azengcase_fairfax\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] consent test for fairfax,0.007482202,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Metrics are missing\Kafka,120022724006081 -[Azure Government] consent test for fairfax,this was a test ticket,this was a test ticket,,,,,,,,
1.20023E+14,14:08.3,CSO 10178/10179 - Issues in setting up HDInsight HBase Accelerated Writes ,"Brief Summary on where we stand today on this.\n \nWe were seeing high latencies in new stage environment as the DNS lookups failing most of the times and succeeding occasionally from Ethos. As per Azure team, DNS lookup should not work at all with out the Azure private DNS or custom DNS solutions in place. Azure DNS/Network team is going to investigate why DNS lookup was working sometimes.\n \nWhat we tried yesterday:\n \n{ALPHANUMERICPII} HDInsight team provided a solution to register the IPs in HBASE instead of hostnames. This avoids the DNS as the communication between the VNET peered hosts with IPs.\n{Alphanumericpii} search team with the help from HDI team rolled out this change new stage environment. Latencies are under control. We will observe the cluster metrics for a week.\n{Alphanumericpii} on the performance and tests in staging, we will rollout this change to production by 3/20. \n{Alphanumericpii}’ve also requested HDI team to document and publish this procedure with known issues or limitations.\n \nThanks,\nDevendar\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",CSO 10178/10179 - Issues in setting up HDInsight HBase Accelerated Writes ,15.97165213,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\General Guidance or Advisory,HBase Accelerated Writes setup and guidance,CSO 10178/10179 - Issues in setting up HDInsight HBase Accelerated Writes,"We did not see anything unusual with the below managed disks and you are working with our product group too in adding additional load. Uma from our Hbase team confirmed that the spikes you were seeing are not problematic and are mostly due to the replication that is happening to other regions. /subscriptions/46c5358b-aac2-475f-94fb-15c420d96c78/resourceGroups/RG0-2F1D444F65F6441994F674245E4F12F0RESOURCEGROUP/providers/Microsoft.Compute/disks/workernode-0-vm-2_disk1_272c6aa871194e35be8147050362c9fd/subscriptions/46c5358b-aac2-475f-94fb-15c420d96c78/resourceGroups/RG0-2F1D444F65F6441994F674245E4F12F0RESOURCEGROUP/providers/Microsoft.Compute/disks/workernode-0-vm-3_disk1_74421e3082bd4d1bbe6d7ee5e24e3efb/subscriptions/46c5358b-aac2-475f-94fb-15c420d96c78/resourceGroups/RG0-2F1D444F65F6441994F674245E4F12F0RESOURCEGROUP/providers/Microsoft.Compute/disks/workernode-0-vm-4_disk1_86b45667773f407790fcad0cf8363ea6I am sharing below details which you have requested as a part of this case. This helps in monitoring the storage accounts and helps in setting up diagnostic logs for storage account.https://docs.microsoft.com/en-us/azure/storage/common/storage-monitor-storage-account#configure-monitoring-for-a-storage-accountAdditionally you can configure metrics charts and metrics alerts based on the conditions you define.If it is for managed disks, you can enable performance diagnostics using below link which will help in identifying any latencies or throttling.https://docs.microsoft.com/en-us/azure/virtual-machines/troubleshooting/performance-diagnosticshttps://docs.microsoft.com/en-us/azure/azure-monitor/insights/vminsights-overview",178207367,,,,,,,
1.20023E+14,22:12.4,ProdSup:kp10tntncapllapnsprdsup01: Hive service down.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: HiveServerInteractive cannot be determined to be up and responding to client requests on the server  {alphanumericpii}.\n\n{alphanumericpii} – ATS Check Failed:\n{AlphanumericPII} cannot be determined to be up and responding to client requests.\n\n\n\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii} – ATS Check Failed:\n{AlphanumericPII} cannot be determined to be up and responding to client requests.\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - HiveServerInteractive cannot be determined to be up and responding to client requests on the server  {alphanumericpii}.\n\n{alphanumericpii} – ATS Check Failed:\n{AlphanumericPII} cannot be determined to be up and responding to client requests.\n\n\n;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii} – ATS Check Failed:\n{AlphanumericPII} cannot be determined to be up and responding to client requests.\n\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ProdSup:kp10tntncapllapnsprdsup01: Hive service down.,0.065447102,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,ProdSup:kp10tntncapllapnsprdsup01: Hive service down.,We noticed that HiveInteractive service was down when a long running query was occupying most of the disk space on the nodes.,"Here are some mitigation steps that you can implement to prevent the disk space to get filled up. Ensure that yarn.log-aggregation-enabled is enabled. If disabled, NMs will keep the logs locally and not aggregate them in remote store on application completion/termination.Cache also uses disk space, so check if yarn.nodemanager.localizer.cache.cleanup.interval-ms (default 10 mins) and yarn.nodemanager.localizer.cache.target-size-mb (default 10240 MB) are set to reasonable valuesEnsure that the cluster size is appropriate for the workload. If the cluster is not appropriately sized, scale up the cluster and retry./mnt/resource might also get filled with orphaned files (as in the case of RM restart). Manually cleaning up /mnt/resource/hadoop/yarn/log and /mnt/resource/hadoop/yarn/local on the worker nodes would help in this scenario.yarn.nodemanager.localizer.cache.target-size-mb: This decides the maximum disk space to be used for localizing resources. (At present there is no individual limit for PRIVATE / APPLICATION / PUBLIC cache. YARN-882). Once the total disk size of the cache exceeds this then Deletion service will try to remove files which are not used by any running containers. At present there is no limit (quota) for user cache / public cache / private cache. This limit is applicable to all the disks as a total and is not based on per disk basis. yarn.nodemanager.localizer.cache.cleanup.interval-ms: After this interval resource localization service will try to delete the unused resources if total cache size exceeds the configured max-size. Unused resources are those resources which are not referenced by any running container. Every time container requests a resource, container is added into the resources’ reference list. It will remain there until container finishes avoiding accidental deletion of this resource. As a part of container resource cleanup (when container finishes) container will be removed from resources’ reference list. That is why when reference count drops to zero it is an ideal candidate for deletion. The resources will be deleted on LRU basis until current cache size drops below target size.  The properties can be added in Ambari à Yarn à Configs à Advanced à custom yarn-site àAdd Property",,,,,,,,
1.20023E+14,46:43.5,[03/02/2020][HDI]I am unable to connect even after restating the Hive2interatcive services using Ambari.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 27, 2020, 9:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: restating the {Alphanumericpii} services using Ambari\n\nQuestion: Additional details about the issue\nAnswer: I am unable to connect to Datalake even after restating the {Alphanumericpii} services using Ambari.\n\nhdinsight: Execution failed: Open Session Error. Couldn't connect to server: System.Net.WebException: The remote server returned an error: (502) Bad Gateway. at System.Net.HttpWebRequest.GetResponse() at Thrift.Transport.THttpClient.SendRequest()\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - restating the {Alphanumericpii} services using Ambari;\nAdditional details about the issue - I am unable to connect to Datalake even after restating the {Alphanumericpii} services using Ambari.\n\nhdinsight: Execution failed: Open Session Error. Couldn't connect to server: System.Net.WebException: The remote server returned an error: (502) Bad Gateway. at System.Net.HttpWebRequest.GetResponse() at Thrift.Transport.THttpClient.SendRequest();\n\n- ProblemStartTime: 02/28/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AVALA Aimbase Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/dbb4eb18-427d-4399-82d2-c8644c869282/resourceGroups/aimbase-data-pd-rg/providers/Microsoft.HDInsight/clusters/c10-pd-ab-hdi\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[03/02/2020][HDI]I am unable to connect even after restating the Hive2interatcive services using Ambari.,0.011394801,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Intermitient connection failures,Hive metastore limit reached.,Leverage the external metastore,177747843,,,,,,,
1.20023E+14,36:14.2,Spark2 thrift server connection lost to headnode 0,"Question: What time did the problem begin?\nAnswer: Fri, Feb 28, 2020, 12:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Connection failed on host hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/SPARK2/2.0.0/package/scripts/alerts/alert_spark2_thrift_port.py', line 149, in execute\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 160, in run\n    self.run_action(resource, action)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 124, in run_action\n    provider_action()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py', line 269, in action_run\n    tries=self.resource.tries, try_sleep=self.resource.try_sleep)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 72, in inner\n    result = function(command, **kwargs)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 102, in checked_call\n    tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 150, in _call_wrapper\n    result = _call(command, **kwargs_copy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 303, in _call\n    raise ExecutionFailed(err_msg, code, out, err)\nExecutionFailed: Execution of '! /{alphanumericpii} -u 'jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http'  -e '' 2&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL' -e 'Error: Could not open'' returned 1. Error: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http. org.apache.http.conn.HttpHostConnectException: Connect to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 [hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net/172.20.251.39] failed: Connection refused (Connection refused) ({AlphanumericPII})\nError: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http. org.apache.http.conn.HttpHostConnectException: Connect to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 [hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net/172.20.251.39] failed: Connection refused (Connection refused) ({AlphanumericPII})\n)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Connection failed on host hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/SPARK2/2.0.0/package/scripts/alerts/alert_spark2_thrift_port.py', line 149, in execute\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 160, in run\n    self.run_action(resource, action)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 124, in run_action\n    provider_action()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py', line 269, in action_run\n    tries=self.resource.tries, try_sleep=self.resource.try_sleep)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 72, in inner\n    result = function(command, **kwargs)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 102, in checked_call\n    tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 150, in _call_wrapper\n    result = _call(command, **kwargs_copy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 303, in _call\n    raise ExecutionFailed(err_msg, code, out, err)\nExecutionFailed: Execution of '! /{alphanumericpii} -u 'jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http'  -e '' 2&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL' -e 'Error: Could not open'' returned 1. Error: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http. org.apache.http.conn.HttpHostConnectException: Connect to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 [hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net/172.20.251.39] failed: Connection refused (Connection refused) ({AlphanumericPII})\nError: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002/default;transportMode=http. org.apache.http.conn.HttpHostConnectException: Connect to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:10002 [hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net/172.20.251.39] failed: Connection refused (Connection refused) ({AlphanumericPII})\n);\n\n- ProblemStartTime: 02/28/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark2 thrift server connection lost to headnode 0,0.049118178,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Spark2 thrift server connection lost to headnode 0,connection issue with spark thrift server,rebooted spark2 thrift sever,,,,,,,,
1.20023E+14,40:01.2,Ubuntu 18.0.4 for HDInsight nodes,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: riaz-test\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: HDInsight cluster nodes are being created with an OS of Ubuntu {Alphanumericpii}. This article (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-os-patching) states that new Ubuntu packages will be available within 3 months of their release, so we are expecting nodes to use Ubuntu {Alphanumericpii}. Is there a way to explicitly specify which Ubuntu version the nodes will use?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - riaz-test;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - HDInsight cluster nodes are being created with an OS of Ubuntu {Alphanumericpii}. This article (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-os-patching) states that new Ubuntu packages will be available within 3 months of their release, so we are expecting nodes to use Ubuntu {Alphanumericpii}. Is there a way to explicitly specify which Ubuntu version the nodes will use?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SilviaTerra Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ubuntu 18.0.4 for HDInsight nodes,0.086583511,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Ubuntu 18.0.4 for HDInsight nodes,expecting nodes to use Ubuntu 18.0.4.,After looking into the document   https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-os-patching. I see that it is about patching the existing version not upgrading to the new linux version. This document uses the screenshot which is not from HDInsight and it is showing the wrong version. The version cannot be changed on HDInsight and HDInsight uses version 16.04.The ubuntu version cannot be used when deploying clusters. It is a documentation issue. I will file a work item to fix it.,,,,,,,,
1.20023E+14,49:40.6,PRDSUP: kp10tntncapllapnsprdsup01 : There is not a single NCAP query run successfully since 7 am today morning. Let us restart please.,"Question: What time did the problem begin?\nAnswer: Fri, Feb 28, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Non of the Hive query getting completed since 7AM\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Non of the Hive query getting completed since 7AM\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Non of the Hive query getting completed since 7AM;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Non of the Hive query getting completed since 7AM;\n\n- ProblemStartTime: 02/28/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kp10tntncapllapnsprdsup01 : There is not a single NCAP query run successfully since 7 am today morning. Let us restart please.,0.855838497,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Hive,Unable to execute any queries from Hive View and beeline,PRDSUP: kp10tntncapllapnsprdsup01 : There is not a single NCAP query run successfully since 7 am today morning,"We do see two issues in this and below are the recommendations, For Issue #1, this should be large enough to handle requests from both web browsers and embedded Views. Consider the following guidance when planning for Views user capacity. On the Ambari Server host, edit the ambari-env.sh file.vi /var/lib/ambari-server/ambari-env.shFor the AMBARI_JVM_ARGS variable, replace the default -Xmx2048m with the following value:-Xmx4096m -XX:PermSize=128m -XX:MaxPermSize=128mRestart the server.ambari-server restart For Issue#2, related to the LLAP stoppage. It looks like this is related to authentication. We can see two trends: Periodic GSS Timeout, Periodic ZK Connection failure. We suggest you to do it periodically (ie: once per week) run the ZK snapshot cleanup steps at https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-fails#next-steps. Addressing ZK health should address the ability to authenticate, which should address the ability to run queries.  Authentication timeouts caused queries to not execute. We see ZK health issues during time of impact, which were addressed. We advise to peridoically cleanup ZK snapshots (until they create a new cluster that will have this bugfix enabled). ",177656147,,,,,,,
1.20023E+14,04:08.2,Ambari Ui is not loading,"Question: What time did the problem begin?\nAnswer: Sat, Feb 29, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are not able to see the ambari UI\nPFB Command output\n\n{alphanumericpii}# service ambari-server status\n● ambari-server.service - ambari-server\n   Loaded: loaded (/etc/systemd/system/ambari-server.service; disabled; vendor preset: enabled)\n   Active: active (running) since {Namepii} 2020-02-25 18:33:44 UTC; 3 days ago\n Main PID: 7583 (java)\n    Tasks: 181\n   Memory: {ALPHANUMERICPII}\n      CPU: 9h {Alphanumericpii} {Alphanumericpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are not able to see the ambari UI\nPFB Command output\n\n{alphanumericpii}# service ambari-server status\n● ambari-server.service - ambari-server\n   Loaded: loaded (/etc/systemd/system/ambari-server.service; disabled; vendor preset: enabled)\n   Active: active (running) since {Namepii} 2020-02-25 18:33:44 UTC; 3 days ago\n Main PID: 7583 (java)\n    Tasks: 181\n   Memory: {ALPHANUMERICPII}\n      CPU: 9h {Alphanumericpii} {Alphanumericpii}\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/28/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaprdhadoop-cus-01-rg/providers/Microsoft.HDInsight/clusters/dxitprdspark\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Ui is not loading,0.149846672,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading, Not able to see the Ambari UI,Ambari DB hitting connection limit Internal Exception: com.microsoft.sqlserver.jdbc.SQLServerException: Resource ID : 1. The request limit for the database is 60 and has been reached," For permanent cluster, with default Ambari DB, we could move Ambari DB to next tier. However, you are creating the clusters dynamically, so we would recommend to go with Custom Ambari DB in higher tier.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-custom-ambari-db",177665053,,,,,,,
1.20023E+14,05:49.6,Hive and MapReduce services are down from all the clusters ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Hive Metastore and MapReduce services are down, this is creating outage with ADLS socket time out issue when the jobs are running. \n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Hive Metastore and MapReduce services are down, this is creating outage with ADLS socket time out issue when the jobs are running. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Hive Metastore and MapReduce services are down, this is creating outage with ADLS socket time out issue when the jobs are running. ;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Hive Metastore and MapReduce services are down, this is creating outage with ADLS socket time out issue when the jobs are running. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/eastudl\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive and MapReduce services are down from all the clusters ,1.175687827,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Unexpected result\Hive,Hive and MapReduce services are down from all the clusters,177705564,"Our Engineering team mitigated the issue now and please restart the cluster and pipeline jobs. Please reply back to this thread if you are noticing any issues with the cluster and the jobs.  I have also included Preliminary RCA for your reference. Summary of impact: Between approximately 28 Feb 2020 and 17:00 UTC on 01 Mar 2020, you were identified as a customer using Azure Data Lake Analytics/Azure Data Lake Store  who may have encountered job submission and job execution failures for resources hosted in this region.   Preliminary root cause: Engineers identified that a backend service became unhealthy after a recent deployment, which resulted in user operation timeouts.   Mitigation: Engineers rolled back the recent deployment to mitigate the issue. Next steps: Engineers will continue to investigate to establish the full root cause and prevent future occurrences. Stay informed about Azure service issues by creating custom service health alerts: https://aka.ms/ash-videos for video tutorials and https://aka.ms/ash-alerts for how-to documentation. Best Regards,","177,705,564,177,740,000",,,,,,,
1.2003E+14,25:01.9,Deployment failed for HDInsight Kafka cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: db-kafka-medium\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Hi support,\n\nwe want to create a new Kafka HDInsight {Namepii}.\nWe get the following error message:\n\nOperation ID: /subscriptions/c56291eb-649a-4eac-aae8-eb4f43436f77/resourceGroups/SIEM-DBNetz-POC/providers/Microsoft.Resources/deployments/HDInsight__2020-03-02T14.12.54.896Z/operations/6A579A4EE026DD8C\nOperation name: {XUIDPII}\nProvisioning operation: Create\nProvisioning state: Failed\nTimestamp: 3/2/2020, 4:14:27 PM\nDuration: 1 hour 1 minute 5 seconds\nTracking {AlphanumericPII}\nStatus: Conflict\n\nStatus message:\n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'AzureResourceCreationFailedErrorCode',\n                'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n            }\n        ]\n    }\n}\n\nType: Microsoft.HDInsight/clusters\nResource ID:/subscriptions/c56291eb-649a-4eac-aae8-eb4f43436f77/resourceGroups/SIEM-DBNetz-POC/providers/Microsoft.HDInsight/clusters/db-kafka-medium\nResource:db-kafka-medium\nDeployment correlation ID: {guidpii}\n\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'AzureResourceCreationFailedErrorCode\\',\\r\\n        \\'message\\': \\'Internal server error occurred while processing the request. Please retry the request or contact support.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n\nDo you have an idea?\n\nBest regards\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - db-kafka-medium;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Hi support,\n\nwe want to create a new Kafka HDInsight {Namepii}.\nWe get the following error message:\n\nOperation ID: /subscriptions/c56291eb-649a-4eac-aae8-eb4f43436f77/resourceGroups/SIEM-DBNetz-POC/providers/Microsoft.Resources/deployments/HDInsight__2020-03-02T14.12.54.896Z/operations/6A579A4EE026DD8C\nOperation name: {XUIDPII}\nProvisioning operation: Create\nProvisioning state: Failed\nTimestamp: 3/2/2020, 4:14:27 PM\nDuration: 1 hour 1 minute 5 seconds\nTracking {AlphanumericPII}\nStatus: Conflict\n\nStatus message:\n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'AzureResourceCreationFailedErrorCode',\n                'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n            }\n        ]\n    }\n}\n\nType: Microsoft.HDInsight/clusters\nResource ID:/subscriptions/c56291eb-649a-4eac-aae8-eb4f43436f77/resourceGroups/SIEM-DBNetz-POC/providers/Microsoft.HDInsight/clusters/db-kafka-medium\nResource:db-kafka-medium\nDeployment correlation ID: {guidpii}\n\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'AzureResourceCreationFailedErrorCode\\',\\r\\n        \\'message\\': \\'Internal server error occurred while processing the request. Please retry the request or contact support.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n\nDo you have an idea?\n\nBest regards\n{Namepii};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c56291eb-649a-4eac-aae8-eb4f43436f77/resourceGroups/SIEM-DBNetz-POC/providers/Microsoft.HDInsight/clusters/db-kafka-medium\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Deployment failed for HDInsight Kafka cluster,24.92133193,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,could not deploy without internet access,Advisory,The only supported way to restrict outbound traffic for HDInsight clusters is to follow the steps outlined in this doc by using either Azure Firewall or customers NVA:https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-restrict-outbound-traffic ,178484849,,,,,,,
1.2003E+14,58:28.7,Hive Query Issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: SELECT * FROM PSBU.MTL_ORDER_TRANSACTIONS where LINE_ID in ('36531178') ;\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: We have two clusters(Spark, LLAP) and both are pointing to same Metastore and Storage. We're using LLAP for down stream application to read the data. \n\nThe above mentioned query works fine in SPARK but in LLAP it throuh an error \n[Code: 0, SQL State: ]  Error retrieving next row\n\nLet me know how to fix it.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - SELECT * FROM PSBU.MTL_ORDER_TRANSACTIONS where LINE_ID in ('36531178') ;;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - We have two clusters(Spark, LLAP) and both are pointing to same Metastore and Storage. We're using LLAP for down stream application to read the data. \n\nThe above mentioned query works fine in SPARK but in LLAP it throuh an error \n[Code: 0, SQL State: ]  Error retrieving next row\n\nLet me know how to fix it.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llapdjenterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Query Issue,1.245454308,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Unable to run Hive query through JDBC connnection with third party toolUser is getting org.apache.thrift.transport.TTransportException: HTTP Response code: 502,"The job succeed in submitting the job through beeline SELECT * FROM PSBU.MTL_ORDER_TRANSACTIONS where LINE_ID in ('36531178') limit 10; However, when submitting the job through DBVisualizer, the query failed. This was due the table wasn't partitioned. The query has to read 50+ files without submitting a yarn job.  ",You were able to solve this issue by paritioning the table. ,,,,,,,,
1.2003E+14,23:06.9,Head nodes are in failed state.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 11:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Resatart all components on two head nodes, but it is still  in failed state.\n\nQuestion: Additional details about the issue\nAnswer: Microservices connected to Kafka is failing due to this issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Resatart all components on two head nodes, but it is still  in failed state.;\nAdditional details about the issue - Microservices connected to Kafka is failing due to this issue.;\n\n- ProblemStartTime: 03/02/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e8134fcd-f6c7-4f98-ab92-8bcac3817a96/resourceGroups/lct-predist-dev-02/providers/Microsoft.HDInsight/clusters/kaf-lct-predist-dev-02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head nodes are in failed state.,0.118716576,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Issue: Headnodes for the kafka cluster in a bad state. Hn0 was unresponsive and hn1 was running fine but ambari-agent was utilizing more CPU.,Node's been up and running for more than a year. Ambari agent process running hot on hn1. Hn0 unresponsive to ssh. ,Resolution : Restarted the problematic node to get past the issue.,,,,,,,,
1.2003E+14,30:39.8,Cluster doesn't start..Generic Error Message,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: bsw-bir-hadoop\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'UnhandledExceptionErrorCode\\',\\r\\n \\'message\\': \\'Internal server error occurred while processing the request. Please retry the request or contact support.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - bsw-bir-hadoop;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'UnhandledExceptionErrorCode\\',\\r\\n \\'message\\': \\'Internal server error occurred while processing the request. Please retry the request or contact support.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]};\n\n- ProblemStartTime: 03/02/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BIIR\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster doesn't start..Generic Error Message,0.028984201,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster doesn't start..Generic Error Message,Networiking issues. ," I verified your Route table once again and noticed that there was a typo in one of the IPs -- HDInsightsMgmtEast2_04139.91.141.162/32The IP mentioned in the documentation -- https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses is 138.91.141.162 Can you please make the change?  2. With that said, the DNS server configured with the Vnet is a custom DNS server DNS Servers:10.7.200.95, 10.130.200.95 Can you make sure these DNS servers are properly configured to forward requests for the DNS suffix of the virtual network to the Azure recursive resolver IP (168.63.129.16) as shown in the documentation below? documentation to follow : https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-create-virtual-network#example-dnshttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#multinet ",,,,,,,,
1.2003E+14,36:28.7,HTTP Error 502.3 - Bad Gateway when checking log,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: HTTP Error 502.3 - Bad Gateway when checking application log\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - HTTP Error 502.3 - Bad Gateway when checking application log;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-CAN-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d24d2ef-d585-4522-a66f-72ca2bfbfd61/resourceGroups/o365ipdican01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdican01-sp-cc01\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HTTP Error 502.3 - Bad Gateway when checking log,0.031889557,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Can access to application logs,HTTP Error 502.3 - Bad Gateway when checking application log,"This is a known issue with an internal work item created. The work item has been completed and the PR for fix was rolled out last week. The client can have access to logs via SSH into headnode. And/Or use SSH tunneling to access logs via Ambari UI, following this document https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-linux-ambari-ssh-tunnel. ",,,,,,,,
1.2003E+14,44:32.3,Edge nodes were removed from Amabari but still available in Azure. Please remove.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 9:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: The following edge nodes were removed from Amabari but still available in Azure. Please see the entries from the host file below.\n\n{Ipaddresspii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n{Ipaddresspii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n\n\nQuestion: Additional details about the issue\nAnswer: The following edge nodes were removed from Amabari but still available in Azure. Please see the entries from the host file below.\n\n{Ipaddresspii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n{Ipaddresspii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - The following edge nodes were removed from Amabari but still available in Azure. Please see the entries from the host file below.\n\n{Ipaddresspii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n{Ipaddresspii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n;\nAdditional details about the issue - The following edge nodes were removed from Amabari but still available in Azure. Please see the entries from the host file below.\n\n{Ipaddresspii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed20-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n{Ipaddresspii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net {alphanumericpii} ed22-qabaus.04f12crn4xcehjeergzjkndw1g.cx.internal.cloudapp.net.\n;\n\n- ProblemStartTime: 03/02/2020 14:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Dev - Enterprise Data Team\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2ef31419-5d77-4f28-b2d9-69db8a6dd358/resourceGroups/QA-HDinsight-BAU-RG/providers/Microsoft.HDInsight/clusters/qabauspark930\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge nodes were removed from Amabari but still available in Azure. Please remove.,25.2286426,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,120030224005315 - Edge nodes were removed from Ambari but still available in Azure. Please remove.,Edge node was removed from Ambari instead of the Azure Portal.,"When you need to remove an edge node from an HDInsight cluster, you should use the Azure Portal.  Deleting an edge node from Ambari will not stop the billing for the edge node and your edge node will still be online.Documentation reference:https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node#delete-an-edge-node",,,,,,,,
1.2003E+14,16:11.3,Pyspark and Key Vault,"Please help us understand how to fetch secrets from an Azure Key Vault in Pyspark on HDInsight without passing credentials or hardcoding service principal IDs and tokens. Our non-domain-joined HDInsight cluster is using a service principal that already has access to our Azure Key Vault, so can we fetch a secret at runtime of a Pyspark script without passing the client_id, secret, and tenantID as described in this article (https://docs.microsoft.com/en-us/python/api/overview/azure/key-vault?view=azure-python)? If so, can you please provide an example? We do not want our developers hardcoding service principal IDs or tokens in their Pyspark scripts.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Pyspark and Key Vault,3.906338884,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Authentication failure\Notebook in standard cluster,"120030224006133 - Customer wanted options for using Azure Key Vault in a Pyspark application without hard-coding the required options (client_id, secret, and tenant)",It is a security vulnerability to hard-code these values in the application ,"Provided customer with three different options:1.          Authenticating with KeyVault using a user-defined MSI would be ideal, but this is not supported2.          Put the information necessary to authenticate into a file, and protect the file with POSIX permissions.  You could store the file in your data lake or on a local cluster drive.3.          Put the information in environment variables and retrieve the environment variable at run time.  You have two good options for adding the environment variables that I can think of:a.          Spark2-env via the Ambari website for your clusterb.          /etc/environment Customer will explore option #2 and open a new case if they face issues during implementation ",,,,,,,,
1.2003E+14,31:06.4,scale up failed,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer:  'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: InternalServerError; ErrorDescription: Encountered failure(s) scaling cluster to 12 nodes. Scaling operation partially succeeded with a final node count of 8. Scaling error code: InternalServerError. Scaling error message: Internal server error occurred while processing the request. Please retry the request or contact support.{Uncpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue -  'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: InternalServerError; ErrorDescription: Encountered failure(s) scaling cluster to 12 nodes. Scaling operation partially succeeded with a final node count of 8. Scaling error code: InternalServerError. Scaling error message: Internal server error occurred while processing the request. Please retry the request or contact support.{Uncpii}\n\n- ProblemStartTime: 03/02/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",scale up failed,0.793977015,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,scaling fail,Reconfiguration due to planned operation coincided with scaling op,retry,,,,,,,,
1.2003E+14,05:38.4,Unable start metric collector and lost 1wn (wn71-hdi01p),"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 3, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to start metrics collector and lost 1 wn ({alphanumericpii})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to start metrics collector and lost 1 wn ({alphanumericpii});\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/02/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0fb6b363-fa59-454d-9f03-2d3667f65469/resourceGroups/RG-SEA-DIP-PRD-001/providers/Microsoft.HDInsight/clusters/hdi01pscbdipsea\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable start metric collector and lost 1wn (wn71-hdi01p),0.358548457,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Ambari Metrics unable to start,Cache memory on headnode 0 unable to allocate memory for AMC,Restart of HN0,,,,,,,,
1.2003E+14,34:10.5,Cannot Access Ambari,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 3, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: Yes\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Hello {Namepii}, I´m not able to access Ambari. We are getting error HTTP Error 502.3 - Bad Gateway.\nRegards,\n\n{Namepii}\n\nQuestion: Additional details about the issue\nAnswer: Hello {Namepii}, I´m not able to access Ambari. We are getting error HTTP Error 502.3 - Bad Gateway.\nRegards,\n\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - Yes;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Hello {Namepii}, I´m not able to access Ambari. We are getting error HTTP Error 502.3 - Bad Gateway.\nRegards,\n\n{Namepii};\nAdditional details about the issue - Hello {Namepii}, I´m not able to access Ambari. We are getting error HTTP Error 502.3 - Bad Gateway.\nRegards,\n\n{Namepii};\n\n- ProblemStartTime: 03/03/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Avanade - SIM Frontend\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Basic Support\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7f6c65a5-ebfd-48d2-80bf-f6f2cdbaa32b/resourceGroups/az-rg-analytics-use-prd/providers/Microsoft.HDInsight/clusters/azhdisimuseprd\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot Access Ambari,0.026822684,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,Symptom: I´m not able to access Ambari. We are getting error HTTP Error 502.3 - Bad Gateway.,"Cause:  unhealthy gateway requestsResolution: It indicates there is an issue with the quorum, and since LeaderDiscoveryService on the gateway relies on the hdinsight zookeeper quorum to be up 100% of the time,this will result in the customer hitting 502 errors. This issue usually auto-recovers after some time which in case recovered automatically and you are able to access the ambari after sometime.","Cause:  unhealthy gateway requestsResolution: It indicates there is an issue with the quorum, and since LeaderDiscoveryService on the gateway relies on the hdinsight zookeeper quorum to be up 100% of the time,this will result in the customer hitting 502 errors. This issue usually auto-recovers after some time which in case recovered automatically and you are able to access the ambari after sometime.",,,,,,,,
1.2003E+14,49:07.2,FD Sandbox:  kpphv604llapfdsbusc01:  Hive view (Ambari) not loading for select user AD group (soi-adf-fdmclaims),"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 24, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Restarted ranger, credentials service to ensure users are synched \n2. Applied ACL permissions and verified its applied correctly \nChecked if the below folders have access to “SOI-ADF-FDMCLAIMS”\n/ - RX\n/adf - RX\n/adf/Clusters - RX\n/adf/Clusters/secure - RX  \n/adf/Clusters/secure/llap - RX\n/{AlphanumericPII}/ -RX\n/{AlphanumericPII} - RX\n/{AlphanumericPII}/ {Alphanumericpii} - RWX  - folder and sub folders\n/{AlphanumericPII}/ - RX\n/{AlphanumericPII} - RWX - folder and sub folders\n\nQuestion: Additional details about the issue\nAnswer: 1, Attached screenshots of hive view (which doesn't {alphanumericpii}\n\n2. When the tab (Tables) is selected, it shows 'Unable to fetch database information' \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. Restarted ranger, credentials service to ensure users are synched \n2. Applied ACL permissions and verified its applied correctly \nChecked if the below folders have access to “SOI-ADF-FDMCLAIMS”\n/ - RX\n/adf - RX\n/adf/Clusters - RX\n/adf/Clusters/secure - RX  \n/adf/Clusters/secure/llap - RX\n/{AlphanumericPII}/ -RX\n/{AlphanumericPII} - RX\n/{AlphanumericPII}/ {Alphanumericpii} - RWX  - folder and sub folders\n/{AlphanumericPII}/ - RX\n/{AlphanumericPII} - RWX - folder and sub folders;\nAdditional details about the issue - 1, Attached screenshots of hive view (which doesn't {alphanumericpii}\n\n2. When the tab (Tables) is selected, it shows 'Unable to fetch database information' ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/24/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kpphv604llapfdsbusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox:  kpphv604llapfdsbusc01:  Hive view (Ambari) not loading for select user AD group (soi-adf-fdmclaims),0.024823737,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,FD Sandbox:  kpphv604llapfdsbusc01:  Hive view (Ambari) not loading for select user AD group (soi-adf-fdmclaims),FD Sandbox:  kpphv604llapfdsbusc01:  Hive view (Ambari) not loading for select user AD group (soi-adf-fdmclaims),"Worked with customer on this and found that ""ranger.plugin.hive.service.name"" was set to kpadfdfdsb01_hive while the service name on ranger plugin customer was managing was ""kpphv604llapfdsbusc01_hive"".Possible options:Update “ranger.plugin.hive.service.name”  to “kpphv604llapfdsbusc01_hive” On Cluster: kpphv604llapfdsbusc01.Since the current value of “ranger.plugin.hive.service.name”  is “kpadfdfdsb01_hive"", you can create ranger policies similar to working cluster “kpph10llapprdsupusc01"" to allow users.Shared above possible solutions, and customer confirmed that they have tried one of the below and agreed to close the case.",,,,,,,,
1.2003E+14,47:10.1,PRDSUP : kp08tntncapsparknsprdsup01 : Not able to execute spark query from DE  WF,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 3, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: Hive ambari query executed successfully. However the DE tool workflow failed with error : om.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Connection reset {AlphanumericPII}'.\n\nCaused by: java.io.IOException: Connection reset {AlphanumericPII}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - NA;\nAdditional details about the issue - Hive ambari query executed successfully. However the DE tool workflow failed with error : om.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Connection reset {AlphanumericPII}'.\n\nCaused by: java.io.IOException: Connection reset {AlphanumericPII};\n\n- ProblemStartTime: 03/03/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp08tntncapsparknsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP : kp08tntncapsparknsprdsup01 : Not able to execute spark query from DE  WF,0.003748451,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,Unable to execute queries and a lot of GC pauses in HiveMetaStore logs, PRDSUP : kp08tntncapsparknsprdsup01 : Not able to execute spark query from DE WF,Found GC pauses and recommended to increase the HiveMetastore heapsize from 7GB to 10GB,,,,,,,,
1.2003E+14,07:24.6,Resource manangers are stopping due to: Connection failed to http://hn0-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 3, 2020, 12:00 AM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: changed the spark settings for executors and drivers, and added a yarn queue this morning\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Tried to restart the resourcemanager services a few times (more than 5 times) and each time the service started and then died after a few seconds.\n\nQuestion: Additional details about the issue\nAnswer: Errors seen: Connection failed to http://hn0-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 (urlopen error [Errno 111] Connection refused) and Connection failed to http://hn1-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 (urlopen error [Errno 111] Connection refused).  Don't know if it's connected, but also cannot access the log files as it returns a status code 503.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - changed the spark settings for executors and drivers, and added a yarn queue this morning;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Tried to restart the resourcemanager services a few times (more than 5 times) and each time the service started and then died after a few seconds.;\nAdditional details about the issue - Errors seen: Connection failed to http://hn0-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 (urlopen error [Errno 111] Connection refused) and Connection failed to http://hn1-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 (urlopen error [Errno 111] Connection refused).  Don't know if it's connected, but also cannot access the log files as it returns a status code 503.;\n\n- ProblemStartTime: 03/03/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Customer 360 DevTest 001\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7c469e39-c3bc-4752-a3f1-7447c5aecfa8/resourceGroups/perf-wus2-03-rg/providers/Microsoft.HDInsight/clusters/perfwus203hdi\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Resource manangers are stopping due to: Connection failed to http://hn0-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088 ,0.075895926,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,120030321002006 - Resource managers are stopping due to: Connection failed to http://hn0-perfwu.z5pipfv3tdyuxorx05ypbu513e.xx.internal.cloudapp.net:8088  HDInsight Service,New YARN queues were added which caused the Resource Managers to not start,Rolled back the YARN queue changes to the version which was working before.,,,,,,,,
1.2003E+14,08:59.9,Not able to call Oozie REST API,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Not able to make calls to the Oozie REST API, getting a 504 error message\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Not able to make calls to the Oozie REST API, getting a 504 error message;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/698a551a-d866-4efc-8411-2f6a9972341a/resourceGroups/USEPFSOPENRSG02/providers/Microsoft.HDInsight/clusters/usepfsopenhdi01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to call Oozie REST API,0.048357325,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Not able to call Oozie REST API,Networking issues. NSG not properly configured. ,We noticed that your client IP from where you were making the Oozie rest calls wasn’t whitelisted on the NSG connected to the Subnet where HDInsight cluster was deployed.Adding your IP and modifying the curl command did result in the Job getting submitted. At this point we noticed that the Oozie jobs are failing with File not found exceptions connecting to the AKS service sitting in a different Vnet. Which most likely means that the connectivity between both these services is being blocked.Customer altered the NSG rules to get past the issue. ,,,,,,,,
1.2003E+14,47:12.3,Application stuck in Accepted statue with plenty of free memory & cores,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer:  'spark.app.name': '{AlphanumericPII}',\n            'spark.yarn.am.attemptFailuresValidityInterval': '1h',\n            'spark.yarn.maxAppAttempts': '1',\n            'spark.executor.extraJavaOptions': '-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -{AlphanumericPII}',\n            'spark.driver.extraJavaOptions': '-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -{AlphanumericPII}',\n            'spark.streaming.stopGracefullyOnShutdown': 'true',\n            'spark.task.maxFailures': '2',\n            'spark.driver.cores': '2',\n            'spark.driver.memory': '8G',\n            'spark.executor.instances': '64',\n            'spark.executor.memory': '6g',\n            'spark.executor.cores': '1'\n\nQuestion: Additional details about the issue\nAnswer: The same issue as {alphanumericpii} \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details -  'spark.app.name': '{AlphanumericPII}',\n            'spark.yarn.am.attemptFailuresValidityInterval': '1h',\n            'spark.yarn.maxAppAttempts': '1',\n            'spark.executor.extraJavaOptions': '-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -{AlphanumericPII}',\n            'spark.driver.extraJavaOptions': '-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -{AlphanumericPII}',\n            'spark.streaming.stopGracefullyOnShutdown': 'true',\n            'spark.task.maxFailures': '2',\n            'spark.driver.cores': '2',\n            'spark.driver.memory': '8G',\n            'spark.executor.instances': '64',\n            'spark.executor.memory': '6g',\n            'spark.executor.cores': '1';\nAdditional details about the issue - The same issue as {alphanumericpii} ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe01-sp-eu01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Application stuck in Accepted statue with plenty of free memory & cores,0.111177292,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,Application stuck in Accepted statue with plenty of free memory & cores,Container was not getting assigned,Modified the below change and restarted the yarn:yarn.scheduler.capacity.schedule-asynchronously.enable  falseyarn.scheduler.capacity.per-node-heartbeat.maximum-container-assignments=100yarn.scheduler.capacity.resource-calculator to org.apache.hadoop.yarn.util.resource.DominantResourceCalculator,183563923,,,,,,,
1.2003E+14,13:12.4,Prodsup: Hive services - LLAP Application is down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: LLAP Application is down \n\nQuestion: Interactive query explain plan if available\nAnswer: LLAP Application is down \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: LLAP Application is down \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - LLAP Application is down ;\nInteractive query explain plan if available - LLAP Application is down ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - LLAP Application is down ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Prodsup: Hive services - LLAP Application is down,0.05192806,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,GC pauses in Hive logs,Prodsup: Hive services -  LLAP Application is down,Recommended to use the  garbage collection method from G1GC to ParallelGC or increase the heapsizes if  you have enough resources,178207875,,,,,,,
1.2003E+14,16:35.7,No module named 'azure.storage',"Question: What time did the problem begin?\nAnswer: {Namepii}, Feb 27, 2020, 12:00 AM EST\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Additional details about the issue\nAnswer: Although I installed azure.storage.blob on cluster still getting error\n\n  No module named 'azure.storage'\n\nwhile importing it in Jupyter notebook\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Never worked;\nAdditional details about the issue - Although I installed azure.storage.blob on cluster still getting error\n\n  No module named 'azure.storage'\n\nwhile importing it in Jupyter notebook\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/27/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",No module named 'azure.storage',1.977977917,Root Cause : HDInsight Service\By Design\HDInsight SDK,Routing Azure HDInsight V5\Client tool issue\Notebooks,No module named azure.storage,Since storage module already exists an import from jupyter doesn't work.,"write to the storage directly by using the below script and giving the following details in the script.1.Storage Provider2.Storage Key3.Actual PathPySpark as :spark._jsc.hadoopConfiguration().set(""fs.azure.account.keyprovider.kcwestus.blob.core.windows.net"",""org.apache.hadoop.fs.azure.SimpleKeyProvider"")spark._jsc.hadoopConfiguration().set(""fs.azure.account.key.kcwestus.blob.core.windows.net"",""storagekey--/b8NAH1gV8NY4Nk3xpTGY4IgCveFghoQ1RoYhZq86w=="")spark.read.csv(""wasb://kafkaomstest1@kcwestus.blob.core.windows.net/user/oozie/share/lib/sharelib.properties"").show()",,,,,,,,
1.2003E+14,17:54.7,QA: LLAP application (slider App)  is down.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: LLAP Application cannot be determined adn up and running.\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: LLAP Application cannot be determined adn up and running.\n\nQuestion: Interactive query explain plan if available\nAnswer: LLAP Application cannot be determined adn up and running.\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: LLAP Application cannot be determined adn up and running.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - LLAP Application cannot be determined adn up and running.;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - LLAP Application cannot be determined adn up and running.;\nInteractive query explain plan if available - LLAP Application cannot be determined adn up and running.;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - LLAP Application cannot be determined adn up and running.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpphv506llapfdqancap01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",QA: LLAP application (slider App)  is down.,0.055293341,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,QA: LLAP application (slider App)  is down.,QA: LLAP application (slider App)  is down.,Support had checked and engaged product group on this. Product group confirmed not to use LLAP service on spark cluster and to use LLAP cluster for LLAP functionality. Customer had created different clusters to achieve the requirement.,,,,,,,,
1.2003E+14,05:24.5,Cannot delete this service.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Also tried cloud shell with the suggeston but got an error:  \n\n AzureRmHDInsightCluster -ClusterName {AlphanumericPII}\nGet-AzHDInsightCluster: Could not find resource group for cluster {AlphanumericPII}.\nAzure:/\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Also tried cloud shell with the suggeston but got an error:  \n\n AzureRmHDInsightCluster -ClusterName {AlphanumericPII}\nGet-AzHDInsightCluster: Could not find resource group for cluster {AlphanumericPII}.\nAzure:/;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AzureCAT_MDX\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/18648d1e-9b0e-4fbc-b4a7-97566b1ae988/resourceGroups/hdinsightG5V4AIRWV6YOURJHGXH6N54IVMFIO555IUMOFM5KU3S7ANFRDMVA-South-Central-US/providers/Microsoft.HDInsight/clusters/AZCat-MDX-HDI-Linux2\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot delete this service.,0.132331896,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to delete the cluster,the cluster is really old and we didn't have a new process inplace for to deleting older cluster. ,PG manually deleted metastore information for older cluster. ,178348088,,,,,,,
1.2003E+14,02:21.2,Head nodes not reachable.,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 4, 2020, 5:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Was performing reboot using script action after performing upgrades.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Was performing reboot using script action after performing upgrades.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Was performing reboot using script action after performing upgrades.;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Was performing reboot using script action after performing upgrades.;\n\n- ProblemStartTime: 03/04/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head nodes not reachable.,0.025425362,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Hn1 not reachable via ssh. ,Rebooted via Script action and node did not come up in a healthy manner,Restarted VM from the backend. ,,,,,,,,
1.20031E+14,08:01.6,Cannot start resource manager,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 4, 2020, 5:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Trying to remove znodes however getting authentication not valid error. Also tried removing the {alphanumericpii} files but it didn't help\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Trying to remove znodes however getting authentication not valid error. Also tried removing the {alphanumericpii} files but it didn't help;\n\n- ProblemStartTime: 03/04/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot start resource manager,0.675907868,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Cannot start resource manager,Cannot start resource manager,"Steps followed to mitigate the issue were - Updated -""-Dzookeeper.skipACL=yes"" added to zookeeper configHiveserver2 was still down while other services were showing as running on the cluster.2. Found below error message while restarting HiveServer2 on the cluster..                Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: $HVF000-FKP5B0LQKEG9@CVSADDS.COM is not allowed to impersonate hive/hn0-rac1hd.cvsadds.com@CVSADDS.COM3. Initially, we did not see the above being a user account or a machine name (not pingable).4. After further analysis, while you were trying to add rule ""hadoop.security.auth_to_local"" to convert the above user to ""hive"", we found that the above name is SamAccountName for UPN: ""hive/hn0-rac1hd.cvsadds.com@cvsadds.com"".5. Product group was engaged on this and they advised that this is a known behavior with jdk upgrade on the cluster and patch was shared to run on the cluster nodes to fix the same.6. You had tested on HN0 and observed that the hivesever2 was no longer reporting SamAccountName on service startup logs.7. You had deployed the fix to all nodes thru Script action successfully and restarted all nodes on the cluster.8. You had removed ""-Dzookeeper.skipACL=yes"" from zookeeper config and deleted ""/hive"" znode on zookeeper, and restarted hive services on the cluster (and other services).9. All services had started successfully and you are able to run hive queries.",178459277,,,,,,,
1.20031E+14,03:21.9,Getting 502.3 - Bad Gateway errors,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 5, 2020, 4:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: No recent changes, and this started this morning. We have had similar issues with HDI having issues on the MS end recently.\n\nQuestion: Additional details about the issue\nAnswer: We have had a number of cases where we run into 50x errors with our HDI clusters, and Azure Support had to fix things on the back end. This has been a topic of our weekly calls. This look like another case.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - No recent changes, and this started this morning. We have had similar issues with HDI having issues on the MS end recently.;\nAdditional details about the issue - We have had a number of cases where we run into 50x errors with our HDI clusters, and Azure Support had to fix things on the back end. This has been a topic of our weekly calls. This look like another case.;\n\n- ProblemStartTime: 03/05/2020 09:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting 502.3 - Bad Gateway errors,0.225139641,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,leGetting 502.3 - Bad Gateway errors,Ambari service was down,rebooted HN0 and 1,178449794,,,,,,,
1.20031E+14,26:42.4,Reason for Hive Service Down,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 5, 2020, 1:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted the Hive Services around 9.31 AM CST today.\n\nQuestion: Additional details about the issue\nAnswer: Issues specifically started around 1.00 AM CST today.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted the Hive Services around 9.31 AM CST today.;\nAdditional details about the issue - Issues specifically started around 1.00 AM CST today.;\n\n- ProblemStartTime: 03/05/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Predictive Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/10051b30-e5c6-487e-9133-8b1425b877a2/resourceGroups/HDISpark01-Prod-Predictive/providers/Microsoft.HDInsight/clusters/ana02hdi36sparkpa01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Reason for Hive Service Down,3.964624668,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Hive services unavailable. ,Hive service was down. ,Issue is a transient error. ,,,,,,,,
1.20031E+14,26:28.1,Cannot convert notebook to v5 because that version doesn't exist,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 5, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Jupyter Notebook\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: Traceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 457, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 101, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 84, in get got = self.helper.get(path, content, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentshelper.py', line 61, in get return self.model_factory.create_model_from_blob(blob, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/model.py', line 45, in create_model_from_blob {alphanumericpii}]) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/__init__.py', line 75, in reads nb = convert(nb, as_version) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/converter.py', line 54, in convert 'version doesn't exist' % (to_version)) ValueError: Cannot convert notebook to v5 because that version doesn't exist\n\nQuestion: Additional details about the issue\nAnswer: Traceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 457, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 101, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 84, in get got = self.helper.get(path, content, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentshelper.py', line 61, in get return self.model_factory.create_model_from_blob(blob, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/model.py', line 45, in create_model_from_blob {alphanumericpii}]) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/__init__.py', line 75, in reads nb = convert(nb, as_version) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/converter.py', line 54, in convert 'version doesn't exist' % (to_version)) ValueError: Cannot convert notebook to v5 because that version doesn't exist\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Jupyter Notebook;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - Traceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 457, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 101, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 84, in get got = self.helper.get(path, content, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentshelper.py', line 61, in get return self.model_factory.create_model_from_blob(blob, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/model.py', line 45, in create_model_from_blob {alphanumericpii}]) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/__init__.py', line 75, in reads nb = convert(nb, as_version) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/converter.py', line 54, in convert 'version doesn't exist' % (to_version)) ValueError: Cannot convert notebook to v5 because that version doesn't exist;\nAdditional details about the issue - Traceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 457, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 101, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentsmanager.py', line 84, in get got = self.helper.get(path, content, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/azurecontentshelper.py', line 61, in get return self.model_factory.create_model_from_blob(blob, type, format) File '/var/lib/.jupyter/jupyterazure/jupyterazure/model.py', line 45, in create_model_from_blob {alphanumericpii}]) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/__init__.py', line 75, in reads nb = convert(nb, as_version) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/converter.py', line 54, in convert 'version doesn't exist' % (to_version)) ValueError: Cannot convert notebook to v5 because that version doesn't exist;\n\n- ProblemStartTime: 03/04/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Free Trial\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: RHC\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Service Health\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b6c786bb-a39c-477f-ad69-c599e0dbdc34/resourceGroups/mdp_training/providers/Microsoft.HDInsight/clusters/day4mdpcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot convert notebook to v5 because that version doesn't exist,0.074199948,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Unexpected result\Spark,Cannot open Jupyter notebook.,A version mismatch,"1.Use ssh command to connect to your cluster. Edit the command below by replacing CLUSTERNAME with the name of your cluster, and then enter the command:ssh sshuser@CLUSTERNAME-ssh.azurehdinsight.net 2.Open _version.py by executing the following command:sudo nano /usr/bin/anaconda/lib/python2.7/site-packages/nbformat/_version.py 3.Change 5 to 4 so the modified line appears as follows:PythonCopyversion_info = (4, 0, 3)Save changes by entering Ctrl + X, Y, Enter. 4.From a web browser, navigate to https://CLUSTERNAME.azurehdinsight.net/#/main/services/JUPYTER, where CLUSTERNAME is the name of your cluster. 5.Restart the Jupyter service.",,,,,,,,
1.20031E+14,21:35.7,PRDSUP: kpph10llapprdsupusc01: Hive query failing,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 5, 2020, 10:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Hive query failing\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Hive query failing \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Hive query failing;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Hive query failing ;\n\n- ProblemStartTime: 03/05/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph10llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kpph10llapprdsupusc01: Hive query failing,0.018625696,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Hive queries are failing,kpph10llapprdsupusc01: Hive query failing,Recommended to use the  garbage collection method from G1GC to ParallelGC ,178492537,,,,,,,
1.20031E+14,30:23.6,kpq044sparkespfdqawus201:Token  refresh issue on the HDI Spark secure cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: 2020-03-05 {Alphanumericpii} INFO com.microsoft.azure.datalake.store.security.AdlHttpServer: END : Starting AdlHttpServer..\n2020-03-05 {Alphanumericpii} ERROR com.microsoft.azure.datalake.store.security.ZookeeperRefreshTokenStore: /refreshtokens znode already exists !!\norg.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /secretmanager/ZKDTSMRoot/refreshtokens\n\n\nQuestion: Additional details about the issue\nAnswer: 2020-03-05 {Alphanumericpii} INFO com.microsoft.azure.datalake.store.security.AdlHttpServer: END : Starting AdlHttpServer..\n2020-03-05 {Alphanumericpii} ERROR com.microsoft.azure.datalake.store.security.ZookeeperRefreshTokenStore: /refreshtokens znode already exists !!\norg.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /secretmanager/ZKDTSMRoot/refreshtokens\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - 2020-03-05 {Alphanumericpii} INFO com.microsoft.azure.datalake.store.security.AdlHttpServer: END : Starting AdlHttpServer..\n2020-03-05 {Alphanumericpii} ERROR com.microsoft.azure.datalake.store.security.ZookeeperRefreshTokenStore: /refreshtokens znode already exists !!\norg.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /secretmanager/ZKDTSMRoot/refreshtokens\n;\nAdditional details about the issue - 2020-03-05 {Alphanumericpii} INFO com.microsoft.azure.datalake.store.security.AdlHttpServer: END : Starting AdlHttpServer..\n2020-03-05 {Alphanumericpii} ERROR com.microsoft.azure.datalake.store.security.ZookeeperRefreshTokenStore: /refreshtokens znode already exists !!\norg.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /secretmanager/ZKDTSMRoot/refreshtokens\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq044sparkespfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kpq044sparkespfdqawus201:Token  refresh issue on the HDI Spark secure cluster,0.038117543,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Token refresh issue on the HDI Spark secure cluster,kpq044sparkespfdqawus201:Token refresh issue on the HDI Spark secure cluster,"Customer did not share any specific issue on this case, but had worked on the same through other cases. Customer advised to close the case as no other work to be done on this.",,,,,,,,
1.20031E+14,25:36.8,HDInsight With Premium Blov Storage,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Not able to use Premium storage account with HDinsight. What is the work around. We are facing bottleneck on standard storage account.\n\n\nDeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Could not validate storage account gmcloudregqacatcsqaprem.blob.core.windows.net. Make sure that the account details are correct. HdInsight supports only general-purpose storage accounts with standard tier. Ensure that the account is not a premium or blob only storage account. Information about various storage accounts can be found at http://go.microsoft.com/fwlink/?LinkId=808302. If the storage account has firewall enabled, the subscription that hosts the account must have Microsoft.HDInsight registered as a resource provider. Information on how to do the registration can be found at: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-register-provider-errors'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Not able to use Premium storage account with HDinsight. What is the work around. We are facing bottleneck on standard storage account.\n\n\nDeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Could not validate storage account gmcloudregqacatcsqaprem.blob.core.windows.net. Make sure that the account details are correct. HdInsight supports only general-purpose storage accounts with standard tier. Ensure that the account is not a premium or blob only storage account. Information about various storage accounts can be found at http://go.microsoft.com/fwlink/?LinkId=808302. If the storage account has firewall enabled, the subscription that hosts the account must have Microsoft.HDInsight registered as a resource provider. Information on how to do the registration can be found at: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-register-provider-errors';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_DEV\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight With Premium Blov Storage,0.375303277,Root Cause : HDInsight Service\Advisory (not for how-to) ,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Looks like, Premium storage account is unsupported for the HDI cluster,https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-compare-storage-optionsAnd I also see the premium storage account is in preview as per the above link and need to check on it...",HDInsight With Premium Blob Storage,Premium storage account is unsupported for the HDI cluster and provided the documentation,,,,,,,,
1.20031E+14,53:54.6,Technical doubt,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 6, 2020, 12:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes, it's a technical doubt\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hello Microsoft Team.\nWe had a meeting with our microsoft partner, Datavision, and we discussed about the posibility of scaling down vertically the cluster. They told us it was indeed possible, to scale down not the number of worker nodes, but the number of cores utilized by the Head Nodes (from 16 to 8) and the Worker Nodes (from 8 to 4).\nCould you help us with the respective documentation of how could we accomplish this, if we can do it via Azure Portal, or that option is just available via CLI, Power {Namepii}, and if necessary the accompaniment in this process.\nWe consider the case in which we have to recreate the cluster if the resizing is nos possible but we have important productive information there, \nso if that is the case, can tell us how to recreate the cluster with the characteristics mentioned above without losing the developments we have on it.\nThank you.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes, it's a technical doubt;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hello Microsoft Team.\nWe had a meeting with our microsoft partner, Datavision, and we discussed about the posibility of scaling down vertically the cluster. They told us it was indeed possible, to scale down not the number of worker nodes, but the number of cores utilized by the Head Nodes (from 16 to 8) and the Worker Nodes (from 8 to 4).\nCould you help us with the respective documentation of how could we accomplish this, if we can do it via Azure Portal, or that option is just available via CLI, Power {Namepii}, and if necessary the accompaniment in this process.\nWe consider the case in which we have to recreate the cluster if the resizing is nos possible but we have important productive information there, \nso if that is the case, can tell us how to recreate the cluster with the characteristics mentioned above without losing the developments we have on it.\nThank you.;\n\n- ProblemStartTime: 03/06/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZRINFRAESTRUCTURA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3f8d5f46-3a0e-4bc6-9e32-3e4774c514aa/resourceGroups/AZRDATALAKE/providers/Microsoft.HDInsight/clusters/prointquerylivc4\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Technical doubt,0.234865597,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,advisory,advisory,sent information,,,,,,,,
1.20031E+14,39:53.3,Sqoop directory version change,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No. What we noticed is that the /etc/sqoop/2.6.5.3016-3/ was changed to  2.6.5.3015-8 in the backend. yesterday, my server version remains the same in the template. \n\nTo my understanding if my template says HDI server version is 3.6 all the libraries will be same. I mean it does not change, that is how I can rely on my testing etc for my jobs. Need to understand why these un-precedented changes are made and how oftern I can expect that.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: Nothing additional\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No. What we noticed is that the /etc/sqoop/2.6.5.3016-3/ was changed to  2.6.5.3015-8 in the backend. yesterday, my server version remains the same in the template. \n\nTo my understanding if my template says HDI server version is 3.6 all the libraries will be same. I mean it does not change, that is how I can rely on my testing etc for my jobs. Need to understand why these un-precedented changes are made and how oftern I can expect that.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - Nothing additional;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EA-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sqoop directory version change,0.223098491,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Customer deploying new cluster each day and by design, new HDI clusters will pull the latest HDI image for that version. So while the major version is 3.6 for this customer, the minor version may change with each new deployment as new bug fixes and other improvements are pulled into the new image.",Customer had a runbook which created a new cluster each day and ran some sqoop jobs. The jobs they were running targeted a specific path for Sqoop. They observed this path had changed to a newer version number thus breaking their job. This is due to HDInsight pulling minor changes to HDP which will update the version in all paths for all components regardless of if those components were changed. ,Customer will use a wildcard in their path to account for changes to the version,"178,632,875,178,632,000,000,000,000",,,,,,,
1.20031E+14,24:01.2,unable to connect to mysql external metastore,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: any, \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: Any customization applied\nAnswer: attempting to use az cli command to create cluster with existingHiveMetastore* parameters\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: az cli is running cleanly inside a docker container to bring up an hdi cluster using the az command below. it is provisioned sucessfully, but then fails due to the database being mysql not mssql, and there does not appear to be a parameter for dbtype when i look for details on these parameters (https://azure.microsoft.com/en-ca/resources/templates/101-hdinsight-linux-ssh-publickey-metastore-vnet/)\n\n error output is below the script/command. I have a script action prepared to run immediately afterwards to add the mysql-connector jar, but it fails due to the cluster creation failure. please advise!\n\n az group deployment create \\\n        --resource-group $RESOURCE_GROUP \\\n        --template-file /app/scripts/hdinsight_arm.json \\\n        --name $CLUSTER_NAME \\\n        --parameters \\\n        clusterName=$CLUSTER_NAME \\\n        clusterLoginUserName=$CLUSTER_USERNAME \\\n        clusterLoginPassword=$CLUSTER_PASSWORD \\\n        sshUserName=$CLUSTER_USERNAME \\\n        sshPassword=$SSH_PASSWORD \\\n        existingHiveMetastoreServerResourceGroupName=$METASTORE_RESOURCE_GROUP \\\n        existingHiveMetastoreServerName=$METASTORE_SERVERNAME \\\n        existingHiveMetastoreDatabaseName=$METASTORE_DBNAME \\\n        existingHiveMetastoreUsername=$METASTORE_USERNAME \\\n        existingHiveMetastorePassword=$METASTORE_PASSWORD \\\n        existingVirtualNetworkResourceGroup=$VNET_RESOURCE_GROUP \\\n        existingVirtualNetworkName=$VNET \\\n        existingVirtualNetworkSubnetName=$SUBNET \\\n        coreSite=$CORE_SITE \\\n        storageAccountName=$STORAGE_ACCOUNT_NAME \\\n        resourceTags=$RESOURCE_TAGS\n\n\n--- \nERROR: Deployment failed. Correlation ID: {Guidpii}. {\n  'error': {\n    'code': 'ResourceNotFound',\n    'message': 'The Resource 'Microsoft.Sql/servers/rbeu-weu-dev-metadb.mysql.database.azure.com' under resource group 'rbeu-weu-dev' was not found.'\n  }\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - any, ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nAny customization applied - attempting to use az cli command to create cluster with existingHiveMetastore* parameters;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - az cli is running cleanly inside a docker container to bring up an hdi cluster using the az command below. it is provisioned sucessfully, but then fails due to the database being mysql not mssql, and there does not appear to be a parameter for dbtype when i look for details on these parameters (https://azure.microsoft.com/en-ca/resources/templates/101-hdinsight-linux-ssh-publickey-metastore-vnet/)\n\n error output is below the script/command. I have a script action prepared to run immediately afterwards to add the mysql-connector jar, but it fails due to the cluster creation failure. please advise!\n\n az group deployment create \\\n        --resource-group $RESOURCE_GROUP \\\n        --template-file /app/scripts/hdinsight_arm.json \\\n        --name $CLUSTER_NAME \\\n        --parameters \\\n        clusterName=$CLUSTER_NAME \\\n        clusterLoginUserName=$CLUSTER_USERNAME \\\n        clusterLoginPassword=$CLUSTER_PASSWORD \\\n        sshUserName=$CLUSTER_USERNAME \\\n        sshPassword=$SSH_PASSWORD \\\n        existingHiveMetastoreServerResourceGroupName=$METASTORE_RESOURCE_GROUP \\\n        existingHiveMetastoreServerName=$METASTORE_SERVERNAME \\\n        existingHiveMetastoreDatabaseName=$METASTORE_DBNAME \\\n        existingHiveMetastoreUsername=$METASTORE_USERNAME \\\n        existingHiveMetastorePassword=$METASTORE_PASSWORD \\\n        existingVirtualNetworkResourceGroup=$VNET_RESOURCE_GROUP \\\n        existingVirtualNetworkName=$VNET \\\n        existingVirtualNetworkSubnetName=$SUBNET \\\n        coreSite=$CORE_SITE \\\n        storageAccountName=$STORAGE_ACCOUNT_NAME \\\n        resourceTags=$RESOURCE_TAGS\n\n\n--- \nERROR: Deployment failed. Correlation ID: {Guidpii}. {\n  'error': {\n    'code': 'ResourceNotFound',\n    'message': 'The Resource 'Microsoft.Sql/servers/rbeu-weu-dev-metadb.mysql.database.azure.com' under resource group 'rbeu-weu-dev' was not found.'\n  }\n};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: rbeu-dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0281ec6a-fb0f-4645-8ca5-e5f1e249b86f/resourceGroups/rbdevl-rbeu-weu-dev-rg/providers/Microsoft.HDInsight/clusters/rbdevl-rbeu-weu-dev\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to connect to mysql external metastore,0.029383904,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,Deployment fails. ,Customer is unable to deploy cluster using Hive External meta-store hosted on MySQL.  ,MySQL is not compatible/supported to host Hive Metastore for HDInsight clusters. ,,,,,,,,
1.20031E+14,46:43.9,yarnui rest ap returns http error on active lead,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: To avoid this issue we must have the cached leader Resource Manager = active Resource Manager.\n\nIf cached leader Resource Manager is not the  active Resource Manager, we stop the active Resource Manager to change the standby Resource Manager to active, and after we start after the other Resourcer Manager to be in standby.\n\n\nQuestion: Additional details about the issue\nAnswer: when we call this url :\n{alphanumericpii}:~$ curl -vi -k -u ___U____ -X GET -H 'Accept: application/json' https://phoenix-spark.hdi.phoenix.dev.euw.gbis.sg-azure.com/yarnui/hn/ws/v1/cluster/apps\n\nwe have always this error information in response :\n\n'x-ms-hdi-errorcode: fc:Failed to get active leader, returning cached leader rm:Failed to get active leader, returning cached leader'\n'x-ms-hdi-errorcode: fc:Failed to get active leader, returning cached leader rm:Failed to get active leader, returning cached leader'\n\nWhen cached leader Resource Manager = active Resource Manager, this is not a blocking issue , we have the expected result (see file logs_active_leader.txt)\n\nBut when cached leader Resource Manager is not the active Resource Manager, we have this error message in the result : 'This is standby RM. The redirect url is: /{alphanumericpii}'.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - To avoid this issue we must have the cached leader Resource Manager = active Resource Manager.\n\nIf cached leader Resource Manager is not the  active Resource Manager, we stop the active Resource Manager to change the standby Resource Manager to active, and after we start after the other Resourcer Manager to be in standby.\n;\nAdditional details about the issue - when we call this url :\n{alphanumericpii}:~$ curl -vi -k -u ___U____ -X GET -H 'Accept: application/json' https://phoenix-spark.hdi.phoenix.dev.euw.gbis.sg-azure.com/yarnui/hn/ws/v1/cluster/apps\n\nwe have always this error information in response :\n\n'x-ms-hdi-errorcode: fc:Failed to get active leader, returning cached leader rm:Failed to get active leader, returning cached leader'\n'x-ms-hdi-errorcode: fc:Failed to get active leader, returning cached leader rm:Failed to get active leader, returning cached leader'\n\nWhen cached leader Resource Manager = active Resource Manager, this is not a blocking issue , we have the expected result (see file logs_active_leader.txt)\n\nBut when cached leader Resource Manager is not the active Resource Manager, we have this error message in the result : 'This is standby RM. The redirect url is: /{alphanumericpii}'.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/01/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/161c647d-ecd7-4e49-a04a-9a328d5eab05/resourceGroups/phoenix-DEV-phoenix-spark-Automation-HDI/providers/Microsoft.HDInsight/clusters/KrWh7GuNHQ-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",yarnui rest ap returns http error on active lead,0.225765259,Root Cause : HDInsight Service\Secure Gateway issues,Routing Azure HDInsight V5\Service unhealthy\Spark,YARN HA flipover gateway issues,yarnui rest ap returns http error on active lead,Provided the guidance and documentation on this,,,,,,,,
1.20031E+14,54:37.4,HDI ambari is trying to start for every minute ,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 7, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Issue : \n{ALPHANUMERICPII} ambari is trying to start for every minute even existing service is running.\n{ALPHANUMERICPII} Ambari views are not responding when we have heavy load. It happened {Alphanumericpii} and 3/5th night in CST hours.\n\n{Namepii} - https://hdi001dldev.azurehdinsight.net/\nThe PID ‘122826’ is existing ambary and the PID ‘55233’ is trying to start one more ambary service.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Issue : \n{ALPHANUMERICPII} ambari is trying to start for every minute even existing service is running.\n{ALPHANUMERICPII} Ambari views are not responding when we have heavy load. It happened {Alphanumericpii} and 3/5th night in CST hours.\n\n{Namepii} - https://hdi001dldev.azurehdinsight.net/\nThe PID ‘122826’ is existing ambary and the PID ‘55233’ is trying to start one more ambary service.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/06/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi001dldev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI ambari is trying to start for every minute ,12.20659296,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Perf issues with Ambari DB,ambari DB already at S2,ambari DB already at S2,,,,,,,,
1.20031E+14,45:02.9,I can't use my academic/lab subscription for (Georgia Tech course CSE6242),"Question: Problem Start Date\nAnswer: Fri, {Namepii} 6, 2020, 12:00 AM EST\n\nQuestion: Select the Subscription ID\nAnswer: Other, don't know or not applicable\n\nQuestion: Subscription ID\nAnswer: HW3 Marchienne {Namepii} ({guidpii})\n\nQuestion: Email ID signing in/accessing the subscription\nAnswer: {emailpii}@gatech.edu\n\nQuestion: Last login date/time\nAnswer: Fri, {Namepii} 6, 2020, 12:00 AM EST\n\nQuestion: Browser Information\nAnswer: Google Chrome\n\nQuestion: Error message/Screenshot of the error \nAnswer: I can see my lab subscription HW3 Marchienne {Namepii} ({guidpii}) but it seems I can't use it when creating a HDInsight Azure cluster. I can't see it in the list except the 'Microsoft Azure Sponsorship 2' (see screenshot)\n\nQuestion: Browser network trace or any other details (if applicable)\nAnswer: Don't have it\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Subscription Management:\nProblem Start Date - {ALPHANUMERICPII};\nSelect the Subscription ID - Other, don't know or not applicable;\nSubscription ID - HW3 Marchienne {Namepii} ({guidpii});\nEmail ID signing in/accessing the subscription - {emailpii}@gatech.edu;\nLast login date/time - {ALPHANUMERICPII};\nBrowser Information - Google Chrome;\nError message/Screenshot of the error  - I can see my lab subscription HW3 Marchienne {Namepii} ({guidpii}) but it seems I can't use it when creating a HDInsight Azure cluster. I can't see it in the list except the 'Microsoft Azure Sponsorship 2' (see screenshot);\nBrowser network trace or any other details (if applicable) - Don't have it;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/06/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Sponsorship 2\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_SUBSCRIPTION_MANAGEMENT\n- SupportPlanDisplayName: Basic support\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I can't use my academic/lab subscription for (Georgia Tech course CSE6242),0.02326538,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure Subscription V5\Unable to access my subscription\Issues signing in or accessing my subscriptions,I can't use my academic/lab subscription for (Georgia Tech course CSE6242),Quota Core limitation ,CX changed the region to US East - 250 Cores ,,,,,,,,
1.20031E+14,24:08.3,PRDSUP: kpph18llapprdsup : Noticing other connection see the gateway logs on the cluster to debug an issue from local to HDInsight. ,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 6, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: We are noticing other connection related issues and would like to work with Microsoft to see the gateway logs on the {alphanumericpii} cluster to debug an issue from local to HDInsight. Please place a ticket to Microsoft requesting Purna as he is knowledgeable about our connection-related issues on HDInsight.\n \nError Message: \n \n11:10 AM PST 3/5/2020.\nError: nanodbc/nanodbc.cpp:983: 00000: [Hortonworks][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct.\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: We are noticing other connection related issues and would like to work with Microsoft to see the gateway logs on the {alphanumericpii} cluster to debug an issue from local to HDInsight. Please place a ticket to Microsoft requesting Purna as he is knowledgeable about our connection-related issues on HDInsight.\n \nError Message: \n \n11:10 AM PST 3/5/2020.\nError: nanodbc/nanodbc.cpp:983: 00000: [Hortonworks][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - We are noticing other connection related issues and would like to work with Microsoft to see the gateway logs on the {alphanumericpii} cluster to debug an issue from local to HDInsight. Please place a ticket to Microsoft requesting Purna as he is knowledgeable about our connection-related issues on HDInsight.\n \nError Message: \n \n11:10 AM PST 3/5/2020.\nError: nanodbc/nanodbc.cpp:983: 00000: [Hortonworks][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct.;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - ODBC;\nAdditional details about the issue - We are noticing other connection related issues and would like to work with Microsoft to see the gateway logs on the {alphanumericpii} cluster to debug an issue from local to HDInsight. Please place a ticket to Microsoft requesting Purna as he is knowledgeable about our connection-related issues on HDInsight.\n \nError Message: \n \n11:10 AM PST 3/5/2020.\nError: nanodbc/nanodbc.cpp:983: 00000: [Hortonworks][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct.;\n\n- ProblemStartTime: 03/06/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kpph18llapprdsup : Noticing other connection see the gateway logs on the cluster to debug an issue from local to HDInsight. ,0.064672879,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Unexpected result\Interactive Query,Experience the No Domain controller exceptions in GW logs,PRDSUP: kpph18llapprdsup : Noticing other connection see the gateway logs on the cluster to debug an issue from local to HDInsight.,Recommended application logic on your end is updated to retry with “increment” of 5 sec rather exponentially and it would help alleviate the occurrences ,176536995,,,,,,,
1.20031E+14,16:17.9,FD QA : kpq049llapfdqawus201 : Commands failing on LLAP HDI 4.0 Zeppelin UI with error 'Unable to read HiveServer2 configs from ZooKeeper',"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 5, 2020, 6:00 PM PST\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Users are unable to run queries using {Namepii} UI. \nExample query :\n%jdbc(hive) show databases\n\nThis has worked before yesterday 6:00 PM \n\nBelow is the exception. \n\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\nat org.apache.hive.jdbc.HiveConnection. init ({AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.zeppelin.scheduler.{Namepii}.run({Namepii}.java:188)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hive.jdbc.HiveConnection. init ({AlphanumericPII})\n... 26 more\nCaused by: java.io.IOException: org.apache.zookeeper.KeeperException$InvalidACLException: KeeperErrorCode = InvalidACL for /{alphanumericpii}\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 30 more\nCaused by: org.apache.zookeeper.KeeperException$InvalidACLException: KeeperErrorCode = InvalidACL for /{alphanumericpii}\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 34 more\n\n\n\nTried to follow previous instructions provided. \n\n{Alphanumericpii} \n1. On the cluster, navigate to the Hive component summary and copy the 'Hive JDBC Url' to the clipboard.\nNavigate to https://clustername.azurehdinsight.net/zeppelin/#/interpreter  ​\nEdit the JDBC settings: update the hive.url value to the Hive JDBC URL copied in step 1... and save and restart the interpreter.\n\n2. In Ambari {Namepii} configs, under shiro_ini_content (applicable for secure clusters):\n      Replace '/api/interpreter/** = authc, roles[admin]' with '/api/interpreter/** = authc'\n \n3. Restarted zeppelin services \n\n{Alphanumericpii} \n1. Updated  /usr/bin/anaconda/lib/python2.7/site-packages/nbformat/_version.py  file from version 5.0.3 to {Alphanumericpii} \n\n2. Restarted ambari-server \n\nBoth approaches did not fix issue \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nAdditional details about the issue - Users are unable to run queries using {Namepii} UI. \nExample query :\n%jdbc(hive) show databases\n\nThis has worked before yesterday 6:00 PM \n\nBelow is the exception. \n\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\nat org.apache.hive.jdbc.HiveConnection. init ({AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.zeppelin.scheduler.{Namepii}.run({Namepii}.java:188)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hive.jdbc.HiveConnection. init ({AlphanumericPII})\n... 26 more\nCaused by: java.io.IOException: org.apache.zookeeper.KeeperException$InvalidACLException: KeeperErrorCode = InvalidACL for /{alphanumericpii}\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 30 more\nCaused by: org.apache.zookeeper.KeeperException$InvalidACLException: KeeperErrorCode = InvalidACL for /{alphanumericpii}\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 34 more\n\n\n\nTried to follow previous instructions provided. \n\n{Alphanumericpii} \n1. On the cluster, navigate to the Hive component summary and copy the 'Hive JDBC Url' to the clipboard.\nNavigate to https://clustername.azurehdinsight.net/zeppelin/#/interpreter  ​\nEdit the JDBC settings: update the hive.url value to the Hive JDBC URL copied in step 1... and save and restart the interpreter.\n\n2. In Ambari {Namepii} configs, under shiro_ini_content (applicable for secure clusters):\n      Replace '/api/interpreter/** = authc, roles[admin]' with '/api/interpreter/** = authc'\n \n3. Restarted zeppelin services \n\n{Alphanumericpii} \n1. Updated  /usr/bin/anaconda/lib/python2.7/site-packages/nbformat/_version.py  file from version 5.0.3 to {Alphanumericpii} \n\n2. Restarted ambari-server \n\nBoth approaches did not fix issue ;\n\n- ProblemStartTime: 03/06/2020 02:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq049llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD QA : kpq049llapfdqawus201 : Commands failing on LLAP HDI 4.0 Zeppelin UI with error 'Unable to read HiveServer2 configs from ZooKeeper',0.573531768,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Notebooks, Commands failing on LLAP HDI 4.0 Zeppelin UI with error 'Unable to read HiveServer2 configs from ZooKeeper', Commands failing on LLAP HDI 4.0 Zeppelin UI with error 'Unable to read HiveServer2 configs from ZooKeeper',"You had followed below steps but did not restart interpreter... You had restarted interpreter and that fixed the issue.                            1. On the cluster, navigate to the Hive component summary and copy the 'Hive JDBC Url' to the clipboard.                                         Navigate to https://clustername.azurehdinsight.net/zeppelin/#/interpreter  ​​                                        Edit the JDBC settings: update the hive.url value to the Hive JDBC URL copied in step 1... and save and restart the interpreter.​​                           2. In Ambari Zeppelin configs, under shiro_ini_content (applicable for secure clusters):​                                     Replace '/api/interpreter/** = authc, roles[admin]' with '/api/interpreter/** = authc'​ ​                         3. Restarted zeppelin services",,,,,,,,
1.20031E+14,05:03.6,Hive server 2 is not running,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Good Morning, our hive server 2 is not running.\nI try to start it manually but i dont have successful after about 1 hour.\nI also try to reboot the hn0 ( sudo reboot )  and services take to long to start.\nCan you help us?\nregards,\n{Namepii}\n\nQuestion: Additional details about the issue\nAnswer: Good Morning, our hive server 2 is not running.\nI try to start it manually but i dont have successful after about 1 hour.\nI also try to reboot the hn0 ( sudo reboot )  and services take to long to start.\nCan you help us?\nregards,\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Good Morning, our hive server 2 is not running.\nI try to start it manually but i dont have successful after about 1 hour.\nI also try to reboot the hn0 ( sudo reboot )  and services take to long to start.\nCan you help us?\nregards,\n{Namepii};\nAdditional details about the issue - Good Morning, our hive server 2 is not running.\nI try to start it manually but i dont have successful after about 1 hour.\nI also try to reboot the hn0 ( sudo reboot )  and services take to long to start.\nCan you help us?\nregards,\n{Namepii};\n\n- ProblemStartTime: 03/09/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Avanade - SIM Frontend\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7f6c65a5-ebfd-48d2-80bf-f6f2cdbaa32b/resourceGroups/az-rg-analytics-use-prd/providers/Microsoft.HDInsight/clusters/azhdisimuseprd\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive server 2 is not running,0.079032271,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Hiveserver2 Interactive did not finish intialiaztion,Zookeeper failover controller was down on hn0,Performed rolling restart of ZKFC from cluster's Ambari website,,,,,,,,
1.20031E+14,42:56.2,Need to disable public access to cluster,"We need to block public access to this cluster. Currently cluster can be access using ssh key through public url.\n\nProblem start date and time\nWed, {Namepii} 4, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/03/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to disable public access to cluster,0.022509608,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Customer requested details on locking down public access to the cluster,Customer needed to lock down public access to the cluster,"Provided customer with documentation on NSG's, general HDInsight architecture with VNET's and our documentation on configuring NSG's correctly to allow for our management endpoints.",,,,,,,,
1.20031E+14,20:41.0,spark process consume lots of cpu,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: hello {Namepii}, i´m seeing that spark process is consuming lots of CPU from HN0. When I kill this process, HN0 comes back with normal CPU consumption for a while and after some time the process start to consume lots of CPU again.\n\nQuestion: Additional details about the issue\nAnswer: hello {Namepii}, i´m seeing that spark process is consuming lots of CPU from HN0. When I kill this process, HN0 comes back with normal CPU consumption for a while and after some time the process start to consume lots of CPU again.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - hello {Namepii}, i´m seeing that spark process is consuming lots of CPU from HN0. When I kill this process, HN0 comes back with normal CPU consumption for a while and after some time the process start to consume lots of CPU again.;\nAdditional details about the issue - hello {Namepii}, i´m seeing that spark process is consuming lots of CPU from HN0. When I kill this process, HN0 comes back with normal CPU consumption for a while and after some time the process start to consume lots of CPU again.;\n\n- ProblemStartTime: 03/02/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Avanade - SIM Frontend\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7f6c65a5-ebfd-48d2-80bf-f6f2cdbaa32b/resourceGroups/az-rg-analytics-use-prd/providers/Microsoft.HDInsight/clusters/azhdisimuseprd\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",spark process consume lots of cpu,0.03964095,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Observation in logs from another engineer,"It is not confirmed, but the customer had many spark streaming applications running in parallel. After discussing internally, this may have caused the history server usage to spike thus using more CPU. This is not confirmed to be the root cause, customer asked to close before we were able to confirm.","We attempted to increase the history server heap size, however, the issue was still observed after this. It is unclear if we made the correct change. The next step was to have cx test decreasing the number of parallel Spark streaming jobs to see if the issue either no longer occurs or occurred less than before. Customer asked to archive before this was confirmed",,,,,,,,
1.20031E+14,53:46.2,QA-Ambari metrics collector failes to connect,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted the services\n\nQuestion: Additional details about the issue\nAnswer: We are getting multiple alerts for last one day like the beow mail,\n\nAMBARI_METRICS\nCRITICAL {Namepii} Collector - HBase Master Process \nConnection failed: [Errno 111] Connection refused to hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net:61310 \n{Namepii}: shmktq \nHost: hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net \nUNKNOWN {Namepii} Collector - HBase Master CPU Utilization \n[Alert][ams_metrics_collector_hbase_master_cpu] Unable to extract JSON from JMX response \n{Namepii}: shmktq \nHost: hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net \n\n\nThanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted the services;\nAdditional details about the issue - We are getting multiple alerts for last one day like the beow mail,\n\nAMBARI_METRICS\nCRITICAL {Namepii} Collector - HBase Master Process \nConnection failed: [Errno 111] Connection refused to hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net:61310 \n{Namepii}: shmktq \nHost: hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net \nUNKNOWN {Namepii} Collector - HBase Master CPU Utilization \n[Alert][ams_metrics_collector_hbase_master_cpu] Unable to extract JSON from JMX response \n{Namepii}: shmktq \nHost: hn0-shmktq.vg4y0og0z2benbvnp1ztvmdhkd.cx.internal.cloudapp.net \n\n\nThanks;\n\n- ProblemStartTime: 03/09/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",QA-Ambari metrics collector failes to connect,0.670853756,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,120030922002819 - QA-Ambari metrics collector fails to connect,Ambari Metrics Collector malfunction,Clean up the AMS metrics and restart the service,,,,,,,,
1.20031E+14,16:23.3,PROD:  kp01sparkadfhdiprodusc01: hive is down,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 9:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Ambari hive not able to access\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Ambari hive not able to access\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Ambari hive not able to access;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Ambari hive not able to access;\n\n- ProblemStartTime: 03/09/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kp01sparkadfhdiprodusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PROD:  kp01sparkadfhdiprodusc01: hive is down,0.024868767,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Hive,HMS and ATS heap size issues,PROD: kp01sparkadfhdiprodusc01: hive is down,Restarted the services fixed the issue. We recommend you to increase the HMS heap size and also advise you to peridoically cleanup ZK snapshots (until they create a new cluster that will have this bugfix enabled).,,,,,,,,
1.20031E+14,18:09.8,Enable storage account used by HDInsight cluster to use secure transfer ,"The storage accounts associated with our HDInsight clusters are configured currently to not use secure data transfer. We would like to change it to use secure data transfer. The documentation does not recommend this after cluster creation. \n\n'Enabling secure storage transfer after creating a cluster can result in errors using your storage account and is not recommended. It is better to create a new cluster using a storage account with secure transfer already enabled.'\n\nIs there a way to enable secure data transfer without redeploying the HDInsight cluster?\nIf yes, what changes have to be done?\n \n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c7e4f49b-8174-4f40-bd74-310d60dc6cb7/resourceGroups/rg-useast2dev-test-datalake-hdis/providers/Microsoft.HDInsight/clusters/hdis-datalake-dev-test\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Enable storage account used by HDInsight cluster to use secure transfer ,0.066183034,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Enable secure transfer with storage account on existing HDInsight cluster,NA,Enabling secure storage transfer after creating a cluster can result in errors using your storage account and is not recommended and not supported as of now. It is better to create a new cluster using a storage account with secure transfer already enabled.As all your data is in storage account you shouldn't have any issues with data and redeploying the cluster.,,,,,,,,
1.20031E+14,46:51.0,Jupyter notebooks do not work,"'Spark': '2.3'\nhdinsight_cluster_version = '3.6'\n\nEvery time I try to open a {alphanumericpii} notebook (the only ones we ever use) we get an error:\n\n\nTraceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 457, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 84, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 56, in get 'metadata': {}}) File '/var/lib/.jupyter/jupyterazure/jupyterazure/model.py', line 45, in create_model_from_blob {alphanumericpii}]) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/__init__.py', line 75, in reads nb = convert(nb, as_version) File '/usr/bin/anaconda/lib/python2.7/site-packages/nbformat/converter.py', line 54, in convert 'version doesn't exist' % (to_version)) ValueError: Cannot convert notebook to v5 because that version doesn't exist\n\nProblem start date and time\nSun, {Namepii} 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 01/25/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Sponsorship\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jupyter notebooks do not work,0.124443928,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Client tool issue\Notebooks, Jupyter notebook do not work.,Known issue,"This was a known issue, We have deployed a hot fix to resolve the issue. All the new cluster will not have this issue.",,,,,,,,
1.20031E+14,32:33.8,Sqoop job failure,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Sqoop\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n               we are not able to run the some of out sqoop jobs which are inter linked to SAP HANA driver . however if i ran those same scrips from out on-prem cluster, i can able to excute without any errors . can someone guide me to check on firewall/security issue ? ,\n\nError: Error: java.lang.RuntimeException: java.lang.RuntimeException: com.sap.db.jdbc.exceptions.JDBCDriverException: SAP DBTech JDBC: Cannot connect to {alphanumericpii} [Cannot connect to host {alphanumericpii} [Connection timed out (Connection timed out)], -813.].\n\nThanks,\n{Namepii}\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Sqoop;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nAdditional details about the issue - Hi {Namepii},\n               we are not able to run the some of out sqoop jobs which are inter linked to SAP HANA driver . however if i ran those same scrips from out on-prem cluster, i can able to excute without any errors . can someone guide me to check on firewall/security issue ? ,\n\nError: Error: java.lang.RuntimeException: java.lang.RuntimeException: com.sap.db.jdbc.exceptions.JDBCDriverException: SAP DBTech JDBC: Cannot connect to {alphanumericpii} [Cannot connect to host {alphanumericpii} [Connection timed out (Connection timed out)], -813.].\n\nThanks,\n{Namepii}\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaenthadoop-cus-01-rg/providers/Microsoft.HDInsight/clusters/entsparkpepgda\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sqoop job failure,0.038324268,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie",Sqoop job failure,Networking issues,1. You would need to identify if the HDinsight cluster is sitting in the same Vnet as the SAP server -- if both the Vnets are peered together / vnet is connected to On-prem where SAP is sitting as shown in the documentation. https://docs.microsoft.com/en-us/office365/enterprise/connect-an-on-premises-network-to-a-microsoft-azure-virtual-network#overview2. If confirmed that both the networks can talk to each other --check if you are able to telnet to the SAP server on the port that you specified from any the headnode of the HDInsight cluster? >>telnet pepldh00127.corp.pep.pvt 32515,,,,,,,,
1.20031E+14,58:48.9,Cluster is deploys and few services Stop when deployed  ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {Namepii} is deploys and few services Stop when deployed  and job connectoin refuses for multiple times and gets connected after multiple tries\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is deploys and few services Stop when deployed  and job connectoin refuses for multiple times and gets connected after multiple tries\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {Namepii} is deploys and few services Stop when deployed  and job connectoin refuses for multiple times and gets connected after multiple tries;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - {Namepii} is deploys and few services Stop when deployed  and job connectoin refuses for multiple times and gets connected after multiple tries;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaprdhadoop-cus-01-rg/providers/Microsoft.HDInsight/clusters/ippprdspark\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is deploys and few services Stop when deployed  ,0.977489249,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Interactive Query,Cluster is deploys and few services Stop when deployed,"In order to provide optimal levels of availability of services HDinsight is designed to have HA for critical services such as·        Apache Ambari server·        Application Timeline Server for Apache YARN·        Job History Server for Hadoop MapReduce·        Apache Livy  It has been documented as well, https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-high-availability-components",By design ,,,,,,,,
1.20031E+14,09:57.1,Unable to restart Hive server 2 and Hive queries fail ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer:  DESCRIBE FORMATTED xref_campaign_email_notification;\nInterrupting... Please be patient this may take some time.\nError: Error while compiling statement: FAILED: SemanticException Unable to fetch table xref_campaign_email_notification. null ({alphanumericpii}\n\nQuestion: Hive query explain plan if available\nAnswer: Running simple queries on certain hive tables are failing. \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {Alphanumericpii}:\nMade some config changes on ambari to enable yarn UI and restarted failed hivee server 2\n{Alphanumericpii}:  simple queries on certain hive tables are failing. \n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable -  DESCRIBE FORMATTED xref_campaign_email_notification;\nInterrupting... Please be patient this may take some time.\nError: Error while compiling statement: FAILED: SemanticException Unable to fetch table xref_campaign_email_notification. null ({alphanumericpii};\nHive query explain plan if available - Running simple queries on certain hive tables are failing. ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - {Alphanumericpii}:\nMade some config changes on ambari to enable yarn UI and restarted failed hivee server 2\n{Alphanumericpii}:  simple queries on certain hive tables are failing. \n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to restart Hive server 2 and Hive queries fail ,0.044165125,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Unable to restart Hive server 2 and Hive queries fail,quota capacity is reached to max (92%),Re-deploying a cluster in a sub ID which has enough quota capacity,,,,,,,,
1.20031E+14,47:35.1,FD Sand : Sandbox cluster : kpphv704llapncapfdsbusc01  : cluster scaled up however softwares  are pending state,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Not able to access hive from Ambari\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Sandbox cluster  {alphanumericpii}  : cluster scaled up however softwares  are pending state\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Not able to access hive from Ambari;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Sandbox cluster  {alphanumericpii}  : cluster scaled up however softwares  are pending state;\n\n- ProblemStartTime: 03/09/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kpphv704llapncapfdsbusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sand : Sandbox cluster : kpphv704llapncapfdsbusc01  : cluster scaled up however softwares  are pending state,0.168945238,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,FD Sand : Sandbox cluster : kpphv704llapncapfdsbusc01 : cluster scaled up however softwares are pending state,"Issue: We noticed that the newly added 12 worker nodes did not come up properly as they didnt have the keytabs installed on them which is required for the ESP clusters. The services were failing with the following error message""2020-03-09 22:26:26,695 ERROR datanode.DataNode - Exception in secureMainjava.io.IOException: Login failure for dn/wn1033-kpphv7.kpaaddsprod.onmicrosoft.com@KPAADDSPROD.ONMICROSOFT.COM from keytab /etc/security/keytabs/dn.service.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user""""","Resolution: We restarted the Credential service on the cluster and scaled down the cluster from 16 to 4 nodes to get rid of the newly added nodes and scaled the cluster back up to 16 to resolve the issue. Please let us know if you have any questions or concerns on this. If not, let me know if I can go ahead with archiving this case.  ",,,,,,,,
1.20031E+14,59:07.6,"Cluster failed to deploy, generic error code, vnet and gen2","Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: {alphanumericpii} \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: Any customization applied\nAnswer: External metastore\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: We have working arm templates for spark cluster, but we are cleaning it, so we removed some parameters we don't know what went wrong.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - {alphanumericpii} ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nAny customization applied - External metastore;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - We have working arm templates for spark cluster, but we are cleaning it, so we removed some parameters we don't know what went wrong.;\n\n- ProblemStartTime: 03/09/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/42c6aec2-324a-4272-9e3c-9daad84bfe06/resourceGroups/CER01-RGP-BI-CER04/providers/Microsoft.HDInsight/clusters/az4062spark001bic04\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Cluster failed to deploy, generic error code, vnet and gen2",0.051451923,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,The cluster failed due to Azure resource generic error,HDInsight cluster creations were failing in Canada central due to failure in provisioning the cluster gateway machines. The gateway service on these machines were failing to come up in the designated time due to an internal issue with our monitoring agent.,We deployed a newer version of the gateway service which addressed the issueICM attached ,179097046,,,,,,,
1.20031E+14,12:24.9,Hive table location fails with READ Permission error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: FAILED: HiveAccessControlException Permission denied: user [imdliiguser] does not have [READ] privilege on [abfs://ahd501@azuscvdls00501.dfs.core.windows.net/hive/warehouse/managed/imdl_irdp_dev.db/raw_cal_fti_scores]\n\nCREATE EXTERNAL TABLE IF NOT EXISTS imdl_irdp_dev.cur_fi_esg_model_scores(\n  `year` string, \n  `country_name` string, \n  `region_name` string, \n  `sub_region_name` string, \n  `{alphanumericpii}` string, \n  `region_code` string, \n  `fti_esg_score` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `perf_start_date` string, \n  `perf_end_date` string, \n  `last_updated_time` timestamp, \n  `last_updated_by` string)\nROW FORMAT SERDE \n  '{AlphanumericPII}' \nSTORED AS INPUTFORMAT \n  'org.apache.hadoop.mapred.TextInputFormat' \nOUTPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\nLOCATION\n'abfs://ahd501@azuscvdls00501.dfs.core.windows.net/hive/warehouse/managed/imdl_irdp_dev.db/raw_cal_fti_scores'\n\n\n\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: We can create tables if we do not specify location, we are not able to create with location parameter specifiied.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - FAILED: HiveAccessControlException Permission denied: user [imdliiguser] does not have [READ] privilege on [abfs://ahd501@azuscvdls00501.dfs.core.windows.net/hive/warehouse/managed/imdl_irdp_dev.db/raw_cal_fti_scores]\n\nCREATE EXTERNAL TABLE IF NOT EXISTS imdl_irdp_dev.cur_fi_esg_model_scores(\n  `year` string, \n  `country_name` string, \n  `region_name` string, \n  `sub_region_name` string, \n  `{alphanumericpii}` string, \n  `region_code` string, \n  `fti_esg_score` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `{alphanumericpii}` {alphanumericpii}), \n  `perf_start_date` string, \n  `perf_end_date` string, \n  `last_updated_time` timestamp, \n  `last_updated_by` string)\nROW FORMAT SERDE \n  '{AlphanumericPII}' \nSTORED AS INPUTFORMAT \n  'org.apache.hadoop.mapred.TextInputFormat' \nOUTPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\nLOCATION\n'abfs://ahd501@azuscvdls00501.dfs.core.windows.net/hive/warehouse/managed/imdl_irdp_dev.db/raw_cal_fti_scores'\n\n\n\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - We can create tables if we do not specify location, we are not able to create with location parameter specifiied.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive table location fails with READ Permission error,0.051135123,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,Hive table location fails with READ Permission error,1. Ranger poicy ID missing in read permission error on Access Manager2. Ranger comes with version 2 with Yarn and Hive plugin only ,DFS was added onto it as version 3 => Updated Newer Config version => HIVE Query successfully ran,,,,,,,,
1.20031E+14,50:30.2,Aumentar capacidade do HDInsight,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Gentileza, aumentar a quantidade de nós do HDinsight cluster ({alphanumericpii}):\n\nVM {ALPHANUMERICPII}: Adicionar mais 2 nós\nVM {ALPHANUMERICPII}: Adicionar mais 1 nó\n\nTotal depois da alteração deverá ser:\n{ALPHANUMERICPII} - 4 node - 32 cores \n{ALPHANUMERICPII} - 4 node - 64 cores\n\nQualquer dúvida, gentileza entrar em contato.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Gentileza, aumentar a quantidade de nós do HDinsight cluster ({alphanumericpii}):\n\nVM {ALPHANUMERICPII}: Adicionar mais 2 nós\nVM {ALPHANUMERICPII}: Adicionar mais 1 nó\n\nTotal depois da alteração deverá ser:\n{ALPHANUMERICPII} - 4 node - 32 cores \n{ALPHANUMERICPII} - 4 node - 64 cores\n\nQualquer dúvida, gentileza entrar em contato.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: BHS Sni - Olé Consignado\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Aumentar capacidade do HDInsight,1.791525751,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Alert in Azure portal when attempting to scale cluster,Customer requested quota increase to scale up their HDInsight cluster,Qutoa's increased - https://dev.azure.com/CapacityRequest/Quota/_workitems/edit/125537,,,,,,,,
1.20031E+14,16:28.4,Not able to login user(a1002634@jci.com) in to HDI cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Issue: Not able to login {emailpii}@jci.com) in to HDI cluster.\n{Namepii}: https://dlqa002acidhdi002.azurehdinsight.net\nRG : {AlphanumericPII}\nUser - {emailpii}@jci.com\n\nThis is the first time this user login into cluster. Keep on prompting login screen. I have change password and tried. \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Issue: Not able to login {emailpii}@jci.com) in to HDI cluster.\n{Namepii}: https://dlqa002acidhdi002.azurehdinsight.net\nRG : {AlphanumericPII}\nUser - {emailpii}@jci.com\n\nThis is the first time this user login into cluster. Keep on prompting login screen. I have change password and tried. \n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/dlqa002acidhdi002\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to login user(a1002634@jci.com) in to HDI cluster,0.169717438,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,Not able to login user(a1002634@jci.com) in to HDI cluster, service id properties in AD,We have updated service id properties in AD. I am able to login into cluster now. We can archive case. Thanks for your support.,,,,,,,,
1.20031E+14,01:15.3,/dev/sda1 of hn0 has 81% of disk usage,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: /{alphanumericpii} takes 22G space, how to safely clean it up, besides, how to clean up unnecessary files to get more free disk space?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - /{alphanumericpii} takes 22G space, how to safely clean it up, besides, how to clean up unnecessary files to get more free disk space?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-NAM-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cda42e6-a623-4800-abdf-431ef3ec65e5/resourceGroups/o365ipdinam02-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdinam02-sp-wu01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",/dev/sda1 of hn0 has 81% of disk usage,0.022809445,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Alerts firing on Services\Spark,/dev/sda1 of hn0 has 81% of disk usage,NA,Please make sure to take the backup of all the /var/log/ files to Azure storage or local and then try to clean up the /var/log files not the directories and that would free up your space. we recommend not to delete /var/lib/spark2/shs_db or any lib files . ,,,,,,,,
1.20031E+14,29:21.3,FD SB HDI4: kps023sparkespfdsbwus401 :  Not able to access to edge node 10.10.196.223 ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 10, 2020, 5:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: We are not able to access one edge node {Ipaddresspii} as {alphanumericpii} disabled. Please help to enable.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - NA;\nAdditional details about the issue - We are not able to access one edge node {Ipaddresspii} as {alphanumericpii} disabled. Please help to enable.;\n\n- ProblemStartTime: 03/11/2020 00:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps023sparkespfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD SB HDI4: kps023sparkespfdsbwus401 :  Not able to access to edge node 10.10.196.223 ,0.142948487,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unexpected result\Spark,Issue: Edgenode1 not accessable to SSH. ,Transient,Resolution: Restarted the edgenode from backend. ,,,,,,,,
1.20031E+14,19:29.8,Head node disk space full,"Question: What time did the problem begin?\nAnswer: {Namepii}, 10 {Namepii}, 2020, 12:00 am IST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: unable to start a jupyter kernel due to insufficient disk space on the head node.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - unable to start a jupyter kernel due to insufficient disk space on the head node.;\n\n- ProblemStartTime: 03/09/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BI Production Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f68db560-dc26-49bc-a39f-710ad3755342/resourceGroups/V18_DS_Dev_Acc/providers/Microsoft.HDInsight/clusters/v18-DS-HDI-RSer-Dev\n- Location: centralindia\n- Location: Central India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head node disk space full,0.30437726,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,"Due to low disk space, you were not able to execute Jupyter job",tcpdump process was running & causing low disk space,Killed the tcpdump process and deleted the files; and restarted servies from Ambari UI,179267212,,,,,,,
1.20031E+14,13:41.9,chkp22adlstream,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Unable to add edge node to the cluster\n'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'Application roles must have at least one install script action specified\\'\\r{uncpii}\n    }\n  ]\n}\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to add edge node to the cluster\n'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'Application roles must have at least one install script action specified\\'\\r{uncpii}\n    }\n  ]\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Unable to add edge node to the cluster\n'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'Application roles must have at least one install script action specified\\'\\r{uncpii}\n    }\n  ]\n};\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to add edge node to the cluster\n'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'Application roles must have at least one install script action specified\\'\\r{uncpii}\n    }\n  ]\n};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP22ADLSTREAM\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",chkp22adlstream,0.118832119,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,could not deploy second Edgenode,unsure,I cleared the previous  invalid scripts (deployments) .. and changed the name  new-edgenode001,,,,,,,,
1.20031E+14,11:45.3,Cluster launch failed,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 11, 2020, 11:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: resolved itself without change\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: We've had issues before launching clusters related to installing HDinsight base components.\n\ngot this message\n\nDeployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'AzureResourceCreationFailedErrorCode',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}\n\n\nWe'll keep the cluster up (not deleting) because we were told that would help your debugging if it happened again. We won't be charged while it's in error state - correct?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - resolved itself without change;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - We've had issues before launching clusters related to installing HDinsight base components.\n\ngot this message\n\nDeployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'AzureResourceCreationFailedErrorCode',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}\n\n\nWe'll keep the cluster up (not deleting) because we were told that would help your debugging if it happened again. We won't be charged while it's in error state - correct?;\n\n- ProblemStartTime: 03/11/2020 15:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SilviaTerra Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/15788394-4a53-4ca5-a1f3-9be9fde89fbd/resourceGroups/SilviaTerraEastUS/providers/Microsoft.HDInsight/clusters/basemap-2019\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster launch failed,0.205390558,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster launch failed,Over the past three months there are 6 cluster creation failures.2 are due to Provisioning agents didn't come up4 are due to Failed for host components to come up. We have a work item which is going in current release to fix Provisioning agent on gateway failures.https://msdata.visualstudio.com/HDInsight/_workitems/edit/503479Other two errors have been fixed by the product team,Auto-resolved,180522395,,,,,,,
1.20031E+14,35:07.2,Installed HDInsight Kafka in private subnet. Ambari UI is not loading,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 11, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Installed HDInsight Kafka cluster on private subnet by opening the suitable inbound ports. Installation is successful. But Ambari UI site is not reachable. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Installed HDInsight Kafka cluster on private subnet by opening the suitable inbound ports. Installation is successful. But Ambari UI site is not reachable. ;\n\n- ProblemStartTime: 03/11/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5b7699ba-9b3e-4279-b311-4a77a5734e4f/resourceGroups/nonprod_rg/providers/Microsoft.HDInsight/clusters/kafka-nonprod-dev01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Installed HDInsight Kafka in private subnet. Ambari UI is not loading,0.066861462,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,Installed HDInsight Kafka in private subnet. Ambari UI is not loading ,User environment, We have connected on a screen sharing session and verified your environment. Whitelisting your public IP on the NSG  resolved the issue.,,,,,,,,
1.20031E+14,43:23.6,"we want to know is it mandatory that when the  java upgrade is done from MS end, we have to restart all the hadoop and mosaic services?","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: we want to know is it mandatory that when the  java upgrade is done from MS end we have to restart all the hadoop and mosaic services?\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: spark-submit  --class com.augmentiq.maxiq.spark.handler.SparkHandler \\\n\n              --verbose \\\n\n              --master yarn-cluster   \\\n\n              --jars $CLASSPATH,$x,/usr/hdp/2.6.3.84-1/hbase/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar \\\n\n              --files /etc/hive/conf/hive-site.xml,/etc/hbase/conf/hbase-site.xml  \\\n\n              --driver-class-path /usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar \\\n\n              --driver-java-options '-Dspark.driver.extraClassPath=/usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar' \\\n\n              --conf 'spark.executor.extraClassPath=/usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar' \\\n\n              --deploy-mode cluster \\\n\n              --conf yarn.log-aggregation-enable=true  \\\n\n              --conf hive.execution.engine=mr \\\n\n              --conf spark.shuffle.compress=true \\\n\n              --executor-cores 5 \\\n\n              --driver-memory 5g \\\n\n              --executor-memory 6g \\\n\n              --num-executors 5 \\\n\n              --name $4 \\\n\n              --queue $5 \\\n\n              --driver-java-options '-{AlphanumericPII}'  '$MAXIQ_HOME'/libs/MaxiqAppProcessor-'$MAXIQ_VERSION'.jar $1 $2 $3 $4 $6\n\nQuestion: Additional details about the issue\nAnswer: Jobs are getting failed and hadoop and mosaic servises restart is mandatory to make sure jobs getting successful.\n\n\ncall us to know about more queries we are having regarding the upgrade happens from MS end.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - we want to know is it mandatory that when the  java upgrade is done from MS end we have to restart all the hadoop and mosaic services?;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - spark-submit  --class com.augmentiq.maxiq.spark.handler.SparkHandler \\\n\n              --verbose \\\n\n              --master yarn-cluster   \\\n\n              --jars $CLASSPATH,$x,/usr/hdp/2.6.3.84-1/hbase/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar \\\n\n              --files /etc/hive/conf/hive-site.xml,/etc/hbase/conf/hbase-site.xml  \\\n\n              --driver-class-path /usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar \\\n\n              --driver-java-options '-Dspark.driver.extraClassPath=/usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar' \\\n\n              --conf 'spark.executor.extraClassPath=/usr/hdp/current/hbase-client/lib/hbase-protocol-1.1.2.2.6.3.84-1.jar' \\\n\n              --deploy-mode cluster \\\n\n              --conf yarn.log-aggregation-enable=true  \\\n\n              --conf hive.execution.engine=mr \\\n\n              --conf spark.shuffle.compress=true \\\n\n              --executor-cores 5 \\\n\n              --driver-memory 5g \\\n\n              --executor-memory 6g \\\n\n              --num-executors 5 \\\n\n              --name $4 \\\n\n              --queue $5 \\\n\n              --driver-java-options '-{AlphanumericPII}'  '$MAXIQ_HOME'/libs/MaxiqAppProcessor-'$MAXIQ_VERSION'.jar $1 $2 $3 $4 $6;\nAdditional details about the issue - Jobs are getting failed and hadoop and mosaic servises restart is mandatory to make sure jobs getting successful.\n\n\ncall us to know about more queries we are having regarding the upgrade happens from MS end.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: QA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c1edc178-6f74-42c6-bb36-6d014d69de84/resourceGroups/Mosaic-APAC-QA-Primary/providers/Microsoft.HDInsight/clusters/omeaqitdpqaapac01\n- Location: eastasia\n- Location: East {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","we want to know is it mandatory that when the  java upgrade is done from MS end, we have to restart all the hadoop and mosaic services?",0.081243549,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Query or Job Failure\Spark,"we want to know is it mandatory that when the java upgrade is done from MS end, we have to restart all the hadoop and mosaic services?",NA,Ms doesn't have the capability to upgrade Java versions on the cluster once after the deployment.Examined the logs for 3 months and could see that the Java version was not upgraded.,,,,,,,,
1.20031E+14,45:09.3,ESP DNS servers are not resolving to the correct hosts,"DNS names are not resolving. PFA sheet for Reference\n\nProblem start date and time\n{Namepii}, {Namepii} 12, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/11/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi003dlprod001\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ESP DNS servers are not resolving to the correct hosts,9.091906294,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\General Guidance or Advisory,ESP DNS servers are not resolving to the correct hosts,ESP cluster redeployed with the same name of cluster ,"The first time of ESP cluster deployment, the IP address that it is given is recorded in the domain server entries, so it has to delete this cluster and re-create it with a different name (making sure that the first six characters of the cluster name are different) - submitted a work item for the PG to correct this behavior",179371850,,,,,,,
1.20031E+14,09:35.2,Failing to create HDI,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: msimdwhdi\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: With new HDI version I use MI and seeing permission issue\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Error:\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToValidateStorageAccountErrorCode\\',\\r\\n \\'message\\': \\'Failed to validate the storage account.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - msimdwhdi;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - With new HDI version I use MI and seeing permission issue;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Error:\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToValidateStorageAccountErrorCode\\',\\r\\n \\'message\\': \\'Failed to validate the storage account.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]};\n\n- ProblemStartTime: 03/09/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Manufacturing Test\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failing to create HDI,7.941999911,Root Cause : HDInsight Service\Azure portal related issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,Failed to validate storage blob account., The Managed Identity does not have permissions on the storage account. Please verify that 'Storage Blob Data Owner' role is assigned to the Managed Identity for the storage account.,Recreated the storage account with user managed Identity role permissions assigned both at the owner and contributer level.,,,,,,,,
1.20031E+14,23:44.8,error 502.3 on accessing ambari on bdqcluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: already tried to restart amabri server & agent on headnodes\n\nQuestion: Additional details about the issue\nAnswer: already tried to restart amabri server & agent on headnodes\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - already tried to restart amabri server & agent on headnodes;\nAdditional details about the issue - already tried to restart amabri server & agent on headnodes;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ea8d856b-f0d4-43e6-a00a-e7fe91533bca/resourceGroups/cat-DEV-BDQCluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/f6sBFCn6Zh-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",error 502.3 on accessing ambari on bdqcluster,32.90585886,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,error 502.3 on accessing ambari on bdqcluster,"SEP being used by the customer. Not supported by HDIAzure services deployed into your virtual network, such as Azure HDInsight, access other Azure services, such as Azure Storage, for infrastructure requirements. Restricting endpoint policy to specific resources could break access to these infrastructure resources for the Azure services deployed in your virtual network.",na,179394455,,,,,,,
1.20031E+14,30:20.1,Failed during upscale,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 11, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Data Factory Activity\n\nQuestion: Additional details about the issue\nAnswer: Getting following error while upscaling the cluster - \n\nError code\nFailedToQueryAmbariServerErrorCode\nError message\nUnable to query Ambari server to retrieve the list of cluster hosts.\n\n{Namepii} have gone to error state.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Data Factory Activity;\nAdditional details about the issue - Getting following error while upscaling the cluster - \n\nError code\nFailedToQueryAmbariServerErrorCode\nError message\nUnable to query Ambari server to retrieve the list of cluster hosts.\n\n{Namepii} have gone to error state.;\n\n- ProblemStartTime: 03/10/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: idx-na-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d29e6b95-1e5c-4ba1-ae9a-d7d3c256e6ba/resourceGroups/idx-dataplane-ssp-rg/providers/Microsoft.HDInsight/clusters/ssp-cdp-atom-v2-hdi-spark\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failed during upscale,0.391029447,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,scaling failed,CA the preliminary look of things is that it had to do with the scaling of the cluster from1 to 170 all at once. ,"In the future please try to limit to 20 - 30  nodes at a time.  Also please take a look at the available space on the Headnodes. While it might seem that you have enough for operations, the scaling process does require temporary resources while it is scaling.",179439990,,,,,,,
1.20031E+14,27:58.4,Problems to monitor hive queries,"Good evening, \nWe are trying to find ways to monitor and optimize our hive queries. \nWe tried to use Hive/Tez Views but they seem no available for us. Yarn Web UI is not enough for us as we cannot see the query which was launched.  Finally, we cannot find anything similar in HDInsight which can help us. \n\nProblem start date and time\n{Namepii}, {Namepii} 12, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/11/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Santander OMEGA Non-Productive\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cb42b9e9-66f5-4b34-8ae9-92aa9fbe3cc3/resourceGroups/hcbae2c01rsgdtl001/providers/Microsoft.HDInsight/clusters/hcbae2c01hdicdlsppbi001\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Problems to monitor hive queries,0.158132377,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\General Guidance or Advisory,HIVE view is not available on Ambari,HDInsight 4.0 doesn't have a HIVE view or another tool to monitor HIVE queries.,Data Analytic Studio (DAS) is available and can be installed through Action Script.https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-migrate-workloads,,,,,,,,
1.20031E+14,23:17.3,Unable to submit Spark app to YARN using Oozie.,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 11, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Oozie\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: This works completely fine in {ALPHANUMERICPII} cluster, But does not works on '{alphanumericpii}'. Please let us know if any configuration changes needs to be performed. I have attached the spark-submit.sh and property files associated to the {Namepii}.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Oozie;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - This works completely fine in {ALPHANUMERICPII} cluster, But does not works on '{alphanumericpii}'. Please let us know if any configuration changes needs to be performed. I have attached the spark-submit.sh and property files associated to the {Namepii}.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/11/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to submit Spark app to YARN using Oozie.,0.88900117,Root Cause : HDInsight Service\Bug\HDInsight,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie",Unable to submit Spark app to YARN using Oozie.,Not supported with Spark Action 4.0 ESP clsuter. ,Couldera issue. Needed to switch over to shell action,181508226,,,,,,,
1.20031E+14,42:50.0,why  v2 commit protocol  is use din hdinsights,"I would like to understand the rationale behind selecting mapreduce.fileoutputcommiter.algorithm.version as 2 .I feel version 2 unsafe.Since ADLS is HDFS compliant storage it should be v1.\n\nTo help understand the problem i am attaching some literature below\n\nCommit Protocols from HDinsight\n\nMapReduce.fileoutputcommitter.algorithm.version 1\n\nMapreduce.fileoutputcommitter.algorithm.version 2: Default\n\n\nCommit Protocols Description\n\nLarge-scale data processing frameworks like {Namepii} Spark implement fault-tolerance by breaking up the work required to execute a job into retriable tasks. Since tasks may occasionally fail, Spark must ensure that only the outputs of successful tasks and jobs are made visible. Formally, this is achieved using a commit protocol, which specifies how results should be written at the end of a job.\n\nMapReduce.fileoutputcommitter.algorithm.version 1: This commit algorithm writes the output to the temporary directory . Once all the output is successfully written into a temporary directory, then it starts renaming it to the actual output directory.\n\nMapreduce.fileoutputcommitter.algorithm.version 2: This commit algorithm starts writing the output to a temporary directory. It starts moving the output of the completed task to the actual output directory before the whole job completes\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/eaasedl-dev/providers/Microsoft.HDInsight/clusters/sparkeaasedldev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",why  v2 commit protocol  is use din hdinsights,0.067453299,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\General Guidance or Advisory,why  v2 commit protocol  is use din hdinsights- General Guidance or Advisory (Preview),NA,Suggested deploying the higher spark version,,,,,,,,
1.20031E+14,37:57.8,Inconsistent processing among partitions,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Kafka topics are not evenly consumed.  Some topics are consumed faster than others as follows.\n{alphanumericpii}$ ./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --broker-info --group luminate.search-sync-service --topic public.dct.shipments.change --zookeeper $KAFKAZKHOSTS\n[2020-03-12 {Alphanumericpii}] WARN WARNING: ConsumerOffsetChecker is deprecated and will be dropped in releases following {Alphanumericpii}. Use ConsumerGroupCommand instead. (kafka.tools.ConsumerOffsetChecker$)\nGroup                                                   Topic   Pid Offset      logSize         Lag             Owner\nluminate.search-sync-service public.dct.shipments.change    0   1883929         1885663         1734            none\nluminate.search-sync-service public.dct.shipments.change    1   1884329         1885695         1366            none\nluminate.search-sync-service public.dct.shipments.change    2   1883999         1885685         1686            none\nluminate.search-sync-service public.dct.shipments.change    3   1884263         1885640         1377            none\nluminate.search-sync-service public.dct.shipments.change    4   1884158         1885682         1524            none\nluminate.search-sync-service public.dct.shipments.change    5   1884059         1885646         1587            none\nluminate.search-sync-service public.dct.shipments.change    6   1885664         1885664         0               none\nluminate.search-sync-service public.dct.shipments.change    7   1885734         1885734         0               none\nluminate.search-sync-service public.dct.shipments.change    8   1885676         1885676         0               none\nluminate.search-sync-service public.dct.shipments.change    9   1885738         1885738         0               none\nluminate.search-sync-service public.dct.shipments.change    10  1885726         1885727         1               none\nluminate.search-sync-service public.dct.shipments.change    11  1885714         1885714         0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nBROKER INFO\n1001 → {Alphanumericpii}\n1003 → {Alphanumericpii}\n1002 → {Alphanumericpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Kafka topics are not evenly consumed.  Some topics are consumed faster than others as follows.\n{alphanumericpii}$ ./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --broker-info --group luminate.search-sync-service --topic public.dct.shipments.change --zookeeper $KAFKAZKHOSTS\n[2020-03-12 {Alphanumericpii}] WARN WARNING: ConsumerOffsetChecker is deprecated and will be dropped in releases following {Alphanumericpii}. Use ConsumerGroupCommand instead. (kafka.tools.ConsumerOffsetChecker$)\nGroup                                                   Topic   Pid Offset      logSize         Lag             Owner\nluminate.search-sync-service public.dct.shipments.change    0   1883929         1885663         1734            none\nluminate.search-sync-service public.dct.shipments.change    1   1884329         1885695         1366            none\nluminate.search-sync-service public.dct.shipments.change    2   1883999         1885685         1686            none\nluminate.search-sync-service public.dct.shipments.change    3   1884263         1885640         1377            none\nluminate.search-sync-service public.dct.shipments.change    4   1884158         1885682         1524            none\nluminate.search-sync-service public.dct.shipments.change    5   1884059         1885646         1587            none\nluminate.search-sync-service public.dct.shipments.change    6   1885664         1885664         0               none\nluminate.search-sync-service public.dct.shipments.change    7   1885734         1885734         0               none\nluminate.search-sync-service public.dct.shipments.change    8   1885676         1885676         0               none\nluminate.search-sync-service public.dct.shipments.change    9   1885738         1885738         0               none\nluminate.search-sync-service public.dct.shipments.change    10  1885726         1885727         1               none\nluminate.search-sync-service public.dct.shipments.change    11  1885714         1885714         0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nluminate.search-sync-service public.dct.shipments.change    {Phonenumberpii}            0               none\nBROKER INFO\n1001 → {Alphanumericpii}\n1003 → {Alphanumericpii}\n1002 → {Alphanumericpii};\n\n- ProblemStartTime: 03/09/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/15ce5075-d8c9-4097-a180-79e7bba8663e/resourceGroups/lct-bd-prd-02/providers/Microsoft.HDInsight/clusters/kaf-lct-bd-prd-02\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Inconsistent processing among partitions,0.158972245,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Kafka,Inconsistent processing among partitions,Inconsistent processing among partitions,Recommended to run the rebalance. This is something on client side on how they configure their consumers groups and how many consumers they have to consume the topic partitions. Following link talks about how one can tune consumer's performance https://docs.cloudera.com/documentation/kafka/latest/topics/kafka_performance.html#kafka_performance_tuning_consumers ,179515773,,,,,,,
1.20031E+14,30:01.5,Fail to deserialize Avro files with Spark SQL,"Question: Quand le problème a-t-il commencé ?\nRépondre: lun. 9 mars 2020 à 09:00 UTC−4\n\nQuestion: Heure approximative lorsque le problème s’est arrêté. {Namepii} le problème est en cours, laissez ce champ vide\nRépondre: \n\nQuestion: Avez-vous modifié l’un de ces composants ?\nRépondre: \n\nQuestion: Y a-t-il eu une augmentation de la charge ?\nRépondre: \n\nQuestion: Mesures d’atténuation prises jusqu’à présent\nRépondre: Tried to override Hive Serde with version 2.3.6\nTried to override Avro with version 1.9.2\nTried to create uber-jar with all dependencies included.\n\nQuestion: Détails supplémentaires sur le problème\nRépondre: Facing Avro exception described in spark issue {ALPHANUMERICPII} : https://issues.apache.org/jira/browse/SPARK-20880\n\nExample of job failure : https://catcluster.hdi.cat.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster/app/application_1584026284778_0116\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\nQuand le problème a-t-il commencé ? - {ALPHANUMERICPII};\nHeure approximative lorsque le problème s’est arrêté. {Namepii} le problème est en cours, laissez ce champ vide - ;\nAvez-vous modifié l’un de ces composants ? - ;\nY a-t-il eu une augmentation de la charge ? - ;\nMesures d’atténuation prises jusqu’à présent - Tried to override Hive Serde with version 2.3.6\nTried to override Avro with version 1.9.2\nTried to create uber-jar with all dependencies included.;\nDétails supplémentaires sur le problème - Facing Avro exception described in spark issue {ALPHANUMERICPII} : https://issues.apache.org/jira/browse/SPARK-20880\n\nExample of job failure : https://catcluster.hdi.cat.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster/app/application_1584026284778_0116\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/09/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier avec Azure Rapid Response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ea8d856b-f0d4-43e6-a00a-e7fe91533bca/resourceGroups/cat-DEV-CATCluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/YKw2TRb9Vo-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Fail to deserialize Avro files with Spark SQL,1.770272315,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Service unhealthy\Spark,Fail to deserialize Avro files with Spark SQL,Fail to deserialize Avro files with Spark SQL," It appears that this issue was fixed with hive 2.2 but spark depends on Hive 1.2.1. This is not supported in spark and can't be solved until spark moves to hive 2.2. From the latest spark docs: Spark SQL is designed to be compatible with the Hive Metastore, SerDes and UDFs. Currently, Hive SerDes and UDFs are based on Hive 1.2.1. Since spark libraries are built according to Hive 1.2.1, it might not help but just updating Hive Serde version to 2.3.6.",179736147,,,,,,,
1.20031E+14,46:11.7,Cannot find the correct sponsor,"Question: Problem Start Date\nAnswer: {Namepii}, {Namepii} 12, 2020, 12:00 AM EDT\n\nQuestion: Select the Subscription ID\nAnswer: Other, don't know or not applicable\n\nQuestion: Subscription ID\nAnswer: HW3 Boxuan {Namepii}\n\nQuestion: Email ID signing in/accessing the subscription\nAnswer: {emailpii}@gatech.edu\n\nQuestion: Last login date/time\nAnswer: \n\nQuestion: Browser Information\nAnswer: Google Chrome\n\nQuestion: Error message/Screenshot of the error \nAnswer: \n\nQuestion: Browser network trace or any other details (if applicable)\nAnswer: Hi, I have the issue of accessing my sponsor when creating a new cluster. I should have the sponsor 'HW3 Boxuan {Namepii}' from {Namepii} Tech Institute. But I cannot find it. And when I created the cluster using the default 'Azure Sponsor 2', it cannot be either deployed or deleted. Could you please help me with it? Thanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Subscription Management:\nProblem Start Date - {ALPHANUMERICPII};\nSelect the Subscription ID - Other, don't know or not applicable;\nSubscription ID - HW3 Boxuan {Namepii};\nEmail ID signing in/accessing the subscription - {emailpii}@gatech.edu;\nLast login date/time - ;\nBrowser Information - Google Chrome;\nError message/Screenshot of the error  - ;\nBrowser network trace or any other details (if applicable) - Hi, I have the issue of accessing my sponsor when creating a new cluster. I should have the sponsor 'HW3 Boxuan {Namepii}' from {Namepii} Tech Institute. But I cannot find it. And when I created the cluster using the default 'Azure Sponsor 2', it cannot be either deployed or deleted. Could you please help me with it? Thanks;\n\n- ProblemStartTime: 03/12/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Microsoft Azure 赞助 2\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_SUBSCRIPTION_MANAGEMENT\n- SupportPlanDisplayName: Basic support\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot find the correct sponsor,0.116496461,Root Cause : HDInsight Service\User Subscription issues,Routing Azure Subscription V5\Unable to access my subscription\Issues signing in or accessing my subscriptions,He couldn't deploy a cluster on one of his subscription,"He had 2 subscriptions, one was a free subscription and the other one was from Georgia Tech, he was mixing both subscriptions, with different resources to work with, when the free one reached the limit the the other resources start to fail causing errors  ",He deploy his cluster on a local VM,,,,,,,,
1.20031E+14,03:21.7,program to load a file to ADLS and it failed with AccessToken exception ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: We are running a simple program to a load file to ADLS using srv_datacat_read user id. It's a domain id and has all required access. However it keeps faling with AccessToken exception \n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: 20/03/12 21:30:10 DEBUG secure.AbstractCredentialServiceCaller: Retrying connect to credential service:https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/. Already tried {5} time(s); retry policy is {{AlphanumericPII}, {Alphanumericpii}]}, delay {{alphanumericpii}.\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: url=https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/?op=GETACCESSTOKEN&service=ADLS_DT_SERVICE&doas=srv_datacat_read&user.name=srv_datacat_read&\n20/03/12 21:30:20 DEBUG client.KerberosAuthenticator: JDK performed authentication on our behalf.\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: request.headers: {Namepii}: {AlphanumericPII}='\n\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: request: Request{method=GET, url=https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/?op=GETACCESSTOKEN&service=ADLS_DT_SERVICE&doas=srv_datacat_read&user.name=srv_datacat_read&, tag=null}\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: TokenManager Response Code: 500\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: Internal Server Error encountered\n20/03/12 21:30:20 ERROR secure.AbstractCredentialServiceCaller: Internal Server Error from TokenManager (Response Code: 500)\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: Internal Server Error from TokenManager (Response Code: 500)\njava.io.IOException: Internal Server Error from TokenManager (Response Code: 500) \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - We are running a simple program to a load file to ADLS using srv_datacat_read user id. It's a domain id and has all required access. However it keeps faling with AccessToken exception ;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - 20/03/12 21:30:10 DEBUG secure.AbstractCredentialServiceCaller: Retrying connect to credential service:https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/. Already tried {5} time(s); retry policy is {{AlphanumericPII}, {Alphanumericpii}]}, delay {{alphanumericpii}.\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: url=https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/?op=GETACCESSTOKEN&service=ADLS_DT_SERVICE&doas=srv_datacat_read&user.name=srv_datacat_read&\n20/03/12 21:30:20 DEBUG client.KerberosAuthenticator: JDK performed authentication on our behalf.\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: request.headers: {Namepii}: {AlphanumericPII}='\n\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: request: Request{method=GET, url=https://hn1-ahd701.azfrk.com:50910/tokenmanager/v1/?op=GETACCESSTOKEN&service=ADLS_DT_SERVICE&doas=srv_datacat_read&user.name=srv_datacat_read&, tag=null}\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: TokenManager Response Code: 500\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: Internal Server Error encountered\n20/03/12 21:30:20 ERROR secure.AbstractCredentialServiceCaller: Internal Server Error from TokenManager (Response Code: 500)\n20/03/12 21:30:20 DEBUG secure.AbstractCredentialServiceCaller: Internal Server Error from TokenManager (Response Code: 500)\njava.io.IOException: Internal Server Error from TokenManager (Response Code: 500) \n;\n\n- ProblemStartTime: 03/02/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data and Analytics Services\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",program to load a file to ADLS and it failed with AccessToken exception ,0.496403446,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Hive,Unable to run application due to access token,AccessToken for user was not refreshed.,Restarted Cred Services,,,,,,,,
1.20031E+14,00:25.0,Cannot start cluster afer restarting it,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 13, 2020, 12:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Restart all hosts\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Not applicable\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We tried restarting the hosts, but we cannot even stop the services, and now the cluster is death and we cannot start the services from the ambari ui\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Restart all hosts;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Not applicable;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We tried restarting the hosts, but we cannot even stop the services, and now the cluster is death and we cannot start the services from the ambari ui;\n\n- ProblemStartTime: 03/13/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZRINFRAESTRUCTURA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3f8d5f46-3a0e-4bc6-9e32-3e4774c514aa/resourceGroups/AZRDATALAKE/providers/Microsoft.HDInsight/clusters/prointquerylivc4\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot start cluster afer restarting it,0.076678478,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,"ODBC connection to the cluster from customers application dropped out and customer was unable to restart the components from Ambari, they then rebooted each node and services came back up.",Unknown,Customer rebooted hn1 and hn0 after which services were restored. Customer has not seen any re-occurrence of the ODBC connection dropout since rebooting the nodes. Not enough data to provide RCA as issue was resolved not long after case was opened so no reproduction of the issue to look into.,,,,,,,,
1.20031E+14,34:38.2,Facing multiple Issues on the cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 12, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are facing multiple issues on the cluster\n1) Head node 1 showing heartbeat lost\n{alphanumericpii} Name node are not showing active/standby\n3) facing issue with ambari metrics \n4) Oozie server alert (There is insufficient memory for the {Namepii} Runtime Environment to continue. )\n\n \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are facing multiple issues on the cluster\n1) Head node 1 showing heartbeat lost\n{alphanumericpii} Name node are not showing active/standby\n3) facing issue with ambari metrics \n4) Oozie server alert (There is insufficient memory for the {Namepii} Runtime Environment to continue. )\n\n ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/11/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdasecure-cus-01-rg/providers/Microsoft.HDInsight/clusters/prdiwsecure\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Facing multiple Issues on the cluster,0.0745466,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Unable to access Ambari UI,"The root cause of this issue. OMS is installed on this cluster on Feb 5th and we have a known issue with OMS creating 1000s of defunct zombie processes. We have over 4000 of such processes from OMS agent. The fix for this issue went into production on Feb 27th. In order to fix the issue, please uninstall the OMS on this cluster and install it again.  ",Reinstall OMS Service to obtain the latest fix.,183113162,,,,,,,
1.20031E+14,31:30.0,Cluster not accessible,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 13, 2020, 6:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Nothing\n\nQuestion: Additional details about the issue\nAnswer: This host-level alert is triggered if the Hive Metastore process cannot be determined to be up and listening on the network.\nThis host-level alert is triggered if the History Server process cannot be established to be up and listening on the network.\nThis host-level alert is triggered if the distro selector such as hdp-select cannot calculate versions available on this host. This may indicate that /usr/$stack/ directory has links/dirs that do not belong inside of it.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Nothing;\nAdditional details about the issue - This host-level alert is triggered if the Hive Metastore process cannot be determined to be up and listening on the network.\nThis host-level alert is triggered if the History Server process cannot be established to be up and listening on the network.\nThis host-level alert is triggered if the distro selector such as hdp-select cannot calculate versions available on this host. This may indicate that /usr/$stack/ directory has links/dirs that do not belong inside of it.\n;\n\n- ProblemStartTime: 03/13/2020 11:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/bpudl101\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster not accessible,0.119675797,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Cluster not accessible,We have noticed that there were quite a lot of connection refused errors seen and we suspect the issue happens when we have multiple jobs running on the cluster which is restricting new hive connections to be made.,"We have restarted the headnodes0,1 and since then the hive connections and the queries are running fine. We have noticed that there were quite a lot of connection refused errors seen and we suspect the issue happens when we have multiple jobs running on the cluster which is restricting new hive connections to be made. When you have a second occurrence of this issue you should notice alerts on Ambari (hive) complaining about connections failed on hiveserver2 instance running on headnodes:10001.Mitigation :you can increase hive.server2.thrift.max.worker.threads count from Ambari > Hive > configs and restart the required services to see if the issue is resolved. (default is 500 increase to 1000)","179,633,073,179,939,000,000,000,000",,,,,,,
1.20031E+14,00:12.4,can't login hadoop ambari with admin account,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 12, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: Switched to backup HDInsight cluster\n\nQuestion: Additional details about the issue\nAnswer: Our production pipeline failed to submit job using the admin account, error message is '403 - Forbidden: Access is denied. You do not have permission to view this directory or page using the credentials that you supplied.' \n\nWe tried to login Ambari portal with same admin user, error message is same. \n\nThis is our production service, username and passoword has not been changed.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - Switched to backup HDInsight cluster;\nAdditional details about the issue - Our production pipeline failed to submit job using the admin account, error message is '403 - Forbidden: Access is denied. You do not have permission to view this directory or page using the credentials that you supplied.' \n\nWe tried to login Ambari portal with same admin user, error message is same. \n\nThis is our production service, username and passoword has not been changed.;\n\n- ProblemStartTime: 03/12/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a3d57404-b155-4977-9306-f0e34b9aff4c/resourceGroups/ResourceGroup-PRODEUSHDIS1/providers/Microsoft.HDInsight/clusters/lh001-prodeushdis1\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",can't login hadoop ambari with admin account,0.050852188,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,120031324004731 - Can't login to the Ambari UI with the admin account​,Ambari admin password was reset​,Assisted customer with resetting the Ambari password using the Azure Portal​,,,,,,,,
1.20031E+14,32:04.1,kp10tntncapllapnsprdsup01:o domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'}\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'}\n\nQuestion: Interactive query explain plan if available\nAnswer: frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'}\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'};\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'};\nInteractive query explain plan if available - frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'};\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - frequent error message:\n\n{'Code':'ServiceUnavailable','Message':'No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com','CorrelationId':'604b75278d3b448a89e807823b6f28b4','ResponseTimestamp':'2020-03-13T21:27:55.3277122Z'};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kp10tntncapllapnsprdsup01:o domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com,1.028493724,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com exceptions,kp10tntncapllapnsprdsup01: No domain controller available to service the request for realm kpaaddsprod.onmicrosoft.com,"As stated this is side-effect of the other change and  as a workaround, please do retry logic. Other fix bring down the failure rate by 50%. At other times, the retries are bringing down the failure rate to 0.As discussed, will track this bug through KP Daily triage report.",180185235,,,,,,,
1.20031E+14,34:47.1,kpph18llapprdsupusc01: LLAP appliation is down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {AlphanumericPII} app is down\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII} app is down\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {AlphanumericPII} app is down;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - {AlphanumericPII} app is down;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kpph18llapprdsupusc01: LLAP appliation is down,0.092973034,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,unable to start Hive Interactive,kpph18llapprdsupusc01: LLAP appliation is down,"Killed the lingering LLAP daemon PID(s) on worker nodes and after that, Hive Interactive started fine",180217568,,,,,,,
1.20032E+14,22:23.9,Change Hive Metastore database,"We are currently using an external hive metastore (Azure SQL DB) which is shared by multiple clusters. For this particular cluster, we want to switch to a different SQL DB, what changes do we need to do in Ambair?\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-rg-compute1/providers/Microsoft.HDInsight/clusters/edsp4rd-workbench-compute-cluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Change Hive Metastore database,0.014549898,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\General Guidance or Advisory,120031624005712 Change Hive Metastore database HDInsight Service,Customer would like to use a custom Hive Metastore Database now,"Advised customer to update the Database Name, Database Username, Database password, and Database URL",,,,,,,,
1.20032E+14,10:57.9,Need to raise core limit,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: We need to raise our cores limit by 24 cores for head room. Right now we want to expand the cluster to 84 cores but we only have 80 cores available.\n\n'The available number of cores required to create or scale a resource for a subscription is less than required User SubscriptionId '{guidpii}' does not have cores left to create resource '{alphanumericpii}'. Required: 84, Available: 80.'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - We need to raise our cores limit by 24 cores for head room. Right now we want to expand the cluster to 84 cores but we only have 80 cores available.\n\n'The available number of cores required to create or scale a resource for a subscription is less than required User SubscriptionId '{guidpii}' does not have cores left to create resource '{alphanumericpii}'. Required: 84, Available: 80.';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Yammer - Analytics - CORP\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerlogs-prod-central/providers/Microsoft.HDInsight/clusters/yammerlogs-prod-central-d13\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to raise core limit,6.673971607,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure due to quota limit,Need to raise core limit,Cores unavailable under subscription.,Collaborated with subscription team and the got the request approved.,,,,,,,,
1.20032E+14,31:00.4,Error during Hive job,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: select 123\n\nQuestion: Hive query explain plan if available\nAnswer: Just I try to execute a simple request, but I get a 401 error.\nNormaly my non-federated account executing the job has right and should work: {emailpii}@sgazureprd.onmicrosoft.com\n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: ent: /{Alphanumericpii}, server: zk2-zkympe.sgazureprd.onmicrosoft.com/10.3.94.68:2181\n2020-03-17 {Alphanumericpii} INFO [main-SendThread(zk2-zkympe.sgazureprd.onmicrosoft.com:2181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server zk2-zkympe.sgazureprd.onmicrosoft.com/10.3.94.68:2181, sessionid = {Alphanumericpii}, negotiated timeout = 60000\n2020-03-17 {Alphanumericpii} INFO [main-EventThread] org.apache.curator.framework.state.ConnectionStateManager: State change: CONNECTED\n2020-03-17 {Alphanumericpii} INFO [{Alphanumericpii}] org.apache.curator.framework.imps.CuratorFrameworkImpl: backgroundOperationsLoop exiting\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.zookeeper.ZooKeeper: Session: {Alphanumericpii} closed\n2020-03-17 {Alphanumericpii} INFO [main-EventThread] org.apache.zookeeper.ClientCnxn: EventThread shut down\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hive.jdbc.Utils: Resolved authority: hn1-zkympe.sgazureprd.onmicrosoft.com:10001\n2020-03-17 {Alphanumericpii} ERROR [main] org.apache.hive.jdbc.HiveConnection: Error opening session\norg.apache.thrift.transport.TTransportException: HTTP Response code: 401\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.mapred.Task: {AlphanumericPII} is done. And is in the process of committing\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.mapred.Task: Task '{alphanumericpii}' done.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - select 123;\nHive query explain plan if available - Just I try to execute a simple request, but I get a 401 error.\nNormaly my non-federated account executing the job has right and should work: {emailpii}@sgazureprd.onmicrosoft.com;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - ent: /{Alphanumericpii}, server: zk2-zkympe.sgazureprd.onmicrosoft.com/10.3.94.68:2181\n2020-03-17 {Alphanumericpii} INFO [main-SendThread(zk2-zkympe.sgazureprd.onmicrosoft.com:2181)] org.apache.zookeeper.ClientCnxn: Session establishment complete on server zk2-zkympe.sgazureprd.onmicrosoft.com/10.3.94.68:2181, sessionid = {Alphanumericpii}, negotiated timeout = 60000\n2020-03-17 {Alphanumericpii} INFO [main-EventThread] org.apache.curator.framework.state.ConnectionStateManager: State change: CONNECTED\n2020-03-17 {Alphanumericpii} INFO [{Alphanumericpii}] org.apache.curator.framework.imps.CuratorFrameworkImpl: backgroundOperationsLoop exiting\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.zookeeper.ZooKeeper: Session: {Alphanumericpii} closed\n2020-03-17 {Alphanumericpii} INFO [main-EventThread] org.apache.zookeeper.ClientCnxn: EventThread shut down\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hive.jdbc.Utils: Resolved authority: hn1-zkympe.sgazureprd.onmicrosoft.com:10001\n2020-03-17 {Alphanumericpii} ERROR [main] org.apache.hive.jdbc.HiveConnection: Error opening session\norg.apache.thrift.transport.TTransportException: HTTP Response code: 401\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.mapred.Task: {AlphanumericPII} is done. And is in the process of committing\n2020-03-17 {Alphanumericpii} INFO [main] org.apache.hadoop.mapred.Task: Task '{alphanumericpii}' done.\n;\n\n- ProblemStartTime: 03/15/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ebf66878-48ac-499a-87d2-942dc602407c/resourceGroups/central_feeder-DEV-rtgasi-negotiation-feeder6-Automation-HDI/providers/Microsoft.HDInsight/clusters/zKymPEhSsC-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error during Hive job,0.579532575,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Error during Hive job,Error during Hive job,"Support checked and suggested that there is a problem with the on-premises Active Directory instance for your HDInsight cluster: the AllowCloudPasswordValidation  policy has not been set by the tenant. Kerberos relies on password hashes and you must enable password hash sync on Azure AD DS. The administrator of the Azure Active Directory (AAD) tenant should update settings to allow the use of password hashes for Active Directory Federation Services (ADFS) backed users.  Recommended Steps​ To setup the AllowCloudPasswordValidation policy, follow the commands in the documentation for Azure Active Directory Domain Services. Supporting Documentation - https://docs.microsoft.com/en-us/azure/hdinsight/domain-joined/apache-domain-joined-architecture#on-premises-active-directory-or-active-directory-on-iaas-vms",,,,,,,,
1.20032E+14,10:39.9,ATS Check failed on Hive service checks,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 17, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Unable to access Hive view from Ambari UI\n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hive view not accessible from Ambari. ATS Check fails.\n\nBelow is the error:\n\nFATAL distributedshell.ApplicationMaster: Error running ApplicationMaster\njava.lang.RuntimeException: Failed to connect to timeline server. Connection retries limit exceeded. The posted timeline event may be missing\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.publishApplicationAttemptEvent(ApplicationMaster.java:1166)\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nHive query if applicable - Unable to access Hive view from Ambari UI;\nDoes the same query work through Beeline from the Headnode? - Other, don't know or not applicable;\nAdditional details about the issue - Hive view not accessible from Ambari. ATS Check fails.\n\nBelow is the error:\n\nFATAL distributedshell.ApplicationMaster: Error running ApplicationMaster\njava.lang.RuntimeException: Failed to connect to timeline server. Connection retries limit exceeded. The posted timeline event may be missing\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.publishApplicationAttemptEvent(ApplicationMaster.java:1166)\nat {AlphanumericPII})\nat {AlphanumericPII});\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/17/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Novelis Global\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5f5c5be9-a2dd-49c9-bfa1-77d4db790171/resourceGroups/GlobalDAPDEV/providers/Microsoft.HDInsight/clusters/gldevhdcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ATS Check failed on Hive service checks,0.22254698,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\Hive View,Hive view not accessible from Ambari,Yarn Timeline server connectivity issue with active headnode,Restarted headnode(s) - You can try to restart Yarn Timeline Server from the UI,180180588,,,,,,,
1.20032E+14,21:28.7,Need details from old ticket #119030723003161,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: Please provide details of ticket #{Phonenumberpii} which I can no longer view. I need these details to help correct a current issue.\n\nQuestion: Additional details about the issue\nAnswer: Please provide details of ticket #{Phonenumberpii} which I can no longer view. I need these details to help correct a current issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - Please provide details of ticket #{Phonenumberpii} which I can no longer view. I need these details to help correct a current issue.;\nAdditional details about the issue - Please provide details of ticket #{Phonenumberpii} which I can no longer view. I need these details to help correct a current issue.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AMN Corporate\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33e633b-9520-48b4-ad05-a81922877e8b/resourceGroups/co-wus2-ifwhdi-rg-p01/providers/Microsoft.HDInsight/clusters/hbasecowus2ifwhdiclusp01\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need details from old ticket #119030723003161,0.016369169,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Perforamance issues during large data transfers ,Similar to 119030723003161Misconfigured lifetime KB setting,Provided information from SR 119030723003161Increased lifetime in KB setting because cx did not want to remove it entirely,,,,,,,,
1.20032E+14,09:52.3,High read and write latencies in hbase,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 9:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: REST API\n\nQuestion: Additional details about the issue\nAnswer: Seeing ~20 secs in write latency.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - REST API;\nAdditional details about the issue - Seeing ~20 secs in write latency.;\n\n- ProblemStartTime: 03/16/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search PRD ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/112d7591-4d06-4945-8323-c9ef2f70158a/resourceGroups/adobeidx-prod-hbase/providers/Microsoft.HDInsight/clusters/adobeidxhbaseprodva7\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",High read and write latencies in hbase,12.81978782,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,"One sample row data in hbase table:hbase(main):001:0> get 'Queue-SC-Slow', 'B06:P0:1584489168424:urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-f698c9134213:18:1584489167309'COLUMN                                     CELLevd:d                                     timestamp=1584489168426, value={""id"":""urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-f                                                                                      698c9134213"",""timestamp"":""1584489168425"",""application_name"":""creative_cloud"",""event_type"":""pubs_mapping_upsert"",""event_tracking_id"":""800b3daf-80c0-41c5-9180-67d2683c3680.1-3-US-1-2412349f-a473-4dc0-a83b-fd5e464e0fff"",""ordering_date"":0,""ordering_version"":1584489167309,""priority"":0,""payload"":{""asset_id"":""urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-698c9134213"",""owner_id"":""07D48BE156BA2A237F000101AdobeID"",""owner_type"":""USM"",""target"":{""asset_id"":""urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-698c9134213"",""owner_id"":""07D48BE156BA2A237F000101@AdobeID"",""region"":""US""}}} status:d                                  timestamp=1584489168988, value=success Server timestamps After initial write:“ColumnFamily: evd” cellv1 1584489168426 -  March 17, 2020 11:52:48.426 PM“ColumnFamily: Status” cellv1 1584489168426 - March 17, 2020 11:52:48.426 PM (Inferred based on evd timestamp - cellv1, since actual data is missing) After the processor scans the data and marks status as done:“ColumnFamily: Status” cellv2 1584489168988 - Tuesday, March 17, 2020 11:52:48.988 PM Below are the client log used for investigation corresponding to this rowkey:After successful write:3/17/20 4:52:48.432 PM 2020-03-17 23:52:48.432 GMT INFO rid=sEnw81URUVaFpAzorqr9Qj7SEmc6cZLT cid=NA 3178 --- [ool-2-thread-13] c.a.i.writer.HbaseMultiplyTableWriter : success for row key : B06:P0:1584489168424:urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-f698c9134213:18:1584489167309 First RangeScan that did not find the row: 2020-03-17 23:52:48.614 c.a.i.s.HbaseScanner [INFO] HbaseScanner:: Scan result count:0, countNewRows:0, sourceSize:0, table:Queue-SC-Slow, prefix:B06, startTime:1584489120672(March 17, 2020 11:52:00.672 PM), endTime:1584489168606 (March 17, 2020 11:52:48.606 PM), consumer:sharedcloud_slowSecond RangeScan that did not find the row:2020-03-17 23:52:49.270 c.a.i.s.HbaseScanner [INFO] HbaseScanner:: Scan result count:0, countNewRows:0, sourceSize:0, table:Queue-SC-Slow, prefix:B06, startTime:1584489120678 (March 17, 2020 11:52:00.678 PM), endTime:1584489169262, consumer:sharedcloud_slow (March 17, 2020 11:52:49.26 PM)After few Range scans that did not find the row, here is the range scan that finds the row:2020-03-17 23:53:11.995 c.a.i.s.HbaseScanner [INFO] HbaseScanner:: Scan result count:1, countNewRows:1, sourceSize:1, table:Queue-SC-Slow, prefix:B06, startTime:1584489166182 (March 17, 2020 11:52:46.182 PM), endTime:1584489191984 (March 17, 2020 11:53:11.984 PM), consumer:sharedcloud_slow.Below is the data returned from RangeScan:2020-03-17 23:53:11.995 c.a.i.s.HbaseScanner [INFO] HbaseScanner::tuple:B06:P0:1584489168424:urn:aaid:sc:us:1a9bb0ea-4d6a-4ce4-9396-f698c9134213:18:1584489167309, event_type:pubs_mapping_upsert, application_name:null, h_timestamp:1584489168426 asset_name: null adding to queue","Adobe wanted to use this investigation to find why for one the slow tables 'Queue-SC-Slow', the newly written row was not returned in the get call for about 20 seconds in some cases. While investigating this we found that some range scan queries do not return the results because they were not looking for the correct start and end timestamps which is expected behavior from HBase. The client keeps the a sliding time window and it takes some time before it queries for the correct time window after which it finds the rowkey that was written around 20 seconds back and it updates a column family named “status”. But while looking at the timestamps on the server we see that update to “status” column family happens within 0.5 seconds after the initial write (the original timestamp of “status” family is not recorded anywhere since table is configured to store only latest cell values and timestamp. Client side logging also doesn’t capture it. We could only make a best guess based on to “evd” column family’s timestamp which was written only once according to Adobe team). This does not make sense since the clients seem to get the records only after 20 seconds. We see there is a disconnect in the timestamps and the logging.","To clarify the confusion in timestamps, here are our asks from Adobe team:  Add more logging on client side to record current values and timestamps of the      “evd” and “status” column families after the successful scan that finds the record (before doing the actual update)Check if the client logs are logging actual values in start and end keys of the scan object that is passed to server (and not the values from local variables which store the timestamps), if not add them.Try adding a point get based on rowkey soon after write was successful to see if the data that was just written is readable. We expect this to work.","180,178,890,180,178,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.20032E+14,40:55.3,Want to limit file sizes generated in storage account to less than 1 GB,We are trying to copy the files from the storage account that are generated during the create table command in hive.  The files that are generated can end up quite large and we want to limit the size if possible to less than a given size of 1 GB\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA Team\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/twoprocesshistorical\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Want to limit file sizes generated in storage account to less than 1 GB,41.05427879,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\General Guidance or Advisory,Files for paraquet are greater than 1GB and that is too large.,File performance issues,From what I’m looking at here https://hudi.apache.org/docs/concepts.html#table-types if they are looking to minimize file size for performance as large parquet files are known for having terrible performance they would want to choose MOR instead of COW also per https://cwiki.apache.org/confluence/display/HUDI/FAQ#FAQ-Whatisthedifferencebetweencopy-on-write(COW)vsmerge-on-read(MOR)storagetypes and also sort of mentioned in our Azure documentation https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-optimize-hive-query#hive-partitioning,,,,,,,,
1.20032E+14,28:27.5,Hive usage from Ranger,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: This LLAP is domain joined and ranger setup is completed.\n\nNow im trying to pull usage report from ranger but unable to perform the same. Is there anyway i can get the  hive usage report with include Table Last Hit time?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - This LLAP is domain joined and ranger setup is completed.\n\nNow im trying to pull usage report from ranger but unable to perform the same. Is there anyway i can get the  hive usage report with include Table Last Hit time?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llapdjenterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive usage from Ranger,0.834229929,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Metrics are missing\Spark,N/A,"Customer wanted to generate a custom dashboard for their Data Analysts to manage the assets in their corp data lake.  The Hive audit data generated by Ranger contained all of the required data points, and customer was seeking assistance with gaining access to the raw dataset","The audit data is stored in log files in the /rager/audit folder and is organized by plugin, and then by date",,,,,,,,
1.20032E+14,31:13.5,Query Delta Lake Format from LLAP,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: jdbc:hive2://llaphdi4enterprisedev-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2;\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I have created a {Namepii} Format table in Azure Databricks and trying to read from LLAP {Namepii} but it is not supported. \n\nKindly let me know any fesible version which support {Namepii} format\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - jdbc:hive2://llaphdi4enterprisedev-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2;;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nAdditional details about the issue - I have created a {Namepii} Format table in Azure Databricks and trying to read from LLAP {Namepii} but it is not supported. \n\nKindly let me know any fesible version which support {Namepii} format;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llapdjenterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Query Delta Lake Format from LLAP,9.761105753,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,Customer advisory question.,Unsupported feature,Provided customer with a possible workaround using this connector ttps://github.com/delta-io/connectors but clarified we cannot support it if there are any issues. Customer is working with Databricks support on this as well.,,,,,,,,
1.20032E+14,49:31.0,ADF QA : kp01sparkadfhdiqausc02 : HDP 2.5 Support for Python3,"HDP 2.6 (HortonWorks Data Platform) does not support {Alphanumericpii}. \n\nPython 2 End of Life Announced as January 1st 2020\n\nWhat is Microsoft plan to upgrade the edge nodes ? Will we be getting a patch ?\n\nSince our applications now use {Alphanumericpii}, we need solution to support {Alphanumericpii} on HDP 2.6\n\nSolutions checked \nhttps://stackoverflow.com/questions/52874985/how-to-enable-python3-support-on-hdp-2-6\n\n\nProblem start date and time\n{Namepii}, {Namepii} 17, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/17/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-edpcore-qa-01/providers/Microsoft.HDInsight/clusters/kp01sparkadfhdiqausc02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF QA : kp01sparkadfhdiqausc02 : HDP 2.5 Support for Python3,70.48246521,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\General Guidance or Advisory,ADF QA : kp01sparkadfhdiqausc02 : HDP 2.5 Support for Python3,ADF QA : kp01sparkadfhdiqausc02 : HDP 2.5 Support for Python3,"We have worked with product group on this and they confirmed that Python3 is not yet supported and is in pipeline. Unfortunately, there are no timelines. Also, product group confirmed that ""hdp-select"" is not supposed to be used by applications as it is internal to Ambari.",180621238,,,,,,,
1.20032E+14,05:19.7,Cluster creation is failed,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Due to the spark thrisftserver failure the cluster creation is failed with terminal provisioning failure.\n\nThrift-Service-Log:\nRefer attachment\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Due to the spark thrisftserver failure the cluster creation is failed with terminal provisioning failure.\n\nThrift-Service-Log:\nRefer attachment\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e1a4b2a0-5a84-40e9-ad02-f848703150d5/resourceGroups/DEVPMEHDIRG-NE/providers/Microsoft.HDInsight/clusters/devpromehdi01\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster creation is failed,0.033509981,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Unable to create the cluster in NE and WE regions due to capacity,Cluster creation is failed,"Provided the temporary workarounds to get pass the issue and you are in follow up with our TAM through other SR, so archiving it as confirmed","180,436,884,180,473,000",,,,,,,
1.20032E+14,29:38.4,Could not run hive queries due to error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select * from cdm.banner\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: could not run hive queries due to below error.\n\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.io.IOException: Password {alphanumericpii} not found\n\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.io.IOException: Password {alphanumericpii} not found\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select * from cdm.banner;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - could not run hive queries due to below error.\n\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.io.IOException: Password {alphanumericpii} not found\n\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.io.IOException: Password {alphanumericpii} not found\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Development 01 (S06)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5d5922ed-d956-4fc6-8321-a23bb580a577/resourceGroups/RS06UE2DInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs06e2diphdigen2dm04\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Could not run hive queries due to error,0.055538848,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Could not run hive queries due to error,"cluster was running on Gen2 as a primary storage, but Hive metastore data is stored in Gen1. Azure HDInsight cluster 3.6/4.0 doesn't support both data lake storage Gen2 and Gen1 and these are not compariable each other to be interchangeable data share",re-create the Hive Metastore & data in AZ data Lake Gen2,,,,,,,,
1.20032E+14,38:01.8,our dns in sao paulo has no route to hdinsight in virginia,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have dns replicated in both sao paulo and virginia, but the services that use the dns of sao paulo are unable to connect to HDinsight in virginia, I did the connection tests on dns {Ipaddresspii} and {Ipaddresspii} and there is no route to wn0- prd1-s.g03w25behl4exjai3gf5st54rb.cx.internal.cloudapp.net.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - We have dns replicated in both sao paulo and virginia, but the services that use the dns of sao paulo are unable to connect to HDinsight in virginia, I did the connection tests on dns {Ipaddresspii} and {Ipaddresspii} and there is no route to wn0- prd1-s.g03w25behl4exjai3gf5st54rb.cx.internal.cloudapp.net.;\n\n- ProblemStartTime: 03/16/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Sponsorship(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/30a25c0e-1b63-4aa3-9240-834cf5725970/resourceGroups/bdata-prd/providers/Microsoft.HDInsight/clusters/prd1-scdf-kafka\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",our dns in sao paulo has no route to hdinsight in virginia,1.264342139,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Service unhealthy\Kafka,add new DNS servers  to the Vnet,how to add the DNS servers to Vnet that is used by HDI clusters,not recommended to make VNet changes with the cluster deployed,,,,,,,,
1.20032E+14,55:55.9,Unable to connect spark-shell to hive ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Unable to connect spark-shell to hive \n\nQuestion: Additional details about the issue\nAnswer: Unable to connect spark-shell to hive \n\nkinit -kt {alphanumericpii} {alphanumericpii}\n{alphanumericpii}$ spark-shell\nSPARK_MAJOR_VERSION is set to 2, using {Alphanumericpii}\nSetting default log level to 'WARN'.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n20/03/18 11:46:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n20/03/18 11:46:42 WARN HiveConf: HiveConf of name hive.llap.daemon.service.hosts does not exist\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - Unable to connect spark-shell to hive ;\nAdditional details about the issue - Unable to connect spark-shell to hive \n\nkinit -kt {alphanumericpii} {alphanumericpii}\n{alphanumericpii}$ spark-shell\nSPARK_MAJOR_VERSION is set to 2, using {Alphanumericpii}\nSetting default log level to 'WARN'.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n20/03/18 11:46:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n20/03/18 11:46:42 WARN HiveConf: HiveConf of name hive.llap.daemon.service.hosts does not exist;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect spark-shell to hive ,0.082362189,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,connetion to spark shell issues,rights issue with ID used,grant appropriate rights,,,,,,,,
1.20032E+14,25:45.3,Head node seems down,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 18, 2020, 8:30 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I receveid an alert tiggered by log analytics regarding heartbeat not found. I tried to open Ambari but the host doesn't answer. I checked the brokers using NewRelic agent and it seems brokers and zookeeper nodes are healthy.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - I receveid an alert tiggered by log analytics regarding heartbeat not found. I tried to open Ambari but the host doesn't answer. I checked the brokers using NewRelic agent and it seems brokers and zookeeper nodes are healthy.;\n\n- ProblemStartTime: 03/18/2020 11:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/demand-impact-prod/providers/Microsoft.HDInsight/clusters/prodik-azwus-prod-demandimpact-kafka001\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head node seems down,0.228376609,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Ambari UI is not loading,Not able to access the ambari ui.,"we noticed that some issue between the your system and the public load balancer which is not allowing the connection to passthrough.By using the private url https://<CLUSTERNAME>-int.azurehdinsight.net as well as a public endpoint. Note the “-int” in this URL, this endpoint will resolve to a private IP in that virtual network and is not accessible from the public Internet.https://azure.microsoft.com/en-us/blog/secure-incoming-traffic-to-hdinsight-clusters-in-a-vnet-with-private-endpoint/","we noticed that some issue between the your system and the public load balancer which is not allowing the connection to passthrough.By using the private url https://<CLUSTERNAME>-int.azurehdinsight.net as well as a public endpoint. Note the “-int” in this URL, this endpoint will resolve to a private IP in that virtual network and is not accessible from the public Internet.https://azure.microsoft.com/en-us/blog/secure-incoming-traffic-to-hdinsight-clusters-in-a-vnet-with-private-endpoint/",180337467,,,,,,,
1.20032E+14,25:09.3,CRITICAL || PREM || Azure HDInsight Service || HD insigts cannot connect to the database,HD insigts cannot connect to the database,CRITICAL || PREM || Azure HDInsight Service || HD insigts cannot connect to the database,10.27866531,Root Cause : HDInsight Service\Configuration\Other,,Unable to restart HS2llap,HDinsigts cannot connect to the database,"Made/revert some config changes and tried LLAP restart worked fine. As an alternative for Hive view, recommended to use DAS, VSCode and Zeppelin in HDI 4.0 and works for ESP",180359933,,,,,,,
1.20032E+14,57:04.0,Cluster is in 'Updating Error' state. Only disabling autoscale is allowed.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} has been stuck in '{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.' mode for 6 days\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} has been stuck in '{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.' mode for 6 days;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ENTRD.EDF.DEV.WEST\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fd0fd294-6d1b-4352-96ee-82d5b886ba69/resourceGroups/hdinsightsdtest/providers/Microsoft.HDInsight/clusters/hdinsightsdtest\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is in 'Updating Error' state. Only disabling autoscale is allowed.,0.034513391,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Delete HDInsight cluster,Cluster is in 'Updating Error' state. ,bad NSG,using the service tags for HDInsight if possible ( instructions found here https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-service-tags) . ,180345220,,,,,,,
1.20032E+14,02:45.8,Jupyter service starts then automatically gets stopped,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 11, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: n/a\n\nQuestion: Additional details about the issue\nAnswer: Jupyter service starts then automatically fails and goes into Stopped state.\nWe've been checking the logs and find out that Python version 2.7 is being used by Jupyter to start. This is currently a problem as Jupyter Hub works only with Python version 3.5.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - n/a;\nAdditional details about the issue - Jupyter service starts then automatically fails and goes into Stopped state.\nWe've been checking the logs and find out that Python version 2.7 is being used by Jupyter to start. This is currently a problem as Jupyter Hub works only with Python version 3.5.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/11/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AIP_Accenture_Suscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/143d2f0e-0601-41f0-bd83-9d240e4a928d/resourceGroups/avieucapznzac01/providers/Microsoft.HDInsight/clusters/AviancaHDPRDcluster\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jupyter service starts then automatically gets stopped,2.202259326,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Jupyter service starts then automatically gets stopped,This cluster is so old that it hit a bug that's been fixed in newer clusters.,The cluster is old and suggested that it’s better to re-deploy the cluster as there have been many updates to the jupyter service to fix known issues since its last used.,,,,,,,,
1.20032E+14,56:48.5,PRDSUP : kp10tntncapllapnsprdsup01 :NodeManager Health -no more usable space,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 18, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: PRDSUP : {alphanumericpii} :: NodeManager Health -no more usable space\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: PRDSUP : {alphanumericpii} :: NodeManager Health -no more usable space. \nWe can found one application master took more than 600 G space.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - PRDSUP : {alphanumericpii} :: NodeManager Health -no more usable space;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - PRDSUP : {alphanumericpii} :: NodeManager Health -no more usable space. \nWe can found one application master took more than 600 G space.;\n\n- ProblemStartTime: 03/18/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP : kp10tntncapllapnsprdsup01 :NodeManager Health -no more usable space,0.108709207,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,PRDSUP : kp10tntncapllapnsprdsup01 :NodeManager Health -no more usable space,PRDSUP : kp10tntncapllapnsprdsup01 :NodeManager Health -no more usable space,"Worked with customer and checks done are - 1/1 local-dirs usable space is below configured utilization percentage/no more usable space [ /mnt/resource/hadoop/yarn/local : used space above threshold of 90.0% ] ; 1/1 log-dirs usable space is below configured utilization percentage/no  more usable space [ /mnt/resource/hadoop/yarn/log : used space above threshold of 90.0% ] ​​1. Ran below command to check the files consuming over 1GB​$ sudo find / -size +1000M -print0 | xargs -0 ls -l​​2. Above command returned few files that were consuming few 10's of GB's on /mnt​​3. (Sample file below)... we see that YARN application is ""application_1584404787868_0018"" and DagID is ""1584404787868_0018_8"" and ""1584404787868_0018_8_05"" represents vertex ID.​​/mnt/resource/hadoop/yarn/local/usercache/hive/appcache/application_1584404787868_0001/usercache/hive/appcache/application_1584404787868_0018/8/attempt_1584404787868_0018_8_05_000000_36_12517_src_142_spill_268.merged65​​4. We had checked if the DagID is still running and found it in failed state.​​5. Found that the query had started on 2020-03-17 ~17:01 UTC and vertex had failed at 2020-03-18 17:48 UTC​​6. You found that the above was the DAG ID consuming space on all worker nodes (WN12, WN14, WN7).​​7. You had successfully deleted files on all nodes as below:​$ /mnt/resource/hadoop/yarn/local/usercache/hive/appcache/application_1584404787868_0001/usercache/hive/appcache/application_1584404787868_0018/8/attempt_1584404787868_0018_8_*​​8. After deletion, you could see that free space available came down to ~18% on the nodes.​$ df -h​The above steps had helped create space on the nodes and customer confirmed to close the case.",,,,,,,,
1.20032E+14,02:31.9,Not able to reset admin crecential,See attached screenshot\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Outlook SVC {Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: japaneast\n- Location: Japan East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Not able to reset admin crecential,0.852119337,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Not able to reset admin credential.,Pop-up menu to enter new password was not showing up due to glitch,Tried to reset credential again and it worked for the second time.,,,,,,,,
1.20032E+14,50:22.4,How to connect multiple ADLS Gen2 with a single HD Insight interactive cluster,"I want to know if we can connect multiple ADLS {Alphanumericpii} storage accounts with a single HD Insight interactive cluster.\n\nAlso, is it possible to change the ADLS storage associated with an existing HD Insight cluster?\n\nProblem start date and time\nWed, {Namepii} 18, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/18/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data-n-Analytics-Nonprod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7ceab26f-148c-455c-bdec-84510ab01220/resourceGroups/RG-BI-SCV-Dev/providers/Microsoft.HDInsight/clusters/azwus-scv-hdiInteractiveQuery-dev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to connect multiple ADLS Gen2 with a single HD Insight interactive cluster,14.65838685,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\General Guidance or Advisory,advisory,Advisory,"My recommendations:Data Lake Storage Gen2 is available as a storage option for almost all Azure HDInsight cluster types as both a default and an additional storage account. As for changing the ADLS storage associated with an existing HD Insight cluster, that is not possible.  You would need to drop and redeploy a cluster to change its primary storage.Here is some documentation that might be useful...https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-storage-gen2PLease let me know if you have further questions i can answer.My recommendations:Data Lake Storage Gen2 is available as a storage option for almost all Azure HDInsight cluster types as both a default and an additional storage account. As for changing the ADLS storage associated with an existing HD Insight cluster, that is not possible.  You would need to drop and redeploy a cluster to change its primary storage.Here is some documentation that might be useful...https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-storage-gen2PLease let me know if you have further questions i can answer.",,,,,,,,
1.20032E+14,40:50.5,Cluster is not coming in running state,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 19, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is not coming in running state. The cluster creation was running for a long time ( greater than 1 hr which ideally takes {Alphanumericpii}) and after that the cluster was coming in an error state. Currently, it is stuck in 'Azure VM Configuration' state. We are unable to use the cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - {Namepii} is not coming in running state. The cluster creation was running for a long time ( greater than 1 hr which ideally takes {Alphanumericpii}) and after that the cluster was coming in an error state. Currently, it is stuck in 'Azure VM Configuration' state. We are unable to use the cluster;\n\n- ProblemStartTime: 03/18/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: diageo-analytics-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3a683d84-be08-4356-bb14-3b62df1bad55/resourceGroups/diageo-analytics-prod-rg-datalake/providers/Microsoft.HDInsight/clusters/diageo-eun-analytics-prod-hdi-hd-prd02\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is not coming in running state,0.171382929,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,capacity issue on data center,Cluster is not coming in running state,Recommended to try to use F v2 beta VMs because of the capacity issue on data center,"180,436,884,180,494,000",,,,,,,
1.20032E+14,30:56.8,Users not able to see databases in HIVE,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 18, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 18, 2020, 11:00 PM MST\n\nQuestion: Does Ambari login work?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Can you log in to Ranger using the cluster local admin credential?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: All the users are not able to see their databases except default in HIVE, i tried to restart the RANGER, but no luck. We have created policies in Ranger and are working fine since yesterday. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nDoes Ambari login work? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes kinit for some or all users work from the Head node? - ;\nCan you log in to Ranger using the cluster local admin credential? - ;\nDoes authentication fail even for the cluster admin account? - ;\nAdditional details about the issue - All the users are not able to see their databases except default in HIVE, i tried to restart the RANGER, but no luck. We have created policies in Ranger and are working fine since yesterday. ;\n\n- ProblemStartTime: 03/19/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Users not able to see databases in HIVE,0.406413866,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Authentication failure\Ranger in cluster with Enterprise Security Package,Unable to use the group in Ranger polocies,Users not able to see databases in HIVE,"It’s an issue with Group name (which has more than 20 characters), so as a workaround ; please create a new group (should have less than 20 characters) and nest old group in to it",180489752,,,,,,,
1.20032E+14,10:40.4,WN2 is loosing heartbeat. Please restart it from backend.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Worker node 2 is loosing heartbeat. And, unable to SSH. Please restart it from backend and confirm ASAP.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Worker node 2 is loosing heartbeat. And, unable to SSH. Please restart it from backend and confirm ASAP.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",WN2 is loosing heartbeat. Please restart it from backend.,0.037622169,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,WN2 is losing heartbeat. Please restart it from backend.,Not able to SSH due to heartbeat lost,Restarted the Ambari-agent on the worker node once you were able to SSH into it. Also rebooted the worker node from my end.,,,,,,,,
1.20032E+14,31:50.1,Node unresponding,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi,\n\nOn this MLAK cluster, I have one node not responding.\nI cannot even log on, ther server is not responding.\n\n{Ipaddresspii} wn1098-dev-ml.p0rm5d4sb1vuhbvqrujaitptjf.ax.internal.cloudapp.net\n\nCan you please reboot this node, I cannot.\n\nThanks\nRgds\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi,\n\nOn this MLAK cluster, I have one node not responding.\nI cannot even log on, ther server is not responding.\n\n{Ipaddresspii} wn1098-dev-ml.p0rm5d4sb1vuhbvqrujaitptjf.ax.internal.cloudapp.net\n\nCan you please reboot this node, I cannot.\n\nThanks\nRgds\n{Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}., Platform & Solution Enablement (CZ)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cacc39b3-c703-4ddc-97a4-bfc9ccdb57aa/resourceGroups/DEV-MLAK-RESGROUP-SPARK-MDEEA/providers/Microsoft.HDInsight/clusters/Dev-MLAK-HDI36-SPARK23-MDEEA\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Node unresponding,0.170600172,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,unable to ssh and node is unresponsive,Node unresponding,Did a reboot and after that node is started working fine,,,,,,,,
1.20032E+14,03:07.9,kp10tntncapllapnsprdsup01: Queries are not returing the results,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: {alphanumericpii}: {Namepii} Are not returning the results\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {alphanumericpii}: {Namepii} Are not returning the {alphanumericpii}: {Namepii} Are not returning the results\n\nQuestion: Interactive query explain plan if available\nAnswer: {alphanumericpii}: {Namepii} Are not returning the results\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}: {Namepii} Are not returning the results\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - {alphanumericpii}: {Namepii} Are not returning the results;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {alphanumericpii}: {Namepii} Are not returning the {alphanumericpii}: {Namepii} Are not returning the results;\nInteractive query explain plan if available - {alphanumericpii}: {Namepii} Are not returning the results;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - {alphanumericpii}: {Namepii} Are not returning the results;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kp10tntncapllapnsprdsup01: Queries are not returing the results,0.220336324,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,HiveLLAP is down and queries are not returning results,kp10tntncapllapnsprdsup01:  Queries are not returing the results,"We observed 2 issues in this  cluster and see the details below,For, issue#1 - If inside our  ambari server we have some views (like Hive/File View ..etc) which is accessed  by many concurrent users Or if there are many users access the ambari UI  concurrently or makes Ambari Rest API calls. Then in such cases we should also  increase the ""client.threadpool.size.max"" property value (default values is 25)  inside the ""/etc/ambari-server/conf/ambari.properties"".  ""client.threadpool.size.max"" : The size of the Jetty connection pool used for  handling incoming REST API requests.We recommended below for Issue  #1,This should be large enough to  handle requests from both web browsers and embedded Views. Consider the  following guidance when planning for Views user capacity. An Ambari Views  server: On an 8-core box with 16GB of RAM  and client.threadpool.size.max = 100 can handle approximately 40 concurrent  usersOn an 16-core box with 32GB of RAM  and client.threadpool.size.max = 100 can handle approximately 60 concurrent  usersIncraesing the  ""client.threadpool.size.max"" value to ""100"" could give you relief but make sure  you need to increase the memory available to ambari views server. On the Ambari Server host, edit  the ambari-env.sh file.vi  /var/lib/ambari-server/ambari-env.shFor the AMBARI_JVM_ARGS variable,  replace the default -Xmx2048m with the following  value:-Xmx4096m -XX:PermSize=128m  -XX:MaxPermSize=128mRestart the  server.ambari-server  restart For Issue#2, related  to the LLAP stoppage.  It looks like this is related to authentication. We can see two  trends: Periodic GSS  Timeout, Periodic ZK Connection  failure. We suspect that the GSS timeout  may be caused by a failure to establish a connection to Zookeeper and do see  CancelledKeyExceptions near the end of 03/27. We suggest you to do it  periodically (ie: once per week) run the ZK snapshot cleanup steps  at https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-fails#next-steps Addressing ZK health should  address the ability to authenticate, which should address the ability to run  queries.  Authentication timeouts caused  queries to not execute. We see ZK health issues during time of impact, which  were addressed. We advise to peridoically cleanup ZK  snapshots (until they create a new cluster that will have this bugfix  enabled). ",,,,,,,,
1.20032E+14,40:15.7,hdfs FS is filling up faster than it should,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 19, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: More data to be processed\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: Ambari is reporting that the hdfs file system is 45% full but the processed data is only about 8TB. The Blob that is connected is no where near its 5PB capacity. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - More data to be processed;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - HBase shell;\nAdditional details about the issue - Ambari is reporting that the hdfs file system is 45% full but the processed data is only about 8TB. The Blob that is connected is no where near its 5PB capacity. ;\n\n- ProblemStartTime: 03/19/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard Free\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cb458380-a7fa-4c7a-befb-ac613cfe0138/resourceGroups/Internal_Development/providers/Microsoft.HDInsight/clusters/dec-poc-02\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hdfs FS is filling up faster than it should,0.69282769,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Unexpected result\Hbase,Ambari is reporting that the HDFS file system is 45% full but the processed data is only about 8TB even when the blob storagethat is connected is no where near its 5PB* capacity,HDInsight HBase cluster is not reflecting storage capacity requested on ticket 120031324003768,Follow the request in the 120031324003768 and increase the Storage Capacity,,,,,,,,
1.20032E+14,26:07.3,History of RAM,I want history of RAM from any node of the cluster.\n\nCan we get the last {Alphanumericpii} of RAM details?\n\nAny we see those details in Amabari UI.?\n\nWhat are the possibilities of getting it.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,History of RAM,0.330170408,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,They didn't know how to check the metrics for cluster nodes.,Client want it to check the historical RAM usage for the cluster.,Information was provided on how to check health and performance of an HDInsight cluster step-by-step referred on the follow link: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-key-scenarios-to-monitor,,,,,,,,
1.20032E+14,48:33.0,All the Fact CDL  Processing is getting failed due to JSON parameter could not be decoded at CDLEngine.py Process run Key:22540131,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 19, 2020, 11:00 PM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string being used\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer:   File '/mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1583409664652_9757/spark-83368cfa-25c4-453f-a351-998b2ece26e7/userFiles-a5631cc3-2d8f-462b-af0a-dcb6c087b57a/CDLEngine.py', line 2436, in send_control_totals\n    ct_types = json.loads(requests.get(apimg_control_totals_parameters, headers=headers).text)\n\n  File '/usr/bin/anaconda/lib/python2.7/json/__init__.py', line 339, in loads\n    return _default_decoder.decode(s)\n\n  File '/usr/bin/anaconda/lib/python2.7/json/decoder.py', line 364, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, {alphanumericpii}())\n\n  File '/usr/bin/anaconda/lib/python2.7/json/decoder.py', line 382, in raw_decode\n    raise ValueError('No JSON object could be decoded')\n\n\nThis is happening for two HD Insights\n\n1. {alphanumericpii} (CDL POS production)\n1. {alphanumericpii} (CDL Shipments production)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string being used - ;\nDoes Ambari login work? - Other, don't know or not applicable;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes hdfs dfs -ls / work? - Other, don't know or not applicable;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Other, don't know or not applicable;\nAdditional details about the issue -   File '/mnt/resource/hadoop/yarn/local/usercache/livy/appcache/application_1583409664652_9757/spark-83368cfa-25c4-453f-a351-998b2ece26e7/userFiles-a5631cc3-2d8f-462b-af0a-dcb6c087b57a/CDLEngine.py', line 2436, in send_control_totals\n    ct_types = json.loads(requests.get(apimg_control_totals_parameters, headers=headers).text)\n\n  File '/usr/bin/anaconda/lib/python2.7/json/__init__.py', line 339, in loads\n    return _default_decoder.decode(s)\n\n  File '/usr/bin/anaconda/lib/python2.7/json/decoder.py', line 364, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, {alphanumericpii}())\n\n  File '/usr/bin/anaconda/lib/python2.7/json/decoder.py', line 382, in raw_decode\n    raise ValueError('No JSON object could be decoded')\n\n\nThis is happening for two HD Insights\n\n1. {alphanumericpii} (CDL POS production)\n1. {alphanumericpii} (CDL Shipments production);\n\n- ProblemStartTime: 03/20/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1600256d-1898-4362-bd35-197e3da6cb60/resourceGroups/AZ-RG-CorePointOfSale-01/providers/Microsoft.HDInsight/clusters/cqmcbjh-hdi-corepos-proc-01\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",All the Fact CDL  Processing is getting failed due to JSON parameter could not be decoded at CDLEngine.py Process run Key:22540131,0.039999985,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to cluster with Enterprise Security Package,All the Fact CDL Processing is getting failed due to JSON parameter could not be decoded at CDLEngine.py Process run Key:22540131,authenticating the connection to your API apimg_control_totals_parameters ,internal API team needs to have  a look,,,,,,,,
1.20032E+14,37:25.0,Unable to read HiveServer2 configs from ZooKeeper,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 18, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Uploaded screen print. But Initial issue is connecting to beeline and DBVIZ.\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: User have been trying to establish the DBviz connection, But not able to establish a connection profile.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Uploaded screen print. But Initial issue is connecting to beeline and DBVIZ.;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - User have been trying to establish the DBviz connection, But not able to establish a connection profile.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/18/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to read HiveServer2 configs from ZooKeeper,0.011122234,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Unable to read HiveServer2 configs from ZooKeeper,Unable to read HiveServer2 configs from ZooKeeper,Worked with customer and identified multiple issues -NSG blocking communication to HDInsight cluster.Name resolution is not happening as source and HDInsight cluster are in different VNETHiveServer2 Interactive was stopped.Started HiveServer2 interactive service on the cluster and connectivity from DBVisualizer tool is restored. Customer approved to close the case.,,,,,,,,
1.20032E+14,12:57.1,Clusters failling - Production Env Affected,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 20, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes made\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: Error code\nAzureResourceCreationFailedErrorCode\n\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.\n\nThis issue is affecting Production enviroment as well as Development\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes made;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - Error code\nAzureResourceCreationFailedErrorCode\n\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.\n\nThis issue is affecting Production enviroment as well as Development;\n\n- ProblemStartTime: 03/19/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2634487e-4001-4f05-ad3e-92356f99c150/resourceGroups/RG-NEU-DEV-01-ARP-NLP-01/providers/Microsoft.HDInsight/clusters/spark-cluster-arp-nlp-dev-01\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Clusters failling - Production Env Affected,0.040554012,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Clusters failling - Production Env Affected - unable to deploy the cluster,West and East EU storage outage,wait out the outage,180436884,,,,,,,
1.20032E+14,28:07.7,FD Sand: kps024llapfdsbwus401:: The  HIS service is stopped in the cluster.,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 20, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: There was a issue in starting up the Hive service in https://kps024llapfdsbwus401-int.azurehdinsight.net {Namepii} which gets failed with errors related to Kerberos principal though we have Kerberos file in place \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - There was a issue in starting up the Hive service in https://kps024llapfdsbwus401-int.azurehdinsight.net {Namepii} which gets failed with errors related to Kerberos principal though we have Kerberos file in place ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/20/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps024llapfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sand: kps024llapfdsbwus401:: The  HIS service is stopped in the cluster.,0.008822886,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Unable to restart the LLAP service,FD Sand: kps024llapfdsbwus401:: The HIS service is stopped in the cluster.,"Found and fixed some permissions on /mnt/resource/hadoop/yarn/local and found issue on WN3 and WN1 as per YARN application log1. LLAP restart attempt failed and below messages on operation status log -WARN cli.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..​WARN cli.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..​2. We had pulled the YARN log for the application:application_1584743291639_006  related to LLAP restart.​main : run as user is hive​main : requested yarn user is hive​Permission mismatch for /mnt/resource/hadoop/yarn/local for caller uid: 203, owner uid: 0.​Couldn't get userdir directory for hive.​3. You had checked the permissions on /mnt/resource/hadoop/yarn/local and found issue on WN3 and WN1 as per YARN application log.​4. You had fixed the permissions on the above path on WN3 and WN1 inline to other worker nodes.​5. You had restarted LLAP application and it started successfully.",,,,,,,,
1.20032E+14,13:54.2,credentialservice.out is too large due to errors,"File /var/log/hdinsight-credentialservice/credentialservice.out keeps growing and it cannot be rotated\n\n{alphanumericpii}# ls -l /var/log/hdinsight-credentialservice/credentialservice.out\n-rw-rw-r-- 1 hcs hcs {Phonenumberpii} {Namepii} 20 18:09 /var/log/hdinsight-credentialservice/credentialservice.out\n{alphanumericpii}#\n\nUpon checking the logs, it contains several instances of below:\n\nCaused by: java.lang.SecurityException: Failed to security UGI org.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 249613 for hive) can't be found in cache\n...\nCaused by: org.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 249613 for hive) can't be found in cache\n\n1) We need to know what is causing this error and how to fix it?\n2) We need to know how to rotate the file /var/log/hdinsight-credentialservice/credentialservice.out\n\nThanks\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data and Analytics Services\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",credentialservice.out is too large due to errors,0.044928005,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\General Guidance or Advisory,Credentialservice.out file growing too large,Cause: Bug causing retention period to not stick,Patch was applied to all VMs,185457747,,,,,,,
1.20032E+14,20:19.7,HDI 4 : Hbase Sclae is not working ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}: scale up issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {alphanumericpii}: scale up issue;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps071hbasefdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI 4 : Hbase Sclae is not working ,4.055258324,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,User need guidance in scaleup/scaledown,HDI 4 : HBase Scale is not working,Worked with you and successfully did the scale up/scale down,,,,,,,,
1.20032E+14,28:48.0,FD QA :  kp05hbasefdhdiqausc01: Ambari agent heartbeat issue on ed21,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 20, 2020, 6:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: FD QA :  {alphanumericpii}: Ambari agent heartbeat issue on {alphanumericpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - FD QA :  {alphanumericpii}: Ambari agent heartbeat issue on {alphanumericpii};\n\n- ProblemStartTime: 03/21/2020 01:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kp05hbasefdhdiqausc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD QA :  kp05hbasefdhdiqausc01: Ambari agent heartbeat issue on ed21,5.984733617,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Ambari agent heartbeat issue on ed21,FD QA : kp05hbasefdhdiqausc01: Ambari agent heartbeat issue on ed21,Recommended to recreate the edgenode because of the ambari-server and ambari-agent version mismatch,,,,,,,,
1.20032E+14,16:08.2,"I have tried to shut down myclusternashinsky3, but I keep getting an error message saying that there is a 409 error. Please advise. ","Question: Problem Start Date\nAnswer: Fri, {Namepii} 20, 2020, 10:14 PM EDT\n\nQuestion: Refund Amount\nAnswer: 5\n\nQuestion: Reason for the Refund \nAnswer: \n\nQuestion: Please provide any additional details (if any)\nAnswer: See attached screenshot. I cannot close down my HDInsight cluste.r \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Billing:\nProblem Start Date - {ALPHANUMERICPII};\nRefund Amount - 5;\nReason for the Refund  - ;\nPlease provide any additional details (if any) - See attached screenshot. I cannot close down my HDInsight cluste.r ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/21/2020 02:14:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Sponsorship 2\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_BILLING\n- SupportPlanDisplayName: Basic support\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","I have tried to shut down myclusternashinsky3, but I keep getting an error message saying that there is a 409 error. Please advise. ",5.585865907,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure Billing V5\Refund request,"I have tried to shut down myclusternashinsky3, but I keep getting an error message saying that there is a 409 error. Please advise.","Leave at least 30 to 60 minutes between create and delete operations. Otherwise the operation may fail with the following error message:Conflict (HTTP Status Code: 409) error when attempting to delete a cluster immediately after creation of a cluster. If you encounter this error, wait until the newly created cluster is in operational state before attempting to delete it.",Cluster is already deleted.,,,,,,,,
1.20032E+14,08:34.4,MR Jobs/pipeline running slowly intermittently,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 21, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, {Namepii} 21, 2020, 6:00 PM GMT+5:30\n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: Need to reboot the cluster worker nodes and need assistance for that\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - NA;\nAdditional details about the issue - Need to reboot the cluster worker nodes and need assistance for that;\n\n- ProblemStartTime: 03/20/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AMN Corporate\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33e633b-9520-48b4-ad05-a81922877e8b/resourceGroups/co-wus2-ifwhdi-rg-p01/providers/Microsoft.HDInsight/clusters/hbasecowus2ifwhdiclusp01\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MR Jobs/pipeline running slowly intermittently,39.53386082,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,120032124000601 - MR Jobs/pipeline running slowly intermittently,"The intermittent cluster performance issues were due to a few backend nodes in the storage scale unit that were processing requests more slowly than expected. The backend storage team took manual action to remove these impacted nodes from the storage backend.Since taking this action, we have observed that disk latencies have returned back to expected levels. The Azure engineers are working with various monitoring components within our system to better detect this issue and proactively mitigate it in the future. We apologize for the impact this issue has caused on your HDInsight cluster.","Recommendations:The HDInsight Product Team provided the below recommendations to address the issues on the cluster:Create a new Hadoop cluster with D14_v2 SKU and 15-20 nodes since YARN utilization during peak workload was very high.There are worker nodes which you have in maintenance mode which cannot be removed dynamically. Even a scale down to 3 and back up won’t ensure that the ‘bad’ worker nodes will be removed. You are being billed for these and the Ambari services are continuing to look for these nodes.There are several improvements and updates which have been made to the HDInsight service since this cluster was created.You are using an HBase cluster which requires additional configurations and memory settings which are not needed for your current workflow.  Using a Hadoop cluster would give you more memory to allocate to the services which you are currently using such as MapReduce, Tez, and Spark.Resolution:AMN will work on a plan to move to a new cluster and create a new support request if assistance is needed during the migration. ","180,801,742,181,147,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.20032E+14,28:46.3,Reboot Worker Node 26,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 22, 2020, 6:30 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to SSH on worker node 26 and it's unresponssive. Please reboot the worker node 26 from backend and confirm back ASAP.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to SSH on worker node 26 and it's unresponssive. Please reboot the worker node 26 from backend and confirm back ASAP.;\n\n- ProblemStartTime: 03/22/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Reboot Worker Node 26,0.021686558,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Worker Node 26 is unresponsive.,Not able to SSH due to heartbeat lost,Rebooted the Worker node from the backend.,,,,,,,,
1.20032E+14,22:18.7,Yarnui not reachable,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 8:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The url is not reachable :\nhttps://catcluster.hdi.cat.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The url is not reachable :\nhttps://catcluster.hdi.cat.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster;\n\n- ProblemStartTime: 03/23/2020 12:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ea8d856b-f0d4-43e6-a00a-e7fe91533bca/resourceGroups/cat-DEV-CATCluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/YKw2TRb9Vo-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Yarnui not reachable,0.355836909,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Yarnui not reachable,NA,NA,,,,,,,,
1.20032E+14,42:57.8,External metastore requires public access to be enabled,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 20, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: NotCreated\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Using external metastore.\n\nOn Azure SQL firewall, setting 'Deny public network access' to NO works, setting to YES does not work.  Also, deploying with VNet Service Endpoints does not work.\n\nError message in first minute o\n'HiveConfigurationValidator' failed the validation. Error: 'Cannot connect to Hive metastore using user provided connection string.\n    \n'Use external metadata stores in Azure HDInsight' docs at  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-use-external-metadata-stores guide does not work and is out of date.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - NotCreated;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Using external metastore.\n\nOn Azure SQL firewall, setting 'Deny public network access' to NO works, setting to YES does not work.  Also, deploying with VNet Service Endpoints does not work.\n\nError message in first minute o\n'HiveConfigurationValidator' failed the validation. Error: 'Cannot connect to Hive metastore using user provided connection string.\n    \n'Use external metadata stores in Azure HDInsight' docs at  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-use-external-metadata-stores guide does not work and is out of date.;\n\n- ProblemStartTime: 03/20/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",External metastore requires public access to be enabled,0.083138361,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,External metastore requires public access to be enabled,By design,We should update the HDI docs to include the new image for SQL firewall blade and then clarify that the SQL Firewall is still tuned on when “Deny public network access” is no.  Updated the Docs. ,"181,195,363,181,195,000",,,,,,,
1.20032E+14,24:51.6,HBase cluster getting restarted during region node scaleup activity,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Complete HBase cluster gets restarted during scaleup activity.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Complete HBase cluster gets restarted during scaleup activity.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HBase cluster getting restarted during region node scaleup activity,16.92050175,Root Cause : HDInsight Service\Configuration\Hbase,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Complete HBase cluster gets restarted during scaleup and scale down activity.,"Microsoft delivered the fix for scale up activity and working successfully.Regarding scale down issue Microsoft will deliver the feature in two phases:  1) Operational Procedure: Microsoft will deliver it to Adobe on April 17th. The deliverable includes an ""interim fix"" and an operational procedure. As shared before, the procedure will allow Adobe to open a ticket specifying the nodes to scale down and Microsoft will scale down the nodes without having to restart HBase services.​ 2) Permanent fix: The permanent fix will allow Adobe to scale down nodes without any services restart and without having to contact Microsoft. The target date for this fix is end of September.More Information: We are maintain the dev ops tracking ADO2088 for this.","Microsoft delivered the fix for scale up activity and working successfully.Regarding scale down issue Microsoft will deliver the feature in two phases:  1) Operational Procedure: Microsoft will deliver it to Adobe on April 17th. The deliverable includes an ""interim fix"" and an operational procedure. As shared before, the procedure will allow Adobe to open a ticket specifying the nodes to scale down and Microsoft will scale down the nodes without having to restart HBase services.​ 2) Permanent fix: The permanent fix will allow Adobe to scale down nodes without any services restart and without having to contact Microsoft. The target date for this fix is end of September.More Information: We are maintain the dev ops tracking ADO2088 for this.","181,018,742,182,018,000",,,,,,,
1.20032E+14,36:49.5,PRDSUP: kpph18llapprdsupusc01 : HiveServer2 Interactive STOPPED,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 11:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Not able to access hive from ambari : error message :\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\nat {AlphanumericPII})\nat {AlphanumericPII})\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Not able to access hive from ambari : error message :\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Not able to access hive from ambari : error message :\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\nat {AlphanumericPII})\nat {AlphanumericPII});\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Not able to access hive from ambari : error message :\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph18.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph18.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\nat {AlphanumericPII})\nat {AlphanumericPII});\n\n- ProblemStartTime: 03/23/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kpph18llapprdsupusc01 : HiveServer2 Interactive STOPPED,0.004785546,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,PRDSUP: kpph18llapprdsupusc01 : HiveServer2 Interactive STOPPED,"We noticed two errors when this issue happened, both on hive server 2 and hive metastore.To add to this the root cause comes down to the disk space issues like we have seen on (120040721001576) where the host that has the interactive server running on is low on disk space which seems like has caused this issue.Article : https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/hdinsight-troubleshoot-out-disk-space Error: HDFS is running out of space for the following host(s): hn0-kpph18.i3pqnysmw2jufmkmo3tuf15qcb.gx.internal.cloudapp.net in the cluster",Restart HS2 interactive,181069867,,,,,,,
1.20032E+14,33:49.4,We are experiencing several unrelated errors in activities that try to create HDI clusters.,"Question: When did the problem start?\nAnswer: {Namepii}, {Namepii} 23, 2020, 11:20 AM {ALPHANUMERICPII}\n\nQuestion: Provide the Pipeline or Activity RunId.\nAnswer: {guidpii}\n\nQuestion: Please provide additional context for the error message you are encountering.\nAnswer: Several pipelines finished on an error:\n\n{guidpii}\n{Guidpii}\n{Guidpii}\n{guidpii}\n{guidpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Data Factory:\nWhen did the problem start? - {ALPHANUMERICPII};\nProvide the Pipeline or Activity RunId. - {guidpii};\nPlease provide additional context for the error message you are encountering. - Several pipelines finished on an error:\n\n{guidpii}\n{Guidpii}\n{Guidpii}\n{guidpii}\n{guidpii}\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/23/2020 16:20:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EY-CTSBP-PROD-Assurance-EY Blockchain {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: northeurope\n- ResourceUri: /subscriptions/af734886-ea52-4bdb-955f-017849f4dfa9/resourceGroups/EUNPBCANETRSG02/providers/Microsoft.DataFactory/factories/eunpbcaproadf02\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are experiencing several unrelated errors in activities that try to create HDI clusters.,0.101257342,Root Cause : HDInsight Service\COVID-19 Capacity Constraints,Routing Azure Data Factory V2\Pipeline or Trigger Execution Issue\Pipeline or Trigger Run Failure,We are experiencing several unrelated errors in activities that try to create HDI clusters.,Capacity issues in North Europe,Customer moved their workloads to US and their jobs are running fine. Confirmed on closuure. ,180436884,,,,,,,
1.20032E+14,15:21.4,Please increase our cores limit in centralus from 260 to 300,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: As we have a lot more traffic coming to Yammer, we need to scale our cluster up a little bit. Right now we have 260 cores limit in centralus and we are using 256. We would like to increase the the limit to 300 cores.\n\nThanks!\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - As we have a lot more traffic coming to Yammer, we need to scale our cluster up a little bit. Right now we have 260 cores limit in centralus and we are using 256. We would like to increase the the limit to 300 cores.\n\nThanks!;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Yammer - Analytics - CORP\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerevents-prod-central/providers/Microsoft.HDInsight/clusters/yammerevents-prod-central-d13\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Please increase our cores limit in centralus from 260 to 300,51.80538849,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure due to quota limit,Please increase our cores limit in central US from 260 to 300,Yammer has 250% increase in traffic over past 3 weeks,Capacity team has been increased the core limit to 300(in total) for DSv2 Series (XIO) - D13v2 VM in US Central region for subscription ID: f01565aa-2d94-41fb-a38f-5d158b3096c1. Note: Previously Capacity team has increased the core limit of Dv2 series VM.,,,,,,,,
1.20032E+14,31:50.1,/var/lib/spark2/shs_db keep growing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We see /{alphanumericpii} takes 22G of disk space, last week, now become 23G, which makes total disk usage 85%, after we delete all log files with `find /var/log -type f -delete' the disk usage still as high as 75%. How to safely clean it up?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We see /{alphanumericpii} takes 22G of disk space, last week, now become 23G, which makes total disk usage 85%, after we delete all log files with `find /var/log -type f -delete' the disk usage still as high as 75%. How to safely clean it up?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-NAM-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cda42e6-a623-4800-abdf-431ef3ec65e5/resourceGroups/o365ipdinam02-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdinam02-sp-wu01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",/var/lib/spark2/shs_db keep growing,0.027140207,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Alerts firing on Services\Spark,/var/lib/spark2/shs_db keep growing,"""spark2-defaults"": {""spark.history.fs.cleaner.enabled"": ""true"",""spark.history.fs.cleaner.interval"": ""7d"",""spark.history.fs.cleaner.maxAge"": ""90d""}were not been added to the spark-defaults.conf","Configuring the below parameters in spark-defaults.conf resolves the issuespark.history.fs.cleaner.enabled true,  => truespark.history.fs.cleaner.interval 7d, => 1dspark.history.fs.cleaner.maxAge 90d => 7d The conf file can be found in head node  - /etc/spark2/conf/ spark-defaults.conf",181367437,,,,,,,
1.20032E+14,35:06.0,Script Actions validation is failing,"Hello,\n\nSee the below error in script action though the blob/container is publicly available.\n\nFailed to submit script action: 'install chef'\nErrorCode: InvalidScriptLocation; ErrorDescription: Failed to validate script action at URI https://adobeidxstagechefsa.blob.core.windows.net/chefsecrets/install_chef.sh. Exception message: Script URI cannot be retrieved correctly. HTTP Status code: Forbidden.\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Script Actions validation is failing,17.80634232,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\General Guidance or Advisory,Unauthorized access.  ,Script access authentication error,"Give access to script action location, then script action validation and run was successful.  ",,,,,,,,
1.20032E+14,01:08.0,critical alerts on Ambari on head node 1 ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: seen some critical alerts on {alphanumericpii} of cluster for below components\nTimeline Service {Alphanumericpii} / YARN \n{Namepii} Metadata Server / IO {Namepii} \nHistory Server / {AlphanumericPII} \n\nwe restarted hn1 {Ipaddresspii}  to resolve this, but still seeing the same alerts on node\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - seen some critical alerts on {alphanumericpii} of cluster for below components\nTimeline Service {Alphanumericpii} / YARN \n{Namepii} Metadata Server / IO {Namepii} \nHistory Server / {AlphanumericPII} \n\nwe restarted hn1 {Ipaddresspii}  to resolve this, but still seeing the same alerts on node;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-cat-workload-rg/providers/Microsoft.HDInsight/clusters/dua98x-fbco-20200323-cat-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",critical alerts on Ambari on head node 1 ,0.152684869,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Spark,critical alerts on Ambari on head node 1,critical alerts on Ambari on head node 1,"Joined call with customer and worked on below to recover the services...When we joined the call, we see that ResourceManager on Hn1 was stopped and Spark Livy, webhcat was not running on Hn1.We had successfully restarted all pending restarts on Workernodes and services.Found YARN reporting 47 nodes as dead/decommissioned and we dont see any workernodes on the cluster.You had successfully restarted YARN and HDFS... and dead/decommissioned count got cleared on the cluster.HDFS was reporting ~25K under replicated blocks and on YARN, both RMs are going to standby mode.We tried to restart RM one of the other and zookeeper services, but no luck.We ran below command to fix zookeeper corruption, if any... but no luck.sudo su - yarnyarn resourcemanager -format-state-storeWe had tried to delete hive scratch dir and restarted RM, but no luck.hdfs dfs -D ""fs.default.name=hdfs://mycluster"" -rm -r -f /tmp/hive/*In YARN RM logs, we found that RM failed to become active due to missing block on /yarn/yarn-nodelabels/*We tried to run: hdfs fsck -D ""fs.default.name=hdfs://mycluster"" -delete /yarn/The above command reported that /yarn/ file system is corruptWe have engaged product group on this and they suggested to run: hdfs dfs -rmr hdfs://mycluster/yarnhdfs dfs -rmr hdfs://mycluster/*One of RM became active and other assumed secondary role.Found Spark Thrift alerts (as RM's were restarted) and you had successfully restarted Spark thrift servers.All services are recovered and no issues now.",181174048,,,,,,,
1.20032E+14,07:23.5,Ambari server out,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 24, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Hi, our hiveserver was out. We try to start mannualy with no success. So we try to restart hn0 from command line and now even ambari is not loading.\nCan you please help us?\n\nQuestion: Additional details about the issue\nAnswer: Hi, our hiveserver was out. We try to start mannualy with no success. So we try to restart hn0 from command line and now even ambari is not loading.\nCan you please help us?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Hi, our hiveserver was out. We try to start mannualy with no success. So we try to restart hn0 from command line and now even ambari is not loading.\nCan you please help us?;\nAdditional details about the issue - Hi, our hiveserver was out. We try to start mannualy with no success. So we try to restart hn0 from command line and now even ambari is not loading.\nCan you please help us?;\n\n- ProblemStartTime: 03/24/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Avanade - SIM Frontend\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7f6c65a5-ebfd-48d2-80bf-f6f2cdbaa32b/resourceGroups/az-rg-analytics-use-prd/providers/Microsoft.HDInsight/clusters/azhdisimuseprd\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari server out,0.075352561,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,Logins to cluster's Ambari website were failing,Ambari server was running on the wrong headnode,Restarted Ambari Server on the active headnode,,,,,,,,
1.20032E+14,37:09.9,HDFS access not working on HDInsight with ESP active,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: 20/03/24 14:22:23 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:~$ klist\nklist: Credentials cache file '/{alphanumericpii}' not found\n{alphanumericpii}:~$ kinit\nPassword for {EmailPII}@DEFINEDCROWD.COM:\n{alphanumericpii}:~$ klist\nTicket cache: {AlphanumericPII}\nDefault principal: {EmailPII}@DEFINEDCROWD.COM\n\nValid starting       Expires              Service principal\n03/24/2020 14:22:07  03/25/2020 00:22:07  {EmailPII}@DEFINEDCROWD.COM\nrenew until 03/31/2020 14:22:00\n{alphanumericpii}:~$ hdfs dfs -ls /\n20/03/24 14:22:23 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n20/03/24 14:22:29 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n20/03/24 14:22:37 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n{alphanumericpii}:~$ /usr/lib/hdinsight-common/scripts/RegisterKerbTicketAndOAuth.sh {emailpii}@definedcrowd.com\nEnter password for the domain user:\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Trying to log into with shortname joao.antonio\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Registering kerberos credentials successful\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Trying to authenticate with credential service to register oAuth token with {emailpii}@definedcrowd.com\nKerbAndOAuthReg: INFO,: 2020.03.24-14.31.00: Registering oAuth token successful\n{alphanumericpii}:~$ hdfs dfs -ls /\n20/03/24 14:31:25 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n\nSucessfully logged in in Ambari\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - 20/03/24 14:22:23 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404);\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii}:~$ klist\nklist: Credentials cache file '/{alphanumericpii}' not found\n{alphanumericpii}:~$ kinit\nPassword for {EmailPII}@DEFINEDCROWD.COM:\n{alphanumericpii}:~$ klist\nTicket cache: {AlphanumericPII}\nDefault principal: {EmailPII}@DEFINEDCROWD.COM\n\nValid starting       Expires              Service principal\n03/24/2020 14:22:07  03/25/2020 00:22:07  {EmailPII}@DEFINEDCROWD.COM\nrenew until 03/31/2020 14:22:00\n{alphanumericpii}:~$ hdfs dfs -ls /\n20/03/24 14:22:23 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n20/03/24 14:22:29 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n20/03/24 14:22:37 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n{alphanumericpii}:~$ /usr/lib/hdinsight-common/scripts/RegisterKerbTicketAndOAuth.sh {emailpii}@definedcrowd.com\nEnter password for the domain user:\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Trying to log into with shortname joao.antonio\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Registering kerberos credentials successful\nKerbAndOAuthReg: INFO,: 2020.03.24-14.30.59: Trying to authenticate with credential service to register oAuth token with {emailpii}@definedcrowd.com\nKerbAndOAuthReg: INFO,: 2020.03.24-14.31.00: Registering oAuth token successful\n{alphanumericpii}:~$ hdfs dfs -ls /\n20/03/24 14:31:25 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n\nSucessfully logged in in Ambari;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DATAMLTEAM-Internal\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDFS access not working on HDInsight with ESP active,0.169815698,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",cannot run hdfs cmds,MFA was enabled on users,added HDInsight IPs to exclusion  list for MFA,,,,,,,,
1.20032E+14,31:40.9,Team needs Scala Runtime Environment for Kafka Cluster to run scala Jar.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 24, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: This has been exiting in on prem {Namepii}. We need to have it on {Namepii} aswell.\n\nQuestion: Additional details about the issue\nAnswer: Question:\n{Alphanumericpii} we use the same Scala runtime environment in Kafka {alphanumericpii}) to run a Scala jar(For Kafka streaming application) exisiting on prem {Namepii}?\n\n{Alphanumericpii} not can Azure Support help us get the scala RE file for setup.\n\n{Alphanumericpii} see the required versions needed as per request.\n\nScala version : 2.11\nKafka version : 2.4.0\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - This has been exiting in on prem {Namepii}. We need to have it on {Namepii} aswell.;\nAdditional details about the issue - Question:\n{Alphanumericpii} we use the same Scala runtime environment in Kafka {alphanumericpii}) to run a Scala jar(For Kafka streaming application) exisiting on prem {Namepii}?\n\n{Alphanumericpii} not can Azure Support help us get the scala RE file for setup.\n\n{Alphanumericpii} see the required versions needed as per request.\n\nScala version : 2.11\nKafka version : 2.4.0;\n\n- ProblemStartTime: 03/24/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP22ADLSTREAM\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Team needs Scala Runtime Environment for Kafka Cluster to run scala Jar.,0.121818044,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Metrics are missing\Spark,advisory,advisory,we found on screenshare you have scala 2.11 on cluster but kafka version is 2.1advised that while they can update we can not recommend or support that.,,,,,,,,
1.20032E+14,41:59.1,only 38 out of 40 node managers are active,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Only 38 out of 40 node managers are active\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Only 38 out of 40 node managers are active;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-EUR-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a43beb5c-af15-4c6a-ab5e-c4ba0fbeee47/resourceGroups/o365ipdieur02-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdieur02-sp-we01\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",only 38 out of 40 node managers are active,0.897013019,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Service unhealthy\Spark,Only 38 out of 40 node managers are active.,"Cluster o365ipdieur02-sp-we01 nodes pointing to the wrong headnode host and Identify the active headnode, determine the nodes that aren't pointing to that wrong headnode","Here’s the Mitigation steps – Recommended Steps  SSH onto the nodes,      given from Support Engineer, within the HDInsight cluster      o365ipdieur02-sp-we01  Open the hosts files vi      /etc/hosts  Update the host files      with the headnodehost pointing to the other headnode  Save and close the fileOr else you can restart the all the service from Ambari with the affected node which is pointing to wrong active headnode.",,,,,,,,
1.20032E+14,59:25.5,System corrupted,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 10:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 1) Got 'socket could not open' from a spark job, then 2) got 'bash not found' when trying to rerun the job with the bash command. 3) when logged out, unable to log back in.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - 1) Got 'socket could not open' from a spark job, then 2) got 'bash not found' when trying to rerun the job with the bash command. 3) when logged out, unable to log back in.;\n\n- ProblemStartTime: 03/24/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-blai-Shared-HDInsight/providers/Microsoft.HDInsight/clusters/ceidev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",System corrupted,50.94098934,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,"Server is not booting, basically all the services were failing to start and at  some point was crashing. (Still need to take a screenshot for this.)","System  corrupted. For this particular case we  need to copy from the Recovery Server that is running Ubuntu 16.04 multiple  binaries including bash binary (Essential to use chroot) and this happen  because all these binary were missing from the Customer Disk. My assumption is  that something or someone launch an update on the OS and this update may have  problems to finish correct on the Customer OS, if this was what it happened this  may lead the update process to remove the binaries as a normal replace process  to install the new updates but because the process could fail then the binaries  could be removed without replacing them with the new ones and leaving the server  without them.Please keep in mind that this is just a my  interpretation of what could happened and unfortunately it will be very  complicate to know if this was the case because I don’t see logs mention why the  binaries disappear ","Reason: The server didn’t have essential  binaries such (cp, rm, mount, ip, mv, netstat) and all this were preventing the  server to boot. For this particular case we  need to copy from the Recovery Server that is running Ubuntu 16.04 multiple  binaries including bash binary (Essential to use chroot) and this happen  because all these binary were missing from the Customer Disk. My assumption is  that something or someone launch an update on the OS and this update may have  problems to finish correct on the Customer OS, if this was what it happened this  may lead the update process to remove the binaries as a normal replace process  to install the new updates but because the process could fail then the binaries  could be removed without replacing them with the new ones and leaving the server  without them.Please keep in mind that this is just a my  interpretation of what could happened and unfortunately it will be very  complicate to know if this was the case because I don’t see logs mention why the  binaries disappear  Resolution: We need to recreate the  environment especial the binaries into the OS disk and run update commands over  the server and at follow I adding the details of what I did. Attach Customer disk to the  Recovery VMCreate a recovery server, for  this case is best to create an Ubuntu 16.04 from the market because the original  OS disk is running Ubuntu 16.04# mkdir /rescue  # Create recovery directory# mount /dev/sdc1 /rescue # For this  case the customer disk is located in sdc1 # mount -o bind /proc  /rescue/proc# mount -o bind /dev /rescue/dev# mount -o bind /sys  /rescue/sys# mount -o bind /run /rescue/run# cp /bin/bash /bin/cp  /bin/mv /bin/mount /bin/ip /bin/netstat /bin/su /bin/echo /bin/egrep /bin/sync  /bin/sed /bin/uname /bin/grep /bin/fgrep /bin/mkdir /bin/umount /bin/date  /bin/df /rescue/bin# chown root.root  /rescue/bin/bash /rescue/bin/cp /rescue/bin/mv /rescue/bin/mount /rescue/bin/ip  /rescue/bin/netstat /rescue/bin/su /rescue/bin/echo /rescue/bin/egrep  /rescue/bin/sync /rescue/bin/sed /rescue/bin/uname /rescue/bin/grep  /rescue/bin/fgrep /rescue/bin/mkdir /rescue/bin/umount /rescue/bin/date  /rescue/bin/df# chmod u+s  /rescue/bin/mount# chroot /rescue # This will change the root to /rescue  or if you want to see it in different way create a jail so we can work into  Customer Disk.In this next  step we may need to remove the extra repositories because they may fail at the  update pending process# cd  /etc/apt/# mv sources.list.d  sources.list.d.old# mkdir  sources.list.d# rm  /etc/apt/trusted*# apt-key  update# apt  update# apt  upgrade# apt  autoremove  At this point  we will need to umount everything and swap the OS disk #  exit# umount  /rescue/proc# umount  /rescue/dev# umount  /rescue/sys# umount  /rescue/run# umount  /rescueServer is not  booting, basically all the services were failing to start and at some point was  crashing because it didn’t have essential binaries such (cp, rm, mount, ip, mv,  netstat) and all this were preventing the server to boot. After recreating the  environment especial the binaries into the OS disk and run update commands over  the server helped to boot the node",181203414,,,,,,,
1.20032E+14,13:54.7,Can't authenicate with users with MFA enabled,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 24, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 24, 2020, 12:00 AM EDT\n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: No\n\nQuestion: Has the AAD service endpoint been enabled to allow traffic from HDInsight VNet?\nAnswer: Yes\n\nQuestion: Are the accounts federated?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: No\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} setup using broker id feature for SSO for MFA enabled user. Can't authenicate with VS and Azure portal.\n\n{'{AlphanumericPII}':'- Authentication failed','data':'{\\'Code\\':\\'Unauthorized\\',\\'Message\\':{Uncpii} acquisition failed{Uncpii}\'CorrelationId\\':\\'65697edbb65348aaa24b5b21ad5cb71a\\',\\'ResponseTimestamp\\':{UNCPII}:40:20.3503979Z{Uncpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - No;\nHas the AAD service endpoint been enabled to allow traffic from HDInsight VNet? - Yes;\nAre the accounts federated? - Other, don't know or not applicable;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes authentication fail even for the cluster admin account? - No;\nHave you logged in to Ambari as local admin and verified the users have been synced? - Yes;\nAdditional details about the issue - {Namepii} setup using broker id feature for SSO for MFA enabled user. Can't authenicate with VS and Azure portal.\n\n{'{AlphanumericPII}':'- Authentication failed','data':'{\\'Code\\':\\'Unauthorized\\',\\'Message\\':{Uncpii} acquisition failed{Uncpii}\'CorrelationId\\':\\'65697edbb65348aaa24b5b21ad5cb71a\\',\\'ResponseTimestamp\\':{UNCPII}:40:20.3503979Z{Uncpii}\n\n- ProblemStartTime: 03/24/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AvidXchange Enterprise DevQA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb7f642a-16cf-48a7-8161-58002441290d/resourceGroups/AvidX-Dv-DataPlatform-RG/providers/Microsoft.HDInsight/clusters/acpollock-dv-dataplatform-lldap-hdi\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't authenicate with users with MFA enabled,0.035374371,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Can't authenicate with users with MFA enabled,NA,"CX wanted  to use the ID Broker method in production HIve Query, but we only support a IDE of IntelliJ at this time. https://docs.microsoft.com/en-us/azure/hdinsight/domain-joined/identity-broker",,,,,,,,
1.20032E+14,45:03.4,Apache Ranger on ADLS,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 23, 2020, 11:00 PM MST\n\nQuestion: Does Ambari login work?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Can you log in to Ranger using the cluster local admin credential?\nAnswer: Yes\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Is there any way we can control access using Ranger on ADLS ? I am seeing we have HDFS plugin in ranger for HDFS file accesses.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nDoes Ambari login work? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes kinit for some or all users work from the Head node? - ;\nCan you log in to Ranger using the cluster local admin credential? - Yes;\nDoes authentication fail even for the cluster admin account? - ;\nAdditional details about the issue - Is there any way we can control access using Ranger on ADLS ? I am seeing we have HDFS plugin in ranger for HDFS file accesses.\n;\n\n- ProblemStartTime: 03/24/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Apache Ranger on ADLS,0.726534362,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Authentication failure\Ranger in cluster with Enterprise Security Package,Apache Ranger on ADLS feature availability,Apache Ranger on ADLS feature availability ,Provided the guidance and information about the ask,,,,,,,,
1.20033E+14,49:47.8,arm deployment hdinsight-202003241800 under azr1473-va8-poc-hdinsight-base  resource group fails,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: keep getting ssh password must be a specific length with 1 lower/upper/numeric. tried various 16 character passwords (https://www.random.org/passwords/?num=16&len=16&format=html&rnd=new) with same result.\n\nunable to attach the arm template, file upload doesnt like json extension so renamed it to .txt\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - keep getting ssh password must be a specific length with 1 lower/upper/numeric. tried various 16 character passwords (https://www.random.org/passwords/?num=16&len=16&format=html&rnd=new) with same result.\n\nunable to attach the arm template, file upload doesnt like json extension so renamed it to .txt;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: IT/{Namepii} Sandbox ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",arm deployment hdinsight-202003241800 under azr1473-va8-poc-hdinsight-base  resource group fails,0.569480956,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Multipule errors: Payload incorrect error,JSON template is missing some information,"Based on requirement, deployed through portal. Then exported the template and used are reference to make necessary changes. ",,,,,,,,
1.20033E+14,52:21.6,HDI 4.0 : Hbase: Diskspace configurations ,We need some clarification and help with  the HBase cluster  related to disk space issue  in HDI 4.0 .\n \nFor a {ALPHANUMERICPII} V2 sku size in HDI 3.6 we used to get 1 TB diskspace in root and 394 G in mnt space.  In HDI  4.0 for the same sku  {ALPHANUMERICPII} V2 we are getting  125 G in root and  {ALPHANUMERICPII} in mnt location.\n \nDue to these disk space issues we are not able to large files into HBase cluster.\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps071hbasefdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,HDI 4.0 : Hbase: Diskspace configurations ,0.070213454,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\General Guidance or Advisory,DS13 V2 disk size inconsistency b/w HDI 3.6 and HDI 4,HDI 4.0 : Hbase: Diskspace configurations ,"Goal is to make this bulk load work. Typically, we give ~20% resources to yarn by default in HBase cluster. Given this is MR job which run under Yarn by default this will have very less cluster resources. We recommended to follow methods to get unblocked. Increase the Yarn node memory to give Yarn more resources to complete the MR jobIncrease the cluster size while MR job is running",181231775,,,,,,,
1.20033E+14,07:26.9,Cluster deployment fails,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: no\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Error code\nFailedToConnectWithClusterThroughGatewayErrorCode\nError message\nUnable to connect to cluster management endpoint. Please retry later.\n\nPlease see attached log from head node and advise on cause of the errors\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - no;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Error code\nFailedToConnectWithClusterThroughGatewayErrorCode\nError message\nUnable to connect to cluster management endpoint. Please retry later.\n\nPlease see attached log from head node and advise on cause of the errors;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cdo-dataplatform-dev-01/providers/Microsoft.HDInsight/clusters/brian00test99\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster deployment fails,0.525313514,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster deployment fails,Cluster deployment fails,"Customer was hitting at exception while attempting to connect to cluster' management endpoint. Customer had added AzureCloud service tag on outbound rules that had fixed the issue. ​Informed customer that on NSG, all rules as outlined on the link would need to be enabled for communication.​​https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-restrict-outbound-traffic​​Since the service tag (AzureCloud) covering across regions and not restricted to specific region, customer would be working with product group on this and advised to close the case.",,,,,,,,
1.20033E+14,53:28.2,Planning to install ubuntu security upgrade on production.,"Planning to install ubuntu security updates using unattended-upgrade option. \n\nAny suggestions, advice or best practices to follow.\n\nProblem start date and time\nWed, {Namepii} 25, 2020, 12:00 AM CDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/25/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Planning to install ubuntu security upgrade on production.,0.085912073,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\General Guidance or Advisory,install ubuntu security upgrade on production documentation guidance,Planning to install ubuntu security upgrade on production,Provided the related documentation - https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-os-patching,,,,,,,,
1.20033E+14,06:00.7,Unable to create hive functions and assign UDFs,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: CREATE FUNCTION default.genSurKey as 'com.ncr.eda.apollo.hive.GenSurKey' USING JAR '/{AlphanumericPII}';\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [hive] does not have [WRITE] privilege on [abfs://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/platform/current/edl-udf-platform-1.0.1-SNAPSHOT.jar] ({alphanumericpii})\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Tried to add a temp function and that works but when we add a permanenet function to hive schema we get permissions issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - CREATE FUNCTION default.genSurKey as 'com.ncr.eda.apollo.hive.GenSurKey' USING JAR '/{AlphanumericPII}';\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [hive] does not have [WRITE] privilege on [abfs://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/platform/current/edl-udf-platform-1.0.1-SNAPSHOT.jar] ({alphanumericpii});\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - Tried to add a temp function and that works but when we add a permanenet function to hive schema we get permissions issue;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to create hive functions and assign UDFs,1.047573353,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hive,itleUnable to create hive functions and assign UDFs,ranger setup,we added hive to  all-url users in ranger,,,,,,,,
1.20033E+14,13:05.7,Various Ambari/Grafana panels not loading,"Question: What time did the problem begin?\nAnswer: Wed, Feb 12, 2020, 12:00 AM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Many of the grafana panels in the grafana instance that comes with the Ambari install do not populate with data. One example is the 'HBASE - RegionServer' dasbhoard, 'MEMORY' panel. But there are numerous others. I can provide other examples if desired.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Many of the grafana panels in the grafana instance that comes with the Ambari install do not populate with data. One example is the 'HBASE - RegionServer' dasbhoard, 'MEMORY' panel. But there are numerous others. I can provide other examples if desired.;\n\n- ProblemStartTime: 02/12/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Base $1200 Annual Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/85b49761-8f6b-45d2-b452-c42625590aee/resourceGroups/WhitingPetroSCADA/providers/Microsoft.HDInsight/clusters/whitingpetroscadahdicls\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Various Ambari/Grafana panels not loading,0.131959246,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Metrics are missing\Hbase,Various Ambari/Grafana panels not loading - MEMORY ,Unknown,Not related to HDInsight/Amari UI ,,,,,,,,
1.20033E+14,39:03.3,Credential Server and HiveServer2 Components are not starting even after reboot,"WARNING 2020-03-25 {Alphanumericpii} FileCache.py:204 - Error occurred during cache update. Error tolerate setting is set to true, so ignoring this error and continuing with current cache. Error details: Can not download file from url http://hn1-ahd501.azfrk.com:8080/resources/common-services/CREDENTIAL_SERVICE/0.1/package/.hash : HTTP Error 404: Not Found\nWARNING 2020-03-25 {Alphanumericpii} FileCache.py:204 - Error occurred during cache update. Error tolerate setting is set to true, so ignoring this error and continuing with current cache. Error details: Can not download file from url http://hn1-ahd501.azfrk.com:8080/resources/common-services/CREDENTIAL_SERVICE/0.1/package/.hash : HTTP Error 404: Not Found\nBinary file (standard input) matches\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Credential Server and HiveServer2 Components are not starting even after reboot,0.957855272,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\General Guidance or Advisory,120032524005682  - Credential Server and HiveServer2 Components are not starting even after reboot,Unknown,Manually started the credential service using the below command:/usr/lib/hdinsight-credentialservice/bin/credential-service.sh start Customer disabled 'Interactive Query' to resolve issue with the Hive service not starting,181463943,,,,,,,
1.20033E+14,58:48.1,Azure HD  - Hive Services are Running out of Heap Spaces,"We are concerned about capacity in the Regions in which we are deployed.\n\nCan you provide reports about how much capacity is available for the services we use in Azure in the region in which we are deployed?\n\nProblem start date and time\nWed, {Namepii} 25, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/25/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: fii-prd-sub\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Azure HD  - Hive Services are Running out of Heap Spaces,1.000114588,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure AD User Prov and Sync\Problem with AADConnect Health\Problem with Health data freshness,General Guidance or Advisory (Preview) on the Capacity in ADF/Databrick,NA,General Guidance or Advisory question,,,,,,,,
1.20033E+14,09:18.9,Spark HBase connection failing on Secured HDInsight clusters,"Spark HBase connection failing on Secured HDInsight clusters\nWe have enabled ESP on our HDInsight clusters and we are running into issues when making a call from Spark to HBase.\nI have created a keytab file with my logon – {emailpii}@devazurehc.athenahealth.com and passing it along to the spark submit job with these parameters\n--conf spark.hbase.connector.security.credentials.enabled=true \\\n--conf {EmailPII}@DEVAZUREHC.ATHENAHEALTH.COM \\\n--conf spark.hbase.connector.security.keytab=/opt/ps.keytab \\\n\nKlist on the keytab file \n \n\nWhen spark is trying to write to HBase, we are seeing this exception \nUser class threw exception: java.io.IOException: Login failure for {EmailPII}@devazurehc.athenahealth.com from keytab /{alphanumericpii}: javax.security.auth.login.LoginException: Unable to obtain password from user\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bc480628-caa3-4479-8a42-11f4e52275a8/resourceGroups/NorthStar-Sandbox-HDInsightSpark/providers/Microsoft.HDInsight/clusters/sparkclusternssbwus\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark HBase connection failing on Secured HDInsight clusters,0.064827391,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\General Guidance or Advisory,Spark HBase connection failing on Secured HDInsight clusters,This is a known issue where the reverse lookup between two clusters fails and there is a workitem pending to fix this issue as well(for your reference :WorkItem ID:  735460)Although I do not have a ETA on when this would be fixed. There is a workaround for this as well. ,"Apart from having to update the RDNS entries on the DNS manager which does not seem like a viable solution, you can update the /etc/hosts file on the spark cluster(all nodes) to have the entries for hbase cluster’s nodes in them. This might take some time if it’s a large cluster so you might want to run this as a script action and have a script to update the hosts file on the spark cluster example : sudo echo $'10.12.0.22 wn1-adk2es.hdinsightcss.com wn1-adk2es wn1-adk2es.hdinsightcss.com. wn1-adk2es.ukzcrg3la5aulfzose2pkhnq4e.jx.internal.cloudapp.net\n10.12.0.7 zk0-adk2es.hdinsightcss.com zk0-adk2es zk0-adk2es.hdinsightcss.com. zk0-adk2es.ukzcrg3la5aulfzose2pkhnq4e.jx.internal.cloudapp.net' >>/etc/hosts",182050387,,,,,,,
1.20033E+14,11:57.5,unresponsive node,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 25, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Trying to restart via Ambari, trying to SSH - both are failing.\n\nQuestion: Additional details about the issue\nAnswer: Unable to restart this broker: wn0-kafkav.kndwsxjut0fe5fpbfvlpymwscc.ex.internal.cloudapp.net\n\nIt won't respond to SSH, or ambari requests.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Trying to restart via Ambari, trying to SSH - both are failing.;\nAdditional details about the issue - Unable to restart this broker: wn0-kafkav.kndwsxjut0fe5fpbfvlpymwscc.ex.internal.cloudapp.net\n\nIt won't respond to SSH, or ambari requests.;\n\n- ProblemStartTime: 03/25/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: ClickDimensions for MsCrm Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3686e84d-435e-4eed-9d12-5957d444875c/resourceGroups/kafkav2prodncus/providers/Microsoft.HDInsight/clusters/kafkav2prodncus\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unresponsive node,0.09480847,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,cannot ssh into the node,Network issue,Rebooted the wn,,,,,,,,
1.20033E+14,36:38.8,Spark-sql error,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 24, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 23, 2020, 11:00 PM MST\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: running spark-sql command in CLI\n\nQuestion: Additional details about the issue\nAnswer: 20/03/25 21:10:54 WARN {AlphanumericPII}: Failed to get HS2 delegation token\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - running spark-sql command in CLI;\nAdditional details about the issue - 20/03/25 21:10:54 WARN {AlphanumericPII}: Failed to get HS2 delegation token\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper;\n\n- ProblemStartTime: 03/25/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark-sql error,0.026622169,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Unable to Launch the saprk-sql session,Spark-sql error and unable to launch,"Spark-sql needs the LLAP service to be UP and RUNNING. After starting the Hive-Interactive service, it started working fine. Recommended to launch the custom HS2 on 10009 port (custom), so that will not have any port conflict or restart issues.Saw that 10001 port is being used by HS2 serviceBala team added one more HiveServer2 on HN0 host is occupied the 10001 port and causing the issues for HS2-Interactive serviceTold to Bala that, we don’t recommend adding/removing the functionality of the cluster but he wanted HA for the HS2 serviceSo to mitigate the issue, we recommend him to change the HS2-Interactive thrift port “10009” and it worked fineAs per the case, “spark-sql” started working fine once after HS2-Interactive UP and RUNNING.",,,,,,,,
1.20033E+14,13:20.6,Unable to spin up HDInsight cluster using Azure Template,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {AlphanumericPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: None\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: Tried spinning up the cluster using Azure CLI commands with in a shell script and passing Json's as parameters to it. Used to work until recently but not anymore. Keeps running for ever and in the deployment  status on Azure portal - it shows InternalServerError\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {AlphanumericPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - None;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - Tried spinning up the cluster using Azure CLI commands with in a shell script and passing Json's as parameters to it. Used to work until recently but not anymore. Keeps running for ever and in the deployment  status on Azure portal - it shows InternalServerError;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data-n-Analytics-Nonprod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to spin up HDInsight cluster using Azure Template,0.634322152,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to spin up HDInsight cluster using Azure Template,Unable to spin up HDInsight cluster using Azure Template,"Support checked and advised customer to remove “Microsoft.Storage/StorageAccounts” in “resources” section, that fixed the issue. Customer agreed to close the case.",,,,,,,,
1.20033E+14,49:32.5,"[Azure Government] Not able to schedule new task, need to be repaired","[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Cannot submit new tasks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Cannot submit new tasks;\n\n- ProblemStartTime: 03/23/2020 07:00:00\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: eDiscovery_ZoomAnalytics_GCC\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/41e30ebe-f125-4b23-a254-5642084dfc5b/resourceGroups/ResourceGroup-PRODFFVAHDIS1/providers/Microsoft.HDInsight/clusters/lh000-prodffvahdis1\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","[Azure Government] Not able to schedule new task, need to be repaired",0.988131292,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Hive,ZK couldn't form a quorum,Zookeeper got in a bad state on the cluster.  ,VijaySr got in escort session and deleted the zookeeper snapshot files,181500247,,,,,,,
1.20033E+14,52:38.7,"[Azure Government] Not able to schedule new tasks, cluster needs to be repaired.","[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Cannot submit new tasks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Cannot submit new tasks;\n\n- ProblemStartTime: 03/23/2020 07:00:00\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: eDiscovery_ZoomAnalytics_GCC\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/41e30ebe-f125-4b23-a254-5642084dfc5b/resourceGroups/ResourceGroup-PRODFFVAHDIS1/providers/Microsoft.HDInsight/clusters/lh001-prodffvahdis1\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","[Azure Government] Not able to schedule new tasks, cluster needs to be repaired.",0.987318438,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hive,Similar issue reported on SR 120032624000096,"Zookeepers had too many snapshots as cluster is old, this caused health issues. Refer to ICM - 181500247","Worked with PG to clean zookeeper quorum and probes, after zookeepers were healthy issue was resolved.",181480309,,,,,,,
1.20033E+14,25:03.5,Unable to drop tables and Databases in hive,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII})\n\nQuestion: Hive query explain plan if available\nAnswer: DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII})\n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII});\nHive query explain plan if available - DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII});\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - DROP DATABASE trans_swd CASCADE\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x)\nINFO  : Completed executing {AlphanumericPII}); Time taken: 1.812 seconds\nError: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='abfss://chsp90adlspark-2019-08-15t00-40-30-814z@adlcertadls2storage.dfs.core.windows.net/data/servicelob/confidential/trans/thingworx/swd/public/trans_campaign':ca230558:hadoop:drwxr-xr-x) ({AlphanumericPII});\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHSP90ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to drop tables and Databases in hive,0.068917976,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,Unable to drop tables and Databases in hive,Unable to drop tables and Databases in hive,Worked with customer and informed customer that with HDP3.x (HDI4.0) onwards Spark and Hive share different metastore and need Spark DataWarehouse connector to run queries on hive. Customer agreed for the same and confirmed to close the case.,182148765,,,,,,,
1.20033E+14,54:35.8,Common MetaStore Security Issue,"We have common metastore and used in multiple HDI. We want to control the access. For Example,\n\n{Namepii} 1 -- Should able to create table only in {Alphanumericpii}\n\nCLuster 2 -- Shaould able to create table only in {Alphanumericpii}\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Common MetaStore Security Issue,0.057004579,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\General Guidance or Advisory,None,Customer wanted guidance on access control for clusters using Apache Ranger and Azure databricks,Provided documents to customer.Apache Rangerhttps://cloudarchitected.com/2019/03/data-level-security-in-azure-databricks/Azure Databrickshttps://docs.microsoft.com/en-us/azure/databricks/administration-guide/access-control/,,,,,,,,
1.20033E+14,24:12.9,HDIAmbari process is consuming too much cpu,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Is issue intermittent?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ambari process is consuming too much CPU. Please find below screens. This causing users not able to run queries.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs issue intermittent? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ambari process is consuming too much CPU. Please find below screens. This causing users not able to run queries.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/24/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi001dldev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDIAmbari process is consuming too much cpu,0.067744213,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Ambari-Server process consuming too much CPU causing a little bit of slow up. ,Amabari Process on Server consuming too much CPU memory. ,Advised customer to move ATS to a new custom database. Also advised customer to deploy a new HDI cluster with a custom Ambari DB.  The documentation on this process is available here https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-custom-ambari-db. This will give the customer the flexibility to customize the database in terms of capacity and scaling up the database. ,,,,,,,,
1.20033E+14,49:44.2,Unable to bring up head node and edge node.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 26, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Restarted the nodes after applying security package updates and now one of the headnode and edge node is down.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Restarted the nodes after applying security package updates and now one of the headnode and edge node is down.;\n\n- ProblemStartTime: 03/26/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to bring up head node and edge node.,0.013180739,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Unable to bring up Headnode and edgenode,guest OS crashed causing this issue because of which you were unable to SSH to the nodes. ,Restarted nodes from ACIS,184331402,,,,,,,
1.20033E+14,12:24.6,spark-shell is not working on Integration Servers fro QA and Perf Envs,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 26, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: 1) spark-shell \n\n2) spark-submit --driver-class-path  /{AlphanumericPII} --conf {alphanumericpii} --num-executors 25 --executor-cores 4 --executor-memory 5g --jars mongo-spark-connector-assembly-2.4.1-SNAPSHOT0212.jar --class com.albertsons.catalog.processor.ProductUpcProcessor --master yarn {AlphanumericPII} \n\nQuestion: Additional details about the issue\nAnswer: spark-shell command not connecting to spark from qa and perf integration servers. But it is working from Dev and ACC integration servers. Please review and help in resolving this issue ASAP.\n\nReceiving the below error message.\n\n{alphanumericpii}:~# spark-shell\n{ALPHANUMERICPII}: Class path contains multiple {ALPHANUMERICPII} bindings.\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/current/spark2-client/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/current/spark_llap/spark-llap-assembly-1.0.0.2.6.5.3005-27.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n{ALPHANUMERICPII}: Actual binding is of type [{AlphanumericPII}]\nSetting default log level to 'WARN'.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n20/03/26 17:46:48 ERROR SparkContext: Error initializing SparkContext.\norg.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - 1) spark-shell \n\n2) spark-submit --driver-class-path  /{AlphanumericPII} --conf {alphanumericpii} --num-executors 25 --executor-cores 4 --executor-memory 5g --jars mongo-spark-connector-assembly-2.4.1-SNAPSHOT0212.jar --class com.albertsons.catalog.processor.ProductUpcProcessor --master yarn {AlphanumericPII} ;\nAdditional details about the issue - spark-shell command not connecting to spark from qa and perf integration servers. But it is working from Dev and ACC integration servers. Please review and help in resolving this issue ASAP.\n\nReceiving the below error message.\n\n{alphanumericpii}:~# spark-shell\n{ALPHANUMERICPII}: Class path contains multiple {ALPHANUMERICPII} bindings.\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/current/spark2-client/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/current/spark_llap/spark-llap-assembly-1.0.0.2.6.5.3005-27.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n{ALPHANUMERICPII}: Actual binding is of type [{AlphanumericPII}]\nSetting default log level to 'WARN'.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n20/03/26 17:46:48 ERROR SparkContext: Error initializing SparkContext.\norg.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.\n;\n\n- ProblemStartTime: 03/26/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",spark-shell is not working on Integration Servers fro QA and Perf Envs,0.577133803,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,spark-shell is not working on Integration Servers fro QA and Perf Envs,spark-shell is not working on Integration Servers fro QA and Perf Envs,"Worked with customer and clarified to customer that name resolution between VNETs is not supported and customer had manually feed in ""spark.driver.host"" with the IP Address of the remote Spark cluster to mitigate the issue. Customer confirmed to close the case.",,,,,,,,
1.20033E+14,22:36.1,Queries get to 100% than hang for 15+ hours,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 26, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: All Hadoop services on the cluster were restarted in an effort to resolve the issue.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: This happens with multiple different queries.\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: We are getting ClientOtherError.  Very Vague.\nThere are no errors in the Hadoop application log files.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - All Hadoop services on the cluster were restarted in an effort to resolve the issue.;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - This happens with multiple different queries.;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - We are getting ClientOtherError.  Very Vague.\nThere are no errors in the Hadoop application log files.\n;\n\n- ProblemStartTime: 03/26/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Greenhouse\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5fcb9b33-e28e-4056-96dc-9ecc709cfd78/resourceGroups/ProductionCluster/providers/Microsoft.HDInsight/clusters/Greenhouse-Production\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Queries get to 100% than hang for 15+ hours,0.017939185,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Queries taking longer than usual to execute. Some queries reach 100%  then hang for 15+ hours.,There appeared to be a rogue worker node showing excessive CPU usage. The worker node showed that there may have been another process that should not be running that was taking up 100% of the CPU along with other processes.,"  Killed the last task that      running on this worker node and it was passed over to another worker node.        I also advised that if it      came down to an issue with a particular node, you can decommission the      worker node and scale up the cluster to add another one.   The steps taken, by you      resolved the issue and the cluster performance is back to normal. ",,,,,,,,
1.20033E+14,49:15.2,Having issues creating cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: p-fs-hdinsights-hbase\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: Ubale to create a cluster\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: There is no notifications getting created\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - p-fs-hdinsights-hbase;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - Ubale to create a cluster;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - There is no notifications getting created;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: JG Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Having issues creating cluster,0.1980534,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Getting a ""Deployment Error"" and a Gateway Timeout Error ",There was a Database miss configuration from the deployment and the cluster has to many nodes since the begining ,"Fix the database configuration previous deployment and reduce the number of nodes, they can add more nodes latter if needed.",181641515,,,,,,,
1.20033E+14,58:29.4,Unable to access this resource via spark from a different subscription,"Dear Microsoft Support,\n\nWe need to access hbase (HDInsight) via Spark from the cluster anir-hdinsight2-ssh.azurehdinsight.net currently installed within the subscription id {guidpii} (POC) from the server {AlphanumericPII} ({Ipaddresspii} {AlphanumericPII}) which is in the NuGene_Production resource group from the  subscription id {guidpii} (pay as you go)\n\nThe error that is being displayed is: Error is connection refused.\n\nKind Regards,\n{Namepii} {Namepii}\n\nProblem start date and time\nFri, {Namepii} 27, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/27/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: POC Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0436c84a-f6a1-4100-942a-97ff0053a79f/resourceGroups/anir-dec-poc2/providers/Microsoft.HDInsight/clusters/anir-hdinsight2\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access this resource via spark from a different subscription,0.012240892,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\General Guidance or Advisory,120032724003208  - Unable to access this resource via spark from a different subscription,The issue was not that the cluster was in a different subscription. The cause was that the cluster was in the Azure-provided VNET. Machines outside of the HDInsight cluster will not be able to resolve the IPs or FQDNs of the zookeeper nodes.,"Deploy an edgenode on the HDI cluster and access HBASE/Hive from thereAlso, advised the customer that recreating the cluster in a custom Virtual Network would be more secure.",,,,,,,,
1.20033E+14,20:33.6,Worker nodes are going off line,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 27, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: None, attempted to ssh to host, but the host is not reachable. \n\nQuestion: Additional details about the issue\nAnswer: Ambari reports wn2 has having a lost heartbeat. The host cannot be pinged from hn0. We have jobs running that we do not want to loose. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - None, attempted to ssh to host, but the host is not reachable. ;\nAdditional details about the issue - Ambari reports wn2 has having a lost heartbeat. The host cannot be pinged from hn0. We have jobs running that we do not want to loose. ;\n\n- ProblemStartTime: 03/27/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cb458380-a7fa-4c7a-befb-ac613cfe0138/resourceGroups/Internal_Development/providers/Microsoft.HDInsight/clusters/dec-poc-02\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Worker nodes are going off line,0.010455899,Root Cause : HDInsight Service\Configuration\Hbase,Routing Azure HDInsight V5\Service unhealthy\Hbase,Worker nodes are going off line and no heartbeat infomation observed.,Unknown,Ambari rebooted/restarted at CX side,,,,,,,,
1.20033E+14,24:45.5,PrdSuP; kp10tntncapllapnsprdsup01: Hiverserver Interacive Service down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {alphanumericpii} : HSI issue\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii} : HSI issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {alphanumericpii} : HSI issue;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - {alphanumericpii} : HSI issue;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PrdSuP; kp10tntncapllapnsprdsup01: Hiverserver Interacive Service down,0.069288467,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Hive Interactive going down very often,PrdSuP; kp10tntncapllapnsprdsup01: Hiverserver Interacive Service down,"We observed 2 issues in this cluster and see the details below,For, issue#1 - If inside our ambari server we have some views (like Hive/File View ..etc) which is accessed by many concurrent users Or if there are many users access the ambari UI concurrently or makes Ambari Rest API calls. Then in such cases we should also increase the ""client.threadpool.size.max"" property value (default values is 25) inside the ""/etc/ambari-server/conf/ambari.properties"". ""client.threadpool.size.max"" : The size of the Jetty connection pool used for handling incoming REST API requests.We recommended below for Issue #1,This should be large enough to handle requests from both web browsers and embedded Views. Consider the following guidance when planning for Views user capacity. An Ambari Views server: On an 8-core box with 16GB of RAM and client.threadpool.size.max = 100 can handle approximately 40 concurrent usersOn an 16-core box with 32GB of RAM and client.threadpool.size.max = 100 can handle approximately 60 concurrent usersIncraesing the ""client.threadpool.size.max"" value to ""100"" could give you relief but make sure you need to increase the memory available to ambari views server. On the Ambari Server host, edit the ambari-env.sh file.vi /var/lib/ambari-server/ambari-env.shFor the AMBARI_JVM_ARGS variable, replace the default -Xmx2048m with the following value:-Xmx4096m -XX:PermSize=128m -XX:MaxPermSize=128mRestart the server.ambari-server restart For Issue#2, related to the LLAP stoppage. It looks like this is related to authentication. We can see two trends: Periodic GSS Timeout, Periodic ZK Connection failure. We suspect that the GSS timeout may be caused by a failure to establish a connection to Zookeeper and do see CancelledKeyExceptions near the end of 03/27. We suggest you to do it periodically (ie: once per week) run the ZK snapshot cleanup steps at https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-fails#next-steps Addressing ZK health should address the ability to authenticate, which should address the ability to run queries.  Authentication timeouts caused queries to not execute. We see ZK health issues during time of impact, which were addressed. We advise to peridoically cleanup ZK snapshots (until they create a new cluster that will have this bugfix enabled).",177656147,,,,,,,
1.20033E+14,26:18.6,Cluster is getting failed while creating.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'FailedToConnectWithClusterErrorCode\\',\\r\\n        \\'message\\': \\'Unable to connect to cluster management endpoint. Please retry later.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'FailedToConnectWithClusterErrorCode\\',\\r\\n        \\'message\\': \\'Unable to connect to cluster management endpoint. Please retry later.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05eu2piphdiscof01\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is getting failed while creating.,0.418812565,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other," ESP cluster creation, multiple issues.",User error.,"We have verified your environment and deployed a new cluster after whitelisting SQL endpoint in the subnet, cluster is  up and running without any issues.",,,,,,,,
1.20033E+14,33:09.5,prdsup: kpph18llapprdsupusc01 : Hive service2 intractive Stopped,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 27, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: HIS service stopped\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: HIS service stopped\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - HIS service stopped;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - HIS service stopped;\n\n- ProblemStartTime: 03/27/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prdsup: kpph18llapprdsupusc01 : Hive service2 intractive Stopped,0.077910605,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Hive service2 intractive Stopped,prdsup: kpph18llapprdsupusc01 : Hive service2 intractive Stopped,"We see GC pauses extending beyond 3 seconds or so, this can cause the server to hang and have a user impact. Please make sure that ParallelGC or G1GC (not CMS) is being used in hive-interactive-env. Also can see occasional warnings related to CachedStore. Please make sure the value of hive.metastore.rawstore.impl is ObjectStore and occasional failures to establish a connection with Hive metastore service. Please try (apply and evaluate) adding socketTimeout=5000 to the end of the Hive Database URL connection string (metastore connection string) in Ambari",181668878,,,,,,,
1.20033E+14,23:18.2,Clamscan is using excessive amount of CPU ,"Hi,\n\nWe have two issues for which we need support from Mirosoft:\n\n1. clamscan is using excessive amount of cpu - adjustments or remove diretories.\n2. Investigation on moving SDA to SSD.\n\n\nProblem start date and time\nFri, Feb 21, 2020, 12:00 AM EST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 02/21/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Clamscan is using excessive amount of CPU ,9.96433803,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Interactive Query,We have two issues for which we need support from Mirosoft: 1. clamscan is using excessive amount of cpu - adjustments or remove diretories.2. Investigation on moving SDA to SSD. ,NA,"What kind of alert is this Clamscan.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-faq#can-i-disable-clamscan-on-my-cluster Clamscan is the antivirus software that runs on the HDInsight cluster and is used by Azure security (azsecd) to protect your clusters from virus attacks. Microsoft strongly recommends that users refrain from making any changes to the default Clamscan configuration.This process does not interfere with or take any cycles away from other processes. It will always yield to other process. CPU spikes from Clamscan should be seen only when the system is idle.In scenarios in which you must control the schedule, you can use the following steps:Disable automatic execution using the following command:/usr/local/vbin/azsecd config -s clamav -d DisabledAdd a Cron job that runs the following command as root:/usr/local/bin/azsecd manual -s clamav 2. The Edge node SKU can be different than cluster VM SKUs.you can select the type of VM for your edge node while provisioning the edge node.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-nodehttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-supported-node-configuration",183905189,,,,,,,
1.20033E+14,43:15.5,HDI 4.0 : HDI 4 Hive warehouse connector issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Regarding  ESP spark cluster issue in HDI 4.0 when we use HWC from spark. \n\nOn the cluster side we are unable to query Hive table from Spark using Hivewarehouse conector. They are failing with below errors.  \n\n-Nullpointerexception\n-Error in acquiring locks\n java.sql.SQLException: Error while processing statement: FAILED: Error in acquiring locks: Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted at shadehive.org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:401\n\nThere are no issue with tables. We are able to query tables from Hive side.  Issue is only when we query Hive table from Spark using Hivewarehouseconnector..\n\n\nQuestion: Additional details about the issue\nAnswer: Summary of Errors: IO NullPointerException , LockException, bucketId out of range, Error in acquiring locks When we use  HWC through spark shell.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - Regarding  ESP spark cluster issue in HDI 4.0 when we use HWC from spark. \n\nOn the cluster side we are unable to query Hive table from Spark using Hivewarehouse conector. They are failing with below errors.  \n\n-Nullpointerexception\n-Error in acquiring locks\n java.sql.SQLException: Error while processing statement: FAILED: Error in acquiring locks: Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted at shadehive.org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:401\n\nThere are no issue with tables. We are able to query tables from Hive side.  Issue is only when we query Hive table from Spark using Hivewarehouseconnector..\n;\nAdditional details about the issue - Summary of Errors: IO NullPointerException , LockException, bucketId out of range, Error in acquiring locks When we use  HWC through spark shell.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq044sparkespfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI 4.0 : HDI 4 Hive warehouse connector issues,0.988223345,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,Error in acquiring locks with HWC,HDI 4.0 : HDI 4 Hive warehouse connector issues,Recommended to set/update hive.direct.sql.max.elements.values.clause = 100,,,,,,,,
1.20033E+14,30:01.4,Prod cluster performance low +WFH +| Delay In Data Load,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: Spark 2.3 (HDI 3.6)\nHead Nodes = 2\nWorker Nodes = 4\n\nQuestion: Additional details about the issue\nAnswer: Having issue running job in cluster . Its taking longer time than usual \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - Spark 2.3 (HDI 3.6)\nHead Nodes = 2\nWorker Nodes = 4;\nAdditional details about the issue - Having issue running job in cluster . Its taking longer time than usual \n;\n\n- ProblemStartTime: 03/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Novelis Global\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5f5c5be9-a2dd-49c9-bfa1-77d4db790171/resourceGroups/GlobalDAPPROD/providers/Microsoft.HDInsight/clusters/glprodhdcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Prod cluster performance low +WFH +| Delay In Data Load,1.062471695,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,Prod cluster performance low +WFH +| Delay In Data Load,Informatica DIS configuration issue,correction of Informatica DIS configuration,,,,,,,,
1.20033E+14,55:28.3,No able to connect to Hive ODBC driver from rs06ue2dipws17.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: No\n\nQuestion: Connection string being used\nAnswer: ODBC\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Not able to connect to ive ODBC driver from the server. Please find the screenshot in File uploaded\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - No;\nConnection string being used - ODBC;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Other, don't know or not applicable;\nAdditional details about the issue - Not able to connect to ive ODBC driver from the server. Please find the screenshot in File uploaded;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05e2piphdidm05\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",No able to connect to Hive ODBC driver from rs06ue2dipws17.,1.99880409,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to standard cluster,https://supportability.visualstudio.com/AzureHDinsight/_wiki/wikis/AzureHDinsight/315085/Hive-2.6.7-ODBC-driver-fails-to-connect-to-Hadoop-cluster,HDInsight Gateway bug,https://supportability.visualstudio.com/AzureHDinsight/_wiki/wikis/AzureHDinsight/315085/Hive-2.6.7-ODBC-driver-fails-to-connect-to-Hadoop-cluster,,,,,,,,
1.20033E+14,47:43.6,YARN Resource Manager not working,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 29, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: \n\n\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Tried to restart the services, tried to SSH {Ipaddresspii} node but it askes to change password, when trying to change password it gives below error:\n\npasswd: Authentication token manipulation error\npasswd: password unchanged\n\n\nQuestion: Additional details about the issue\nAnswer: Resource Manager is is unable to perform as one Zookeeper node appears to have read-only filesystem. \n\n{Ipaddresspii} nodes seems to have read-only filesystem and YARN is unable to write znodes on this VM.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - \n\n;\nIncrease in load? - ;\nMitigating actions taken so far - Tried to restart the services, tried to SSH {Ipaddresspii} node but it askes to change password, when trying to change password it gives below error:\n\npasswd: Authentication token manipulation error\npasswd: password unchanged\n;\nAdditional details about the issue - Resource Manager is is unable to perform as one Zookeeper node appears to have read-only filesystem. \n\n{Ipaddresspii} nodes seems to have read-only filesystem and YARN is unable to write znodes on this VM.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/28/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",YARN Resource Manager not working,0.484750106,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Ambari Services are not healthy. Both RM are in Standby mode.,the node-label. Mirror file missing from HDFS issue. As explained in the doc https://hdinsight.github.io/yarn/bothRMstandby.html,Explained in the doc belowhttps://hdinsight.github.io/yarn/bothRMstandby.html,"181,986,663,181,995,000",,,,,,,
1.20033E+14,53:38.8,We have some general questions surrounding network security of HDInsight clusters,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Dear Microsoft Support,\n\nThis cluster was implemented by a collegue who is no longer with the organization.\n\nDoes there need to be some kind of firewall, network security group or Virtual Network in order to secure an HDIninsight cluster?\n\nWhat protections are in place for this particular cluster?\n\nAny guidance that you can provide would be greatly appreciated.\n\nKind Regards,\n{Namepii} {Namepii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Dear Microsoft Support,\n\nThis cluster was implemented by a collegue who is no longer with the organization.\n\nDoes there need to be some kind of firewall, network security group or Virtual Network in order to secure an HDIninsight cluster?\n\nWhat protections are in place for this particular cluster?\n\nAny guidance that you can provide would be greatly appreciated.\n\nKind Regards,\n{Namepii} {Namepii}\n;\n\n- ProblemStartTime: 03/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: POC Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0436c84a-f6a1-4100-942a-97ff0053a79f/resourceGroups/anir-dec-poc2/providers/Microsoft.HDInsight/clusters/anir-hdinsight2\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We have some general questions surrounding network security of HDInsight clusters,0.051518203,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hbase,Client has some general questions surrounding network security of HDInsight clusters.,Client has some general questions surrounding network security of HDInsight clusters.,Couple of useful links were provided:  Create virtual networks for Azure      HDInsight clusters: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-create-virtual-network   Network security      group (NSG) service tags for Azure HDInsight: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-service-tag  How to      assign single public IP for VNet-injected workspaces using Azure      Firewall: https://docs.microsoft.com/en-us/azure/databricks/kb/cloud/azure-vnet-single-ip  Management IP for HDInsight: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses  HDInsight      cluster with the enterprise security package (ESP): https://docs.microsoft.com/en-us/azure/hdinsight/domain-joined/hdinsight-security-overviewAlso for ARM templates: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-create-linux-clusters-arm-templates#generate-templates ,,,,,,,,
1.20033E+14,01:12.2,Technical doubt about the virtual machines time,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 7:00 AM CST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Reading documentation\n\nQuestion: Additional details about the issue\nAnswer: A few doubts.\n-Want to know what are the best practices in orde to change the cluster time to synchronize it with the time in Mexico and and what would be the possible effects\n-Here in México we are having and schedule change so we were wondering if there was some action we should do or something to be aware of in order to avoid any technical functionality\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Reading documentation;\nAdditional details about the issue - A few doubts.\n-Want to know what are the best practices in orde to change the cluster time to synchronize it with the time in Mexico and and what would be the possible effects\n-Here in México we are having and schedule change so we were wondering if there was some action we should do or something to be aware of in order to avoid any technical functionality;\n\n- ProblemStartTime: 03/30/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZRINFRAESTRUCTURA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3f8d5f46-3a0e-4bc6-9e32-3e4774c514aa/resourceGroups/AZRDATALAKE/providers/Microsoft.HDInsight/clusters/prointquerylivc4\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Technical doubt about the virtual machines time,0.052693872,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Questions about the virtual machine time. ,Customer was inquiring about VM Time Settings. ,I informed the customer that they can change to the local time zone in Ambari but the Linux VMs only work in UTC time.,,,,,,,,
1.20033E+14,57:45.0,Can't access to yarn UI,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I used to use Yarn UI to monitor my applications, but today I can't access it : \nhttps://dart-spark.hdi.dart.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster/apps/RUNNING\n\nI have an error : dart-spark.hdi.dart.dev.euw.gbis.sg-azure.com redirected you too many times.\n\nI didn't change anything on the cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I used to use Yarn UI to monitor my applications, but today I can't access it : \nhttps://dart-spark.hdi.dart.dev.euw.gbis.sg-azure.com/yarnui/hn/cluster/apps/RUNNING\n\nI have an error : dart-spark.hdi.dart.dev.euw.gbis.sg-azure.com redirected you too many times.\n\nI didn't change anything on the cluster;\n\n- ProblemStartTime: 03/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Basic Support\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/44f9a17e-e4f6-490f-9e4b-bcbdf9817a88/resourceGroups/frm-rpc-dart-1-DEV-dart-spark-Automation-HDI/providers/Microsoft.HDInsight/clusters/lAfmVxMv18-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't access to yarn UI,0.06305516,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Service unhealthy\Hadoop,120033026003522  - Can't access to yarn UI,"The HDInsight gateways are automatically configured to resolve the following endpoints:Ambari UI Endpoints:https://lafmvxmv18-projectspark-int.azurehdinsight.nethttps://lafmvxmv18-projectspark.azurehdinsight.netFor Yarn UI access, our gateways are automatically configured to use the links within the Ambari UI.  Here is the documentation on this: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-access-yarn-app-logs-linux#yarn-resourcemanager-ui",Customer's networking team will resolve as they have configured a reverse proxy to access the HDInsight endpoints.,,,,,,,,
1.20033E+14,07:10.3,Spark Thrift server connection issue,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: hn1-ensdat.1rkhznh5za5utbat20kwunuzmd.yx.internal.cloudapp.net\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Connection failed on host hn1-ensdat.1rkhznh5za5utbat20kwunuzmd.yx.internal.cloudapp.net:10002 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/SPARK2/2.0.0/package/scripts/alerts/alert_spark2_thrift_port.py', line 149, in execute\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run()\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - hn1-ensdat.1rkhznh5za5utbat20kwunuzmd.yx.internal.cloudapp.net;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - Connection failed on host hn1-ensdat.1rkhznh5za5utbat20kwunuzmd.yx.internal.cloudapp.net:10002 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/SPARK2/2.0.0/package/scripts/alerts/alert_spark2_thrift_port.py', line 149, in execute\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run();\n\n- ProblemStartTime: 03/30/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6900704a-e368-4960-9a99-ee57384d17ea/resourceGroups/HDInsightClusterResources/providers/Microsoft.HDInsight/clusters/ensdatacatalystprod\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Thrift server connection issue,4.145367213,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,"Connection between Power BI and HDInsight Spark Cluster is failing, PowerBI is attempting to connect to hn1 instead of hn0 (which is the default). Throwing the error OBDC: ERROR[HY000][Microsoft][DriverSupport](1170)Issue 2: HIVEVIEW failure CX wanted to be keep opening ICM for further principal root cause",pp Timeline server and History server stopped working on hn1,Restarted these apps and all the components on hn1,"182,184,923,182,736,000",,,,,,,
1.20033E+14,30:16.3,Having Issue to create Hdi cluster in east asia,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: batchclustereasia\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I am not able to create a cluster in east asia. Please find attached error\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - batchclustereasia;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I am not able to create a cluster in east asia. Please find attached error;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Teams-RecGen_StreamProcessing-PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/95fcc4dc-c3b2-463c-9a36-471714d13ad4/resourceGroups/batchcluster/providers/Microsoft.HDInsight/clusters/batchclustereasia\n- Location: eastasia\n- Location: East {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Having Issue to create Hdi cluster in east asia,0.069244468,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Having Issue to create Hdi cluster in east asia.,Logs Revealed the capacity issues under subscription.,Recreating the cluster with lower configuration and rescaling the nodes fixed the issue.,,,,,,,,
1.20033E+14,23:36.8,unable to create R studio edge server,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: rdemocluster\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - rdemocluster;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Internal Consumption\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to create R studio edge server,0.388474664,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,When creating a new HDI ML R server Internal server error was caused.,Unable to identify cause.,Had the user retry deployment after doing a repo of the issue.,,,,,,,,
1.20033E+14,37:03.6,HDI  4.0 : Spark :Scale up operation is  failing through portal,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer:     'properties': {\n        'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: FailedToScaleClusterErrorCode; ErrorDescription: Unable to retrieve actual node/host counts from Ambari cluster manager. Please contact support if the failure persists.{Uncpii}\n    },\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue -     'properties': {\n        'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: FailedToScaleClusterErrorCode; ErrorDescription: Unable to retrieve actual node/host counts from Ambari cluster manager. Please contact support if the failure persists.{Uncpii}\n    },;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps020sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI  4.0 : Spark :Scale up operation is  failing through portal,3.486474233,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,itleHDI 4.0 : Spark :Scale up operation is failing through portal,nodes not released,deleted the wnodes manually tested scaling down and upworking fine,,,,,,,,
1.20033E+14,22:12.7,Pipeline got failed (SephoraMasterPipeline),"It seems that the code is failing to connect to key vault and get secret keys.\n\nProblem start date and time\n{Namepii}, {Namepii} 31, 2020, 3:00 PM GMT+5:30\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 03/31/2020 09:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinerg/providers/Microsoft.DataFactory/factories/mpcosmuse2sephtsadf1\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Pipeline got failed (SephoraMasterPipeline),0.845328081,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,"Routing Azure Data Factory V2\Pipeline Activities\HDInsight (Hive, MapReduce, Pig, Spark, Streaming)",Spark was not able to connect to key vault,Key vault outage,Key vault team had an outage and came back up.  Contacted key vault team for confirmation of this outage.,,,,,,,,
1.20033E+14,07:21.2,Hive tables access issue from pyspark,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: We will share the details on further disucssion over email, for now please fine the error message screenshot attached with this ticket.\n\nQuestion: Additional details about the issue\nAnswer: We are reading and writing hive tables using pyspark application. During one testing we did do a query on the table and discover it was empty and then suddenly had data without any runs or other intervention from us.\n\nIt's unexpected behaviour of hive tables. Please help to troubleshoot the issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Python;\nSpark configuration details - We will share the details on further disucssion over email, for now please fine the error message screenshot attached with this ticket.;\nAdditional details about the issue - We are reading and writing hive tables using pyspark application. During one testing we did do a query on the table and discover it was empty and then suddenly had data without any runs or other intervention from us.\n\nIt's unexpected behaviour of hive tables. Please help to troubleshoot the issue.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/25/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BBY-NP-APP-PaaS-Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/13422346-eb93-429e-85d8-3039a19d52da/resourceGroups/BBY-NP-UBP-RG-USC-01/providers/Microsoft.HDInsight/clusters/dt-spark-ubp-usc-01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive tables access issue from pyspark,0.183203626,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Hive tables access issue from pyspark,Hive tables access issue from pyspark,"HDInsight support had checked the logs and collaborated with Storage engineer to understand the call pattern, but no helpful info was found on storage logs. Shared debug settings for WASB/ADLS/ADL Gen2 with customer to enable debugging from client end and also diagnostics logs on storage accounts to capture the calls for later investigation if issue recurs. Customer confirmed to close the case.",,,,,,,,
1.20033E+14,17:27.9,Error Scaling Cluster Up,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 8:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: no\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: removed udr and nsg to make sure that was not the issue. Might be an issue because subnet only has 6 addresses left.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - no;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - removed udr and nsg to make sure that was not the issue. Might be an issue because subnet only has 6 addresses left.;\n\n- ProblemStartTime: 03/31/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1fbd08f6-3801-41ce-833c-c01f921e2223/resourceGroups/dsi_centralus_sit_rg01/providers/Microsoft.HDInsight/clusters/dsisit-centralus2-sit-hdi01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error Scaling Cluster Up,0.060880453,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,,,,,,,,,,,
1.20033E+14,46:23.1,Disk usage full,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: spark job fails due to lack of disk space\n\nQuestion: Additional details about the issue\nAnswer: spark job fails due to lack of disk space\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Python;\nSpark configuration details - spark job fails due to lack of disk space;\nAdditional details about the issue - spark job fails due to lack of disk space;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: TBDC-TIMS-CAS-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/853a7c3e-9554-4f69-a0cd-fa48a4362d54/resourceGroups/cas_prod_rg/providers/Microsoft.HDInsight/clusters/casdbcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Disk usage full,0.223656287,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,Disk usage full,so the / directory on the headnode seems to be almost full at a point it was 99% full/dev/sda1       125G  120G  4.4G  97% /  which caused the services to fail(ambari-server) and every other service runningI looked at the disk usage and found out that out of the 125 G alloted to the mnt /dev/sda156-60% was being used up by /var/log/mdsd.warnthis mdsd service runs on all the Azure Vmslooking at hn1 I see the same behaviour where the log file size is some 12G and OMS is not enabled on the cluster. I opened a collaboration task to the Az Linux CSS team. No one has answered me yet,Cleaned up the mdsd logs,182163614,,,,,,,
1.20033E+14,11:51.9,Test Test,TEST TEST\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: kathapa\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Test Test,0.000719152,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Test,Test,Test,,,,,,,,
1.20033E+14,21:58.2,Ambari metrics not available.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ambari {Namepii} service stopping repeatedly. We are staring the service again it is stopping.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ambari {Namepii} service stopping repeatedly. We are staring the service again it is stopping.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/30/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdalatamrm-prdhadoop-scus-01-rg/providers/Microsoft.HDInsight/clusters/prdhadooplatamrm\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari metrics not available.,0.078053033,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Metrics are missing\Hadoop,ATS service is going down,Issue: Ambari metrics not available,"  Login into the Ambari portal  Set AMS to maintenance  Stop AMS from Ambari  Identify the following from the AMS Configs screen:     hbase.rootdir (Default value is file:///mnt/data/ambari-metrics-collector/hbase)   hbase.tmp.dir(Default value is /var/lib/ambari-metrics-collector/hbase-tmp)    SSH into headnode0. as superuser  Remove the AMS zookeeper data by backing up and      removing the contents of 'hbase.tmp.dir'/zookeeper  Remove any Phoenix spool files from 'hbase.tmp.dir'/phoenix-spool folder  Note: It is worthwhile to skip this step and first      restarting AMS to see if the issue is resolved. If AMS is still failing to      come up, try this step: AMS data would be stored in hbase.rootdir identified      above. Use regular OS commands to backup and remove the files: # tar czf /mnt/backupof-ambari-metrics-collector-hbase-$(date      +%Y%m%d-%H%M%S).tar.gz /mnt/data/ambari-metrics-collector/hbase  Restart AMS using Ambari",,,,,,,,
1.20033E+14,19:29.7,Cluster stuck at scaling up because RM not being allocated,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 11:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} stuck at scaling up because RM not being allocated\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} stuck at scaling up because RM not being allocated;\n\n- ProblemStartTime: 03/31/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-STG-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24cccmcaistage\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster stuck at scaling up because RM not being allocated,0.898591589,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to submit applications to standby RM,Both the RM are in standby state due to under replicated files.,"According to HA architecture, stopped both the RM. Cleared under replicated files and made one RM as Active and other as Standby by starting one by one. This related to 120040121000013  ",,,,,,,,
1.2004E+14,10:40.6,Can not scale up,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 31, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The cluster can not be scaled up through portal UI.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The cluster can not be scaled up through portal UI.;\n\n- ProblemStartTime: 03/31/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-STG-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24cccmcaistage\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can not scale up,0.863418788,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,"Autoscale fails with ""[{""ErrorCode"":""InternalServerError"",""ErrorDescription"":""Encountered failure(s) scaling cluster to 10 nodes. Scaling operation partially succeeded with a final node count of 1. Scaling error code: InternalServerError. Scaling error message: Failed to setup hosts during scale up.""}]""",Issue with scaling up as both RM's are standby state,Both the RM are in standby state. We have to make one RM as active and other as Standby state.,,,,,,,,
1.2004E+14,38:19.8,kp10tntncapllapnsprdsup01: Hive service is down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Hive service is down\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Hive service down.\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk1-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk4-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk5-kp10tn.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk1-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk4-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk5-kp10tn.kpaaddsprod.onmicrosof\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Hive service is down;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Hive service down.\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk1-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk4-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk5-kp10tn.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=svcespadfprdsup\n\n{AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk1-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk4-kp10tn.kpaaddsprod.onmicrosoft.com:2181,zk5-kp10tn.kpaaddsprod.onmicrosof;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kp10tntncapllapnsprdsup01: Hive service is down,0.067791107,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,kp10tntncapllapnsprdsup01: Hive service is down,kp10tntncapllapnsprdsup01: Hive service is down,"Support checked and found GC Pauses on the logs and requested customer to increase heap size. Alternatively customer worked with PG aswell on this and advised to use ""hive.fetch.task.conversion=none"" (whereever required) to minimize the pressure on HiveServer2. Customer agreed to close the case.",,,,,,,,
1.2004E+14,13:23.7,Unable to view tables on hive,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: Exact Error: When we create any table in any schema through spark-sql . It is not accessible in Hive and vice versa.\n\nAttached are some findings:\n1) Created a Hive tables using Spark and is visible only through Spark.\n2) Listed the tables of the schema in hive.(It is not available)\n\n\nQuestion: Additional details about the issue\nAnswer: Exact Error: When we create any table in any schema through spark-sql . It is not accessible in Hive and vice versa.\n\nAttached are some findings:\n1) Created a Hive tables using Spark and is visible only through Spark.\n2) Listed the tables of the schema in hive.(It is not available)\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - Exact Error: When we create any table in any schema through spark-sql . It is not accessible in Hive and vice versa.\n\nAttached are some findings:\n1) Created a Hive tables using Spark and is visible only through Spark.\n2) Listed the tables of the schema in hive.(It is not available)\n;\nAdditional details about the issue - Exact Error: When we create any table in any schema through spark-sql . It is not accessible in Hive and vice versa.\n\nAttached are some findings:\n1) Created a Hive tables using Spark and is visible only through Spark.\n2) Listed the tables of the schema in hive.(It is not available)\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to view tables on hive,0.089332745,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Spark,Unable to view tables on hive,Unable to view tables on hive,"Worked with customer and advised that beginning with HDInsight 4.0, Apache Spark 2.3.1 and Apache Hive 3.1.0 have separate metastores, which can make interoperability difficult. The Hive Warehouse Connector makes it easier  to use Spark and Hive together. https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.5/integrating-hive/content/hive_hivewarehouseconnector_for_handling_apache_spark_data.htmlOn HDInsight, you would need follow below steps to complete the Hive Warehouse connector setup. https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector#hive-warehouse-connector-setup",,,,,,,,
1.2004E+14,44:22.1,Unable to deploy LLAP Cluster using ADDS,"Question: What time did the problem begin?\nAnswer: Wed, Apr 1, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: New {Namepii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We received the following error while deploying the cluster,\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'code\\': \\'BadRequest\\',\\r\\n \\'message\\': \\''securityProfile.ldapsUrls' ldaps://PCLOUDPLATFORM.CO.UK:636 didn't match any subjectAltNames in the configured LDAPS certificate containing DNS patterns [*.PCLOUDPLATFORM.CO.UK] and IP Addresses [].\\'\\r{uncpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - New {Namepii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We received the following error while deploying the cluster,\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'code\\': \\'BadRequest\\',\\r\\n \\'message\\': \\''securityProfile.ldapsUrls' ldaps://PCLOUDPLATFORM.CO.UK:636 didn't match any subjectAltNames in the configured LDAPS certificate containing DNS patterns [*.PCLOUDPLATFORM.CO.UK] and IP Addresses [].\\'\\r{uncpii}\n\n- ProblemStartTime: 03/31/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: REBUS_PRODUCTION_INSIGHTS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c003680b-ac89-49ab-9002-303f05c69b0f/resourceGroups/AM-RB-PRDX-RA-HDIN-RG01/providers/Microsoft.HDInsight/clusters/rbliveventaggregator\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to deploy LLAP Cluster using ADDS,0.269582704,Root Cause : HDInsight Service\Azure Certificate issue,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,Unable to deploy LLAP Cluster using ADDS.,LDAP certificate is not configured properly.,Deploy the cluster with new LDAP certificate.,,,,,,,,
1.2004E+14,35:53.6,Hive Service is down,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 31, 2020, 11:00 PM MST\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hive and spark thrift services are down. Lot of business users are impacting with this issue.\n\nConnecting to jdbc:hive2://zk1-aa-esp.petsmartazureds.com:2181,zk4-aa-esp.petsmartazureds.com:2181,zk6-aa-esp.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2;principal=hive/_HOST@PETSMARTAZUREDS.COM\nError: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper ({alphanumericpii})\nBeeline version 1.2.1000.2.6.5.3006-29 by {Namepii} Hive\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hive and spark thrift services are down. Lot of business users are impacting with this issue.\n\nConnecting to jdbc:hive2://zk1-aa-esp.petsmartazureds.com:2181,zk4-aa-esp.petsmartazureds.com:2181,zk6-aa-esp.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2;principal=hive/_HOST@PETSMARTAZUREDS.COM\nError: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper ({alphanumericpii})\nBeeline version 1.2.1000.2.6.5.3006-29 by {Namepii} Hive\n;\n\n- ProblemStartTime: 04/01/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Service is down,0.153268014,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Hive Service is down,Hive Service is down,"HiveServer2 and SparkThriftServices were down on the cluster due to Namenode in safe mode. Customer had taken HDFS out of safe mode. Product group had shared below recommendations for the cluster - 1.            We see that the cluster is not provisioned recommended SKU's... Please find the recommended sizes belowhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-supported-node-configuration#all-supported-regions-except-brazil-south-and-japan-west2.            LLAP was stopped on the cluster and on ESP clusters, Spark-sql would need LLAP to be running on the cluster.                                             Since there are not enough YARN containers on the cluster and Spark-thrift and LLAP was sharing resources from same queue, you had reduced Nodes for LLAP daemon to 2 from 8 and started LLAP successfully.",182314760,,,,,,,
1.2004E+14,10:23.4,ADF SB : kps053sparkespadfsbwus201 : Node is not accessible,"The “ {Ipaddresspii} “ with the password is not accessible.\n\nProblem start date and time\nWed, Apr 1, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/01/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-edpcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps053sparkespadfsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF SB : kps053sparkespadfsbwus201 : Node is not accessible,0.050528225,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,ADF SB : kps053sparkespadfsbwus201 : Node is not accessible,By design ,Went on screenshare session and followed. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-the-ssh-user-password,,,,,,,,
1.2004E+14,25:52.8,Need confirmation for the change in property in coresite.xml,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: {Namepii} engine\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hi,the jobs executed from the BDM tool to HDI cluster fails with the sequence geneartor issue -This is a huge impact for our business .\nInformatica BDM team has investigated on the same and they have suggested few changes in HDI cluster to fix the issue.\nThey want the -Property fs.wasb.impl.disable.cache: true in core_site_xml\nWe need your advise if the changes recommended can be implemented?\nThanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - {Namepii} engine;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Hi,the jobs executed from the BDM tool to HDI cluster fails with the sequence geneartor issue -This is a huge impact for our business .\nInformatica BDM team has investigated on the same and they have suggested few changes in HDI cluster to fix the issue.\nThey want the -Property fs.wasb.impl.disable.cache: true in core_site_xml\nWe need your advise if the changes recommended can be implemented?\nThanks;\n\n- ProblemStartTime: 03/02/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need confirmation for the change in property in coresite.xml,1.385244945,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,Need confirmation for the change in property in coresite.xml,NA,"Without doing FS caching, there is a new fs object for every command against the file system and this increases the chance of the issue happening .This is a transient issue. It has a chance of happening with each fs object. With caching, we reuse objects so the chance of hitting the error is decrease. https://issues.apache.org/jira/browse/HIVE-4605 The community has already proposed a fix. Later in the summer we are going to production with our ""distro"" infra which means MS+Apache. so we will be able to deliver this change once that is available. I know the only fix for you to deal with memory leak is to disable cache. But for now, the recommendation would still to be using the cache flag ON to fix this issue.",187169035,,,,,,,
1.2004E+14,04:26.3,error message: existing domain cvsadds.com could not be found,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 6:44 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Error message: Domain cvsadds.com not found in the Active Directory.\nthe Domain exist\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Error message: Domain cvsadds.com not found in the Active Directory.\nthe Domain exist;\n\n- ProblemStartTime: 03/31/2020 22:44:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Redpoint CDP NonProd\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6a1a7290-7f6c-4bc0-ad5c-cfb9321813d3/resourceGroups/UATCDPTestTemplateRG/providers/Microsoft.HDInsight/clusters/karma1234\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",error message: existing domain cvsadds.com could not be found,0.016396996,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,existing domain cvsadds.com could not be found,error message: existing domain cvsadds.com could not be found,suggested to verify and update the DNS servers on HDInsight VNET with the ADDS IP addresses. Also requested to add the East US2 management IPs,,,,,,,,
1.2004E+14,29:13.3,Edge node root filesystem size,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: NA\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have 2 edge nodes created for this HDInsight cluster {alphanumericpii}.\n\ned11-ahd501.azfrk.com  Size {Alphanumericpii}\ned20-ahd501.azfrk.com Size {Alphanumericpii}\n\n{alphanumericpii}:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nudev             14G     0   14G   0% /dev\ntmpfs           {ALPHANUMERICPII}  {ALPHANUMERICPII}  {ALPHANUMERICPII}  10% /run\n/{alphanumericpii}       {ALPHANUMERICPII}   22G  {ALPHANUMERICPII}  18% /\ntmpfs            14G   12K   14G   1% /dev/shm\ntmpfs           {ALPHANUMERICPII}     0  {ALPHANUMERICPII}   0% /run/lock\ntmpfs            14G     0   14G   0% /sys/fs/cgroup\n/{alphanumericpii}       {ALPHANUMERICPII}  {ALPHANUMERICPII}  {ALPHANUMERICPII}   2% /mnt\n{alphanumericpii}:~$\n\nBoth edge nodes came with / volue size as {ALPHANUMERICPII}. Previously edge nodes with same size came with / volume 1TB. Can you please let us know how we can have highter / root volume size for these edge node VM's.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - NA;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - We have 2 edge nodes created for this HDInsight cluster {alphanumericpii}.\n\ned11-ahd501.azfrk.com  Size {Alphanumericpii}\ned20-ahd501.azfrk.com Size {Alphanumericpii}\n\n{alphanumericpii}:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nudev             14G     0   14G   0% /dev\ntmpfs           {ALPHANUMERICPII}  {ALPHANUMERICPII}  {ALPHANUMERICPII}  10% /run\n/{alphanumericpii}       {ALPHANUMERICPII}   22G  {ALPHANUMERICPII}  18% /\ntmpfs            14G   12K   14G   1% /dev/shm\ntmpfs           {ALPHANUMERICPII}     0  {ALPHANUMERICPII}   0% /run/lock\ntmpfs            14G     0   14G   0% /sys/fs/cgroup\n/{alphanumericpii}       {ALPHANUMERICPII}  {ALPHANUMERICPII}  {ALPHANUMERICPII}   2% /mnt\n{alphanumericpii}:~$\n\nBoth edge nodes came with / volue size as {ALPHANUMERICPII}. Previously edge nodes with same size came with / volume 1TB. Can you please let us know how we can have highter / root volume size for these edge node VM's.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge node root filesystem size,0.044753933,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,Edge node root filesystem size,NA,No way of higher root file system size for the edge node VM and also this is not allowed to add more spacehttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-release-notes-archive#behavior-changes-1,,,,,,,,
1.2004E+14,57:52.2,All the nodes are unhealthy and not reacheable,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We were unable to connect to the headnodes\n\nQuestion: Additional details about the issue\nAnswer: The hednodes are not reachable and all the services are unhealthy.Can you please reboot the nodes and bring the services up\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We were unable to connect to the headnodes;\nAdditional details about the issue - The hednodes are not reachable and all the services are unhealthy.Can you please reboot the nodes and bring the services up;\n\n- ProblemStartTime: 03/31/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",All the nodes are unhealthy and not reacheable,0.173030508,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop, Services unhealthy.,Connectivity issue with active headnode       ,Restarted headnode(s),182340141,,,,,,,
1.2004E+14,13:12.3,Ambari does not provide error message ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: any Query will run the same.\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Any errors in the query, error messages are not reported.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - any Query will run the same.;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Any errors in the query, error messages are not reported.;\n\n- ProblemStartTime: 03/30/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/910c6c2e-938b-4a69-8bab-2f57583abe08/resourceGroups/CTBIDL-CTM00102-NonProd/providers/Microsoft.HDInsight/clusters/ctbiclusterprep\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari does not provide error message ,0.012485066,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hive,Ambari does not provide error message,By design,The complete error message can be seen in the Notification section. You can see the same error message in the hive view logs that are stored in the same node where ambari-server is running and the location is : /var/log/ambari-server/hive20-view ,,,,,,,,
1.2004E+14,13:08.9,Poor cluster performance,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: There are two major issues here\n\n-{Namepii} query is speed is very low and it is not even running on longer query . ( It is throwing timeout error)\n\n-We cannot able to extract columns of Hbase where there is special symbol in column name (Ex., °F)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - {Namepii};\nAdditional details about the issue - There are two major issues here\n\n-{Namepii} query is speed is very low and it is not even running on longer query . ( It is throwing timeout error)\n\n-We cannot able to extract columns of Hbase where there is special symbol in column name (Ex., °F);\n\n- ProblemStartTime: 04/02/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cb458380-a7fa-4c7a-befb-ac613cfe0138/resourceGroups/Internal_Development/providers/Microsoft.HDInsight/clusters/dec-poc-02\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Poor cluster performance,0.270788127,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,120040224001297 - Poor cluster performance HDInsight Service and ascii characters in HBase column names,  Phoenix tables cannot translate the ascii      characters during HBase column mapping  HBase data was not evenly distributed      across all of the Region Servers due to lack of indexing/partitions during      table creation,"  It was recommended to use only      alpha-numeric characters in the column names before ingesting the data      into HBASE.  It was also recommended to use salting and      buckets for the Phoenix tables to improve read performance.  Ultimately, the customer decided not to      use HBase for their use-case.",182451418,,,,,,,
1.2004E+14,33:15.3,Failed to submit Spark job,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 8:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Error reported by the pipeline;\n{\n   'errorCode': '2310',\n   'message': 'Failed to submit Spark job. Error: 'BadGateway'',\n   'failureType': 'UserError',\n   'target': 'SFFileRecommActivity',\n   'details': []\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Error reported by the pipeline;\n{\n   'errorCode': '2310',\n   'message': 'Failed to submit Spark job. Error: 'BadGateway'',\n   'failureType': 'UserError',\n   'target': 'SFFileRecommActivity',\n   'details': []\n};\n\n- ProblemStartTime: 04/02/2020 14:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsRG/providers/Microsoft.HDInsight/clusters/cas-hdi-ml-spark23\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failed to submit Spark job,0.04354963,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,Failed to submit Spark job,Failed to submit Spark job,"Customer had mitigated the issue by starting Livy on HN1. Customer found that HN1 is the active headnodehost and one of their engineer had stopped Livy on HN1, expecting it to be running on one of the headnode.Shared below document with customer for availability of services on the cluster based on active headnode -                   https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-high-availability-components#hdinsight-high-availability-services​Customer can determine the active headnode by pinging ""headnodehost"" on both the nodes and both should be reporting same node. Customer agreed to close the case.","182,451,113,182,451,000",,,,,,,
1.2004E+14,07:56.1,Unable to start hiveserver2 service ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 6:00 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Attempted to restart the {alphanumericpii} service on hn0 without success. Rebooted hn0, {alphanumericpii} was still unable to start, apparently it is unable to detect that the yarn application has started. Restarted all services on wn1 and wn3 successfully, but still not able to start the {alphanumericpii} service on hn0. Looking at the yarn logs of the related application and the only error I see is that it gets a 500 error when attempting to hit the Timeline Service. I am not certain if this error is causing the problem, if it is just taking a while for the yarn application to completely start and I should increase the timeout, or if there is a different issue in play.\n\nQuestion: Additional details about the issue\nAnswer: WARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nLLAP status unknown\n--------------------------------------------------------------------------------\n\n\n\n\n{\n  'amInfo' : {\n    'appName' : '{alphanumericpii}',\n    'appType' : 'yarn-service',\n    'appId' : '{alphanumericpii}'\n  },\n  'state' : 'UNKNOWN',\n  'appStartTime' : 0,\n  'runningThresholdAchieved' : false,\n  'desiredInstances' : 2,\n  'liveInstances' : 1,\n  'runningInstances' : [ {\n    'hostname' : 'wn3-c10-pd.avalamarketing.com',\n    'containerId' : '{alphanumericpii}',\n    'yarnContainerExitStatus' : 0\n  } ]\n}\nWARN status.LlapStatusServiceDriver: Watch timeout {Alphanumericpii} exhausted before desired state RUNNING is attained.\nINFO status.LlapStatusServiceDriver: LLAP status finished\nERROR status.LlapStatusServiceDriver: LLAP did not start. Check the application log for more info:\nyarn logs --applicationId {alphanumericpii} -out \n\nCommand failed after 1 tries\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Attempted to restart the {alphanumericpii} service on hn0 without success. Rebooted hn0, {alphanumericpii} was still unable to start, apparently it is unable to detect that the yarn application has started. Restarted all services on wn1 and wn3 successfully, but still not able to start the {alphanumericpii} service on hn0. Looking at the yarn logs of the related application and the only error I see is that it gets a 500 error when attempting to hit the Timeline Service. I am not certain if this error is causing the problem, if it is just taking a while for the yarn application to completely start and I should increase the timeout, or if there is a different issue in play.;\nAdditional details about the issue - WARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nLLAP status unknown\n--------------------------------------------------------------------------------\n\n\n\n\n{\n  'amInfo' : {\n    'appName' : '{alphanumericpii}',\n    'appType' : 'yarn-service',\n    'appId' : '{alphanumericpii}'\n  },\n  'state' : 'UNKNOWN',\n  'appStartTime' : 0,\n  'runningThresholdAchieved' : false,\n  'desiredInstances' : 2,\n  'liveInstances' : 1,\n  'runningInstances' : [ {\n    'hostname' : 'wn3-c10-pd.avalamarketing.com',\n    'containerId' : '{alphanumericpii}',\n    'yarnContainerExitStatus' : 0\n  } ]\n}\nWARN status.LlapStatusServiceDriver: Watch timeout {Alphanumericpii} exhausted before desired state RUNNING is attained.\nINFO status.LlapStatusServiceDriver: LLAP status finished\nERROR status.LlapStatusServiceDriver: LLAP did not start. Check the application log for more info:\nyarn logs --applicationId {alphanumericpii} -out \n\nCommand failed after 1 tries;\n\n- ProblemStartTime: 04/02/2020 12:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AVALA Aimbase Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/dbb4eb18-427d-4399-82d2-c8644c869282/resourceGroups/aimbase-data-pd-rg/providers/Microsoft.HDInsight/clusters/c10-pd-ab-hdi\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to start hiveserver2 service ,0.123343231,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Unable to start hiveserver2 service,Service getting hung at wn1 possibly due to port conflict   ,Restarted wn1,182469661,,,,,,,
1.2004E+14,14:23.2,Error when executing spark job : org.apache.hadoop.hive.ql.exec.MoveTask,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: /\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I execute a spark job which recover data from a cassandra database in order to insert into hive.\nI can execute some job but I often have the following error :\nCaused by: java.lang.RuntimeException: java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask. Exception when loading 1121 in table tableschema with loadPath=abfs://dsjdgignpd05bidatadev04@dsjdgignpd05bidatadev04.dfs.core.windows.net/hive/warehouse/managed/reportinformation.db/tableschema/.hive-staging_hive_2020-04-02_18-55-53_995_4853630775886664170-15/-ext-10000\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 26 more\n\n\nThe tableschema table is a metastore table in Hive, and it seems that something is wrong about a MoveTask.\nThanks a for help \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - /;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I execute a spark job which recover data from a cassandra database in order to insert into hive.\nI can execute some job but I often have the following error :\nCaused by: java.lang.RuntimeException: java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask. Exception when loading 1121 in table tableschema with loadPath=abfs://dsjdgignpd05bidatadev04@dsjdgignpd05bidatadev04.dfs.core.windows.net/hive/warehouse/managed/reportinformation.db/tableschema/.hive-staging_hive_2020-04-02_18-55-53_995_4853630775886664170-15/-ext-10000\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 26 more\n\n\nThe tableschema table is a metastore table in Hive, and it seems that something is wrong about a MoveTask.\nThanks a for help ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4sparkbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error when executing spark job : org.apache.hadoop.hive.ql.exec.MoveTask,0.920380152,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,120040221002365 - Error when executing spark job : org.apache.hadoop.hive.ql.exec.MoveTask ,User executing the jobs did not have permissions to move data from the staging directory to the final storage location,Changed the following configs:hive.exec.stagingdir=${hive.exec.scratchdir}/${user.name}/.staginghive.server2.enable.doAs=trueCustomer also set some additional configs ,,,,,,,,
1.2004E+14,23:51.2,Server not found in Kerberos Database,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 8:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: {alphanumericpii}\n\nQuestion: Interactive query if applicable\nAnswer: /\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hello,\nI execute some spark job (with spark-submit command) since several days on this cluster and today I have the following error that seems to be associated to Kerberos.\nI execute jobs on Spark cluster that use an Interactive query cluster to populate a database.\n\nThe jdbc connection string that is in a log is the one I have configured using the documentation below:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector\n\nI can confirm that it was working well.\nThanks for your help.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - {alphanumericpii};\nInteractive query if applicable - /;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hello,\nI execute some spark job (with spark-submit command) since several days on this cluster and today I have the following error that seems to be associated to Kerberos.\nI execute jobs on Spark cluster that use an Interactive query cluster to populate a database.\n\nThe jdbc connection string that is in a log is the one I have configured using the documentation below:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector\n\nI can confirm that it was working well.\nThanks for your help.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/02/2020 12:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV05/providers/Microsoft.HDInsight/clusters/dsjd5sparkbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Server not found in Kerberos Database,0.031212446,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,1. Server not found in Kerberos Database2. JDBC connectivity Error3. Spark-sumit run error,"incorrect JDBC string, spark conf and automation script","Correction of a JDBC string and Spark Configuration (conf=spark.security.credentials.hiveserver2.enabled=true instead of false), and automation script for spark-sumit job run  ",,,,,,,,
1.2004E+14,42:36.8,I can't see the performance logs of HDInsight nodes through Log analytics queries.,"Can't see the performance logs of HDInisight nodes through log analytics. Already installed OMS on all the nodes through script action.\n\nProblem start date and time\n{Namepii}, Apr 2, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/02/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Internal Consumption\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb77f20d-db5b-46d5-bbae-bb5656730ffc/resourceGroups/franklin-hdi/providers/Microsoft.HDInsight/clusters/franklin-hdi\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I can't see the performance logs of HDInsight nodes through Log analytics queries.,3.154133969,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\HDInsight workload monitoring solution,Can't see the performance logs of HDInsight nodes through Log analytics queries.,Need to Query under Custom log to see the performance log of worker node.,"To see the worker node performance log, have to query under tables>Custom log> log_nodemanager_CL and have to write the manual query as per the requirement to see the performance.",,,,,,,,
1.2004E+14,39:03.4,Scaling Failing,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: 'Resize/scale operation cannot be performed on this cluster at this time as it is not in 'Running' state. It is possible that the cluster is undergoing other update operations. Please retry later.'\n\nWe had this issue happened before and as per Microsoft was told to host our own Ambari DB which will fix the issue but we are still seeing the same issue. We hosted P1 database for Ambari. Couple of support requests raised earlier\n{Phonenumberpii}\n{Phonenumberpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - 'Resize/scale operation cannot be performed on this cluster at this time as it is not in 'Running' state. It is possible that the cluster is undergoing other update operations. Please retry later.'\n\nWe had this issue happened before and as per Microsoft was told to host our own Ambari DB which will fix the issue but we are still seeing the same issue. We hosted P1 database for Ambari. Couple of support requests raised earlier\n{Phonenumberpii}\n{Phonenumberpii};\n\n- ProblemStartTime: 04/02/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ba4526ea-6a69-40d2-8f7b-8f7a10dbafdf/resourceGroups/gehc-datasvc-spark-01/providers/Microsoft.HDInsight/clusters/dtspwsuwsparkcluster1a\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Scaling Failing,38.05365322,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,Scalign failign when scaling up +200 or +100 nodes ,Ambari server timing out when adding large # of nodes,And regarding the best practices for scaling up to really large cluster sizes –   please      follow the properties mentioned in the baseline values section of the doc.      https://github.com/apache/ambari/blob/release-2.7.1/ambari-server/docs/configuration/index.md#baseline-values   please      scale up the cluster +100 nodes at a time (instead of +358 and +411 like      we saw earlier in the failed runs),182503175,,,,,,,
1.2004E+14,51:28.6,Simple Query not working,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select * from {alphanumericpii} where rdr_pub_veh_vin in ('{ALPHANUMERICPII}');\n\nQuestion: Hive query explain plan if available\nAnswer: \n'\n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: refer attachment for error\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select * from {alphanumericpii} where rdr_pub_veh_vin in ('{ALPHANUMERICPII}');;\nHive query explain plan if available - \n';\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - refer attachment for error;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/30/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/910c6c2e-938b-4a69-8bab-2f57583abe08/resourceGroups/CTBIDL-CTM00102-NonProd/providers/Microsoft.HDInsight/clusters/ctbiclusterprep\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Simple Query not working,0.452319981,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,Simple Query not working,Simple Query not working,"Worked with customer and confirmed that the issue due to query performance. Informed customer that they use ""hive.fetch.task.conversion=none"". Also, worked with product group on this and they suggested few steps to optimize the table statistics and run query again. Customer confirmed that he dont need further assistance on this.",183143744,,,,,,,
1.2004E+14,17:44.3,Jupyter automated fix,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 14, 2020, 12:00 AM EST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: This is a follow-up to the previous support case {Phonenumberpii}, where our Jupyter service was not working correctly after cluster deployment, and we had to correct /usr/bin/anaconda/lib/python2.7/site-packages/nbformat/_version.py by changing the 5 to a 4, and restarting Jupyter.\n\nAs a short-term workaround when this issue occurred back in January, we implemented the attached example powershell syntax at the end of our HDI deployment script to move a corrected _version.py from our {Alphanumericpii} ADLS to our HDInsight headnodes, and restart Jupyter.\n\nAs per {Namepii} in the previous case {Phonenumberpii}, a long-term fix was implemented by Microsoft Support that automated these actions on the cluster post-deployment.\n\nBoth solutions have the same end-result, but the one we have as a workaround (post-deployment powershell) allows the cluster to be ready earlier compared to Microsoft's long-term fix. \n\nI would like to understand the technological difference between our custom short-term fix and Microsoft's long-term fix. What does Microsoft recommend to use? Is it acceptable to use the short-term workaround as the long-term fix since it seems to work better?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - This is a follow-up to the previous support case {Phonenumberpii}, where our Jupyter service was not working correctly after cluster deployment, and we had to correct /usr/bin/anaconda/lib/python2.7/site-packages/nbformat/_version.py by changing the 5 to a 4, and restarting Jupyter.\n\nAs a short-term workaround when this issue occurred back in January, we implemented the attached example powershell syntax at the end of our HDI deployment script to move a corrected _version.py from our {Alphanumericpii} ADLS to our HDInsight headnodes, and restart Jupyter.\n\nAs per {Namepii} in the previous case {Phonenumberpii}, a long-term fix was implemented by Microsoft Support that automated these actions on the cluster post-deployment.\n\nBoth solutions have the same end-result, but the one we have as a workaround (post-deployment powershell) allows the cluster to be ready earlier compared to Microsoft's long-term fix. \n\nI would like to understand the technological difference between our custom short-term fix and Microsoft's long-term fix. What does Microsoft recommend to use? Is it acceptable to use the short-term workaround as the long-term fix since it seems to work better?;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 01/14/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jupyter automated fix,0.189625704,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Service unhealthy\Spark,Answer the followed questions regarding to an improvement on HDInsight Spark Cluster feture for Jupyter service:I would like to understand the technological difference between our custom short-term fix and Microsoft's long-term fix. (i.e. is Microsoft’s fix also executed by Powershell?)What does Microsoft recommend to use?Is it acceptable for Selective to use the short-term workaround as the long-term fix since it seems to work better?,Version got updated on the PyPI repo to 5.0.3. HDInsight image created and shipped in January got the wrong version of nbformat in the _version.py file.,"I would like to understand the technological difference between our custom short-term fix and Microsoft's long-term fix. (i.e. is Microsoft’s fix also executed by Powershell?)The fix is now available on Azure Portal and and is not necessary to restart any service at the deployment, just run with the latest HDInsight template What does Microsoft recommend to use?Microsoft recommend to use the default template. Nevertheless, in case you need a custom feature you are free to modify it your template.Is it acceptable for selective to use the short-term workaround as the long-term fix since it seems to work better?Since the the fix is already in the portal, there is no need to run any post-deployment script.",,,,,,,,
1.2004E+14,59:12.6,unknow status from headnode host 1,"Question: What time did the problem begin?\nAnswer: Fri, Apr 3, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Try to restart hn1 for two times, disable / enable alerts\n\nQuestion: Additional details about the issue\nAnswer: Hi, our headnode host 1 are in unknow status for some time. I try to restart hn1 two times, disable / enable alerts but don´t have success.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Try to restart hn1 for two times, disable / enable alerts;\nAdditional details about the issue - Hi, our headnode host 1 are in unknow status for some time. I try to restart hn1 two times, disable / enable alerts but don´t have success.;\n\n- ProblemStartTime: 04/03/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {Namepii} - Desenvolvimento\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/715a8512-1a2a-4027-8bd3-397b42e369f7/resourceGroups/DevelopmentAnalyticsResources/providers/Microsoft.HDInsight/clusters/sparksimdev\n- Location: brazilsouth\n- Location: {Namepii} South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unknow status from headnode host 1,0.015050427,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,unknow status from headnode host 1,ambari-agent was having problems. ,restarted the headnode,,,,,,,,
1.2004E+14,38:33.4,Hive query is not working through Ambari,"Query is getting right results in {Namepii} server but same query is failing with ' table not found error' in Amabari\n\nProblem start date and time\nFri, Apr 3, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/03/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive query is not working through Ambari,0.106464923,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hive,Hive view logs show deadline passed exceptions like  java.util.concurrent.TimeoutException: deadline passed,"Hive view fetch timeout was too low, this caused some deadline passed issues and a table not found exception was surfaced.",Increased the fetch timeout using the instructions in our documentation - https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/interactive-query-troubleshoot-view-time-out#issue   We used beeline to run the query and find the amount of time needed for the query to execute and fetch results. Then cx updated the fetch timeout accordingly,,,,,,,,
1.2004E+14,08:37.6,kps020sparkfdsbwus401: Multiple components issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: 1. Edge node is not started and throwing errror.\n{Alphanumericpii} number of data nodes on the ambari portal\n{Alphanumericpii} of the required Tez components are failing.\n{Alphanumericpii} of the required  Hive components are failing\n{Alphanumericpii} of the required  oozie  components  are failing.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - 1. Edge node is not started and throwing errror.\n{Alphanumericpii} number of data nodes on the ambari portal\n{Alphanumericpii} of the required Tez components are failing.\n{Alphanumericpii} of the required  Hive components are failing\n{Alphanumericpii} of the required  oozie  components  are failing.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps020sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kps020sparkfdsbwus401: Multiple components issues,0.548199635,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,kps020sparkfdsbwus401: Multiple components issues,kps020sparkfdsbwus401: Multiple components issues,"Engineer worked with customer on this and helped fix printPackages function to python 2 format in hdp-select, which fixed the issue",182631479,,,,,,,
1.2004E+14,16:02.6,Micro-sgementation,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: N/A\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: From a security perspective, we are interested in micro-segmenting our HDInsight environment within it's subnet. Meaning, we want the next hop from any HDInsight node to always be a firewall; whether it is going to another HDInsight node or the open internet.\n\nPlease help us understand the network traffic dependencies for HDInsight deployments and proper functionality, this would include node-to-node traffic and node-to-internet traffic.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - N/A;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - From a security perspective, we are interested in micro-segmenting our HDInsight environment within it's subnet. Meaning, we want the next hop from any HDInsight node to always be a firewall; whether it is going to another HDInsight node or the open internet.\n\nPlease help us understand the network traffic dependencies for HDInsight deployments and proper functionality, this would include node-to-node traffic and node-to-internet traffic.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Micro-sgementation,0.026521285,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Advisory information question for routing HDInsight traffic from nodes to a firewall in micro-segment network,NA,Not supported in a feature of routing HDInsight traffic from nodes to a firewall in micro-segment network,,,,,,,,
1.2004E+14,15:49.7,Unable to SSH into the cluster from SAW,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The cluster has entered a weird state since {Alphanumericpii} March. Our VM is not able to manage the cluster. There seems to be authentication issue but I have no logs to support this theory. When I try to SSH into the cluster from my SAW, it says 'Connection closed unexpectedly'. When I enter wrong SSH password, it shows a distinct message 'Authentication denied'. When I run YARN service check using Ambari UI, it says something like OpenSSLProvider not found [detailed logs attached]. Please help us by investigating why the cluster is not responding to our SSH requests.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - The cluster has entered a weird state since {Alphanumericpii} March. Our VM is not able to manage the cluster. There seems to be authentication issue but I have no logs to support this theory. When I try to SSH into the cluster from my SAW, it says 'Connection closed unexpectedly'. When I enter wrong SSH password, it shows a distinct message 'Authentication denied'. When I run YARN service check using Ambari UI, it says something like OpenSSLProvider not found [detailed logs attached]. Please help us by investigating why the cluster is not responding to our SSH requests.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/30/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HDFS Test (Microsoft Azure Internal Consumption)\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3000151d-7a84-4120-b71c-336feab0b0f0/resourceGroups/ADLS-PERF/providers/Microsoft.HDInsight/clusters/mhtsparkscus05\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to SSH into the cluster from SAW,0.023221036,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,120040321001709 - Unable to SSH into the cluster from SAW,Your cluster is deployed into a VNET which contains our Corporate Network Security Group(NSG) policy. The name of the NSG is ssnsgscus. This NSG contains a rule which explicitly allows ssh access from only certain IP ranges. (NSG rule name: Cleanuptool-Allow-100)This NSG also contains another rule which explicitly denies all other IP addresses the ability to ssh. (NSG rule name: Cleanuptool-Deny-103),"Option #1•           Add the public IP address of your SAW machine to the NSG rule named: Cleanuptool-Allow-100. The drawback of this option is that when/if your SAW machine's IP address changes, then you will have to update this rule every time before trying to ssh. Option #2•           Deploy a VM inside of the same Virtual Network where the cluster lives: Virtual Network Name: SSVNET13 Then, use that VM to ssh to the cluster. This is a good option if you are using a Virtual SAW machine which gets deleted everyday.",,,,,,,,
1.2004E+14,28:03.4,Unknown Host Exception Host wn6-prd-ts ,"Question: What time did the problem begin?\nAnswer: Sat, Apr 4, 2020, 11:54 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: App team can see the unknown host {alphanumericpii} in their logs.\nBut the cluster looks fine and every worker nodes are running and there is no down time.\nWe can see the Hbase logs there is unknown host.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - {Namepii};\nAdditional details about the issue - App team can see the unknown host {alphanumericpii} in their logs.\nBut the cluster looks fine and every worker nodes are running and there is no down time.\nWe can see the Hbase logs there is unknown host.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/04/2020 06:24:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7fe693d5-2d30-4322-99a9-d83c97c0eba6/resourceGroups/prd-vims-cat-rg-01/providers/Microsoft.HDInsight/clusters/prd-ts-vims-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unknown Host Exception Host wn6-prd-ts ,0.500723979,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hbase,HBase Region Servers are communicating only with IP addresses,"The communication of client coming from outside of the VNet, or in this case, within VNet but requires DNS server** are not very common scenarios we encounter. We are sorry that our dependent service's internal migration had  affected your business. We will add to our test suite to cover this scenario in the future.  **Note: You can refer to this public documentation on name resolution solution for use of App Service Web Apps case, as listed,  customer-managed DNS server is required for use of Web App to VM in same VNet:After provding below short-term/long-term fixes, we also mentioned that,That said, if you continue to work with the current IP address settings (that we applied as mitigation), and it should work. There is not an immediate need to find an alternate.·         The choice of where and how client application is hosted is something out of scope of HDInsight, if you choose to continue using web applications, the Web App's team will be able to better address your questions. However, please do reach out to us if you need any help.","Below  is the fix updated in Ambari on Region Server level, (To  be added before the line {% if security_enabled %} )1.    Add export  HBASE_REGIONSERVER_OPTS=""$HBASE_REGIONSERVER_OPTS -Dip.address=$(hostname -i)""  In hbase-env template2.    Add following setting to custom  hbase-site.xml hbase.regionserver.hostname  = ${ip.address}3.   export HBASE_OPTS=”$HBASE_OPTS  -Dip.address=$(hostname -i)""hbase.regionserver.hostname  = ${ip.address}hbase.master.hostname  = ${ip.address}4.  HBASE_OPTS=”$HBASE_OPTS -Dip.address=$(hostname -i)"" In  terms of permanent fixes, below are a few options:1.        Setup DNS server as specified here, https://docs.microsoft.com/en-us/azure/hdinsight/connect-on-premises-network.  Thought this talks about on premise, it should apply for ant client outside of  vnet.2.        Create VM within the same VNet and subnet: https://docs.microsoft.com/en-us/azure/hdinsight/hbase/apache-hbase-provision-vnet#connect-to-the-apache-hbase-cluster-using-apache-hbase-java-rpc-apis  3.        Use an empty edge node to host your client application (what Uma had mentioned  during the call): https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node4.        There are two types of web app services, one of which you are currently using,  which does not automatically provide name resolution, while the other: App  Service Environment promises that (https://docs.microsoft.com/en-us/azure/app-service/environment/intro)","182,703,681,182,735,000",,,,,,,
1.2004E+14,31:34.4,worker node is down,"Question: What time did the problem begin?\nAnswer: Sat, Apr 4, 2020, 12:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: wn11-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net is not sending heartbeats\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - wn11-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net is not sending heartbeats;\n\n- ProblemStartTime: 04/04/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsEuRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi-eu\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",worker node is down,0.234822059,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,unable to SSH,worker node is down ,"Worked with PG team to take worker node back to running state. Hardware issue caused the vm to migrate because of the capacity issue. The VM migration didn't happen successfully because there is a bug on migration failure. It is reverted in the lasted code, and it should be rolled out to the production for 2-3 weeks.","182,758,537,182,758,000,000,000,000",,,,,,,
1.20041E+14,45:28.1,CI/CD Deployment from Azure DevOps erased several resources in the resource group.,"[‎4/‎5/‎2020 2:41 PM]  {Namepii}, {Namepii}:  \nCI/CD Deployment from Azure DevOps erased several resources in the resource group. We need to be able to restore them to how they were before the CI deployment.\n \n\n\nProblem start date and time\nSun, Apr 5, 2020, 12:00 AM CDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/05/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ONE Gas - Primary\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",CI/CD Deployment from Azure DevOps erased several resources in the resource group.,0.102047774,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Customer reported,"Customer ran Dev Ops pipeline afterwhich several ADF, HDI, and Databricks resources were unexpectedly deleted","Confirmed with all teams if resources could be recovered, Databricks was the only team that may be able to recover the resource. Guided customer on how to use the deployment templates from the deployment history of the resource group which will deploy a fresh deployment of the resource using the same configurations as it was originally deployed with. The customer mentioned their RServer HDI cluster was using an older version of Spark, however it is unclear if that was something the cluster was deployed with or if this is something the customer installed on the cluster. Asked customer to open new ticket with Databricks team for assistance recovering the Databricks workspace.",,,,,,,,
1.20041E+14,01:11.8,The name node process is frequently getting restarted & gracefully shutting down on Insights Production Processing Cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Issue Description:\n\n \n\nThe name node process is frequently getting restarted & gracefully shutting down on Insights Production Processing {Namepii} (rblivprocessingcluster) due to which observing the name node process unavailability alert in Dynatrace monitoring tool.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Issue Description:\n\n \n\nThe name node process is frequently getting restarted & gracefully shutting down on Insights Production Processing {Namepii} (rblivprocessingcluster) due to which observing the name node process unavailability alert in Dynatrace monitoring tool.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: REBUS_PRODUCTION_INSIGHTS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c003680b-ac89-49ab-9002-303f05c69b0f/resourceGroups/AM-RB-PRDX-RA-HDIN-RG01/providers/Microsoft.HDInsight/clusters/rblivprocessingcluster\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",The name node process is frequently getting restarted & gracefully shutting down on Insights Production Processing Cluster,25.4568889,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Namenode restarting frequently / Services Unhealthy,Ambari DB running at 100%,Ambari DB purge performed.Cleaned the Zk snapshotsCleared the Metric Collector PG updates the Ambari Db to S1####################################################Additional recommendations provided:Use separate  DB for ATSStop ATS for Mitigation Please follow these steps:1. set yarn.timeline-service.enabled  to false2. restart resourcemanagers and impacted components for this configuration change using ambari3. stop timelineservers using ambari.,182983355,,,,,,,
1.20041E+14,27:11.2,Edge is not is not responding,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Unable to connect to the edge node through ssh .\n\nQuestion: Additional details about the issue\nAnswer: The edge nose is not responding.When tried to connect the edge node through putty,the connection couldnt be established.\nThanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Unable to connect to the edge node through ssh .;\nAdditional details about the issue - The edge nose is not responding.When tried to connect the edge node through putty,the connection couldnt be established.\nThanks;\n\n- ProblemStartTime: 03/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge is not is not responding,0.05973169,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Unable to SSH into Edge Node.,Edge Node has degraded any attempts taken to restart the services and get it back online have failed.,  Asked to delete the current      edge node and deploy a new one. Provided instructions on how to      Delete Edge       Node: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node#delete-an-edge-node   Create a new       Edge Node:  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node#add-an-edge-node-to-an-existing-cluster     Also provided instructions on      installing the application Datameer on the Edge Node https://github.com/ZoinerTejada/hdinsight-docs/blob/master/hdinsight-apps-install-applications.md#install-applications-to-existing-clusters,,,,,,,,
1.20041E+14,08:45.4,PRDSUP: kp08tntncapsparknsprdsup01 : spark-shell is not working,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 6, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: spark shell is failling \n\nat {AlphanumericPII})\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n                at {AlphanumericPII})\n\nQuestion: Additional details about the issue\nAnswer: at {AlphanumericPII})\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n                at {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - spark shell is failling \n\nat {AlphanumericPII})\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n                at {AlphanumericPII});\nAdditional details about the issue - at {AlphanumericPII})\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n                at {AlphanumericPII});\n\n- ProblemStartTime: 04/06/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp08tntncapsparknsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kp08tntncapsparknsprdsup01 : spark-shell is not working,0.007611226,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,Issue: Spark-shell does not work when running simple sql commands,"Root Cause: We noticed that the headnodes were running at high loads caused by the Hive Metastore process on both the headnodes: Output of the Top commands from the headnodes: hn0:root@hn0-kp08tn:/home/sshuser# toptop - 19:41:05 up 56 days, 19:09,  3 users,  load average: 33.48, 34.84, 36.13Tasks: 265 total,   2 running, 179 sleeping,   0 stopped,   0 zombie%Cpu(s): 91.5 us,  4.5 sy,  0.5 ni,  3.0 id,  0.2 wa,  0.0 hi,  0.2 si,  0.0 stKiB Mem : 57691228 total,  1605536 free, 38158956 used, 17926736 buff/cacheKiB Swap:  7340028 total,  6295804 free,  1044224 used. 16863824 avail Mem PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND101305 hive      20   0 12.249g 7.669g  42568 S 673.8 13.9  18641:41 java à metastore process​hn1 :root@hn1-kp08tn:/home/sshuser# toptop - 19:49:27 up 38 days, 10:17,  1 user,  load average: 17.72, 15.74, 15.02Tasks: 236 total,   2 running, 152 sleeping,   0 stopped,   0 zombie%Cpu(s): 92.5 us,  3.8 sy,  0.8 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.1 si,  0.0 stKiB Mem : 57691220 total, 24964524 free, 17351684 used, 15375012 buff/cacheKiB Swap:  7340028 total,  6010940 free,  1329088 used. 38895576 avail MemPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND119782 hive      20   0 12.074g 7.582g  41948 S 689.3 13.8  20826:05 java à metastore process Hive metastore process was in a bad state as a result.  Caused by: java.io.IOException: SQL Server did not return a response. The connection has been closed. ClientConnectionId:1f97b8f4-1a1b-40b8-834b-149f2150c8dd        at com.microsoft.sqlserver.jdbc.TDSChannel$SSLHandshakeInputStream.ensureSSLPayload(IOBuffer.java:786)        at com.microsoft.sqlserver.jdbc.TDSChannel$SSLHandshakeInputStream.readInternal(IOBuffer.java:836)        at com.microsoft.sqlserver.jdbc.TDSChannel$SSLHandshakeInputStream.read(IOBuffer.java:829)        at com.microsoft.sqlserver.jdbc.TDSChannel$ProxyInputStream.readInternal(IOBuffer.java:999)        at com.microsoft.sqlserver.jdbc.TDSChannel$ProxyInputStream.read(IOBuffer.java:989)        at sun.security.ssl.InputRecord.readFully(InputRecord.java:465)        at sun.security.ssl.InputRecord.read(InputRecord.java:503)        at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975)        at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)        at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1395)        at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1379)        at com.microsoft.sqlserver.jdbc.TDSChannel.enableSSL(IOBuffer.java:1756)        ... 17 more2020-04-06 19:31:59,048 DEBUG [HikariPool-1 housekeeper] pool.HikariPool: HikariPool-1 - Pool stats (total=6, active=1, idle=5, waiting=0)2020-04-06 19:32:08,946 DEBUG [HikariPool-4 connection adder] pool.HikariPool: HikariPool-4 - Cannot acquire connection from data sourcecom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: ""Connection reset ClientConnectionId:7b289b62-39b5-45d5-8933-bc113137fb90"".        at com.microsoft.sqlserver.jdbc.SQLServerConnection.terminate(SQLServerConnection.java:2826)",Resolution: We were able to get past the issue by killing both the Hive Metastore processes running on the headnodes.,,,,,,,,
1.20041E+14,12:48.3,ADF Sandbox : kps053sparkespadfsbwus201 : Reset edge node password,"Couldn't reset edge node password \n\nSteps followed:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-passwords\n\nNode Login details\nuser: sshuser\nIP: {Ipaddresspii}\n\nPlease reset or create temp password which we can use to reset.\n\nProblem start date and time\nFri, Apr 3, 2020, 3:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/03/2020 10:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-edpcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps053sparkespadfsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF Sandbox : kps053sparkespadfsbwus201 : Reset edge node password,0.038329984,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,ADF Sandbox : kps053sparkespadfsbwus201 : Reset edge node password,The initial GitHub script had some validation issues as per the error message from Ambari. You were using the github path for the script action was : https://github.com/neelamari/scriptaction/blob/master/script/changepassword.sh (which is just a path to view the code)  ,We were able to run the same script again to resolve the issue in a screenshare session earlier.For the actual script to be usable it should be something like this.  https://raw.githubusercontent.com/neelamari/scriptaction/master/script/changepassword.sh ,,,,,,,,
1.20041E+14,28:49.2,connection issue with kafka,"Question: What time did the problem begin?\nAnswer: Sun, Apr 5, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: not able to connect to kafka from the application, PFA logs for connectivity issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - not able to connect to kafka from the application, PFA logs for connectivity issue.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/04/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",connection issue with kafka,2.397289677,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Kafka,"Not able to connect to kafka from the application, PFA logs for connectivity issue.Error message:[2020-04-10 15:14:43,656] WARN [ReplicaFetcher replicaId=1001, leaderId=1004, fetcherId=1] Error in response for fetch request (type=FetchRequest, replicaId=1001, maxWait=2000, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1942697549, epoch=8060)) (kafka.server.ReplicaFetcherThread)java.io.IOException: Connection to 1004 was disconnected before the response was readat org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:241)at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:130)at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:129)at scala.Option.foreach(Option.scala:257)at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)?2020-04-10 15:28:04,282] WARN [ReplicaFetcher replicaId=1001, leaderId=1004, fetcherId=4] Error in response for fetch request (type=FetchRequest, replicaId=1001, maxWait=2000, minBytes=1, maxBytes=10485760, fetchData={admin-request-topic-15=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[4])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1345030285, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)java.io.IOException: Connection to 1004 was disconnected before the response was readat org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:241)at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:130)at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:129)at scala.Option.foreach(Option.scala:257)at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)","Customer's cluster faced with deadlock issue in kafka (https://issues.apache.org/jira/browse/KAFKA-7697), which is fixed in 2.1.1. ",PG team provided patch for the customer on their QA and PROD clusters and they have been functioning properly with deadlock issue resolved.,183238898,,,,,,,
1.20041E+14,24:26.0,Security concern : Zeppelin Notebook UI is accessible from all network,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of Notebook?\nAnswer: {Namepii}\n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Additional details about the issue\nAnswer: Today, at 03:05AM application team looks the cluster and found that he was able to see the webui of zeppelin notebook and able to run query from network which are outside the CAT network (i.e. accessible to public network)\nAs a security concern need immidiate action\nwe have 15 Hbase clusters with 5 prod all are access  in public. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of Notebook? - {Namepii};\nDoes Ambari login work? - Yes;\nDoes the issue affect all users or a few users? - All users;\nAdditional details about the issue - Today, at 03:05AM application team looks the cluster and found that he was able to see the webui of zeppelin notebook and able to run query from network which are outside the CAT network (i.e. accessible to public network)\nAs a security concern need immidiate action\nwe have 15 Hbase clusters with 5 prod all are access  in public. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT PerfTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2f533aaa-6ce7-4273-ab45-2333db12ad29/resourceGroups/perf-hlt-cat-rg-01/providers/Microsoft.HDInsight/clusters/prf-maud-hlt-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Security concern : Zeppelin Notebook UI is accessible from all network,0.374733517,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Notebook in standard cluster,Security concern : Zeppelin Notebook UI is accessible from all network,Security concern : Zeppelin Notebook UI is accessible from all network,Worked with customer and detailed on the workflow and steps helpful to validate and deploy the changes required to restrict access to cluster. Customer confirmed to close the case.,,,,,,,,
1.20041E+14,27:20.0,Ambari metrics not available,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We tried to start {Namepii} collector it is stopping in few minutes.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We tried to start {Namepii} collector it is stopping in few minutes.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/06/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaprdhadoop-cus-01-rg/providers/Microsoft.HDInsight/clusters/prdiw\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari metrics not available,0.310127269,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Metrics are missing\Hbase,AMS metrics issue..,Ambari metrics not available,"Recommended Steps:Login into the Ambari portalSet AMS to maintenanceStop AMS from AmbariIdentify the following from the AMS Configs screen:hbase.rootdir (Default value is file:///mnt/data/ambari-metrics-collector/hbase)hbase.tmp.dir(Default value is /var/lib/ambari-metrics-collector/hbase-tmp)SSH into headnode0. as superuserRemove the AMS zookeeper data by backing up and removing the contents of 'hbase.tmp.dir'/zookeeperRemove any Phoenix spool files from 'hbase.tmp.dir'/phoenix-spool folderNote: It is worthwhile to skip this step and first restarting AMS to see if the issue is resolved. If AMS is still failing to come up, try this step: AMS data would be stored in hbase.rootdir identified above. Use regular OS commands to backup and remove the files: # tar czf /mnt/backupof-ambari-metrics-collector-hbase-$(date +%Y%m%d-%H%M%S).tar.gz /mnt/data/ambari-metrics-collector/hbaseRestart AMS using AmbariRecommended DocumentsCleaning up Ambari Metrics System Data",,,,,,,,
1.20041E+14,43:13.8,Need to cjhange VM family for my worker node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to change the VM family sizing for worker nodes\n\nExpected Cores and RAM : 32 vCPU, 128 GB for 4 worker nodes\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to change the VM family sizing for worker nodes\n\nExpected Cores and RAM : 32 vCPU, 128 GB for 4 worker nodes;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: REBUS_DEVELOPMENT_HOBS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e27f4bd3-6257-4b17-9522-feaa2bf4ea04/resourceGroups/AM-RB-SITB-CO-HOB-RG01/providers/Microsoft.HDInsight/clusters/rbsibcohobspk01\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to cjhange VM family for my worker node,0.161368229,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to scale the cluster,"Need to change VM family for my worker nodeYou also had issue with scaling where the cluster was in ""updating error"" state. ","1.  For Hdinsight, you can only change the VM family during the creation of the HDinsight cluster. Thus, You won't be to change VM Family unless you redeploy the cluster again with the specified  VM family.2. For scaling, the issue was with your HN0. I have restarted the head node on my end. Thus, allow the cluster work to function fine again. As the result, you were able to scale the cluster successfully again. ",183256083,,,,,,,
1.20041E+14,07:27.3,Cluster Delete errors,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: None Known\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: Intermittent issue and RUnbook output error is below and runbook is attached.\n\nClusters that the delete has failed on:\n{alphanumericpii}\nFailed with -- Get-AzureRmResourceGroup : Cannot validate argument on parameter 'Name'. The argument is null or empty. Provide an argument that is not null or empty, and then try the command again. At {alphanumericpii} {alphanumericpii} + if (Get-AzureRmResourceGroup -Name $resourceGroupName) + ~~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidData: (:) [Get-AzureRmResourceGroup], ParameterBindingValidationException + FullyQualifiedErrorId : ParameterArgumentValidationError,Microsoft.Azure.Commands.ResourceManager.Cmdlets.Implemen tation.GetAzureResourceGroupCmdlet\n\n\n\n\n{alphanumericpii} failed with:\nRemove-AzureRmResourceGroup : Long running operation failed with status 'Conflict'. At {alphanumericpii} {alphanumericpii} + ... Remove-AzureRmResourceGroup -Name $resourceGroupName -For ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : CloseError: (:) [Remove-AzureRmResourceGroup], CloudException + FullyQualifiedErrorId : Microsoft.Azure.Commands.Resources.RemoveAzureResourceGroupCmdlet\n\n\nRunbook is attached.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - None Known;\nHow was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - Intermittent issue and RUnbook output error is below and runbook is attached.\n\nClusters that the delete has failed on:\n{alphanumericpii}\nFailed with -- Get-AzureRmResourceGroup : Cannot validate argument on parameter 'Name'. The argument is null or empty. Provide an argument that is not null or empty, and then try the command again. At {alphanumericpii} {alphanumericpii} + if (Get-AzureRmResourceGroup -Name $resourceGroupName) + ~~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidData: (:) [Get-AzureRmResourceGroup], ParameterBindingValidationException + FullyQualifiedErrorId : ParameterArgumentValidationError,Microsoft.Azure.Commands.ResourceManager.Cmdlets.Implemen tation.GetAzureResourceGroupCmdlet\n\n\n\n\n{alphanumericpii} failed with:\nRemove-AzureRmResourceGroup : Long running operation failed with status 'Conflict'. At {alphanumericpii} {alphanumericpii} + ... Remove-AzureRmResourceGroup -Name $resourceGroupName -For ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : CloseError: (:) [Remove-AzureRmResourceGroup], CloudException + FullyQualifiedErrorId : Microsoft.Azure.Commands.Resources.RemoveAzureResourceGroupCmdlet\n\n\nRunbook is attached.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Stage Classic (DevTest)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/543c0572-d153-4029-b134-dae30593657e/resourceGroups/chc-dp-97800000-ffac-0003-4823-08d7da535f16-stage-rg/providers/Microsoft.HDInsight/clusters/f-blzv-chc-dp-97800000-ffac-0003-4823-08d7da535f16\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster Delete errors,1.040737263,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Delete HDInsight cluster,Runbook issues with deleting a cluster. ,Issue appears to be code related. For some reason the script is not able to determine the cluster's resource group name.,"We went over the runbook provided as well as the error message. Unfortunately I was not able to reproduce the issue using the script. I did go over the script with my colleagues and the issue appears to be code related. For some reason the script is not able to determine the cluster's resource group name. I would advise for your team to review the script, they could just pass in a method to acquire the resource group name separately instead of calling it from the clustername property.",,,,,,,,
1.20041E+14,49:28.1,Some Queries are not working via Zeppelin,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 1:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: %jdbc(phoenix)\nselect A assetKey,H processedTimestamp,i {alphanumericpii} {AlphanumericPII} contentType from {alphanumericpii} where H BETWEEN to_timestamp('2020-04-07 06:35') and to_timestamp('2020-04-07 06:36') limit 10\n\nQuestion: How was the HBase job submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: We usually run the queries from zeppelin but few of them are showing operation timed out error.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - %jdbc(phoenix)\nselect A assetKey,H processedTimestamp,i {alphanumericpii} {AlphanumericPII} contentType from {alphanumericpii} where H BETWEEN to_timestamp('2020-04-07 06:35') and to_timestamp('2020-04-07 06:36') limit 10;\nHow was the HBase job submitted? - {Namepii};\nAdditional details about the issue - We usually run the queries from zeppelin but few of them are showing operation timed out error.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/07/2020 07:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT PerfTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2f533aaa-6ce7-4273-ab45-2333db12ad29/resourceGroups/perf-hlt-cat-rg-01/providers/Microsoft.HDInsight/clusters/prf-maud-hlt-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Some Queries are not working via Zeppelin,0.054789978,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Hbase,Unable to run few queries  through Zeppelin/sqlline,Some Queries are not  working via Zeppelin,"Provided  below recommendations,1.       Since the  table is very large, full scan is expected to time out. One thing they can do is  simply do some testing and increase the phoenix.query.timeout value, however  given the size of the table, this value may need to be set to be an extremely  high number, thus it may not be the best solution.2.       As seen in  below screenshot, column 'H' that the query is trying to filter by is not a  primary row key, accessing columns other than row key will result in FULL SCAN.  Customer can try secondary index with their table (see https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-phoenix-in-hdinsight#secondary-indexes).  3.       As per query  plan, we can see that it is doing a timestamp based query, customer can also try  to set 'H' as row timestamp column (see https://phoenix.apache.org/rowtimestamp.html).  When it is marked as ROW_TIMESTAMP during table creation, HBase will perform a  time range query thus can greatly improve performance on queries associated with  time range.",183270938,,,,,,,
1.20041E+14,54:20.7,PRDSUP: kp10tntncapllapnsprdsup01: HiveServer2 Interactive service stopped,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 8:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: {AlphanumericPII} Interactive service has been stoppedd \n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII} Interactive service has been stoppedd \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - {AlphanumericPII} Interactive service has been stoppedd ;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - {AlphanumericPII} Interactive service has been stoppedd ;\n\n- ProblemStartTime: 04/07/2020 15:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kp10tntncapllapnsprdsup01: HiveServer2 Interactive service stopped,0.084910325,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,PRDSUP: kp10tntncapllapnsprdsup01: HiveServer2 Interactive service stopped,At the time of the issue we noticed the following alerts on the host.1/1 local-dirs usable space is below configured utilization percentage/no more usable space... followed 50 minutes later by hs2i and hms going down. ,"Here is a good doc that talks about troubleshooting disk space issues.  https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/hdinsight-troubleshoot-out-disk-space Apart from that, Similar to the past cases(120021021001379) we also notice GC Pauses-- that might have caused Hive to go down. You can try increasing the Heap size to an extra 50% (ie: if the value is N GB, add another N/2)",183293812,,,,,,,
1.20041E+14,09:16.0,PRDSUP: kpps83sparkespprdsupwus201: most of the services down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}- services down\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii}- services down;\n\n- ProblemStartTime: 04/07/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kpps83sparkespprdsupwus201: most of the services down,0.032696766,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Issue: Cluster services down including Hive Interactive service. ,Root Cause: The root cause is that there was a configurational change made on the Hive Interactive service running on the spark cluster to increase the memory drastically causing the service to fail.,Resolution: We moved the configuration to the default and restarted the service.     ,,,,,,,,
1.20041E+14,23:58.0,newly created cluster is broken,"Question: What time did the problem begin?\nAnswer: ‎4‎/‎7‎/‎2020‎ ‎12‎:‎00‎:‎00‎ ‎PM\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\n\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: A new created cluster is in a bad state and I can't go to resource or figure out how to delete it. \nI think this occured becasue I accidently created one earlier withthe same name but deleted it becasue it was in the incorrect subscriptions. I then recreated it again and the deployment seems to have run but I can't get to it. \n\n{AlphanumericPII} \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - \n\n;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - A new created cluster is in a bad state and I can't go to resource or figure out how to delete it. \nI think this occured becasue I accidently created one earlier withthe same name but deleted it becasue it was in the incorrect subscriptions. I then recreated it again and the deployment seems to have run but I can't get to it. \n\n{AlphanumericPII} ;\n\n- ProblemStartTime: 04/07/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",newly created cluster is broken,20.09745401,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Newly created cluster is broken.,The cluster hdi31p1 is not under the subscriptionID mentioned in the ticket.Instead it is under different subscription ab294b64-b9fa-4db5-af46-f3a42fd93673 and hence the issue.,The cluster is already deleted.,,,,,,,,
1.20041E+14,27:05.6,unable to create cluster,"Operation on target {Alphanumericpii} failed: Failed to create the on demand HDI cluster. {Namepii} or linked service name: '{AlphanumericPII}', error: 'Failed to create the on demand HDI cluster. {Namepii} or linked service name: '{alphanumericpii}', error: '{'error':{'code':'AuthorizationFailed','message':'The client '{guidpii}' with object id '{guidpii}' does not have authorization to perform action 'Microsoft.HDInsight/clusters/write' over scope '/subscriptions/97a9588b-973c-4bae-a57c-91a9f39b1b4e/resourceGroups/cvs_resouce_grp/providers/Microsoft.HDInsight/clusters/n77c2f1eb-4e15-47a0-80e5-f26f0bf914f3' or the scope is invalid. If access was recently granted, please refresh your credentials.'}}''\n\nProblem start date and time\n{Namepii}, Apr 7, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/07/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Genpact Digital Development Environment\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to create cluster,0.145259751,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,Unable to create on demand HDI cluster,"Failed to create the on demand HDI cluster. Cluster or linked service name: 'n77c2f1eb-4e15-47a0-80e5-f26f0bf914f3', error: '{'error':{'code':'AuthorizationFailed','message':'The client '5222174b-0876-44d5-b762-348f8a9c565c' with object id '5222174b-0876-44d5-b762-348f8a9c565c' does not have authorization to perform action",Need to create App registration under AAD and that App need to add under role assignment at subscription level for the authentication purpose.Please refer to -  https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-appSame key need to use at the on demand HDI cluster creation.,,,,,,,,
1.20041E+14,08:54.9,Cluster not sclae up due to RM,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 7, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: RM are all standby modes.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - RM are all standby modes.;\n\n- ProblemStartTime: 04/07/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-DEV-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/is24cccmcaidev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster not sclae up due to RM,0.011343773,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Cluster not scale up due to RM,"We introduced the ‘node label’ features in the context of Autoscale.When cluster is scaled up, a new node will be added to the resource pool. We noticed sometimes jobs got dispatched to the newly added node even before the script action (last step customization for the new node) completion.To address this issue, we enabled node label to make sure YARN only assign tasks to the nodes which have been marked available.We put node label information in the file nodelabel.mirror. This file is stored in HDFS. If the replication = 1, then this file only has one replication. During a cluster scale down, if the node which stores this file is taken away and this file failed to be backed up in the remaining nodes, YARN will not be able to find available nodes to assign tasks which is the situation this cluster ran into. We have applied a fix to set the replication =3 for this file.This should reduce the likelihood of encountering the issue","We introduced the ‘node label’ features in the context of Autoscale.When cluster is scaled up, a new node will be added to the resource pool. We noticed sometimes jobs got dispatched to the newly added node even before the script action (last step customization for the new node) completion.To address this issue, we enabled node label to make sure YARN only assign tasks to the nodes which have been marked available.We put node label information in the file nodelabel.mirror. This file is stored in HDFS. If the replication = 1, then this file only has one replication. During a cluster scale down, if the node which stores this file is taken away and this file failed to be backed up in the remaining nodes, YARN will not be able to find available nodes to assign tasks which is the situation this cluster ran into. We have applied a fix to set the replication =3 for this file.This should reduce the likelihood of encountering the issue","183,120,930,183,121,000,000,000,000",,,,,,,
1.20041E+14,36:55.7,[Azure Government] Exception in thread 'main' java.io.IOException: Failed to create a temp directory (under /tmp) after 10 attempts!,"[Azure Government] Spark jobs will work for a time, and then the cluster will periodically stop accepting Spark jobs from Data Factory/go unresponsive and we'll get error logs like this:\n\nstdout: \nWarning: Ignoring non-spark config property: {alphanumericpii}\nWarning: Master yarn-cluster is deprecated since 2.0. Please use master 'yarn' with specified deploy mode instead.\nException in thread 'main' java.io.IOException: Failed to create a temp directory (under /tmp) after 10 attempts!\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n\nstderr: \n\nYARN Diagnostics: \nNo YARN application is found with tag {alphanumericpii} in 120 seconds. This may be because 1) spark-submit fail to submit application to YARN; or 2) YARN cluster doesn't have enough resources to start the application.\n\nOur current remediation is to reboot the cluster, which appears to solve the problem for a time, but the cluster will ulimately fail again. \n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: IDML_IP_FF_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d2c6c0af-8137-44f8-9aeb-e7321e57325d/resourceGroups/csafairfaxusvrg/providers/Microsoft.HDInsight/clusters/csafairfaxhdiusv\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Exception in thread 'main' java.io.IOException: Failed to create a temp directory (under /tmp) after 10 attempts!,0.956508197,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,cannot run spark workload,unknown. customer fixed,customer resolved,,,,,,,,
1.20041E+14,54:17.9,kps024llapfdsbwus401: Authentication exception,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii})\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii})\n\nQuestion: Interactive query explain plan if available\nAnswer: java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii})\n\nQuestion: How was the interactive query submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii});\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii});\nInteractive query explain plan if available - java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii});\nHow was the interactive query submitted? - {Namepii};\nAdditional details about the issue - java.io.IOException: Password {alphanumericpii} not found ({alphanumericpii});\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps024llapfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kps024llapfdsbwus401: Authentication exception,0.030800157,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,kps024llapfdsbwus401: Authentication exception,kps024llapfdsbwus401: Authentication exception,Issue was observed due to cluster: kps024llapfdsbwus401 was pointing to wrong metastore and customer had updated metastore to kpsqldbmshivefdsbwus501 and able to run query successfully now.,183202014,,,,,,,
1.20041E+14,03:00.2,"Query Exectuion Failures :query running through beeline, but not through VS Code or Zeppelin","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Attached the issue reported for query running through beeline, but not through VS Code or {Namepii}\n\nQuestion: Interactive query explain plan if available\nAnswer: Attached the issue reported for query running through beeline, but not through VS Code or {Namepii}\n\nQuestion: How was the interactive query submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: Attached the issue reported for query running through beeline, but not through VS Code or {Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Attached the issue reported for query running through beeline, but not through VS Code or {Namepii};\nInteractive query explain plan if available - Attached the issue reported for query running through beeline, but not through VS Code or {Namepii};\nHow was the interactive query submitted? - {Namepii};\nAdditional details about the issue - Attached the issue reported for query running through beeline, but not through VS Code or {Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq049llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Query Exectuion Failures :query running through beeline, but not through VS Code or Zeppelin",0.774418464,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,"Query Exectuion Failures :query running through beeline, but not through VS Code or Zeppelin","Query Exectuion Failures :query running through beeline, but not through VS Code or Zeppelin","Customer was connecting to different (Spark) cluster (kpq044) while the query is intended to run on kpq049 (LLAP) cluster. By updating connection string on beeline, Customer was able to see same error on beeline as he had thru zeppelin/VS Code. ​hive.direct.sql.max.elements.values.clause=100​hive.direct.sql.max.elements.in.clause=100​ ​Customer had updated the above configs on “custom hive-interactive-site” and “custom hivemetastore-site” and restarted the services successfully. This has fixed the issue.",183209348,,,,,,,
1.20041E+14,57:45.4,Delete DNS entries when deleting HDInsight Cluster,"Hello,\nI'm currently working with several HDInsght environment, and I keep the same name for each cluster when I create a new one.\nFor example, in my first environment, if I delete the cluster '{alphanumericpii}' and I create a new one, the name will be the same '{alphanumericpii}'.\nHowever I noticed that in the DNS entries (azure.mvtdevdesjardins.com), the IP associated to each nodes were'nt updated and keep the former IP adress.\nI don't have access to the domain controller to manage it on my own. I would like to know if there is a way to automate the updating of the DNS.\nThanks a lot\n\nProblem start date and time\n{Namepii}, Apr 6, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/06/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Delete DNS entries when deleting HDInsight Cluster,0.437183037,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Delete DNS entries when deleting HDInsight Cluster.,"As there is a known issue with ESP clusters and we are not cleaning up old DNS entries. whenever we reuse the name, the DNS entries will not be updated and they will still point to the old cluster.","HDInsight cluster reads DNS entries from host entries which are in /etc/hosts. So those stale DNS entries don't impact the cluster, they are stored in Azure Active Directory Domain services DNS server.",,,,,,,,
1.20041E+14,03:12.9,Unable to change the ownership of files in adls storage using hdfs commands.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 7, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: N/A\n\nQuestion: Hive query explain plan if available\nAnswer: N/A\n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Loading data to table rx_rtl_stg.adhoc_crctn_s from adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive\\\n/{AlphanumericPII}\nERROR : Failed with exception org.apache.hadoop.security.AccessControlException: Set Owner failed with  failed with error 0x83090aa\\\n2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested op\\\neration.). [{AlphanumericPII}] [{AlphanumericPII}\\\n1067985]\norg.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.security.AccessControlException: Set Owner failed with  failed \\\nwith error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perf\\\norm the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}-\\\n{alphanumericpii}]\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - N/A;\nHive query explain plan if available - N/A;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - Loading data to table rx_rtl_stg.adhoc_crctn_s from adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive\\\n/{AlphanumericPII}\nERROR : Failed with exception org.apache.hadoop.security.AccessControlException: Set Owner failed with  failed with error 0x83090aa\\\n2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested op\\\neration.). [{AlphanumericPII}] [{AlphanumericPII}\\\n1067985]\norg.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.security.AccessControlException: Set Owner failed with  failed \\\nwith error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perf\\\norm the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}-\\\n{alphanumericpii}]\n;\n\n- ProblemStartTime: 04/07/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to change the ownership of files in adls storage using hdfs commands.,0.028878087,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,Unable to change the ownership of files in adls storage using hdfs commands.,Unable to change the ownership of files in adls storage using hdfs commands.,Support worked with customer and requested customer to grant the permissions to Service Principal used during cluster provisioning which fixed the issue. Customer confirmed to close the case.,,,,,,,,
1.20041E+14,11:34.5,YARN services are down,"YARN resource managers are down. The oozie jobs are not being processed\n\nProblem start date and time\nWed, Apr 8, 2020, 12:00 AM CDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/08/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EA-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",YARN services are down,0.165028741,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Hadoop,"YARN resource managers are down. The oozie jobs are not being processed.After reviewing the logs we found: 2020-04-08 07:56:32,598 WARN  ha.ActiveStandbyElector - Exception handling the winning of electionCausing RMStateStore get stuck in the state FENCED and many other errors;2020-04-08 07:12:48,261 INFO  recovery.ZKRMStateStore - Fencing node /rmstore/ZKRMStateRoot/RM_ZK_FENCING_LOCK doesn't exist to delete2020-04-08 07:55:54,254 ERROR recovery.RMStateStore - Error storing appAttempt: appattempt_1586329968056_0760_000001​2020-04-08 07:55:54,271 ERROR recovery.RMStateStore - State store operation failed org.apache.hadoop.yarn.server.resourcemanager.recovery.StoreFencedException: RMStateStore has been fenced","This issue can happen if users lower the value of yarn.scheduler.maximum-allocation-mb and then restart ResourceManager. ResourceManager fails to recover the applications left in RMStateStore which requires more memory than yarn.scheduler.maximum-allocation-mb, even though those applications failed for a long time. ",Probable solution for this problem. (The cluster was deleted before start troubleshooting this issue).https://mapr.com/support/s/article/ResourceManager-fails-to-transition-to-Active-mode-with-InvalidResourceRequestException?language=en_USIdentify the RMStateStore class. You can find that information from Ambari -> Yarn -> Config and search for yarn.resourcemanager.store.classFind the location of RMStateStoreMove or remove all the applications directories in RMStateStoreRestart ResourceManager,,,,,,,,
1.20041E+14,41:01.2,HDInsight cluster Azure Monitor integration not working,"I have several HDI clusters, and I am not able to integrate all of my HDI clusters with Azure Monitor/Log Analytics Workspace. \n\nI am using the table 'metrics_cluster_alerts_CL' in my log analytics workspace to view ambari alerts from my clusters, and I noticed today that only 1 of my 6 clusters had logs going to that table. From what I understand, to get logs to that table 'Azure Monitor Integration' has to be enabled. However, that feature is not working for me.\n\nProblem start date and time\nSun, Apr 5, 2020, 12:00 AM EDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/05/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP22ADLSTREAM\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight cluster Azure Monitor integration not working,6.837127662,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\Azure Log Analytics Integration,HDInsight cluster Azure Monitor integration not working,1. ambari-server access via the hdinsightwatchdog user was failing. 2. OMS failing on a particular node as it was in a bad state,1. removed the domain-hdinsight watchdog user and forced Ambari sync2. OMS failing on a particular node as it was in a bad state. restarted the node to get past the issue. ,183417122,,,,,,,
1.20041E+14,38:41.8,My webjobs are failing to submit spark jobs,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 25, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: it is affecting prod cluster too, but eventually the submit will work it just fails 2 or 3 times, wait til the next interval.\n\nQuestion: Additional details about the issue\nAnswer: I have 200 webjobs who try to submit spark commands by sshing into the hdinsight cluster. Can we look at the ssh port and system? Is there any issue or max concurrent connections for this service\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - it is affecting prod cluster too, but eventually the submit will work it just fails 2 or 3 times, wait til the next interval.;\nAdditional details about the issue - I have 200 webjobs who try to submit spark commands by sshing into the hdinsight cluster. Can we look at the ssh port and system? Is there any issue or max concurrent connections for this service;\n\n- ProblemStartTime: 03/25/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ICE-ContentIntelQualityRanking-Test\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c23a622-dfc8-4ab7-a957-1ec284d4f1bb/resourceGroups/sparktesteus/providers/Microsoft.HDInsight/clusters/sparktesteus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",My webjobs are failing to submit spark jobs,2.12466619,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,My webjobs are failing to submit spark jobs,Customer is executing 200 web jobs who try to submit spark commands by ssh into the cluster. For every job he is opening different SSH connection. All those jobs are running parallely. -- Due to this the command which customer executing timed out.,Recommended customer to submit spark jobs by using apache REST API.https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-livy-rest-interface,,,,,,,,
1.20041E+14,50:30.8,ADF Sandbox - kps053sparkespadfsbwus201 - Multiple services not starting,"Question: What time did the problem begin?\nAnswer: Wed, Apr 8, 2020, 7:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 8, 2020, 12:00 AM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Restart services which are down \n2. Verify logs for issues \n\n\nQuestion: Additional details about the issue\nAnswer: Multiple services down and not starting up on this cluster. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. Restart services which are down \n2. Verify logs for issues \n;\nAdditional details about the issue - Multiple services down and not starting up on this cluster. ;\n\n- ProblemStartTime: 04/09/2020 02:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-edpcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps053sparkespadfsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF Sandbox - kps053sparkespadfsbwus201 - Multiple services not starting,1.007050724,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Hive Interactive down issues on Spark HDI 4.0 cluster,ADF Sandbox - kps053sparkespadfsbwus201 - Multiple services not starting,"Below are fixes and steps recommended,Did the cross functional setup b/w HDI 4.0 of Hive Interactive and Spark clustersWe recommend you set spark.security.credentials.hiveserver2.enabled=false for client mode and cluster mode should set spark.security.credentials.hiveserver2.enabled=truespark-shell --master yarn \--jars /usr/hdp/current/hive_warehouse_connector/hive-warehouse-connector-assembly-<STACK_VERSION>.jar \--conf spark.security.credentials.hiveserver2.enabled=false--conf spark.hadoop.hive.llap.daemon.service.hosts='<LLAP_APP_NAME>'--conf spark.sql.hive.hiveserver2.jdbc.url='jdbc:hive2://<ZOOKEEPER_QUORUM>;serviceDiscoveryMode=zookeeper;zookeeperNamespace=hiveserver2-interactive'--conf spark.datasource.hive.warehouse.load.staging.dir='<STAGING_DIR>'--conf spark.datasource.hive.warehouse.metastoreUri='<METASTORE_URI>'--conf spark.hadoop.hive.zookeeper.quorum='<ZOOKEEPER_QUORUM>'Did the scaleup/scaledown to get-rid off faulty node (wn10) in kps025sparkespfdsbwus401 clusterSetup the Livy2 interpreter to work against to Hive Interactive cluster and below are configs to update,1) Update in Spark2->config>Advanced->Custom livy2-conf. livy.file.local-dir-whitelist=/usr/hdp/current/hive_warehouse_connector/2) Update livy proxy on LLAP clusterhdfs->conf->Advanced->Custom core-sitehadoop.proxyuser.livy.groups=*hadoop.proxyuser.livy.hosts=*3) Zeppelin livy interpreter config update. open the interpreter and go to livy section and edit and add the below configs    livy.spark.hadoop.hive.llap.daemon.service.hosts=@llap0    livy.spark.jars=file:///usr/hdp/current/hive_warehouse_connector/hive-warehouse-connector-assembly-1.0.0.3.1.2.2-1.jar    livy.spark.security.credentials.hiveserver2.enabled=truelivy.spark.sql.hive.hiveserver2.jdbc.url=jdbc:hive2://zk0-kps024.kpaaddsprod.onmicrosoft.com:2181,zk2-kps024.kpaaddsprod.onmicrosoft.com:2181,zk5-kps024.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-interactivelivy.spark.sql.hive.hiveserver2.jdbc.url.principal=hive/_HOST@KPAADDSPROD.ONMICROSOFT.COMlivy.spark.sql.hive.llap=true    livy.spark.submit.pyFiles=file:///usr/hdp/current/hive_warehouse_connector/pyspark_hwc-1.0.0.3.1.2.2-1.zip    livy.spark.yarn.security.credentials.hiveserver2.enabled=true    livy.superusers=livy,zeppelin    spark.security.credentials.hiveserver2.enabled=true    spark.sql.hive.hiveserver2.jdbc.url.principal=hive/_HOST@KPAADDSPROD.ONMICROSOFT.COM    zeppelin.livy.url=http://hn0-kps023.kpaaddsprod.onmicrosoft.com:8998",183419656,,,,,,,
1.20041E+14,12:45.4,ADF QA - kpq063sparkespadfqawus201 - Multiple services down,"Question: What time did the problem begin?\nAnswer: Wed, Apr 8, 2020, 7:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 8, 2020, 7:00 PM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. restart services\n2. verify logs \n\nQuestion: Additional details about the issue\nAnswer: Multiple services are down on this cluster. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. restart services\n2. verify logs ;\nAdditional details about the issue - Multiple services are down on this cluster. ;\n\n- ProblemStartTime: 04/09/2020 02:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-edpcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq063sparkespadfqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF QA - kpq063sparkespadfqawus201 - Multiple services down,0.434278011,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Spark,ADF QA - kpq063sparkespadfqawus201 - Multiple services down,ADF QA - kpq063sparkespadfqawus201 - Multiple services down,"Both namenodes in Standby state and fixed that issue, which initially caused teh Hive Interactive serviceTried to restart the LLAP but saw issues. As confirmed by PG, we don’t recommend to use Hive Interactive service in Spark HDI 4.0 versionYou are ok with that, so we disabled the Hive Interactive service and after taht everything started working fine when tested running queries",,,,,,,,
1.20041E+14,42:30.4,"Multiple services like  HS2I,TEZ AM's are down","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n\n{alphanumericpii}\n{alphanumericpii}\n\n\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n\n\nQuestion: Interactive query explain plan if available\nAnswer: Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n\n{alphanumericpii}\n{alphanumericpii}\n\n;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n;\nInteractive query explain plan if available - Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Multiple  services like {ALPHANUMERICPII} AM's are down the below 2 clusters:\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Multiple services like  HS2I,TEZ AM's are down",0.516546592,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,"Multiple services like HS2I,TEZ AM's are down","Multiple services like HS2I,TEZ AM's are down","Customer has multiple concerns and filed another case and as part of this case customer requested for DAS uninstallation step(s), shared the same.",183386649,,,,,,,
1.20041E+14,15:51.3,Remainig Name of Deleted Cluster,"Hi,\nI created a cluster {alphanumericpii} and had to remove it. Now when I try to recreate the cluster, I cannot name it {alphanumericpii} because it says there is already a cluster with that name (first screenshot of uploaded file) despite the cluster does not appear anymore when listing HDInsight clusters (second screenshot of uploaded file)\nIs it possible to remove whatever residue remains there to be able to create a new cluster with name {alphanumericpii}?\nThanks\n\nProblem start date and time\n{Namepii}, Apr 9, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/08/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Santander OMEGA Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Remainig Name of Deleted Cluster,0.057565623,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to use clustername even if it was deleted. ,Issue at HDI side. ,Seems like the last delete operation didn’t delete the edgenode dns entries properly causing this issue.We have now cleared them up from our end I see that the cluster name is now available.,184044114,,,,,,,
1.20041E+14,16:17.0,Unable to access cluster management site,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 9, 2020, 9:41 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: host not responding\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - host not responding;\n\n- ProblemStartTime: 04/09/2020 13:41:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7bb948ae-e29d-4a26-9b1f-8aa3da56f80c/resourceGroups/PTS-PMTDW-PROD-NUA01-HDINSIGHT-RG/providers/Microsoft.HDInsight/clusters/ptspmtdwprod-kafka\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access cluster management site,0.205914018,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to access the cluster,Unable to access cluster management site,Recommended to use existing NSG with all the required information or asked update the management and other IP's on the associated NSG,,,,,,,,
1.20041E+14,52:51.1,Recommendations on making WASB Hbase write ready,"\n{Alphanumericpii} are the recommendations on making WASB Hbase write ready?\nAs per link : https://hadoop.apache.org/docs/current/hadoop-azure/index.html, there are properties such as : fs.azure.block.blob.with.compaction.dir, fs.azure.page.blob.dir and fs.azure.atomic.rename.dir to be configured especially for Hbase WAL to make sure that Hbase writes logs are not treated with Default policy of WASB.\n{Alphanumericpii} happens if above mentioned three properties are not set in cluster.\n{Alphanumericpii} there any recommendations for making WASB Solr write ready also, as we use HDFS for solr too?\n\n\nProblem start date and time\n{Namepii}, Apr 9, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/08/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Azure R&D DW with ADFS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Recommendations on making WASB Hbase write ready,0.290022283,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Unexpected result\Hbase,"Customer said they are using their on HBase cluster (non HDInsight) but have seen a HBase cluster created (also deleted).So we tried to help our best on this, though we understood customer is tricking us. We asked the cluster details to help further and she said that, don't have any and asked to close the case","Below are the asks, 1)What are the recommendations on making WASB Hbase write ready? As per link : https://hadoop.apache.org/docs/current/hadoop-azure/index.html, there are properties such as : fs.azure.block.blob.with.compaction.dir, fs.azure.page.blob.dir and fs.azure.atomic.rename.dir to be configured especially for Hbase WAL to make sure that Hbase writes logs are not treated with Default policy of WASB. 2)What happens if above mentioned three properties are not set in cluster. 3)Are there any recommendations for making WASB Solr write ready also, as we use HDFS for solr too?","Please see below for the  initial ask of the case,https://issues.apache.org/jira/browse/HADOOP-12089 - If they use HDI version 4.0, they will have  the fix, With HDI version 3.6 they may hit this issue. We recommend  to use HDI 4.0 latest  version fs.azure.block.blob.with.compaction.dir,  fs.azure.page.blob.dir and fs.azure.atomic.rename.dir propertiesHere are the updates from the SME:> fs.azure.block.blob.with.compaction.dir, fs.azure.page.blob.dir and fs.azure.atomic.rename.dirIt is recommended to use Page blobs for HBase WAL files. “fs.azure.page.blob.dir”  should be configured such that the HBase WAL files will be Page blobs.    Page blobs is supposed to see better latency guarantees compared to block blobs too..  So HBase clusters should not avoid this configThis is the default value in HDI 3.6 clusterfs.azure.page.blob.dir  =>   /hbase/WALs,/hbase/oldWALs,/mapreducestaging,/hbase/MasterProcWALs,/atshistory,/tezstaging,/ams/hbase/WALs,/ams/hbase/oldWALs,/ams/hbase/MasterProcWALs “fs.azure.atomic.rename.dir” – This should be used for all dirs under hbase’s root dir. But I can see within Hadoop code, it is been default added.atomicRenameDirs = getDirectorySet(KEY_ATOMIC_RENAME_DIRECTORIES);    String hbaseRoot;    try {      // Add to this the hbase root directory, or /hbase is that is not set.      hbaseRoot = verifyAndConvertToStandardFormat(        sessionConfiguration.get(""hbase.rootdir"", ""hbase""));     if (hbaseRoot != null) {       atomicRenameDirs.add(hbaseRoot);      }     }So its ok to not specific this config.fs.azure.block.blob.with.compaction.dir – This is relevant only when block blob is used for HBase WAL files also. But we recommend using page blobs for that. So its fine to just ignore this config.3)What happens if above mentioned three properties are not set in cluster - Please see answer to 2) above... HDInsight cluster has the fs.azure.page.blob.dir property set out of box.4)Are there any recommendations for making WASB Solr write ready also, as we use HDFS for solr too? - We strongly recommend using Accelerated writes cluster for HBase with the latest HDI Versionhere are links to go through the Accelerated writes to go through,https://docs.microsoft.com/en-us/azure/hdinsight/hbase/apache-hbase-accelerated-writeshttps://azure.microsoft.com/en-us/updates/hdinsight-hbase-accelerated-writes-is-now-generally-available/If you are seeing any performance  issues around the sizing and we may need to enable DEBUG mode on HDInsight-HBase  and WASB to troubleshoot further,please feel free to reach us to  troubleshoot or share the HDI cluster details with  us to look in to it to understand better what issues you guys are  hitting.",183526005,,,,,,,
1.20041E+14,25:48.2,/usr/bin/hive org.apache.thrift.transport.TTransportException: HTTP Response code: 431,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:~$ \n20/04/09 16:52:26 [main]: ERROR jdbc.HiveConnection: Error opening session\norg.apache.thrift.transport.TTransportException: HTTP Response code: 431\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - {alphanumericpii}:~$ \n20/04/09 16:52:26 [main]: ERROR jdbc.HiveConnection: Error opening session\norg.apache.thrift.transport.TTransportException: HTTP Response code: 431;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",/usr/bin/hive org.apache.thrift.transport.TTransportException: HTTP Response code: 431,0.343898073,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Few users are not able to connect to beeline.,"As per the ERROR statement provided we see that ""Header size is too large"". As customer have three groups, three of those credentials are passing through header which ended up ""Header size too large"" issue.",Adding  below properties in Hive Config. hive.server2.thrift.http.response.header.size=65536hive.server2.thrift.http.request.header.size=65536,,,,,,,,
1.20041E+14,15:20.2,FD Sandbox : kps023sparkespfdsbwus401 : Hive Service Interactive Down,"Question: What time did the problem begin?\nAnswer: Wed, Apr 8, 2020, 7:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 8, 2020, 7:00 PM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Start hive interactive service on hn0\n2. reboot head and worker nodes\n3. stopping other non essential resources to give daemon more resources to start \n4. reducing concurrent queries = 4 (from 8)\n\n\nQuestion: Additional details about the issue\nAnswer: LLAP status unknown\n--------------------------------------------------------------------------------\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\n\nLog is attached.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. Start hive interactive service on hn0\n2. reboot head and worker nodes\n3. stopping other non essential resources to give daemon more resources to start \n4. reducing concurrent queries = 4 (from 8)\n;\nAdditional details about the issue - LLAP status unknown\n--------------------------------------------------------------------------------\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\nWARN status.LlapStatusServiceDriver: Watch mode enabled and got YARN error. Retrying..\n\nLog is attached.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/09/2020 02:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps023sparkespfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox : kps023sparkespfdsbwus401 : Hive Service Interactive Down,7.251178766,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Hive Interactive down issues on Spark HDI 4.0 ESP clusters,FD Sandbox :  kps023sparkespfdsbwus401 : Hive Service Interactive Down,"Below are  actions recommended and taken,Did  the cross functional setup b/w HDI 4.0 of Hive Interactive and Spark  clustersWe recommend you set spark.security.credentials.hiveserver2.enabled=false for client mode and cluster mode  should set spark.security.credentials.hiveserver2.enabled=truespark-shell  --master yarn \--jars  /usr/hdp/current/hive_warehouse_connector/hive-warehouse-connector-assembly-<STACK_VERSION>.jar  \--conf  spark.security.credentials.hiveserver2.enabled=false--conf  spark.hadoop.hive.llap.daemon.service.hosts='<LLAP_APP_NAME>'--conf  spark.sql.hive.hiveserver2.jdbc.url='jdbc:hive2://<ZOOKEEPER_QUORUM>;serviceDiscoveryMode=zookeeper;zookeeperNamespace=hiveserver2-interactive'--conf  spark.datasource.hive.warehouse.load.staging.dir='<STAGING_DIR>'--conf  spark.datasource.hive.warehouse.metastoreUri='<METASTORE_URI>'--conf  spark.hadoop.hive.zookeeper.quorum='<ZOOKEEPER_QUORUM>'Found  that old DNS entries cauing the issues in the communication, which observed with  exceutor heartbeat lostsAs  a workaround, copied the Spark /etc/hosts entries in to Hive Interactive  /etc/hots file on all the nodes and after that it started working  fine.We  recommend you to clean the old DNS entries in the DNS server would fix this  issue.Setup  the Livy2 interpreter to work against to Hive Interactive cluster and below are  configs to update,1)  Update in Spark2->config>Advanced->Custom  livy2-conf. livy.file.local-dir-whitelist=/usr/hdp/current/hive_warehouse_connector/2)  Update livy proxy on LLAP  clusterhdfs->conf->Advanced->Custom  core-sitehadoop.proxyuser.livy.groups=*hadoop.proxyuser.livy.hosts=*3)  Zeppelin livy interpreter config update. open the interpreter and go to livy  section and edit and add the below  configs      livy.spark.hadoop.hive.llap.daemon.service.hosts=@llap0      livy.spark.jars=file:///usr/hdp/current/hive_warehouse_connector/hive-warehouse-connector-assembly-1.0.0.3.1.2.2-1.jar      livy.spark.security.credentials.hiveserver2.enabled=truelivy.spark.sql.hive.hiveserver2.jdbc.url=jdbc:hive2://zk0-kps024.kpaaddsprod.onmicrosoft.com:2181,zk2-kps024.kpaaddsprod.onmicrosoft.com:2181,zk5-kps024.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-interactivelivy.spark.sql.hive.hiveserver2.jdbc.url.principal=hive/_HOST@KPAADDSPROD.ONMICROSOFT.COMlivy.spark.sql.hive.llap=true      livy.spark.submit.pyFiles=file:///usr/hdp/current/hive_warehouse_connector/pyspark_hwc-1.0.0.3.1.2.2-1.zip      livy.spark.yarn.security.credentials.hiveserver2.enabled=true      livy.superusers=livy,zeppelin      spark.security.credentials.hiveserver2.enabled=true      spark.sql.hive.hiveserver2.jdbc.url.principal=hive/_HOST@KPAADDSPROD.ONMICROSOFT.COM      zeppelin.livy.url=http://hn0-kps023.kpaaddsprod.onmicrosoft.com:8998","183,419,656,184,346,000",,,,,,,
1.20041E+14,41:41.7,Seeing Alerts in Ambari Dashboard - HDFS and MapReduce,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Turn on the Maintenance mode\n\nQuestion: Additional details about the issue\nAnswer: [Hortonworks][{Namepii}] (35) Error from server: error code: \\'2\\' error message: \\'Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex re-running, vertexName=Map 9, {AlphanumericPII} failed\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Turn on the Maintenance mode;\nAdditional details about the issue - [Hortonworks][{Namepii}] (35) Error from server: error code: \\'2\\' error message: \\'Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex re-running, vertexName=Map 9, {AlphanumericPII} failed;\n\n- ProblemStartTime: 04/09/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-workload-rg/providers/Microsoft.HDInsight/clusters/eb5v2i-loader-20200409-creg-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Seeing Alerts in Ambari Dashboard - HDFS and MapReduce,0.293243948,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Seeing Alerts in Ambari Dashboard - HDFS and MapReduce,Seeing Alerts in Ambari Dashboard - HDFS and MapReduce,"Verified and found customer is using local hdfs for table storage which is not recommended. For the failures, we found that local HDFS (/mnt) was cleared due to restart causing the table data to get cleared. This happened due to “dfs.replication = 1” on the cluster. Customer updated “dfs.replication=2” to avoid these issues.",183410283,,,,,,,
1.20041E+14,06:58.2,Resource Mangers are Down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 9, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 9, 2020, 12:00 AM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Two resource managers are all stopped. So the cluster now can not be used.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Two resource managers are all stopped. So the cluster now can not be used.;\n\n- ProblemStartTime: 04/09/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-DEV-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/is24cccmcaidev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Resource Mangers are Down,0.405970044,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Both RM goes to Standby,Resource Mangers are Down and Standby,"Resolution/RCA: However, in the case of node labels, the file nodelabel.mirror is stored in local HDFS in YARN. During scaledown, if decommissioning of HDFS node (where nodelabel.mirror stays) fails, then we lose the only replica of the file. This unavailability of this file seems to cause YARN RM to go into standby. To reduce the change of this happening, we run an update-node-labels.sh script during scale down to increase the replica count of this file to 3. However this script only runs if customer has persisted script actions. So, in the case of a customer where node labels are enabled and there are no script actions, The script execution is skipped leading to the increased possibility of corruption.",184180758,,,,,,,
1.20041E+14,46:35.1,Not able to connect the Hive Odbc Driver,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string being used\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: No\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Yes\n\nQuestion: Connection string used from Beeline\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Error 1 :\n\n[Microsoft][ThriftExtension] (8) Authentication/authorization error occured. Error details: Bad Status: {ALPHANUMERICPII} 401 - Authentication failed\n\nError 2:\n[Microsoft][{Namepii}] (34) Error from server: Bad Status: {ALPHANUMERICPII} 413 FULL head.\n\nError 3:\n[Microsoft][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string being used - ;\nDoes Ambari login work? - No;\nDoes kinit for some or all users work from the Head node? - Yes;\nDoes hdfs dfs -ls / work? - Yes;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Yes;\nConnection string used from Beeline - ;\nAdditional details about the issue - Error 1 :\n\n[Microsoft][ThriftExtension] (8) Authentication/authorization error occured. Error details: Bad Status: {ALPHANUMERICPII} 401 - Authentication failed\n\nError 2:\n[Microsoft][{Namepii}] (34) Error from server: Bad Status: {ALPHANUMERICPII} 413 FULL head.\n\nError 3:\n[Microsoft][DriverSupport] (1170) Unexpected response received from server. Please ensure the server host and port specified for the connection are correct. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05e2piphdidm05\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to connect the Hive Odbc Driver,4.835809238,Root Cause : HDInsight Service\By Design\Simba Hive ODBC Driver,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to cluster with Enterprise Security Package,unable to connect using odbc driver and groups were not syncing.,"Cx was using the wrong connection string.  Also, we found that ADDS team released a new engine for syncing to handle more group syncs that Cx was trying to sync.",  Corrected connectino string for drive and ADDS team confirmed this new change on call,,,,,,,,
1.20041E+14,56:05.1,"Observing failures  'SparkException:' in the logs, the data load is not happening ","Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 2020-04-09 19:23:48 ERROR (Driver) - User class threw exception: org.apache.spark.SparkException: {Namepii} aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 24, wn0-us1cs6.ttnmgircyeyuvhhj3dzvemltee.cx.internal.cloudapp.net, executor 16): java.io.EOFException: Unexpected end of input stream\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII}) \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - 2020-04-09 19:23:48 ERROR (Driver) - User class threw exception: org.apache.spark.SparkException: {Namepii} aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 24, wn0-us1cs6.ttnmgircyeyuvhhj3dzvemltee.cx.internal.cloudapp.net, executor 16): java.io.EOFException: Unexpected end of input stream\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII}) ;\n\n- ProblemStartTime: 04/09/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-workload-rg/providers/Microsoft.HDInsight/clusters/us1cs6-metlloader-20200409-creg-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Observing failures  'SparkException:' in the logs, the data load is not happening ",0.115114942,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Service unhealthy\Spark,"Observing failures 'SparkException:' in the logs, the data load is not happening","Storage level latencies seen when this intermittent issue is seen,",as part of 120041623000805 ,,,,,,,,
1.20041E+14,46:22.8,Spark Job failed after successful execution,"Question: What time did the problem begin?\nAnswer: Wed, Apr 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: {\n    'file': 'wasb://jars@sacomputeapius1usc.blob.core.windows.net/dbc978b5-a76c-419d-a735-1f080a081851/ngp-spark-job-standalone-5.jar',\n    'className': 'com.pros.ngp.dataload.DataLoadEventHubJavaApp',\n    'driverMemory': '{Alphanumericpii}',\n    'driverCores': 1,\n    'executorMemory': '{Alphanumericpii}',\n    'executorCores': 2,\n    'numExecutors': 1,\n    'name': '{AlphanumericPII}',\n    'args': [\n        '{alphanumericpii}',\n        '',\n        '1',\n        '',\n        '',\n        'ListenOnly',\n        '',\n        'ngp',\n        '2',\n        '',\n        'AES',\n        '{AlphanumericPII}',\n        'RSA',\n        '{AlphanumericPII}',\n        '',\n        '{ALPHANUMERICPII}',\n        'false',\n        '{ALPHANUMERICPII}',\n        'TXN',\n        '100',\n        'external'\n    ],\n    'forceRestart': false,\n    'conf': {\n        'spark.yarn.maxAppAttempts': '1',\n        'spark.custom.eventhubs.progressdir': 'wasb://eventhubs@sacomputeapius1usc.blob.core.windows.net/progressdir/dbc978b5-a76c-419d-a735-1f080a081851_bcd2c61c-e8e8-46ef-bdc2-212131642b81_DATALOAD-TXN',\n        'spark.custom.kafka.broker': '10.95.4.10:9092,10.95.4.11:9092,10.95.4.12:9092,10.95.4.13:9092,10.95.4.14:9092',\n        'spark.custom.zookeeper.hosts': '{Alphanumericpii}'\n    }\n}\n\nQuestion: Additional details about the issue\nAnswer: The job did what it's supposed to do, but it failed while shutting down and the final status is FAILED\n\nexcerpt from the logs\n\n20/04/08 04:01:26 INFO ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0\n20/04/08 04:01:26 INFO SparkContext: Invoking stop() from shutdown hook\n\n20/04/08 04:01:56 WARN ShutdownHookManager: ShutdownHook '${alphanumericpii}' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/04/08 04:02:26 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/04/08 04:02:57 ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully after 30 seconds. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - {\n    'file': 'wasb://jars@sacomputeapius1usc.blob.core.windows.net/dbc978b5-a76c-419d-a735-1f080a081851/ngp-spark-job-standalone-5.jar',\n    'className': 'com.pros.ngp.dataload.DataLoadEventHubJavaApp',\n    'driverMemory': '{Alphanumericpii}',\n    'driverCores': 1,\n    'executorMemory': '{Alphanumericpii}',\n    'executorCores': 2,\n    'numExecutors': 1,\n    'name': '{AlphanumericPII}',\n    'args': [\n        '{alphanumericpii}',\n        '',\n        '1',\n        '',\n        '',\n        'ListenOnly',\n        '',\n        'ngp',\n        '2',\n        '',\n        'AES',\n        '{AlphanumericPII}',\n        'RSA',\n        '{AlphanumericPII}',\n        '',\n        '{ALPHANUMERICPII}',\n        'false',\n        '{ALPHANUMERICPII}',\n        'TXN',\n        '100',\n        'external'\n    ],\n    'forceRestart': false,\n    'conf': {\n        'spark.yarn.maxAppAttempts': '1',\n        'spark.custom.eventhubs.progressdir': 'wasb://eventhubs@sacomputeapius1usc.blob.core.windows.net/progressdir/dbc978b5-a76c-419d-a735-1f080a081851_bcd2c61c-e8e8-46ef-bdc2-212131642b81_DATALOAD-TXN',\n        'spark.custom.kafka.broker': '10.95.4.10:9092,10.95.4.11:9092,10.95.4.12:9092,10.95.4.13:9092,10.95.4.14:9092',\n        'spark.custom.zookeeper.hosts': '{Alphanumericpii}'\n    }\n};\nAdditional details about the issue - The job did what it's supposed to do, but it failed while shutting down and the final status is FAILED\n\nexcerpt from the logs\n\n20/04/08 04:01:26 INFO ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0\n20/04/08 04:01:26 INFO SparkContext: Invoking stop() from shutdown hook\n\n20/04/08 04:01:56 WARN ShutdownHookManager: ShutdownHook '${alphanumericpii}' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/04/08 04:02:26 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/04/08 04:02:57 ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully after 30 seconds. ;\n\n- ProblemStartTime: 04/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/97b07783-4db1-431d-8061-031f604fa724/resourceGroups/RgComputeUs1Usc/providers/Microsoft.HDInsight/clusters/computeus1usc\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Job failed after successful execution,11.04010602,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,Spark Job failed after successful execution,ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully after 30 seconds,Provided the below references that has recommendations on how to shut down a spark streaming application gracefully without loosing data.https://www.linkedin.com/pulse/apache-spark-streaming-how-do-graceful-shutdown-chandan-prakashhttps://metabroadcast.com/blog/stop-your-spark-streaming-application-gracefully,,,,,,,,
1.20041E+14,09:19.3,Multiple core dumps per day in Java Runtime Environment,"Application log is indicating multiple core dumps per day (see attachment).  Specifically, 'A fatal error has been detected by the {Namepii} Runtime Environment' and 'SIGSEGV'.\n\nWe are seeking your advice in how to rectify this.\n\nProblem start date and time\nWed, Feb 26, 2020, 12:00 AM CST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 02/26/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Multiple core dumps per day in Java Runtime Environment,18.88910589,Root Cause : HDInsight Service\User Error,Routing Azure Activity & Diagnostic Logs\Issues with Activity Log Alerts,Multiple core dumps per day in Java Runtime Environment,Multiple core dumps per day in Java Runtime Environment,Discussed with customer and dumps are created by 3rd party process. Customer had engaged the 3rd party team and customer is planning to upgrad the 3rd party software causing dumps/issues on the cluster node(s).,,,,,,,,
1.20041E+14,15:38.7,Error in group sync to Ambari,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: getting error in syncing group to ambari cluster.\nbut group dows exist in AD.\n\n{alphanumericpii}:~$ sudo ambari-server sync-ldap --groups /tmp/groups.txt\nUsing python  /usr/bin/python\nSyncing with LDAP...\nEnter Ambari Admin login: rbshdidmadmin\nEnter Ambari Admin password:\nSyncing specified users and groups...ERROR: Exiting with exit code 1.\nREASON: Caught exception running LDAP sync. Couldn't sync LDAP group aag-na-datasci-fiona-corp, it doesn't exist\n{alphanumericpii}:~$\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - getting error in syncing group to ambari cluster.\nbut group dows exist in AD.\n\n{alphanumericpii}:~$ sudo ambari-server sync-ldap --groups /tmp/groups.txt\nUsing python  /usr/bin/python\nSyncing with LDAP...\nEnter Ambari Admin login: rbshdidmadmin\nEnter Ambari Admin password:\nSyncing specified users and groups...ERROR: Exiting with exit code 1.\nREASON: Caught exception running LDAP sync. Couldn't sync LDAP group aag-na-datasci-fiona-corp, it doesn't exist\n{alphanumericpii}:~$\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05u2piphdidm04\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error in group sync to Ambari,13.3117163,Root Cause : HDInsight Service\Azure platform issues\Networking issue,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,User groups are not synching to Ambari,AAD to AADDS sync is failing,worked with AAD team and resolved the sync issues,184310263,,,,,,,
1.20041E+14,20:42.3,Enabling Azure Monitor does not log data to sparkapplication_stats_xxxx_CL tables in Log analytics workspace (maxplatformprod),"Enabling Azure Monitor on cluster (maxhdindwsparkprod) does not log data to sparkapplication_stats_xxxx_CL tables in Log analytics workspace (maxplatformprod)\n\nProblem start date and time\nWed, Apr 1, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/01/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT MSCIT {Namepii} ADL\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/892e9c08-9a45-479b-82bf-f34e7ff27da3/resourceGroups/maxscrgadls/providers/Microsoft.HDInsight/clusters/maxhdindwsparkprod\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Enabling Azure Monitor does not log data to sparkapplication_stats_xxxx_CL tables in Log analytics workspace (maxplatformprod),0.086095829,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\Azure Log Analytics Integration,Enabling Azure Monitor does not log data to sparkapplication_stats_xxxx_CL tables in Log analytics workspace,Transient issue/unknown - customer unresponsive,Next attempt - script action successful on all nodes,,,,,,,,
1.20041E+14,46:35.6,Not able to Access Templeton/WebHCat,"We are not able to access templeton rest using the service id - {emailpii}@jci.com\nHDI {Namepii} - https://hdi001dldev.azurehdinsight.net/\nError:\n{'Code':'Forbidden','Message':'User {emailpii}@jci.com is unauthorized to access the admin endpoint /{AlphanumericPII}'}\n\n\nProblem start date and time\nFri, Apr 10, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/09/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi001dldev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to Access Templeton/WebHCat,4.258233993,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Not able to Access Templeton/WebHCat,not supported on HDI,not supported on HDI,,,,,,,,
1.20041E+14,54:56.1,unable to connect via PowerBI,"Question: What time did the problem begin?\nAnswer: Wed, Apr 8, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Connection string being used\nAnswer: deventanalyticshdinsight.azurehdinsight.net\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Yes\n\nQuestion: Connection string used from Beeline\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are trying to connect to HDInsight cluster from PowerBI desktop using the Azure HDInsight Spark connector. We provide the HDInsight URL as deventanalyticshdinsight.azurehdinsight.net and provide the credentials for read-only cluster user that we have created. The connection was successful previously, but lately it has started to fail. I am attaching 2 files which provide the details of the error. Please help in troubleshoot.  We are able to connect to other HDInsight clusters using PowerBI without any issues.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - Yes;\nConnection string being used - deventanalyticshdinsight.azurehdinsight.net;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Yes;\nConnection string used from Beeline - ;\nAdditional details about the issue - We are trying to connect to HDInsight cluster from PowerBI desktop using the Azure HDInsight Spark connector. We provide the HDInsight URL as deventanalyticshdinsight.azurehdinsight.net and provide the credentials for read-only cluster user that we have created. The connection was successful previously, but lately it has started to fail. I am attaching 2 files which provide the details of the error. Please help in troubleshoot.  We are able to connect to other HDInsight clusters using PowerBI without any issues.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/08/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LXK.DigitalTransformation.BigDecisions.Non-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/27f2890d-6e16-464f-853b-ae7f681978d5/resourceGroups/dev_qa_resource_group/providers/Microsoft.HDInsight/clusters/deventanalyticshdinsight\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to connect via PowerBI,5.263737673,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to standard cluster,"Can't connect Power BI to HDInsight Spark Cluster, no metrics over Ambari UI, hn0 was complete down.","Client was getting  error: ODBC: ERROR [HY000] [Microsoft][DriverSupport] (1170)Caused by a failure on Spark2 Thrift Servers service, the service was down.Also there was another issues on the cluster, other services were down.",After several intent to restart the services from Ambari UI we proceed to restart the headnodes from our end.Suggest to client to use the ODBC connector from ODBC data sources and recommend to decrease the amount of connections from Power BI to cluster.For ambari metrics we restart the services over the hn0 manually 1 by one. ,183872240,,,,,,,
1.20041E+14,09:47.3,BDM jobs failed with unhealthy node issue,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 31, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Its a BDM job\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: The BDM job has filed with the unhealthy node issue and the infroamtcia team has investigated and provided the details attached.\nWe did not get any alerts for the node being used for more than 90% eventhough we have setup the alert in Ambari.\nWe need your analysis to understand whats the issue from HDI end and solution to fix the issue in future.\nThanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Its a BDM job;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - The BDM job has filed with the unhealthy node issue and the infroamtcia team has investigated and provided the details attached.\nWe did not get any alerts for the node being used for more than 90% eventhough we have setup the alert in Ambari.\nWe need your analysis to understand whats the issue from HDI end and solution to fix the issue in future.\nThanks;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/31/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",BDM jobs failed with unhealthy node issue,41.02769318,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,BDM jobs failed with unhealthy node issue,wn12 unhealthy ,CX not observed unhealthy in wns without troubleshooting,,,,,,,,
1.20041E+14,31:21.9,Not able to delete the cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Tried through Azure Powershell and UI\nException: Remove-AzureRMHDInsightCluster : Conflict: Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Tried through Azure Powershell and UI\nException: Remove-AzureRMHDInsightCluster : Conflict: Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Payouts PayoutJournal Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb075b87-16bb-42c1-9e6a-1338cc47f6e2/resourceGroups/payoutjournal_ca_prod_eastus_spark/providers/Microsoft.HDInsight/clusters/payoutjournalsparkclusterprodeastus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to delete the cluster,0.090209972,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Not able to delete the cluster.,Received delete for a cluster when there is a concurrent create in progress.Returning Conflict for the cluster.,Deleted cluster from backend.,183562067,,,,,,,
1.20041E+14,44:17.4,Unable to see logs in worker nodes,"Question: What time did the problem begin?\nAnswer: Sun, Apr 12, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Yarn logs on workernodes are not loading\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Yarn logs on workernodes are not loading;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/12/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard Free\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9c9cb9aa-49f6-40d2-a073-d0c1d291327d/resourceGroups/amn-prod-eastus2/providers/Microsoft.HDInsight/clusters/trg-hadoop-cluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to see logs in worker nodes,0.818560271,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,Unknown,Unknown,cx deleted the cluster already,,,,,,,,
1.20041E+14,16:43.1,FD Sandbox - kps023sparkespfdsbwus401 - Accessing ADLS container from secure cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM PDT\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. ACLs applied \n2. Ranger hive policies configured \n\n\nQuestion: Additional details about the issue\nAnswer: Unable to access files ( adf container - file system ) from secure spark cluster edge node \n\nExample:\nhdfs dfs -ls abfss://adf@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/raw/clarity_mvp/nw/staging/data/in/ZC_SBO_HAR_TYPE/initial/ZC_SBO_HAR_TYPE_20200318_064018.dat\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - Yes;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. ACLs applied \n2. Ranger hive policies configured \n;\nAdditional details about the issue - Unable to access files ( adf container - file system ) from secure spark cluster edge node \n\nExample:\nhdfs dfs -ls abfss://adf@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/raw/clarity_mvp/nw/staging/data/in/ZC_SBO_HAR_TYPE/initial/ZC_SBO_HAR_TYPE_20200318_064018.dat;\n\n- ProblemStartTime: 04/13/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps023sparkespfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox - kps023sparkespfdsbwus401 - Accessing ADLS container from secure cluster,0.608274648,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",kps023sparkespfdsbwus401 - Accessing ADLS container from secure cluster,BY design,We were able to determine that the folders we were trying to access from the cluster didn’t have proper permissions on the root level.As a mitigation we applied same permissions for the user group at the root level to get past the issue.,,,,,,,,
1.20041E+14,20:12.5,"Applied NSG, Jupyter notebook not working.","Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: test-nonprod\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I was following this doc:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#directly-connect-to-apache-hadoop-services\n\nto add nsg to hdi.\n\nI am able to access the cluster from within VNET. but my jupyter notebook kernel is not able to connect and run queries.\nWhen I remove hdi from nsg, Jupyter works again.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - test-nonprod;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I was following this doc:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#directly-connect-to-apache-hadoop-services\n\nto add nsg to hdi.\n\nI am able to access the cluster from within VNET. but my jupyter notebook kernel is not able to connect and run queries.\nWhen I remove hdi from nsg, Jupyter works again.;\n\n- ProblemStartTime: 04/12/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: wadogo-nonprod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Applied NSG, Jupyter notebook not working.",0.337285648,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,"IssueWhen you access the Jupyter service on HDInsight, you see an error box saying “Not Found”.If you check the Jupyter logs(on hn0 /var/log/jupyter) , you will see something like this:[W 2018-08-21 17:43:33.352 NotebookApp] 404 PUT /api/contents/PySpark/notebook.ipynb (10.16.0.144) 4504.03ms referer=https://pnhr01hdi-corpdir.msappproxy.net/jupyter/notebooks/PySpark/notebook.ipynbBlocking Cross Origin API request.  Origin: https://xxx.xxx.xxx, Host: hn0-pnhr01.j101qxjrl4zebmhb0vmhg044xe.ax.internal.cloudapp.net:8001You may also see an IP address in the “Origin” field in the Jupyter log.","CauseThis error can be caused by a few things:If you have configured Network Security Group (NSG) Rules to restricts access to the cluster. Restricting access with NSG rules will still allow you to directly access Apache Ambari and other services using the IP address rather than the cluster name. However, when accessing Jupyter, you could see a 404 “Not Found” error.If you have given your HDInsight gateway a customized DNS name other than the standard xxx.azurehdinsight.net.","Please modify the jupyter.py files in these two places on the headnode0:/var/lib/ambari-server/resources/common-services/JUPYTER/1.0.0/package/scripts/jupyter.py/var/lib/ambari-agent/cache/common-services/JUPYTER/1.0.0/package/scripts/jupyter.pyFind the line that says:NotebookApp.allow_origin='\""https://{2}.{3}\""'And change it to:NotebookApp.allow_origin='\""*\""'Restart the Jupyter service from Ambari.Typing ps aux | grep jupyter at the command prompt should show that it allows for any URL to connect to it.[!Note] Do note that this is less secure than the setting we already had in place. But it is assumed access to the cluster is restricted as we have NSG in place.",,,,,,,,
1.20041E+14,49:26.3,Null vs Empty issue in Spark,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: default\n\nQuestion: Additional details about the issue\nAnswer: Facing issue in differentiating the blank (i.e null) and empty (i.e '') values. \nData from input source (CSV and Database(Sql Server, Snowflake)) were incorrectly loaded into Spark 2.3.1. \nBecause of this, we are not able to differentiate between blank and empty string values in dataframe. \n\ne.g if CSV has below data.\n\nname,color,is_pretty\nrose,red,true\nsunflower,,true\nlotus,'',true\n\nSpark gives below data frame\n+---------+-----+---------+\n|     name   |color |is_pretty|\n+---------+-----+---------+\n|     rose      |  red  |     true|\n|sunflower |  null |     true|\n|    lotus      | null  |     true|\n+---------+-----+---------+\n\nbut expected is \n+---------+-----+---------+\n|     name  |color| is_pretty|\n+---------+-----+---------+\n|     rose     |   red |     true|\n|sunflower|          |     true|\n|    lotus     |  null |     true|\n+---------+-----+---------+\n\nAs we tried few options as option('treatEmptyValuesAsNulls', 'true/false') , option('nullValue', 'someString') but seems this option also not working for spark 2.3.1.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - default;\nAdditional details about the issue - Facing issue in differentiating the blank (i.e null) and empty (i.e '') values. \nData from input source (CSV and Database(Sql Server, Snowflake)) were incorrectly loaded into Spark 2.3.1. \nBecause of this, we are not able to differentiate between blank and empty string values in dataframe. \n\ne.g if CSV has below data.\n\nname,color,is_pretty\nrose,red,true\nsunflower,,true\nlotus,'',true\n\nSpark gives below data frame\n+---------+-----+---------+\n|     name   |color |is_pretty|\n+---------+-----+---------+\n|     rose      |  red  |     true|\n|sunflower |  null |     true|\n|    lotus      | null  |     true|\n+---------+-----+---------+\n\nbut expected is \n+---------+-----+---------+\n|     name  |color| is_pretty|\n+---------+-----+---------+\n|     rose     |   red |     true|\n|sunflower|          |     true|\n|    lotus     |  null |     true|\n+---------+-----+---------+\n\nAs we tried few options as option('treatEmptyValuesAsNulls', 'true/false') , option('nullValue', 'someString') but seems this option also not working for spark 2.3.1.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c7e4f49b-8174-4f40-bd74-310d60dc6cb7/resourceGroups/rg-useast2dev-test-datalake-hdis/providers/Microsoft.HDInsight/clusters/hdis-datalake-dev-test\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Null vs Empty issue in Spark,14.97361907,Root Cause : HDInsight Service\Configuration\HDInsight SDK,Routing Azure HDInsight V5\Query or Job Failure\Spark,Null vs Empty issue in Spark,The data that data frame stores after data being fetched from source database is dependent on driver being used to fetch data from the relevant data source and how driver parsed NULL and empty.  ,Suggested workaround with the below JDBC Driver and provided required steps to attain the resolution and customer confirmed that the given resolution fix the issue.https://docs.microsoft.com/en-us/sql/connect/jdbc/download-microsoft-jdbc-driver-for-sql-server?view=sql-server-ver15,184056314,,,,,,,
1.20041E+14,09:05.4,Ranger REST API for ROW LEVEL FILLTER,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: curl -iv -u {AlphanumericPII} -H 'Content-Type: application/json' -d '{'policyName':' 1crussia_raw','resourceName':'/rumgom_cdc/*/*','description':'','repositoryName':'llaphdi4enterprisedev_hive','repositoryType':'hive','permMapList':[{'userList':[],'groupList':['g_az_devadls_data_raw_1crussia_readonly'],'permList':['select','Read']}],'tables':'*','columns':'*','databases':'1crussia_raw','tableType':'Inclusion','columnType':'Inclusion','isEnabled':true,'isRecursive':false,'isAuditEnabled':true,'version':'1','replacePerm':false}' -X POST https://llaphdi4enterprisedev-int.azurehdinsight.net/ranger/service/public/api/policy/\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nI'm trying to automate the Ranger policy. Im able to sucessfully create policy but unable to create row level security. \n\nI need to know the steps to add row level secruity using rest api\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - curl -iv -u {AlphanumericPII} -H 'Content-Type: application/json' -d '{'policyName':' 1crussia_raw','resourceName':'/rumgom_cdc/*/*','description':'','repositoryName':'llaphdi4enterprisedev_hive','repositoryType':'hive','permMapList':[{'userList':[],'groupList':['g_az_devadls_data_raw_1crussia_readonly'],'permList':['select','Read']}],'tables':'*','columns':'*','databases':'1crussia_raw','tableType':'Inclusion','columnType':'Inclusion','isEnabled':true,'isRecursive':false,'isAuditEnabled':true,'version':'1','replacePerm':false}' -X POST https://llaphdi4enterprisedev-int.azurehdinsight.net/ranger/service/public/api/policy/\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - Hi {Namepii},\n\nI'm trying to automate the Ranger policy. Im able to sucessfully create policy but unable to create row level security. \n\nI need to know the steps to add row level secruity using rest api;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ranger REST API for ROW LEVEL FILLTER,0.063143996,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hive,Ranger REST API for ROW LEVEL FILLTER,NA,Advisory information request for creating RLS with Rest API,,,,,,,,
1.20041E+14,55:44.2,Hadoop Space /usr/hdp is getting full,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: \nHadoop Space /usr/hdp is getting full, and hive is throwing errors.\n\nHIVE Error - Logistics Jobs Are Failing\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: \nHadoop Space /usr/hdp is getting full, and hive is throwing errors.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - \nHadoop Space /usr/hdp is getting full, and hive is throwing errors.\n\nHIVE Error - Logistics Jobs Are Failing;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - \nHadoop Space /usr/hdp is getting full, and hive is throwing errors.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: ABI GLOBAL PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2db7c27b-2f9f-4088-981b-2bd88c5c1905/resourceGroups/Global-EnterpriseDataHub-RG-GB-PROD/providers/Microsoft.HDInsight/clusters/ca182c-edhhdisparkgbprod-hdi-prod-eu\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hadoop Space /usr/hdp is getting full,27.94720853,Root Cause : HDInsight Service\Bug\SQL,Routing Azure HDInsight V5\Query or Job Failure\Hive,"  Based on troubleshoot we found that we are hitting bug https://issues.apache.org/jira/browse/HIVE-20824  As the support for the “Spark 2.1, 2.2 & Kafka 1.0      support will expire on June 30, 2020.” is going to expire soon. After      discussing with your internal team you have planned to upgrade Talend ETL      which is depend of spark version to higher version so that going forward      it will support higher version of spark. As a workaround, you will be      writing the script which will monitor the ‘/usr/hdp’ disk space and      restart the HiveServer2 service when no jobs are running to release the      files marked for deletion because of bug because roll back of fix to lower      version will take sometime(fixing, testing, validation would take more      time).",Hadoop Space /usr/hdp is getting fullsshuser@hn0-ca182c:~$ sudo df -hFilesystem      Size  Used Avail Use% Mounted onudev             56G     0   56G   0% /devtmpfs            12G  1.1G   10G  10% /run/dev/sda1       125G   31G   94G  25% /tmpfs            56G   36K   56G   1% /dev/shmtmpfs           5.0M     0  5.0M   0% /run/locktmpfs            56G     0   56G   0% /sys/fs/cgroup/dev/sdb1       788G  7.6G  740G   2% /mnttmpfs            12G     0   12G   0% /run/user/2018tmpfs            12G     0   12G   0% /run/user/202tmpfs            12G     0   12G   0% /run/user/2008tmpfs            12G  8.0K   12G   1% /run/user/2012tmpfs            12G     0   12G   0% /run/user/203tmpfs            12G     0   12G   0% /run/user/2002tmpfs            12G     0   12G   0% /run/user/118tmpfs            12G     0   12G   0% /run/user/201tmpfs            12G     0   12G   0% /run/user/2007tmpfs            12G     0   12G   0% /run/user/2001tmpfs            12G     0   12G   0% /run/user/2019sshuser@hn0-ca182c:~$sshuser@hn0-ca182c:~$ sudo du /usr/hdp/ -h --max-depth=1 | sort -n6.7G    /usr/hdp/2.6.2.38-17.1G    /usr/hdp/18M     /usr/hdp/current371M    /usr/hdp/sharesshuser@hn0-ca182c:~$sshuser@hn0-ca182c:~$ sudo find /usr/hdp/ -xdev -type f -size +100M -printf '%s %TY-%Tm-%Td %TH:%TM %Tz %p\n'| sort -nr405918259 2020-02-12 03:58 +0000 /usr/hdp/2.6.2.38-1/oozie/oozie-sharelib.tar.gz211040044 2018-03-29 12:00 +0000 /usr/hdp/2.6.2.38-1/hadoop/mapreduce.tar.gz190876322 2020-02-12 04:26 +0000 /usr/hdp/2.6.2.38-1/oozie/share/lib/spark/spark-assembly-1.6.3.2.6.2.38-1-hadoop2.7.3.2.6.2.38-1.jar190876322 2018-03-29 13:32 +0000 /usr/hdp/2.6.2.38-1/spark/lib/spark-assembly-1.6.3.2.6.2.38-1-hadoop2.7.3.2.6.2.38-1.jar187288666 2018-03-29 13:52 +0000 /usr/hdp/2.6.2.38-1/zeppelin/interpreter/spark/dep/zeppelin-spark-dependencies_2.10-0.7.2.2.6.2.38-1.jar184016988 2018-03-29 14:04 +0000 /usr/hdp/2.6.2.38-1/falcon/webapp/falcon.war136018623 2020-02-12 04:26 +0000 /usr/hdp/2.6.2.38-1/oozie/oozie-server/webapps/oozie.war134589766 2018-03-29 12:43 +0000 /usr/hdp/2.6.2.38-1/pig/pig.tar.gz127737570 2018-03-29 13:49 +0000 /usr/hdp/2.6.2.38-1/oozie/oozie.war126253627 2018-02-08 10:23 +0000 /usr/hdp/share/hst/smartsense-activity-explorer-1.4.2.2.5.2.10-3.tar.gz124882880 2018-03-29 13:10 +0000 /usr/hdp/2.6.2.38-1/storm-slider-client/contrib/storm-starter/storm-starter-topologies-1.1.0.2.6.2.38-1.jar124882880 2018-03-29 13:10 +0000 /usr/hdp/2.6.2.38-1/storm/contrib/storm-starter/storm-starter-topologies-1.1.0.2.6.2.38-1.jar113795854 2018-03-29 13:32 +0000 /usr/hdp/2.6.2.38-1/spark/lib/spark-examples-1.6.3.2.6.2.38-1-hadoop2.7.3.2.6.2.38-1.jar107567188 2018-03-29 13:43 +0000 /usr/hdp/2.6.2.38-1/phoenix/phoenix-4.7.0.2.6.2.38-1-client.jar106125523 2018-03-29 12:26 +0000 /usr/hdp/2.6.2.38-1/hive/hive.tar.gzsshuser@hn0-ca182c:~$ sudo lsof -Fn -Fs |grep -B1 -i deleted | grep ^s  | cut -c 2- | awk '{s+=$1} END {print s}'109146551672," Workaround:   Explicitly add jar functionality is bug in Spark 2.1      version. This issue has been addressed in the Spark 2.2 or higher.   Instead of adding jar file in each session while      executing the job can we use hive.aux.jars.path parameter which will places the jars in a location /usr/lib/customhivelibs/ on head and worker nodes. So when we start a session we      don’t have to explicitly add the jars, session by default will pick all      the jars from that location. This would solve your problem. Below link      helps you with more details. I would also like to check “Add custom Apache Hive libraries when creating your HDInsight cluster” see if that works for you instead of using add jars option. Below link gives you more details: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-add-hive-libraries",184320400,,,,,,,
1.20041E+14,25:54.2,PROD : kpph16llapprodusc01 : HiveServer2 Interactive stopped,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: {AlphanumericPII} Interactivestopped\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII} Interactivestopped\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - {AlphanumericPII} Interactivestopped;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - {AlphanumericPII} Interactivestopped;\n\n- ProblemStartTime: 04/13/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpph16llapprodusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PROD : kpph16llapprodusc01 : HiveServer2 Interactive stopped,0.180541566,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,PROD: kpph16llapprodusc01: HiveServer2 Interactive stopped,"looking at the metrics, hn0 had very low free memory and high load on one of the days. If it was during the issue timeframe, that is most likely why the HS2Interactive service went down.","Restarted the HiveServer2 from the Ambari and noted for a week, service is up and running. More Info- Also, it shows you had a Hive connection timeout on hn0 from 4/10/2020 – 4/13/2020. The following Cloudera article shows some mitigations for this issue since it is happening frequently: https://community.cloudera.com/t5/Support-Questions/Hive-server-2-process-connection-failed/td-p/206016 We have notice Resource Manager connection alerts. This can cause the HS2Interactive service to go down. Since current configuration are only allocating 1GB to the Resource Manager heap size, I would suggest increasing it to 2GB.",,,,,,,,
1.20041E+14,12:57.7,Required Instruction to Create workload manager,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Kindly assing this case to {Namepii} {Namepii} {emailpii}@microsoft.com\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: I have followed the instruction provided but unable to implement work load manager. {Namepii} {Namepii} {emailpii}@microsoft.com already helped me with similar case in 3.0 and i want to setup in 4.0\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Kindly assing this case to {Namepii} {Namepii} {emailpii}@microsoft.com;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - I have followed the instruction provided but unable to implement work load manager. {Namepii} {Namepii} {emailpii}@microsoft.com already helped me with similar case in 3.0 and i want to setup in 4.0;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Required Instruction to Create workload manager,23.93841751,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Hive,Customer requested Instructions to setup the Hive workload management feature,"Trigger needs to be mapped to a user or application to work. If Hive is submitting the queries, map the trigger to the hive user.  If Hive impersonation is enabled, map the trigger to the user(s) submitting the queries.","Prerequisites:• Set up and run Hive low-latency analytical processing (LLAP), which includes a YARN queue configured forLLAP. Ambari sets hive.llap.daemon.queue.name to the name of this queue.• Set up a second YARN queue for interactive workload management.• Add a custom property hive.server2.tez.interactive.queue to hiveserver2-interactive-site that names the interactiveworkload management queue.Configuration steps:create RESOURCE PLAN testrp2;CREATE POOL testrp2.default.c1 WITH ALLOC_FRACTION=0.3, QUERY_PARALLELISM=3, SCHEDULING_POLICY='fair';CREATE POOL testrp2.default.c2 WITH ALLOC_FRACTION=0.6, QUERY_PARALLELISM=2, SCHEDULING_POLICY='fair';SELECT * FROM SYS.WM_POOLS;ALTER RESOURCE PLAN testrp2 VALIDATE;ALTER RESOURCE PLAN testrp2 ENABLE ACTIVATE;CREATE USER MAPPING 'hive' IN high_concurr_rp to testrp2.default.c1;CREATE TRIGGER testrp2.trigger_1 WHEN ELAPSED_TIME > 300 DO KILL;",184161103,,,,,,,
1.20041E+14,47:02.3,Very high WAL slow sync cost caused clients failed to get region server.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 9:03 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 13, 2020, 9:05 PM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: REST API\n\nQuestion: Additional details about the issue\nAnswer: client errors:\n\n2020-04-14 {Alphanumericpii} GMT ERROR {AlphanumericPII} cid=NA 3178 --- [{alphanumericpii}] o.a.hadoop.hbase.client.AsyncProcess     : Failed to get region location \n\n\nHBase WAL sync cost is very high on one of the region servers: 301 secs\n\n4/14/20\n{Alphanumericpii} AM\n2020-04-14 {Alphanumericpii} INFO  [{alphanumericpii}] wal.FSHLog: Slow sync cost: 301090 ms, current pipeline: []\nhost = {alphanumericpii} = /{alphanumericpii} = {alphanumericpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - REST API;\nAdditional details about the issue - client errors:\n\n2020-04-14 {Alphanumericpii} GMT ERROR {AlphanumericPII} cid=NA 3178 --- [{alphanumericpii}] o.a.hadoop.hbase.client.AsyncProcess     : Failed to get region location \n\n\nHBase WAL sync cost is very high on one of the region servers: 301 secs\n\n4/14/20\n{Alphanumericpii} AM\n2020-04-14 {Alphanumericpii} INFO  [{alphanumericpii}] wal.FSHLog: Slow sync cost: 301090 ms, current pipeline: []\nhost = {alphanumericpii} = /{alphanumericpii} = {alphanumericpii}\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/14/2020 04:03:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search PRD ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/112d7591-4d06-4945-8323-c9ef2f70158a/resourceGroups/adobeidx-prod-hbase/providers/Microsoft.HDInsight/clusters/adobeidxhbaseprodva7\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Very high WAL slow sync cost caused clients failed to get region server.,0.550401354,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase," [sync.3] wal.FSHLog: Slow sync cost: 301090 ms, current pipeline: [] host = wn6-adobeisource = /var/log/hbase/hbase-hbase-regionserver-wn6-adobei.logsourcetype = log4j",Very high WAL slow sync cost caused clients failed to get region server,RegionNotFound error  occurred only for a few seconds but client did not send requests for next 4-5  mins and this is due to some synchronization in client code,"184,380,667,185,490,000",,,,,,,
1.20041E+14,08:11.7,Access the json file from Spark webUI,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer:       'spark.driver.supervise' : 'true',\n      'spark.scheduler.mode': 'FIFO',\n      'spark.sql.catalogImplementation': 'hive',\n      'spark.task.maxFailures': 8,\n      'spark.yarn.am.attemptFailuresValidityInterval': '1h',\n      'spark.yarn.executor.failuresValidityInterval': '1h',\n      'spark.yarn.max.executor.failures': 160,\n      'spark.yarn.maxAppAttempts': 6,\n      'spark.sql.shuffle.partitions': 2048,\n      'spark.executor.instances': '3'\n\nQuestion: Additional details about the issue\nAnswer: I would like to get the json file from spark webUI. \nhttps://p02las01.azurehdinsight.net/yarnui/hn/proxy/application_1581465695317_0667/streaming/\n\nHow Can I get it from command line or using pyspark? I found this documentation (https://spark.apache.org/docs/2.3.0/monitoring.html#web-interfaces), but could not make it work. Could you please give more guidance? Thanks. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details -       'spark.driver.supervise' : 'true',\n      'spark.scheduler.mode': 'FIFO',\n      'spark.sql.catalogImplementation': 'hive',\n      'spark.task.maxFailures': 8,\n      'spark.yarn.am.attemptFailuresValidityInterval': '1h',\n      'spark.yarn.executor.failuresValidityInterval': '1h',\n      'spark.yarn.max.executor.failures': 160,\n      'spark.yarn.maxAppAttempts': 6,\n      'spark.sql.shuffle.partitions': 2048,\n      'spark.executor.instances': '3';\nAdditional details about the issue - I would like to get the json file from spark webUI. \nhttps://p02las01.azurehdinsight.net/yarnui/hn/proxy/application_1581465695317_0667/streaming/\n\nHow Can I get it from command line or using pyspark? I found this documentation (https://spark.apache.org/docs/2.3.0/monitoring.html#web-interfaces), but could not make it work. Could you please give more guidance? Thanks. ;\n\n- ProblemStartTime: 04/13/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Access the json file from Spark webUI,0.247699651,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Unexpected result\Spark,advisory,wanted to access the streaming analytics as shown in the Spark documentation but could not find the correct URL.,"Resolution: We found the following should work... http://xxxxxxxxxxx:8088/proxy/application_1581465695317_0667/api/v1/applications/application_1581465695317_0667/<endpoint from below>          Endpoint         Meaning             /applications         A list of   all applications.   ?status=[completed|running] list only applications in the chosen   state.   ?minDate=[date] earliest start date/time to list.   ?maxDate=[date] latest start date/time to list.   ?minEndDate=[date] earliest end date/time to list.   ?maxEndDate=[date] latest end date/time to list.   ?limit=[limit] limits the number of applications   listed.   Examples:   ?minDate=2015-02-10   ?minDate=2015-02-03T16:42:40.000GMT   ?maxDate=2015-02-11T20:41:30.000GMT   ?minEndDate=2015-02-12   ?minEndDate=2015-02-12T09:15:10.000GMT   ?maxEndDate=2015-02-14T16:30:45.000GMT   ?limit=10             /applications/[app-id]/jobs         A list of   all jobs for a given application.   ?status=[running|succeeded|failed|unknown] list only jobs in the specific   state.             /applications/[app-id]/jobs/[job-id]         Details   for the given job.             /applications/[app-id]/stages         A list of   all stages for a given application.   ?status=[active|complete|pending|failed] list only stages in the state.             /applications/[app-id]/stages/[stage-id]         A list of   all attempts for the given stage.             /applications/[app-id]/stages/[stage-id]/[stage-attempt-id]         Details   for the given stage attempt.             /applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskSummary         Summary   metrics of all tasks in the given stage attempt.   ?quantiles summarize the metrics with the given   quantiles.   Example: ?quantiles=0.01,0.5,0.99             /applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskList         A list of   all tasks for the given stage attempt.   ?offset=[offset]&length=[len] list tasks in the given range.   ?sortBy=[runtime|-runtime] sort the tasks.   Example: ?offset=10&length=50&sortBy=runtime             /applications/[app-id]/executors         A list of   all active executors for the given application.             /applications/[app-id]/allexecutors         A list of   all(active and dead) executors for the given application.             /applications/[app-id]/storage/rdd         A list of   stored RDDs for the given application.             /applications/[app-id]/storage/rdd/[rdd-id]         Details   for the storage status of a given RDD.             /applications/[base-app-id]/logs         Download   the event logs for all attempts of the given application as files within a   zip file.             /applications/[base-app-id]/[attempt-id]/logs         Download   the event logs for a specific application attempt as a zip file.             /applications/[app-id]/streaming/statistics         Statistics   for the streaming context.             /applications/[app-id]/streaming/receivers         A list of   all streaming receivers.             /applications/[app-id]/streaming/receivers/[stream-id]         Details   of the given receiver.             /applications/[app-id]/streaming/batches         A list of   all retained batches.             /applications/[app-id]/streaming/batches/[batch-id]         Details   of the given batch.             /applications/[app-id]/streaming/batches/[batch-id]/operations         A list of   all output operations of the given batch.             /applications/[app-id]/streaming/batches/[batch-id]/operations/[outputOp-id]         Details   of the given operation and given batch.             /applications/[app-id]/environment         Environment   details of the given application.             /version         Get the   current spark version.      Thank you again for contacting Microsoft Support !Best Regards,   Hernán MarzorattiAzure Big Data Support Eng.Phone: +1 (980) 776 7076hernan.marzoratti@microsoft.comWork hrs.: Mon-Fri 9:00 AM - 5:00 PM  Eastern Time (US and Canada)",,,,,,,,
1.20041E+14,33:15.5,Hive going down frequently,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Frequently Amabari Metric and Hive going down. And i'm getting this error HTTP Response code: 502\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Frequently Amabari Metric and Hive going down. And i'm getting this error HTTP Response code: 502;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/cmidevllapdj\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive going down frequently,89.93438042,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Cluster service instability due to local disk filling on both headnodes,"Bug in Jersey 1.9 framework causing the following exception to be logged over and over again causing the credentialservice.out file to rapidly grow without bound:java.lang.IllegalAccessException: Class com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator$8 can not access a member of class javax.ws.rs.core.Response with modifiers ""protected""        at sun.reflect.Reflection.ensureMemberAccess(Reflection.java:102)        at java.lang.Class.newInstance(Class.java:436)        at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator$8.resolve(WadlGeneratorJAXBGrammarGenerator.java:467)        at com.sun.jersey.server.wadl.WadlGenerator$ExternalGrammarDefinition.resolve(WadlGenerator.java:181)        at com.sun.jersey.server.wadl.ApplicationDescription.resolve(ApplicationDescription.java:81)        at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.attachTypes(WadlGeneratorJAXBGrammarGenerator.java:518)        at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:124)        at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:104)        at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:120)        at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:98)        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:617)        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:576)        at com.microsoft.azure.datalake.store.security.filters.AuthFilter.doFilter(Unknown Source)        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1426)        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)        at org.mortbay.jetty.Server.handle(Server.java:326)        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)             ",Applied patch to cluster that prevents the above class from logging the exceptoin,"184,039,790,185,457,000,000,000,000,000,000,000",,,,,,,
1.20041E+14,54:29.7,See attached PDF for full description,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: Please see attached pdf for details.\n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Will attach pdf after submitting case\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - Please see attached pdf for details.;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Will attach pdf after submitting case;\n\n- ProblemStartTime: 04/14/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Airsis MSDN DevTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a27a4488-539f-4603-b8aa-1ece32df8e99/resourceGroups/rg-mip-devtest/providers/Microsoft.HDInsight/clusters/hdi4-mip-dev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",See attached PDF for full description,0.085571033,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Unexpected result\Hbase,Grafana dashboard showing different metrics or not provide any metrics at all,Default metrics and default aggregators did not provide need/correct metrics ,Made a new copy of the dash board by exporting the json and importing to a new dashboard with the correct metrics and aggregators.,"185,827,513,188,280,000",,,,,,,
1.20041E+14,25:38.5,need to determine need for ssh11 rule (telnet),"Question: Please select the type of Load Balancer that you need configuration support for\nAnswer: Azure Load Balancer\n\nQuestion: Please select the Load Balancer SKU that you need help with\nAnswer: Don't know\n\nQuestion: Please select the Load Balancer resource type that you need help with\nAnswer: Public Load Balancer\n\nQuestion: Please select the Load Balancer IP address family\nAnswer: IPv4 Load Balancer\n\nQuestion: Please select the Load Balancer fault-tolerence scope\nAnswer: Zone-specific / zonal Load Balancer\n\nQuestion: Please select the specific configuration topic that you need help with\nAnswer: Load Balancer or NAT Rule\n\nQuestion: When did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 12:00 AM CDT\n\nQuestion: Please specify any additional details or questions\nAnswer: We are leveraging HD Insight, but need a resolution for why telnet is needed outbound,  If not we need to safely remove it.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Load Balancer:\nPlease select the type of Load Balancer that you need configuration support for - Azure Load Balancer;\nPlease select the Load Balancer SKU that you need help with - Don't know;\nPlease select the Load Balancer resource type that you need help with - Public Load Balancer;\nPlease select the Load Balancer IP address family - IPv4 Load Balancer;\nPlease select the Load Balancer fault-tolerence scope - Zone-specific / zonal Load Balancer;\nPlease select the specific configuration topic that you need help with - Load Balancer or NAT Rule;\nWhen did the problem begin? - {ALPHANUMERICPII};\nPlease specify any additional details or questions - We are leveraging HD Insight, but need a resolution for why telnet is needed outbound,  If not we need to safely remove it.;\n\n- ProblemStartTime: 04/14/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HCSC Azure Test - Infrastructure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: northcentralus\n- ResourceUri: /subscriptions/b896c19d-3467-4c2d-9e46-d93bf2eccc41/resourceGroups/hcsc_00006681_test_rg/providers/Microsoft.Network/loadBalancers/headnode-29d3db22b285413f83cccc8f48e1e092\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",need to determine need for ssh11 rule (telnet),0.135943359,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure Load Balancer V1\Configuration and Setup\Configure Load Balancer,need to determine need for ssh11 rule (telnet),By design ,Hdinsight cluster gets deployed with three load balancersload balancer with Public IP for https access (ambari)Load balancer with Public IP for SSH access( in question)Load balancer with Private IP( for internal https access) à for your use case.Below doc explains the networking architecture in detail https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-virtual-network-architecture#basic-virtual-network-resourcesYou can secure your cluster access from public internet by using NSGs on top of the Subnet/vnet where the cluster is deployed to.The NSG would need some HDinsight management IPs needed (docs below)https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-service-tagshttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addressesComing to the headnode load balancerThere are two inbound rules one for headnode0 and the other for headnode1 the target port for both the rules would be 22 only.These target machines would be sitting in our internal subscription.Other topics discussed:Patching : https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-os-patching  ,,,,,,,,
1.20041E+14,55:10.0,Error message 'Cannot allocate memory’   from kafka node wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 9:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 14, 2020, 9:00 AM {ALPHANUMERICPII}\n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Error message 'Cannot allocate memory’   from kafka node wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: No\n\nQuestion: Additional details about the issue\nAnswer: Sometime, we get error message in below servers\n\n{Ipaddresspii} wn0-mazcac.prd-ebu01.cc.az.rci.rogers.com wn0-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net\n{Ipaddresspii} wn1-mazcac.prd-ebu01.cc.az.rci.rogers.com wn1-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net\n{Ipaddresspii} wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com wn2-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net \nthis is azure hdinsight kafka\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nType of node affected? - Workernode;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Error message 'Cannot allocate memory’   from kafka node wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - No;\nAdditional details about the issue - Sometime, we get error message in below servers\n\n{Ipaddresspii} wn0-mazcac.prd-ebu01.cc.az.rci.rogers.com wn0-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net\n{Ipaddresspii} wn1-mazcac.prd-ebu01.cc.az.rci.rogers.com wn1-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net\n{Ipaddresspii} wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com wn2-mazcac.1xjcz50abdsuzief30kkhnkaxd.ux.internal.cloudapp.net \nthis is azure hdinsight kafka;\n\n- ProblemStartTime: 04/14/2020 03:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EBU PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/967935a1-3840-440e-bbfd-f1397d409dd0/resourceGroups/maz-cac-prd-apigw-rg/providers/Microsoft.HDInsight/clusters/mazcacprdapigwhdi01\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error message 'Cannot allocate memory’   from kafka node wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com,0.939652249,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,120041424004372 - Error message 'Cannot allocate memory' from kafka node wn2-mazcac.prd-ebu01.cc.az.rci.rogers.com,CancelledKeyExceptions in Zookeeper nodesCustom DNS not configured,Performed mitigation for CancelledKeyExceptions in Zookeeper:https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-fails#resolutionAdvised customer to update the custom DNS so the MuleSoft application could communicate with the Kafka cluster.  ,,,,,,,,
1.20041E+14,59:17.5,Cannot figure out how to access running applications api,"So this is not an issue with the HDInsight SDK, but there was no 'other' option. My issue is that I can't get access to the application monitoring api detailed here: https://spark.apache.org/docs/latest/monitoring.html#rest-api\n\nCan you help me with this?\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot figure out how to access running applications api,0.14012127,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\HDInsight SDK,Unable to list out or filter out the RUNNING jobs,Cannot figure out how to access running applications api,"Provided the below information and guidancecurl -vi -k -u ""USERNAME:PASSWORD"" -X GET -H 'Accept: application/json' https://CLUSTERNAME.azurehdinsight.net/yarnui/hn/ws/v1/cluster/apps?states=RUNNING and filters can be used are NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED",,,,,,,,
1.20041E+14,37:32.7,Error while create spark jupyter notebook,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Additional details about the issue\nAnswer: Error Message: \nTraceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 503, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 84, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 53, in get 'content': self.httpFSClient.read_file(hdfs_path) if content else None, File '/usr/bin/anaconda/lib/python2.7/site-packages/pywebhdfs/webhdfs.py', line 211, in read_file _raise_pywebhdfs_exception(response.status_code, response.content) File '/usr/bin/anaconda/lib/python2.7/site-packages/pywebhdfs/webhdfs.py', line 722, in _raise_pywebhdfs_exception raise errors.PyWebHdfsException(msg=message) PyWebHdfsException: {'RemoteException':{'message':null,'exception':'NullPointerException','javaClassName':'java.lang.NullPointerException'}}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Never worked;\nAdditional details about the issue - Error Message: \nTraceback (most recent call last): File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/base/handlers.py', line 503, in wrapper result = yield gen.maybe_future(method(self, *args, **kwargs)) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1021, in run yielded = self.gen.throw(*exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 216, in post yield self._new_untitled(path, type=type, ext=ext) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 1015, in run value = future.result() File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/concurrent.py', line 237, in result raise_exc_info(self._exc_info) File '/usr/bin/anaconda/lib/python2.7/site-packages/tornado/gen.py', line 285, in wrapper yielded = next(result) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/handlers.py', line 171, in _new_untitled model = yield gen.maybe_future(self.contents_manager.new_untitled(path=path, type=type, ext=ext)) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 338, in new_untitled return self.new(model, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 364, in new model = self.save(model, path) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 84, in save self.create_checkpoint(path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/manager.py', line 459, in create_checkpoint return self.checkpoints.create_checkpoint(self, path) File '/usr/bin/anaconda/lib/python2.7/site-packages/notebook/services/contents/checkpoints.py', line 79, in create_checkpoint model = contents_mgr.get(path, content=True) File '/var/lib/.jupyter/jupyterazure/jupyterazure/httpfscontentsmanager.py', line 53, in get 'content': self.httpFSClient.read_file(hdfs_path) if content else None, File '/usr/bin/anaconda/lib/python2.7/site-packages/pywebhdfs/webhdfs.py', line 211, in read_file _raise_pywebhdfs_exception(response.status_code, response.content) File '/usr/bin/anaconda/lib/python2.7/site-packages/pywebhdfs/webhdfs.py', line 722, in _raise_pywebhdfs_exception raise errors.PyWebHdfsException(msg=message) PyWebHdfsException: {'RemoteException':{'message':null,'exception':'NullPointerException','javaClassName':'java.lang.NullPointerException'}};\n\n- ProblemStartTime: 04/14/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a04d1510-3444-42bc-9ce1-41b3c9a9c558/resourceGroups/cat-operational-dl-rg-01/providers/Microsoft.HDInsight/clusters/cat-operational-dl-hdinsight-01\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error while create spark jupyter notebook,0.792109911,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Client tool issue\Notebooks,Error while create spark jupyter notebook.,NA,"Customer have deployed the new cluster and everything is working fine. As per customer confirmation, closing this ticket.",184203909,,,,,,,
1.20042E+14,37:26.7,Cannot use variables in hive commands,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: \\hive -e 'select ${hiveconf:dl_data_dt}' -hiveconf {alphanumericpii}\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: I know that in HDI 4.0, we need to add variable into whitelist before use it. I've already confiured that parameter and restart Hive service, but we still got error message that we cannot use that parameter. \nSee the detail in attached file, Hive_Whitelist_Error.png.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - \\hive -e 'select ${hiveconf:dl_data_dt}' -hiveconf {alphanumericpii};\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - I know that in HDI 4.0, we need to add variable into whitelist before use it. I've already confiured that parameter and restart Hive service, but we still got error message that we cannot use that parameter. \nSee the detail in attached file, Hive_Whitelist_Error.png.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/13/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/28a9cf5d-c706-4531-8650-55d69d7facfb/resourceGroups/RG-SEA-DIP-DEV-001/providers/Microsoft.HDInsight/clusters/hdi22dscbdipsea\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot use variables in hive commands,21.77466789,Root Cause : HDInsight Service\By Design\HDInsight SDK,Routing Azure HDInsight V5\Unexpected result\Hive,Cannot use variables in hive command.,"As the customer is using a ESP cluster the whitelisting variables were being  separated by the delimiter `,` in custom-hiverserver2-site.",In HDI4.0 ESP cluster need to whitelist the variables by using the delimiter `|` in the custom-hiveserver2-site like below.Property Key: hive.security.authorization.sqlstd.confwhitelist.appendProperty Value: environment|env|dl_data_dt,,,,,,,,
1.20042E+14,42:53.7,Auto-Scale Job Failure,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 13, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 14, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: We enabled load based Auto-scale feature on the cluster on 9th April, the initial static cluster was 20 worker nodes and we changed it to minimum 10 nodes to maximum 50 nodes.\nOn {Alphanumericpii} April, some jobs were killed by ResourceManager as it had exceeded its lifetime period.\nThese jobs usually takes 1.5 to 2 hours but they were killed after 3.5 hours of wait. \nThe cluster load was increased and a spike in auto-scale was observed from 10 workers to 11 workers. \nInternally we suspect that the auto-scale was unable to add required workers and the job failed due to lack of resources.\nFailed jobs:\n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n\n\nQuestion: Increase in load?\nAnswer: Number of jobs\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii} \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: spark.executor.cores = 4\nspark.executor.memory = {Alphanumericpii}\n\nQuestion: Additional details about the issue\nAnswer: Error Snippet:\n\n20/04/13 10:06:57 ERROR ApplicationMaster: Exception from Reporter thread.\norg.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException: Application attempt {alphanumericpii} doesn't exist in ApplicationMasterService cache.\nat {AlphanumericPII})\nat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\nat org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\nat \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - We enabled load based Auto-scale feature on the cluster on 9th April, the initial static cluster was 20 worker nodes and we changed it to minimum 10 nodes to maximum 50 nodes.\nOn {Alphanumericpii} April, some jobs were killed by ResourceManager as it had exceeded its lifetime period.\nThese jobs usually takes 1.5 to 2 hours but they were killed after 3.5 hours of wait. \nThe cluster load was increased and a spike in auto-scale was observed from 10 workers to 11 workers. \nInternally we suspect that the auto-scale was unable to add required workers and the job failed due to lack of resources.\nFailed jobs:\n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \n;\nIncrease in load? - Number of jobs;\nYARN Application ID for the Spark job if known - {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii},  {alphanumericpii} ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - spark.executor.cores = 4\nspark.executor.memory = {Alphanumericpii};\nAdditional details about the issue - Error Snippet:\n\n20/04/13 10:06:57 ERROR ApplicationMaster: Exception from Reporter thread.\norg.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException: Application attempt {alphanumericpii} doesn't exist in ApplicationMasterService cache.\nat {AlphanumericPII})\nat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\nat org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\nat ;\n\n- ProblemStartTime: 04/12/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Auto-Scale Job Failure,11.61531629,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Spark,Job Failure,Unknown// Data insufficient for RCA,N/A,185273915,,,,,,,
1.20042E+14,03:21.3,All nodes showing Heartbeat lost in AMbaari,"Question: What time did the problem begin?\nAnswer: Wed, Apr 15, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: All nodes are showing heartbeat lost in Ambari,\nWe are able to do ssh to the nodes,\nbut when we checked th ambari server status it is showing active with some error in status.\nkindly look into this ASAP.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - All nodes are showing heartbeat lost in Ambari,\nWe are able to do ssh to the nodes,\nbut when we checked th ambari server status it is showing active with some error in status.\nkindly look into this ASAP.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/14/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdasecure-cus-01-rg/providers/Microsoft.HDInsight/clusters/prdiwsecure\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",All nodes showing Heartbeat lost in AMbaari,0.140019886,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,All nodes showing Heartbeat lost in AMbaari,All nodes showing Heartbeat lost in AMbaari,Customer was requested to Disable/Enable OMS on the cluster to receive fix for the OMS. Customer confirmed to close the case,,,,,,,,
1.20042E+14,23:21.1,Error while performing schema merge of 2 JSON/Parquet files,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: N/A\n\nQuestion: Hive query explain plan if available\nAnswer: N/A\n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: In our Production environment, while merging 2 different JSON data files using Schemamerge, it fails with the following error message: Failed to merge fields '{AlphanumericPII}' and '{AlphanumericPII}'. Failed to merge fields 'sources' and 'sources'. Failed to merge incompatible data types StringType and ArrayType(StringType,true). Please see the attached error log and same data files.\n\nFor your reference, our HDInsight clusters are deployed at 1:00AM and deleted at 12PM EST daily.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - N/A;\nHive query explain plan if available - N/A;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - In our Production environment, while merging 2 different JSON data files using Schemamerge, it fails with the following error message: Failed to merge fields '{AlphanumericPII}' and '{AlphanumericPII}'. Failed to merge fields 'sources' and 'sources'. Failed to merge incompatible data types StringType and ArrayType(StringType,true). Please see the attached error log and same data files.\n\nFor your reference, our HDInsight clusters are deployed at 1:00AM and deleted at 12PM EST daily.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2-Prod/providers/Microsoft.HDInsight/clusters/sigi02prodspark\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error while performing schema merge of 2 JSON/Parquet files,0.080543066,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Hive,"120041524003479 - Error while performing schema merge of 2 JSON/Parquet files HDInsight Service. Error:Failed to merge incompatible data types StringType and ArrayType(StringType,true)",Customer is having Spark to infer the schema instead of explicitly setting it,Run a script to cleanse the parquet files before trying to merge them or explicitly set the schema,,,,,,,,
1.20042E+14,32:15.9,Removing executor 15 because it has been idle for 60 seconds,"Question: What time did the problem begin?\nAnswer: Wed, Apr 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: More data to be processed\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: spark-submit  --driver-class-path {alphanumericpii} --jars mongo-spark-connector-assembly-2.4.1-SNAPSHOT0212.jar --num-executors 25 --executor-cores 4 --executor-memory 4g --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.enabled=true --conf {AlphanumericPII} --class com.albertsons.catalog.processor.ShopSiteDataProcessor --master yarn {AlphanumericPII} 100\n\nQuestion: Additional details about the issue\nAnswer: Every time, after 5-6 mins of job kicked off, the executors reduced from 45 to 2. This is load testing, so we have 8+ million of records processing and update. With 2 executors, spark job did not have efficient resource to save to database. The RU consumed for each partition is only 400 RU, while it should 15k per partition.\n\nThis is happening to the existing job, which used to work on 4/6, but it is not working now. \n\nIt is a potential blocker for tonight’s catalog production deploymnent.\n\nThe HDInsight {Namepii} has enough resources.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - More data to be processed;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - spark-submit  --driver-class-path {alphanumericpii} --jars mongo-spark-connector-assembly-2.4.1-SNAPSHOT0212.jar --num-executors 25 --executor-cores 4 --executor-memory 4g --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.enabled=true --conf {AlphanumericPII} --class com.albertsons.catalog.processor.ShopSiteDataProcessor --master yarn {AlphanumericPII} 100;\nAdditional details about the issue - Every time, after 5-6 mins of job kicked off, the executors reduced from 45 to 2. This is load testing, so we have 8+ million of records processing and update. With 2 executors, spark job did not have efficient resource to save to database. The RU consumed for each partition is only 400 RU, while it should 15k per partition.\n\nThis is happening to the existing job, which used to work on 4/6, but it is not working now. \n\nIt is a potential blocker for tonight’s catalog production deploymnent.\n\nThe HDInsight {Namepii} has enough resources.\n;\n\n- ProblemStartTime: 04/15/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Removing executor 15 because it has been idle for 60 seconds,0.333010487,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,"Every time, after 5-6 mins of job kicked off, the executors reduced from 45 to 2. ",Cause:  Issues with Dynamic Allocation.,Resolution:  We met and discussed the settings and where and how to set them.,184209530,,,,,,,
1.20042E+14,32:25.6,Saprk clusters: Admin acl issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii} Notebook\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Saprk clusters: Admin acl issue\n\nQuestion: Additional details about the issue\nAnswer: Saprk clusters: Admin acl issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii} Notebook;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Saprk clusters: Admin acl issue;\nAdditional details about the issue - Saprk clusters: Admin acl issue;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps020sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Saprk clusters: Admin acl issue,0.026670726,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,All users unable to see application logs,Saprk clusters: Admin acl issue,"Recommended to update below configurations,Under YARN service,yarn.acl.enable=trueyarn.admin.acl=* or specific users/groupsUnder MR2 service,mapreduce.cluster.acls.enabled=truemapreduce.job.acl-view-job=* or specific users/groups The wildcard character (*), meaning all users and groups have access and privileges and can set to specific users/groups",,,,,,,,
1.20042E+14,55:32.6,Zeppelin is not working to access hive tables,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 14, 2020, 11:00 PM MST\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is not working in {ALPHANUMERICPII} to access hive tables via JDBC connection. BBANDI user has cluster administrator role, still not able to add interpretors as we desired.\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Never worked;\nAdditional details about the issue - {Namepii} is not working in {ALPHANUMERICPII} to access hive tables via JDBC connection. BBANDI user has cluster administrator role, still not able to add interpretors as we desired.\n\n;\n\n- ProblemStartTime: 04/15/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zeppelin is not working to access hive tables,0.03170575,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Client tool issue\Notebooks,Unable to access/use hive tables Zeppelin UI ,Zeppelin is not working to access hive tables,"In Ambari Zeppelin configs, under shiro_ini_content (applicable for secure clusters):  Replace ""/api/interpreter/** = authc, roles[admin]"" with ""/api/interpreter/** = authc""  and also updated the JDBC ( hive url) settings",,,,,,,,
1.20042E+14,57:56.3,Getting error while accessing Gen2 account from HDI4.0,"Getting error while listing the files in {Alphanumericpii} account from {ALPHANUMERICPII}\n\n{alphanumericpii}:~$ hadoop fs -ls /\nls: Operation failed: 'This request is not authorized to perform this operation using this permission.', 403, GET, https://ngaadlsgen2prod.dfs.core.windows.net/sprk01-prod-eastus2?upn=true&resource=filesystem&maxResults=500&timeout=90&recursive=false, AuthorizationPermissionMismatch, 'This request is not authorized to perform this operation using this permission. {AlphanumericPII} {AlphanumericPII}'\n\n\nProblem start date and time\n{Namepii}, Apr 14, 2020, 11:00 PM MST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/15/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting error while accessing Gen2 account from HDI4.0,0.021118778,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\HDInsight SDK,Getting error while accessing Gen2 account from HDI4.0,Getting error while accessing Gen2 account from HDI4.0,"Shared details with customer on how ADL Gen2 folders can be browsed and for other issue related to 403 on /hdp2/spark-events, suggested customer to grant 777 permissions on the path. Customer confirmed to close the case.",,,,,,,,
1.20042E+14,21:45.7,slowness in processing jobs in HDInsights cluster to storage,"Question: {Namepii} would you want us to help you?\nAnswer: Troubleshoot a performance issue\n\nQuestion: Is it currently ongoing or happened in past and resolved?\nAnswer: Reporting an ongoing performance issue\n\nQuestion: Approximate local start time of the most recent occurrence\nAnswer: \n\nQuestion: Storage server Request ID\nAnswer: \n\nQuestion: Error code\nAnswer: None of the above\n\nQuestion: Blob Container\nAnswer: \n\nQuestion: Blob path\nAnswer: \n\nQuestion: Provide details of your advisory ask. For troubleshooting issues provide additional details like error message or exception stack\nAnswer: While running our prod aplication, writing/reading data from storage very slowely for beloe 2 storage account on PROD region.\nPlease take a look asap\n\n1. gmcloudregproddata\n2. gmcloudregprodcatdata\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Blob Storage:\n{Namepii} would you want us to help you? - Troubleshoot a performance issue;\nIs it currently ongoing or happened in past and resolved? - Reporting an ongoing performance issue;\nApproximate local start time of the most recent occurrence - ;\nStorage server Request ID - ;\nError code - None of the above;\nBlob Container - ;\nBlob path - ;\nProvide details of your advisory ask. For troubleshooting issues provide additional details like error message or exception stack - While running our prod aplication, writing/reading data from storage very slowely for beloe 2 storage account on PROD region.\nPlease take a look asap\n\n1. gmcloudregproddata\n2. gmcloudregprodcatdata\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-workload-{namepii}/providers/Microsoft.Storage/storageAccounts/gmcloudregproddata\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",slowness in processing jobs in HDInsights cluster to storage,36.76324365,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure Storage Blob\Performance and Throughput\Low throughput,slowness in processing jobs in HDInsights cluster to storage,slowness in processing jobs in HDInsights cluster to storage,Queries were taken longer one day and unable to repro it in the other clusters. ,184279354,,,,,,,
1.20042E+14,54:35.0,Heartbeat missing on worker node ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Heartbeat missing on the only active worker node. Cannot even ssh to it. Due to this reason, we aren't able to scale the cluster either.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Heartbeat missing on the only active worker node. Cannot even ssh to it. Due to this reason, we aren't able to scale the cluster either.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-rg-compute1/providers/Microsoft.HDInsight/clusters/edsp4rd-workbench-compute-cluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Heartbeat missing on worker node ,5.362766124,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Heartbeat missing on worker node,Observed dead wn0 and other woker nodes ,deployed a new cluster,"184,288,056,184,308,000",,,,,,,
1.20042E+14,12:34.9,Don't have access to yarn API,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hello,\nI need to have access to the YARN API\nWhen I try to access it : https://spark-dart.hdi.dart.dev.euw.gbis.sg-azure.com/ws/v1/cluster/scheduler\n\nwith the user {emailpii}@sgazureprd.onmicrosoft.com\n\nI have this error :\n\n{'Code':'Forbidden','Message':'User {emailpii}@sgazureprd.onmicrosoft.com is unauthorized to access the admin endpoint /{AlphanumericPII}'}\n\nCan you tell me what is wrong and how to fix it ?\nWe need this access in order to dynamically tune our process resources\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - Other, don't know or not applicable;\nDoes the user have proper permission on the target location recursively? - Other, don't know or not applicable;\nAdditional details about the issue - Hello,\nI need to have access to the YARN API\nWhen I try to access it : https://spark-dart.hdi.dart.dev.euw.gbis.sg-azure.com/ws/v1/cluster/scheduler\n\nwith the user {emailpii}@sgazureprd.onmicrosoft.com\n\nI have this error :\n\n{'Code':'Forbidden','Message':'User {emailpii}@sgazureprd.onmicrosoft.com is unauthorized to access the admin endpoint /{AlphanumericPII}'}\n\nCan you tell me what is wrong and how to fix it ?\nWe need this access in order to dynamically tune our process resources;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/44f9a17e-e4f6-490f-9e4b-bcbdf9817a88/resourceGroups/frm-rpc-dart-1-DEV-spark-dart-Automation-HDI/providers/Microsoft.HDInsight/clusters/cFSlyzkXH8-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Don't have access to yarn API,3.97959557,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Auditing,issues with api from custom gateway,ws/v1/cluster/scheduler has to be prefixed by yarnui : yarnui/ws/v1/cluster/scheduler,ws/v1/cluster/scheduler has to be prefixed by yarnui : yarnui/ws/v1/cluster/scheduler,,,,,,,,
1.20042E+14,02:58.2,YARN is not working as expected,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi, \n\nWe're migrating to HDI LLAP 4.0. IN previous version we use to have YARN to display the application details and it allow us to kill{uncpii} logs. \n\nBut in 4.0, we're unable to view the running sessions and kill session.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi, \n\nWe're migrating to HDI LLAP 4.0. IN previous version we use to have YARN to display the application details and it allow us to kill{uncpii} logs. \n\nBut in 4.0, we're unable to view the running sessions and kill session.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",YARN is not working as expected,0.269453617,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Spark,YARN isn't showing the applications in the UI. No information available.,Two configurations must be added to the custom mapred-site in Ambari MapReduce2 configs.,"From a web browser, navigate to https://CLUSTERNAME.azurehdinsight.net, where CLUSTERNAME is the name of your cluster.From the Ambari UI, navigate to MapReduce2 > Configs > Advanced > Custom mapred-site.Modify the followed properties:mapred.acls.enabled=truemapreduce.job.acl-view-job=*",,,,,,,,
1.20042E+14,01:14.2,HDISamples custom script for password update failing,The ADLS certificate expired so we updated that last night using the script MS sent us to use. Everything is now working as far as we can tell with the cluster writing to adls. When we try and use the custom actions script to change the password it fails. Please see attached log files. We followed the same steps in our Dev environment to renew the cert and the custom script works there. We are unable to sync passwords across the 2 nodes. If we need to failover we won't be able to.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Integration Classic\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/eb328f52-25cd-4bce-8bb6-f771541ab3d5/resourceGroups/chc-dp-dp-sparkly-integ-rg/providers/Microsoft.HDInsight/clusters/f-fbnq-chc-dp-dp-sparkly\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,HDISamples custom script for password update failing,0.889396227,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Custom script for password update failing,< % ~ / were part of password. These do not work with the password.  ,Removed < % ~ / & custom script action succeeded for password change,184796562,,,,,,,
1.20042E+14,56:18.0,Beeline client is not working after scaleup,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: ODBC/JDBC\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: {alphanumericpii}\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - ODBC/JDBC;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - {alphanumericpii};\nAdditional details about the issue - {alphanumericpii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps020sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Beeline client is not working after scaleup,33.11441003,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,Beeline client is not working after scaleup,Issue with ZooKepper,Redeploy the VM ZK6 resolved the issue.,185458578,,,,,,,
1.20042E+14,57:00.8,command yarn application -list taking an hour,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Password, access key, or certificate rotation\n\nQuestion: Detail of the changes\nAnswer: Our adls certificate expired from the sparkly cluster to adls but since the processes were still running it was stilling processing and running. Tuesday we noticed it would take 2 to 3 minutes to run the yarn application -list command on the cluster -  typically it takes 10 seconds. Last night 9 - 10pm ish central time we ran the script to Refresh the HDInsight certificate for Data {Namepii} Storage {Alphanumericpii} access. When we went to run the yarn application -list command it took 1 hour for the output to come back - see screenshot attached.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: \nexport environment=INTEGRATION\nexport lake='adl://4fo4eo5werxbs.azuredatalakestore.net'\nexport sparklyroot=$lake/opt/rhi/sparklymessagetracking\nexport sparklylib=$sparklyroot/releases/latest_carnegie\n#export sparklyconf=$sparklyroot/releases/latest/conf/$environment\nexport sparklyconf=$sparklyroot\n\n\nEventProcessorText=`hdfs dfs -tail $sparklyconf/EventProcessor.config`\necho '$EventProcessorText'\n\nx=$(./checkADLS.py $sparklyroot/offsets/event mt-event-dp 24)\n\nwhile read -r line; do\n    echo '$line'\ndone REMOVED 3 LESS THAN SIGNS  '$x' \n\nwhile read -r line; do\n    if [[ $line == ERROR* ]] ;\nthen\n    echo 'Error occurred - stopping script'\nexit -1\nfi\ndone '$x' REMOVED 3 LESS THAN SIGNS\n\nspark-submit \\\n--verbose \\\n--driver-memory 4g \\\n--executor-memory 4g \\\n--num-executors 4 \\\n--executor-cores 6 \\\n--class consumer.EventProcessing.EventProcessor \\\n--conf {AlphanumericPII} \\\n--master yarn \\\n--deploy-mode cluster \\\n--conf spark.streaming.backpressure.enabled=true \\\n--conf {AlphanumericPII} \\\n--conf spark.dynamicAllocation.enabled=false \\\n--conf {alphanumericpii} \\\n--conf {AlphanumericPII} \\\n--conf {AlphanumericPII} \\\n--files ${AlphanumericPII} \\\n    $sparklylib/SparklyMessageTracking.jar EventProcessor.config ElasticSearch.config $lake 60\n\nQuestion: Additional details about the issue\nAnswer: We followed the same steps in our development envinroment and it is working.\n\nWe are running these same steps in production tonight.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Password, access key, or certificate rotation;\nDetail of the changes - Our adls certificate expired from the sparkly cluster to adls but since the processes were still running it was stilling processing and running. Tuesday we noticed it would take 2 to 3 minutes to run the yarn application -list command on the cluster -  typically it takes 10 seconds. Last night 9 - 10pm ish central time we ran the script to Refresh the HDInsight certificate for Data {Namepii} Storage {Alphanumericpii} access. When we went to run the yarn application -list command it took 1 hour for the output to come back - see screenshot attached.;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Python;\nSpark configuration details - \nexport environment=INTEGRATION\nexport lake='adl://4fo4eo5werxbs.azuredatalakestore.net'\nexport sparklyroot=$lake/opt/rhi/sparklymessagetracking\nexport sparklylib=$sparklyroot/releases/latest_carnegie\n#export sparklyconf=$sparklyroot/releases/latest/conf/$environment\nexport sparklyconf=$sparklyroot\n\n\nEventProcessorText=`hdfs dfs -tail $sparklyconf/EventProcessor.config`\necho '$EventProcessorText'\n\nx=$(./checkADLS.py $sparklyroot/offsets/event mt-event-dp 24)\n\nwhile read -r line; do\n    echo '$line'\ndone REMOVED 3 LESS THAN SIGNS  '$x' \n\nwhile read -r line; do\n    if [[ $line == ERROR* ]] ;\nthen\n    echo 'Error occurred - stopping script'\nexit -1\nfi\ndone '$x' REMOVED 3 LESS THAN SIGNS\n\nspark-submit \\\n--verbose \\\n--driver-memory 4g \\\n--executor-memory 4g \\\n--num-executors 4 \\\n--executor-cores 6 \\\n--class consumer.EventProcessing.EventProcessor \\\n--conf {AlphanumericPII} \\\n--master yarn \\\n--deploy-mode cluster \\\n--conf spark.streaming.backpressure.enabled=true \\\n--conf {AlphanumericPII} \\\n--conf spark.dynamicAllocation.enabled=false \\\n--conf {alphanumericpii} \\\n--conf {AlphanumericPII} \\\n--conf {AlphanumericPII} \\\n--files ${AlphanumericPII} \\\n    $sparklylib/SparklyMessageTracking.jar EventProcessor.config ElasticSearch.config $lake 60;\nAdditional details about the issue - We followed the same steps in our development envinroment and it is working.\n\nWe are running these same steps in production tonight.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Integration Classic\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/eb328f52-25cd-4bce-8bb6-f771541ab3d5/resourceGroups/chc-dp-dp-sparkly-integ-rg/providers/Microsoft.HDInsight/clusters/f-fbnq-chc-dp-dp-sparkly\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",command yarn application -list taking an hour,0.038671507,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,command yarn application -list taking an hour,hno wasn't worked out,needs to be restart hn0.  CX will restart hno after the completion of their project plan.Also CX will upgrade spark cluster to 2.3/2.4  and HDInsight vertions to 4.0/3.6 from current version 3.5 as recommended,,,,,,,,
1.20042E+14,24:22.0,Ambari metrics not working,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ambari {Namepii} stopped\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ambari {Namepii} stopped;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9154d5ed-a402-450a-963e-4eec0cf72259/resourceGroups/ResourceGroup-HDIEUR01/providers/Microsoft.HDInsight/clusters/lh000-eur01\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari metrics not working,0.229339718,Root Cause : HDInsight Service\Configuration\HDInsight SDK,Routing Azure HDInsight V5\Metrics are missing\Hadoop,Ambari metrics not working,/usr/sbin/ambari-metrics-monitor: No such file or directory,Customer needs to either recreate the cluster or the possible solution is to manually install ambari metrics.,,,,,,,,
1.20042E+14,39:24.2,Unable to conect to Ambari. ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: Impossible to connect to Amabari.\nThe password or user were not changed.\nnetworking or any other changes.\nWe have some alerts about IP limitations with the subscription. \n\nQuestion: Additional details about the issue\nAnswer: Not able to connect to Amabari dashboard. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - Impossible to connect to Amabari.\nThe password or user were not changed.\nnetworking or any other changes.\nWe have some alerts about IP limitations with the subscription. ;\nAdditional details about the issue - Not able to connect to Amabari dashboard. ;\n\n- ProblemStartTime: 04/15/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Enterprise Dev-Test Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9056e9d8-2664-4c1d-983c-7ebb7c3dcdcb/resourceGroups/GRP-WEU-DEV-RGP-KFKA/providers/Microsoft.HDInsight/clusters/grpweudevkfka\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to conect to Ambari. ,0.013758808,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,120041622002775 - Unable to connect to Ambari.,unknown,Restarted both gateway nodes and customer released IP addresses.  ,,,,,,,,
1.20042E+14,51:19.2,Ambari Metric collector service issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Ambari Metric collector service issues\n\nQuestion: Interactive query explain plan if available\nAnswer: Ambari Metric collector service issues\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Ambari Metric collector service issues\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Ambari Metric collector service issues;\nInteractive query explain plan if available - Ambari Metric collector service issues;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Ambari Metric collector service issues;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Metric collector service issues,0.008862962,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Unable to start Ambari Metrics Collector service,Ambari Metric collector service issues,"There is a problem with the Ambari Metrics Collector configured for your HDInsight cluster kpps84llapprdsupwus201.Recommended StepsLogin into the Ambari portalSet AMS to maintenanceStop AMS from AmbariIdentify the following from the AMS Configs screen:hbase.rootdir (Default value is file:///mnt/data/ambari-metrics-collector/hbase)hbase.tmp.dir(Default value is /var/lib/ambari-metrics-collector/hbase-tmp)SSH into headnode0. as superuserRemove the AMS zookeeper data by backing up and removing the contents of 'hbase.tmp.dir'/zookeeperRemove any Phoenix spool files from 'hbase.tmp.dir'/phoenix-spool folderNote: It is worthwhile to skip this step and first restarting AMS to see if the issue is resolved. If AMS is still failing to come up, try this step: AMS data would be stored in hbase.rootdir identified above. Use regular OS commands to backup and remove the files: # tar czf /mnt/backupof-ambari-metrics-collector-hbase-$(date +%Y%m%d-%H%M%S).tar.gz /mnt/data/ambari-metrics-collector/hbaseRestart AMS using AmbariRecommended DocumentsCleaning up Ambari Metrics System Data",,,,,,,,
1.20042E+14,00:41.3,Unable to created a HDI cluster with Name: anahdist01hdoop36redsdv01,"Question: What time did the problem begin?\nAnswer: Wed, Apr 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Remove the cluster {alphanumericpii} from azure DNS. Though cluster deleted from our zurich side, cluster name is still residing in the azure DNS. \n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: PFA\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Remove the cluster {alphanumericpii} from azure DNS. Though cluster deleted from our zurich side, cluster name is still residing in the azure DNS. ;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - PFA;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to created a HDI cluster with Name: anahdist01hdoop36redsdv01,28.05425593,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to create a cluster with same name as deleted one.,Cluster CRUD delete workflow did not successfully clean up DNS," basically, CNames were leaked when exception was thrown during removing application workflow so that not all CNames are deleted. fixed has been done and will be deployed in the next release.RCA ICM:  https://icm.ad.msft.net/imp/v3/incidents/details/151805514/home",184348334,,,,,,,
1.20042E+14,20:05.6,Data Analytics Studio (DAS) Configuration Issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi,\n\nWe followed the steps provided by microsoft and DAS is not enabled. Kindly help me to fix it.\n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-migrate-workloads#query-execution-across-hdinsight-versions\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi,\n\nWe followed the steps provided by microsoft and DAS is not enabled. Kindly help me to fix it.\n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-migrate-workloads#query-execution-across-hdinsight-versions;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llaphdi4enterprisedev\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Data Analytics Studio (DAS) Configuration Issue,7.176671108,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Data Analytics Studio (DAS) Configuration Issue ,The installation script itself also has some built in repair logic to retry steps that previously did not run.,"I would like to request running the script again >> Try running ""Regenerate Keytabs"" in the DAS options. Use the LDAP credentials from this script: sudo python -c ""import hdinsight_common.ClusterManifestParser as ClusterManifestParser;cluster_manifest = ClusterManifestParser.parse_local_manifest();print cluster_manifest.settings['ldap_user'];print cluster_manifest.settings['ldap_password']; >> Make sure that 'hive' has 'repladmin' permissions via apache ranger Please note that we will be moving away from DAS in the near future so it may not be advisable  to take a production dependency on DAS. Please also note that DAS on ESP does not integrate with Apache Ranger. This means that queries run on DAS will be executed as the `hive` user. Viable alternatives at this time are HDI tools for VSCode (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-for-vscode) and Zeppelin for LLAP. To delete DAS, or any other service, the Ambari API can be used:https://cwiki.apache.org/confluence/display/AMBARI/Using+APIs+to+delete+a+service+or+all+host+components+on+a+host Note: I would not recommend deleting any services as we (HDI) do not support this scenario explicitly. In addition, even if the DAS installation has some issue, it will not affect other parts of the cluster. More info:When deleted DAS from cluster, afterwards it had to add `hive` to the `all` ranger policy under `yarn` (This likely was not related but I wanted to share just in case). ",184710805,,,,,,,
1.20042E+14,36:18.9,Issue:  We lost sshuser password. Could you please reset sshuser password for HDI Cluster's Head nodes.,"Question: What time did the problem begin?\nAnswer: Fri, Apr 17, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Issue:  We lost sshuser password. Could you please reset sshuser password for HDI {Namepii}'s Head nodes.\nHDI {Namepii} - hdi002dlqa001.azurehdinsight.net\nRG - {AlphanumericPII}.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nHave you ever successfully connected to Ambari? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Issue:  We lost sshuser password. Could you please reset sshuser password for HDI {Namepii}'s Head nodes.\nHDI {Namepii} - hdi002dlqa001.azurehdinsight.net\nRG - {AlphanumericPII}.;\n\n- ProblemStartTime: 04/16/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi003dlprod001\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Issue:  We lost sshuser password. Could you please reset sshuser password for HDI Cluster's Head nodes.,0.079098305,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,Issue:  We lost sshuser password. Could you please reset sshuser password for HDI Cluster's Head nodes.,NA,Customer is able to reset password by following below documenthttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-the-ssh-user-password,,,,,,,,
1.20042E+14,47:36.3,Cannot access associated storage container,"Question: What time did the problem begin?\nAnswer: Wed, Apr 15, 2020, 12:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: When I try to run the following command: hdfs dfs -mkdir wasbs://privacyexphdifs@privacyexpsa.blob.core.windows.net/data/testdir/        I get the following error message        No credentials found for account privacyexpsa.blob.core.windows.net in the configuration, and its container privacyexphdifs is not accessible using anonymous credentials. Please check if the container exists first. If it is not publicly available, you have to provide account credentials\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - When I try to run the following command: hdfs dfs -mkdir wasbs://privacyexphdifs@privacyexpsa.blob.core.windows.net/data/testdir/        I get the following error message        No credentials found for account privacyexpsa.blob.core.windows.net in the configuration, and its container privacyexphdifs is not accessible using anonymous credentials. Please check if the container exists first. If it is not publicly available, you have to provide account credentials;\n\n- ProblemStartTime: 04/15/2020 19:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Privacy Management dev test 001\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bb6772c7-6a30-4153-8533-0dc9c4e7de9b/resourceGroups/PrivacyExperiment/providers/Microsoft.HDInsight/clusters/privacyexphdi\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot access associated storage container,0.166802188,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in standard cluster",Cannot access associated storage container,Customer is trying to access ADLSGEN2 storage account using below file path and was hitting exception with anonymous credentials.hdfs dfs -mkdir wasbs://privacyexphdifs@privacyexpsa.blob.core.windows.net/data/testdir/,As per the below document to access storage account in ADLSGEN1/GEN2 the below file path need to be used.hdfs dfs -mkdir abfs://<containername>@<accountname>.dfs.core.windows.net/<file.path>/ ,,,,,,,,
1.20042E+14,02:16.1,Script action failed,"Getting error ValidationFaild when running script action in azure data lake.\n\nhttps://portal.azure.com/#@daadevops.onmicrosoft.com/resource/subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourceGroups/helx-dev-common-hdi-westus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-westus-hdis/scriptactions\n\nProblem start date and time\nFri, Apr 17, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/17/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourceGroups/helx-dev-common-hdi-westus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-westus-hdis\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Script action failed,0.0548605,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Script action failed,Script action failed,"Informed customer that public access is required for script action and to meet security concerns, shared alternate ways for customer to run script action",,,,,,,,
1.20042E+14,29:52.5,Question about JMX RMI on Kafka Cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 16, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: ELC Security has scanned this environment, and we are getting some unexpected results from the HDI nodes.\n\n{AlphanumericPII} registered hostname\n38711\n\n{Namepii} JMX RMI Accessible with Common Credentials (Unauthenticated check)'{Namepii} JMX interface is accessible via following username/password pairs:\nadmin/password \nadmin/admin \nadmin/activemq \nmonitorRole/QED \n{AlphanumericPII}\ncontrolrole/password \nmonitorrole/password \ncassandra/cassandrapassword \nmonitorRole/tomcat \ncontrolRole/tomcat \nmonitorRole/mrpasswd \ncontrolRole/crpasswd \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \nadmin/thisIsSupposedToBeAStrongPassword! \nQID Detection Logic (Authenticated):  \nThis QID tries to log into JMX RMI server using above credentials.\n\nNote:if remote JMX RMI sever accessible without authentication. all of above credentials will post.'Successful exploitation allows attacker to execute arbitrary {Namepii} code.Change the common {alphanumericpii}\n\nI am opening this support request to understand the JMX RMI interface, and how to change the common password, and whether or not this will have an impact.\n\nThis related to 10M Ticket {ALPHANUMERICPII}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - ELC Security has scanned this environment, and we are getting some unexpected results from the HDI nodes.\n\n{AlphanumericPII} registered hostname\n38711\n\n{Namepii} JMX RMI Accessible with Common Credentials (Unauthenticated check)'{Namepii} JMX interface is accessible via following username/password pairs:\nadmin/password \nadmin/admin \nadmin/activemq \nmonitorRole/QED \n{AlphanumericPII}\ncontrolrole/password \nmonitorrole/password \ncassandra/cassandrapassword \nmonitorRole/tomcat \ncontrolRole/tomcat \nmonitorRole/mrpasswd \ncontrolRole/crpasswd \n{alphanumericpii} \n{alphanumericpii} \n{alphanumericpii} \nadmin/thisIsSupposedToBeAStrongPassword! \nQID Detection Logic (Authenticated):  \nThis QID tries to log into JMX RMI server using above credentials.\n\nNote:if remote JMX RMI sever accessible without authentication. all of above credentials will post.'Successful exploitation allows attacker to execute arbitrary {Namepii} code.Change the common {alphanumericpii}\n\nI am opening this support request to understand the JMX RMI interface, and how to change the common password, and whether or not this will have an impact.\n\nThis related to 10M Ticket {ALPHANUMERICPII};\n\n- ProblemStartTime: 04/16/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ELC-AM-PROD-PAAS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f57996ce-6cfe-400a-a311-f797fd8484d8/resourceGroups/RG-AM-EastUS-Prod-CDPNA/providers/Microsoft.HDInsight/clusters/hdikezprod-am-eastus-cdpna\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Question about JMX RMI on Kafka Cluster,2.903652029,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Kafka,Guidance,Guidance,"Since the scanner has direct access to the cluster's VM's (bypassing the gateway), the JMX port would be accessible and would not be configured to require authentication. ",,,,,,,,
1.20042E+14,13:54.4,Hive instability on Interactive Hive cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 16, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Some parameters added:\n{alphanumericpii}\n{alphanumericpii}\n\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: A warning occurs on Hive during about 8 minutes before to disappear.\nDuring this period, the connection to Hive is interrupted and make fail the jobs which are currenrly deploying .\nI am using a interactive Hive {Namepii} linked with a Spark {Namepii}.\nThis warning appears several time a day. About one or two times each two hours.\nIt is not the first time I noticed this problem, I had this trouble on {AlphanumericPII} and also when I used a single Spark {Namepii}.\nWhat can be the root issue of the port connection interruption (port 10001) ?\nThanks for support\n\nThe warning is described as below :\n\nConnection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HIVE/package/alerts/alert_hive_interactive_thrift_port.py', line 210, in execute\n    ldap_password=ldap_password)\n  File '/usr/lib/ambari-agent/lib/resource_management/libraries/functions/hive_check.py', line 84, in check_thrift_port_sasl\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE,\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 160, in run\n    self.run_action(resource, action)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 124, in run_action\n    provider_action()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py', line 263, in action_run\n    returns=self.resource.returns)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 72, in inner\n    result = function(command, **kwargs)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 102, in checked_call\n    tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy, returns=returns)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 150, in _call_wrapper\n    result = _call(command, **kwargs_copy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 308, in _call\n    raise ExecuteTimeoutException(err_msg)\nExecuteTimeoutException: Execution of 'ambari-sudo.sh su ambari-qa -l -s /bin/bash -c 'export  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/bin/:/usr/bin/:/usr/lib/hive/bin/:/usr/sbin/ ; beeline -n hive -u '''''jdbc:hive2://hn0-dsjd4l.azure.mvtdevdesjardins.com:10001/;transportMode=http;httpPath=cliservice;principal=hive/_HOST@AZURE.MVTDEVDESJARDINS.COM'''''  -e ''''';''''' 2&1 | awk '''''{print}''''' | grep -i -e '''''Connected to:''''' -e '''''Transaction isolation:''''''' was killed due timeout after 60 seconds\n)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Some parameters added:\n{alphanumericpii}\n{alphanumericpii}\n;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - A warning occurs on Hive during about 8 minutes before to disappear.\nDuring this period, the connection to Hive is interrupted and make fail the jobs which are currenrly deploying .\nI am using a interactive Hive {Namepii} linked with a Spark {Namepii}.\nThis warning appears several time a day. About one or two times each two hours.\nIt is not the first time I noticed this problem, I had this trouble on {AlphanumericPII} and also when I used a single Spark {Namepii}.\nWhat can be the root issue of the port connection interruption (port 10001) ?\nThanks for support\n\nThe warning is described as below :\n\nConnection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HIVE/package/alerts/alert_hive_interactive_thrift_port.py', line 210, in execute\n    ldap_password=ldap_password)\n  File '/usr/lib/ambari-agent/lib/resource_management/libraries/functions/hive_check.py', line 84, in check_thrift_port_sasl\n    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE,\n  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__\n    self.env.run()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 160, in run\n    self.run_action(resource, action)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 124, in run_action\n    provider_action()\n  File '/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py', line 263, in action_run\n    returns=self.resource.returns)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 72, in inner\n    result = function(command, **kwargs)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 102, in checked_call\n    tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy, returns=returns)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 150, in _call_wrapper\n    result = _call(command, **kwargs_copy)\n  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 308, in _call\n    raise ExecuteTimeoutException(err_msg)\nExecuteTimeoutException: Execution of 'ambari-sudo.sh su ambari-qa -l -s /bin/bash -c 'export  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/bin/:/usr/bin/:/usr/lib/hive/bin/:/usr/sbin/ ; beeline -n hive -u '''''jdbc:hive2://hn0-dsjd4l.azure.mvtdevdesjardins.com:10001/;transportMode=http;httpPath=cliservice;principal=hive/_HOST@AZURE.MVTDEVDESJARDINS.COM'''''  -e ''''';''''' 2&1 | awk '''''{print}''''' | grep -i -e '''''Connected to:''''' -e '''''Transaction isolation:''''''' was killed due timeout after 60 seconds\n);\n\n- ProblemStartTime: 04/16/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4llapbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive instability on Interactive Hive cluster,0.070110955,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,"Original issue:Connection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):  File '/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HIVE/package/alerts/alert_hive_interactive_thrift_port.py', line 210, in execute    ldap_password=ldap_password)  File '/usr/lib/ambari-agent/lib/resource_management/libraries/functions/hive_check.py', line 84, in check_thrift_port_sasl    timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE,  File '/usr/lib/ambari-agent/lib/resource_management/core/base.py', line 166, in __init__    self.env.run()  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 160, in run    self.run_action(resource, action)  File '/usr/lib/ambari-agent/lib/resource_management/core/environment.py', line 124, in run_action    provider_action()  File '/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py', line 263, in action_run    returns=self.resource.returns)  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 72, in inner    result = function(command, **kwargs)  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 102, in checked_call    tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy, returns=returns)  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 150, in _call_wrapper    result = _call(command, **kwargs_copy)  File '/usr/lib/ambari-agent/lib/resource_management/core/shell.py', line 308, in _call    raise ExecuteTimeoutException(err_msg)ExecuteTimeoutException: Execution of 'ambari-sudo.sh su ambari-qa -l -s /bin/bash -c 'export  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/bin/:/usr/bin/:/usr/lib/hive/bin/:/usr/sbin/ ; beeline -n hive -u '''''jdbc:hive2://hn0-dsjd4l.azure.mvtdevdesjardins.com:10001/;transportMode=http;httpPath=cliservice;principal=hive/_HOST@AZURE.MVTDEVDESJARDINS.COM'''''  -e ''''';''''' 2&1 | awk '''''{print}''''' | grep -i -e '''''Connected to:''''' -e '''''Transaction isolation:''''''' was killed due timeout after 60 seconds);===========================================================","Original issue:hn1 was the head node active, hn0 was on stand by, after restart the HIVE service, tried to connect to hn0 but was already running on hn1======================================================================Second issue:hn0-dsjd4l.azure.mvtdevdesjardins.com   ResourceManager CPU Utilization (12h 30m).   ResourceManager RPC Latency (12h 30m). hn1-dsjd4l.azure.mvtdevdesjardins.com   ResourceManager RPC Latency (9d 6h 39m).","Original issue:Stop HIVE service, start it again from Ambari UI========================================================================Second issue:ResourceManager CPU Utilization is triggered if CPU utilization of the ResourceManager exceeds certain thresholds. Unusually caused by a very unusual job/query workload.Use the top command over the affected host to determine which processes are consuming excess CPU, and reset the offending process.ResourceManager RPC Latency is also a host-level alert triggered by the ResourceManager operations RPC latency exceed the configured critical threshold. Typically, an increase in the RPC processing time increase the RPC queue length, causing the average queue wait time to increase for ResourceManager operations. Review the job or application for potential bugs causing it to perform too many ResourceMAnager operations.",,,,,,,,
1.20042E+14,34:46.8,Brute Force attack,"Question: What time did the problem begin?\nAnswer: Fri, Apr 17, 2020, 12:00 AM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: General information\nDESCRIPTION  Network traffic analysis detected incoming Telnet communication to {Ipaddresspii}, associated with your resource {alphanumericpii} from {Ipaddresspii}.\nWhen the compromised resource is a load balancer or an application gateway, the suspected incoming traffic has been forwarded to one or more of the resources in the backend pool (of the load balancer or application gateway).\nSpecifically, sampled network data shows suspicious activity between 4/9/2020 9:28:19 AM UTC and 4/9/2020 9:33:07 AM UTC on port 23.\nThis activity is consistent with brute force attempts against Telnet servers.\nACTIVITY TIME  Thursday, April 9, 2020, 5:00:00 AM\nSEVERITY   Medium\nSTATE  Active\nATTACKED RESOURCE  {alphanumericpii}\nSUBSCRIPTION  Analytics-and-Data-Science-DevTest ({guidpii})\nDETECTED BY   Microsoft\nACTION TAKEN  Detected\nENVIRONMENT  Azure\nRESOURCE TYPE  Networking\nVICTIM IP  {Ipaddresspii}\nVICTIM PORT  23\nSERVICE NAME  Telnet\nCOMPROMISED HOST  {alphanumericpii}\nATTACKER IP  {Ipaddresspii}\nSTART TIME  4/9/2020 9:28:19 AM UTC\nEND TIME  4/9/2020 9:33:07 AM UTC\n\n{Namepii} and Threat Intelligence Information\nIP {Ipaddresspii}\n{Namepii} Information\nIP ADDRESS  {Ipaddresspii}\nCITY  {Namepii} Noi\nCOUNTRY CODE  VN\nCOUNTRY NAME  {Namepii} {Namepii}\nSTATE  {Namepii} Noi\nASN  18403\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - General information\nDESCRIPTION  Network traffic analysis detected incoming Telnet communication to {Ipaddresspii}, associated with your resource {alphanumericpii} from {Ipaddresspii}.\nWhen the compromised resource is a load balancer or an application gateway, the suspected incoming traffic has been forwarded to one or more of the resources in the backend pool (of the load balancer or application gateway).\nSpecifically, sampled network data shows suspicious activity between 4/9/2020 9:28:19 AM UTC and 4/9/2020 9:33:07 AM UTC on port 23.\nThis activity is consistent with brute force attempts against Telnet servers.\nACTIVITY TIME  Thursday, April 9, 2020, 5:00:00 AM\nSEVERITY   Medium\nSTATE  Active\nATTACKED RESOURCE  {alphanumericpii}\nSUBSCRIPTION  Analytics-and-Data-Science-DevTest ({guidpii})\nDETECTED BY   Microsoft\nACTION TAKEN  Detected\nENVIRONMENT  Azure\nRESOURCE TYPE  Networking\nVICTIM IP  {Ipaddresspii}\nVICTIM PORT  23\nSERVICE NAME  Telnet\nCOMPROMISED HOST  {alphanumericpii}\nATTACKER IP  {Ipaddresspii}\nSTART TIME  4/9/2020 9:28:19 AM UTC\nEND TIME  4/9/2020 9:33:07 AM UTC\n\n{Namepii} and Threat Intelligence Information\nIP {Ipaddresspii}\n{Namepii} Information\nIP ADDRESS  {Ipaddresspii}\nCITY  {Namepii} Noi\nCOUNTRY CODE  VN\nCOUNTRY NAME  {Namepii} {Namepii}\nSTATE  {Namepii} Noi\nASN  18403;\n\n- ProblemStartTime: 04/17/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Analytics-and-Data-Science-DevTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f9c0d3ae-5a6d-44f8-86db-e9e8a174998f/resourceGroups/rgHaddopD001/providers/Microsoft.HDInsight/clusters/dsDevTestHDCluster001\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Brute Force attack,15.86817395,Root Cause : HDInsight Service\Secure Gateway issues,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Brute Force Attack,Hackers trying to access the 104.214.63.215 via port 23,"Load Balancers, NSG, network interface, Vnet and don’t see any evident that affect or compromise  security at network level.what we ca try is check with AD team to see if they have any option about it, like smart lockout https://docs.microsoft.com/en-us/azure/active-directory/authentication/howto-password-smart-lockoutOr something like Azure security center: https://azure.microsoft.com/en-us/blog/how-azure-security-center-helps-reveal-a-cyberattack/",,,,,,,,
1.20042E+14,56:57.1,scale down two nodes in HDI Hbase cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Please scale down the nodes with out  downtime or with out restarting the services in the cluster.\n\nHDI HBase cluster: adbeidxhbasestagenew\nSubscription: {guidpii}\n\nNodes to be scaled down: \nwn11-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net\nwn12-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Please scale down the nodes with out  downtime or with out restarting the services in the cluster.\n\nHDI HBase cluster: adbeidxhbasestagenew\nSubscription: {guidpii}\n\nNodes to be scaled down: \nwn11-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net\nwn12-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",scale down two nodes in HDI Hbase cluster,11.03032265,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,scale down two nodes in HDI Hbase cluster,scale down two nodes in HDI Hbase cluster,"Since this is a new process defined exclusively for Adobe, support checked for basic requirements in place and engaged Product group on this. Product group had executed the customer ask and update customer. Customer had checked and confirmed on requested action completion and agreed to close the case.",184837363,,,,,,,
1.20042E+14,42:55.0,User not able to run the query for wms database,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select * from wms.ALFILE limit 10\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: org.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 43 more\nCaused by: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.fs.adl.HdiAdlFileSystem.getFileStatus(Unknown Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 47 more\n\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select * from wms.ALFILE limit 10;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - org.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\norg.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hive.service.cli.HiveSQLException: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: java.io.IOException: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 43 more\nCaused by: org.apache.hadoop.security.AccessControlException: GETFILESTATUS failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{Guidpii}] failed with error 0x83090aa2 (Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.). [{AlphanumericPII}] [{AlphanumericPII}]\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.fs.adl.HdiAdlFileSystem.getFileStatus(Unknown Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 47 more\n\n\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: QA Test 01 (S08)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/af77a77b-b079-4996-89d4-e314a74e94a2/resourceGroups/RS08UE2QInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs08ue2qiphdidm03\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",User not able to run the query for wms database,3.032326025,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,User was not able to query any tables in wms database,Cx was using storage for Dev instead of QADev storage is rs06QA storage is rs08,Fixed location of tables,,,,,,,,
1.20042E+14,40:14.3,We are facing an error for one of the production Hdinsight cluster for Hive queries.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer:  ERROR:\n\n java.util.concurrent.TimeoutException: deadline passed\n\n java.util.concurrent.TimeoutException: deadline passed\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer:  ERROR:\n\n java.util.concurrent.TimeoutException: deadline passed\n\n java.util.concurrent.TimeoutException: deadline passed\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n\n       \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable -  ERROR:\n\n java.util.concurrent.TimeoutException: deadline passed\n\n java.util.concurrent.TimeoutException: deadline passed\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue -  ERROR:\n\n java.util.concurrent.TimeoutException: deadline passed\n\n java.util.concurrent.TimeoutException: deadline passed\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n at {AlphanumericPII})\n\n       \n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: ABI GLOBAL PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2db7c27b-2f9f-4088-981b-2bd88c5c1905/resourceGroups/Global-EnterpriseDataHub-RG-GB-PROD/providers/Microsoft.HDInsight/clusters/f0d523-edhhdisupplychaingbprod-hdi-eu-prod\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are facing an error for one of the production Hdinsight cluster for Hive queries.,0.064163584,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,We are facing an error for one of the production Hdinsight cluster for Hive queries.,We are facing an error for one of the production Hdinsight cluster for Hive queries.,"Joined call with customer and observed that the issue is with query and no Cluster issue. Suggested customer to validate and use ""set hive.fetch.task.conversion=none"" hive property while running queries. Customer tested query with the property on beeline and query returned results in few seconds.Customer agreed to resolve the case.",184564371,,,,,,,
1.20042E+14,05:09.0,User is facing runtime error while loggin ambari,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: User is not able to login ambari in {alphanumericpii} ESP HDI cluster. Attached error. \nPlease check whether user ID 'jkunick' having issues syncing from AD to ADDS.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - User is not able to login ambari in {alphanumericpii} ESP HDI cluster. Attached error. \nPlease check whether user ID 'jkunick' having issues syncing from AD to ADDS.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05ue2piphdidm03\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",User is facing runtime error while loggin ambari,0.584328942,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,When user tried to sign in to ambari user was the sign in kept looping to have the user sign in again.,User sync from AAD to ADDS was not working as expected.  A MFA was also causing issues.,"AAD team released a patch to help with large numbers of syncning.  Also, there was a MFA in placed that would redirect the user to sign in again.",,,,,,,,
1.20042E+14,53:59.8,Need help adding application ID to Kafka zookeeper ACLs to allow it to create topics,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have HDI Kafka clusters with ESP. This means 'zookeeper.set.acl'='true' for Kafka and that only the 'kafka' user can create kafka topics. We want to allow a different application ID to create topics as well and we need help with how to set the zookeeper ACLs to allow that.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nAdditional details about the issue - We have HDI Kafka clusters with ESP. This means 'zookeeper.set.acl'='true' for Kafka and that only the 'kafka' user can create kafka topics. We want to allow a different application ID to create topics as well and we need help with how to set the zookeeper ACLs to allow that.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP22ADLSTREAM\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need help adding application ID to Kafka zookeeper ACLs to allow it to create topics,0.150558307,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Unexpected result\Kafka,advisory,advisory," kafka-topics.sh uses zookeeper to create topics, not going through Kafka Admin client. So, there is no way to enforce ranger policies, since ranger plugins for zookeeper is not available. So, that’s why we say customers should use AdminClient to create topics in secure cluster, and not kafka-topics.sh.",,,,,,,,
1.20042E+14,58:34.5,Unable to purge ambari database,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 20, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:~$ sudo ambari-server stop\nUsing python  /usr/bin/python\nStopping ambari-server\nWaiting for server stop...\nAmbari Server stopped\n{alphanumericpii}:~$ sudo ambari-server status\nUsing python  /usr/bin/python\nAmbari-server status\nAmbari Server not running. Stale PID File at: /var/run/ambari-server/ambari-server.pid\n{alphanumericpii}:~$ sudo ambari-server db-purge-history --cluster-name gldevhdcluster --from-date 2020-04-15\nUsing python  /usr/bin/python\nPurge database history...\nAmbari Server configured for MSSQL. Confirm you have made a backup of the Ambari Server database [y/n]y\nERROR: The database purge historical data cannot proceed while Ambari Server is running. Please shut down Ambari first.\nAmbari Server 'db-purge-history' completed successfully.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii}:~$ sudo ambari-server stop\nUsing python  /usr/bin/python\nStopping ambari-server\nWaiting for server stop...\nAmbari Server stopped\n{alphanumericpii}:~$ sudo ambari-server status\nUsing python  /usr/bin/python\nAmbari-server status\nAmbari Server not running. Stale PID File at: /var/run/ambari-server/ambari-server.pid\n{alphanumericpii}:~$ sudo ambari-server db-purge-history --cluster-name gldevhdcluster --from-date 2020-04-15\nUsing python  /usr/bin/python\nPurge database history...\nAmbari Server configured for MSSQL. Confirm you have made a backup of the Ambari Server database [y/n]y\nERROR: The database purge historical data cannot proceed while Ambari Server is running. Please shut down Ambari first.\nAmbari Server 'db-purge-history' completed successfully.\n;\n\n- ProblemStartTime: 04/20/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Novelis Global\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5f5c5be9-a2dd-49c9-bfa1-77d4db790171/resourceGroups/GlobalDAPDEV/providers/Microsoft.HDInsight/clusters/gldevhdcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to purge ambari database,0.079611749,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,The ambari-server db-purge-history command failed with the following error after ambari-server was stopped via the ambari-server CLI:ERROR: The database purge historical data cannot proceed while Ambari Server is running. Please shut down Ambari first.,The ambari-server service was being automatically restarted after being stopped with the ambari-server stop command,Use sudo service ambari-server stop,,,,,,,,
1.20042E+14,35:13.3,How to schedule creation of cluster,"Question: What time did the problem begin?\nAnswer: Wed, Apr 1, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 1, 2020, 12:00 AM EDT\n\nQuestion: {Namepii} name\nAnswer: {ALPHANUMERICPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Well first of all we don't have an issue.  I have a 'how do I' type question.\n\nSince there is no way to shut down the cluster, we would like to destroy it instead every night at 7pm, and start up a new one in the morning at 7am.  What is the best way to go about automating this?\n\nI'm guessing the answer is powershell.  This brings me to the next question.  Is there an azure cloud service that we can use to run powershell commands on a schedule, or do we need to run it from a server/workstation?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Well first of all we don't have an issue.  I have a 'how do I' type question.\n\nSince there is no way to shut down the cluster, we would like to destroy it instead every night at 7pm, and start up a new one in the morning at 7am.  What is the best way to go about automating this?\n\nI'm guessing the answer is powershell.  This brings me to the next question.  Is there an azure cloud service that we can use to run powershell commands on a schedule, or do we need to run it from a server/workstation?;\n\n- ProblemStartTime: 04/01/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise Commercial Maintenance\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1b214a16-edd3-4f6f-ba90-436dadee1e25/resourceGroups/RG-HDI-Dev-001/providers/Microsoft.HDInsight/clusters/hdi-dia-dev-001\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to schedule creation of cluster,0.093468558,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Guidance regarding automating cluster creation/deletion and permission issues for automation account,Permission issue needed subscription level access to create automation account    ,"Below documentation provided & subscription level access acquiredYou can automate creation/deletion using Azure Automation --> https://docs.microsoft.com/en-us/azure/hdinsight/manage-clusters-runbooksFollow to schedule creation/deletion of a cluster --> https://docs.microsoft.com/en-us/azure/automation/shared-resources/schedules#creating-a-scheduleIn order to create the “Run As” account, Subscription Owner permissions are required --> https://docs.microsoft.com/en-us/azure/automation/manage-runas-account",,,,,,,,
1.20042E+14,07:09.6,Bad Gateway error: Not able to access the ambari UI,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: https://kp10tntncapllapnsprdsup01-int.azurehdinsight.net/\n\nGateway error. Not able to access the Ambari UI\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Gateway error. Not able to access the Ambari UI\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Gateway error. Not able to access the Ambari UI\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - https://kp10tntncapllapnsprdsup01-int.azurehdinsight.net/\n\nGateway error. Not able to access the Ambari UI;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Gateway error. Not able to access the Ambari UI;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Gateway error. Not able to access the Ambari UI;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp10tntncapllapnsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Bad Gateway error: Not able to access the ambari UI,0.013060088,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Bad Gateway error: Not able to access the ambari UI,"Ambari-server was in a bad state when this issue happened, ",we restarted ambari-server as a mitigation to this issue,184848801,,,,,,,
1.20042E+14,39:54.0,connectivity issue when submit job to Livy using VM,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: curl -k --user '****' -X POST -H 'Content-Type:application/json' -H 'X-Requested-By: user' --data '@Livy_job/Test/test.txt' https://p02las01.azurehdinsight.net/livy/batches\n\nQuestion: Additional details about the issue\nAnswer: We are trying to submit livy job from DSVM ({alphanumericpii}). There are some connectivity issues, such as'curl: (7) Failed to connect to p02las01.azurehdinsight.net port 443: Connection timed out'.\nBut we didn't find this issue usning other machine in the same subnet. \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Python;\nSpark configuration details - curl -k --user '****' -X POST -H 'Content-Type:application/json' -H 'X-Requested-By: user' --data '@Livy_job/Test/test.txt' https://p02las01.azurehdinsight.net/livy/batches;\nAdditional details about the issue - We are trying to submit livy job from DSVM ({alphanumericpii}). There are some connectivity issues, such as'curl: (7) Failed to connect to p02las01.azurehdinsight.net port 443: Connection timed out'.\nBut we didn't find this issue usning other machine in the same subnet. \n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",connectivity issue when submit job to Livy using VM,0.076146116,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,connectivity issue when submit job to Livy using VM,Livy job specifically is looking for local directories in the node where the livy server is active on and for this to work you would have to set this property in the ambari>custom livy2> livy.file.local-dir-whitelist as we discussed earlier. For example say Livy server is active on hn1 and if you plan on using a local file -- by default it would look at the local files on hn1.,"So based on your use case I have done some investigation on using a local py file to pass to a livy job. Livy job specifically is looking for local directories in the node where the livy server is active on and for this to work you would have to set this property in the ambari>custom livy2> livy.file.local-dir-whitelist as we discussed earlier. For example say Livy server is active on hn1 and if you plan on using a local file -- by default it would look at the local files on hn1.  Running a test on a VM outside the HDInsight cluster environment. curl -k --user ""admin:pwd"" -v -H ""Content-Type: application/json"" -X POST -d '{ ""file"":""file:/home/aditya/test.py"" }' ""https://cluster-int.azurehdinsight.net/livy/batches"" -H ""X-Requested-By: admin"" Here I have a script located in the VM that is not a part of the HDInsight cluster. 20/04/30 00:20:33 INFO LineBufferedStream: stdout: 20/04/30 00:20:33 INFO Client: Uploading resource file:/home/aditya/test.py -> wasb://hdicontainer@mystorescus.blob.core.windows.net/user/livy/.sparkStaging/application_1588203999996_0006/test.py20/04/30 00:20:33 INFO LineBufferedStream: stdout: 20/04/30 00:20:33 WARN AzureFileSystemThreadPoolExecutor: Disabling threads for Delete operation as thread count 0 is <= 120/04/30 00:20:33 INFO LineBufferedStream: stdout: 20/04/30 00:20:33 INFO AzureFileSystemThreadPoolExecutor: Time taken for Delete operation is: 2 ms with threads: 020/04/30 00:20:33 INFO LineBufferedStream: stdout: 20/04/30 00:20:33 INFO Client: Deleted staging directory wasb://hdicontainer@mystorescus.blob.core.windows.net/user/livy/.sparkStaging/application_1588203999996_000620/04/30 00:20:33 INFO LineBufferedStream: stdout: Exception in thread ""main"" java.io.FileNotFoundException: File file:/home/aditya/test.py does not exist If you see the error message on the livy logs : Livy is not able to locate the file on its active livy server and fails to establish a session.  Same test on a HDInsight headnode(where the livy server is running) works just fine. So uploading the file to a default storage account would be the best approach here.you can consider using command line utilities such as AzCopy to copy the file over to the storage account.",,,,,,,,
1.20042E+14,23:01.2,confusing resource setup; unable to scale up,"Question: What time did the problem begin?\nAnswer: Wed, Apr 1, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We have an HDInsight cluster, nam is 'etl-bcbstx'. \nWe run our Spark application in it, and failed with 'OutOfMemory' error. The same job runs fine on AWS. I set up the cluster with 'enable autoscale' with minimal {alphanumericpii}, initially I set maximum nodes to 11. Later on I was able to set it to 13 (see attached screenshot).\n\nI noticed that when I run the Spark job (by issuing spark-submit on linux shell), the Ambari shows only 2 data nodes. So I manually set 'minimum' nodes to 10, then I start to see 10 nodes showing up on Ambari. But still Outofmemory error occurs.\n\nOne more concern - I have requested for more nodes, Azure ticket number {Phonenumberpii}. After that I still can't increase maximum node count in 'enable autoscale'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We have an HDInsight cluster, nam is 'etl-bcbstx'. \nWe run our Spark application in it, and failed with 'OutOfMemory' error. The same job runs fine on AWS. I set up the cluster with 'enable autoscale' with minimal {alphanumericpii}, initially I set maximum nodes to 11. Later on I was able to set it to 13 (see attached screenshot).\n\nI noticed that when I run the Spark job (by issuing spark-submit on linux shell), the Ambari shows only 2 data nodes. So I manually set 'minimum' nodes to 10, then I start to see 10 nodes showing up on Ambari. But still Outofmemory error occurs.\n\nOne more concern - I have requested for more nodes, Azure ticket number {Phonenumberpii}. After that I still can't increase maximum node count in 'enable autoscale';\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/01/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BST Test Azure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Developer\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Developer\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",confusing resource setup; unable to scale up,0.196467758,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,confusing resource setup; unable to scale up.,NA,"As customer have ""OutOfMemoryError"" Java heap space issue and customer tried below document and resolved the issue and successfully able to execute jobs. http://answers.flyppdevportal.com/MVC/Post/Thread/682d7598-0a0f-4e7a-b97a-1727d1834ab4?category=hdinsight Regarding customer another issue on not able to submit spark jobs. Customer have active ticket on this issue. As per customer confirmation closing this ticket.",,,,,,,,
1.20042E+14,01:15.1,HDInsight cluster appears to be down with multple issues,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 21, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Attempted to restart HDInsight resources and was unsuccessful.\n\nQuestion: Additional details about the issue\nAnswer: Cannot access any data in my cluster or the query tool. All ADF jobs related to this resource are hanging.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Attempted to restart HDInsight resources and was unsuccessful.;\nAdditional details about the issue - Cannot access any data in my cluster or the query tool. All ADF jobs related to this resource are hanging.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/21/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data and Analytics - Dev/Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/77098106-d426-4d5d-853a-2597acd1afe5/resourceGroups/phcslsmkt01-dev-rg/providers/Microsoft.HDInsight/clusters/dev04-HDInsight\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight cluster appears to be down with multple issues,1.003483137,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,120042024005702 - HDInsight cluster appears to be down with multiple issues ,The ADLS gen1 certificate had expired on the cluster.,"Run the following script in Windows PowerShell to refresh the certificate:#Start of script$clusterName = 'dev04-HDInsight'$resourceGroupName = 'phcslsmkt01-dev-rg'$subscriptionId = '77098106-d426-4d5d-853a-2597acd1afe5'$appId = 'da9c4e54-2082-475b-863a-55b296d1f424'$certPassword = ""CERT_PASSWORD"" Login-AzAccountSelect-AzSubscription -SubscriptionId $subscriptionId     Write-Host ""Generating new SelfSigned certificate""     $cert = New-SelfSignedCertificate -CertStoreLocation ""cert:\CurrentUser\My"" -Subject ""CN=hdinsightAdlsCert1new"" -KeySpec KeyExchange    $certBytes = $cert.Export([System.Security.Cryptography.X509Certificates.X509ContentType]::Pkcs12, $certPassword);    $certString = [System.Convert]::ToBase64String($certBytes)     Write-Host ""Creating new KeyCredential for the app""    $keyValue = [System.Convert]::ToBase64String($cert.GetRawCertData())    New-AzADAppCredential -ApplicationId $appId -CertValue $keyValue -EndDate $cert.NotAfter -StartDate $cert.NotBefore    Write-Host ""Waiting for 7 minutes for the permissions to get propagated""    Start-Sleep -s 420 #7 minutes Write-Host ""Updating the certificate on HDInsight cluster..."" Invoke-AzResourceAction `    -ResourceGroupName $resourceGroupName `    -ResourceType 'Microsoft.HDInsight/clusters' `    -ResourceName $clusterName `    -ApiVersion '2015-03-01-preview' `    -Action 'updateclusteridentitycertificate' `    -Parameters @{ ApplicationId = $appId; Certificate = $certString; CertificatePassword = $certPassword.ToString() } `    -Force ******************************************************************* ",191646879,,,,,,,
1.20042E+14,03:02.7,Looking for Cluster Usage details,"we are looking for the cluster usage details for the month March and April. We want to know whether 200 nodes of the cluster effectively used or not. Does cluster has that much load during this time to have on 200 nodes?\n\nProblem start date and time\n{Namepii}, Apr 20, 2020, 12:00 AM CDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/20/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/71aacd49-ff43-4567-9a08-b93980f13225/resourceGroups/Common01-Compute-DR/providers/Microsoft.HDInsight/clusters/ana02hadoop36distcpdr01\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Looking for Cluster Usage details,0.634991603,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\Cluster Metrics on Azure Portal,"Cluster was created with 200 workers, and customer wanted to understand the cluster utilization over a 2 month period. If possible, they wanted to reduce the size of the cluster to realize a cost savings.",N/A,"Recommended customer enable auto-scaling, or drop and re-create the cluster to utilize auto-scaling",,,,,,,,
1.20042E+14,10:57.3,Unable to access beeline ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 20, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Unable to connect to Beeline\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Unable to connect to beeline using the command beeline -u '{AlphanumericPII}'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Unable to connect to Beeline;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Unable to connect to beeline using the command beeline -u '{AlphanumericPII}';\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/20/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data-n-Analytics-Nonprod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7ceab26f-148c-455c-bdec-84510ab01220/resourceGroups/RG-BI-SCV-Dev/providers/Microsoft.HDInsight/clusters/g-hdq-3d-scv-app-01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access beeline ,0.586223284,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Interactive Query,Unable to access beeline,url wrong for LLAP cluster,grabbed URL from hive service in ambari,,,,,,,,
1.20042E+14,27:35.5,Critical Alerts reported in AMBARI ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The Ambari UI is reporting critical alerts on 'Ambari {Namepii}' and 'Kafka' services.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The Ambari UI is reporting critical alerts on 'Ambari {Namepii}' and 'Kafka' services.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/92478112-5cb4-43da-9db1-8b759b4276c4/resourceGroups/RgQtxKafkaAu1/providers/Microsoft.HDInsight/clusters/qtxkafkaau1\n- Location: australiaeast\n- Location: {Namepii} East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Critical Alerts reported in AMBARI ,1.182320534,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Kafka,Critical Alerts reported in AMBARI,Kafka Broker Process Connection failed: 'NoneType' object has no attribute 'split' to wn1-qtxkaf.l32ktpioypfezcqqlq1bmntfha.px.internal.cloudapp.net:9092 Alert: Ambari Metrics Collector configured for your HDInsight cluster qtxkafkaau1.,"Recommended Steps for Ambari Metrics Collector  Login into the Ambari portal  Set AMS to maintenance  Stop AMS from Ambari  Identify the following from the AMS Configs screen:     hbase.rootdir (Default value is file:///mnt/data/ambari-metrics-collector/hbase)   hbase.tmp.dir(Default value is /var/lib/ambari-metrics-collector/hbase-tmp)    SSH into headnode0. as superuser  Remove the AMS zookeeper data by backing up and removing the      contents of 'hbase.tmp.dir'/zookeeper  Remove any Phoenix spool files from 'hbase.tmp.dir'/phoenix-spool folder  Note: It is worthwhile to      skip this step and first restarting AMS to see if the issue is resolved.      If AMS is still failing to come up, try this step: AMS data would be      stored in hbase.rootdir identified above. Use regular OS commands to backup and      remove the files: # tar czf      /mnt/backupof-ambari-metrics-collector-hbase-$(date +%Y%m%d-%H%M%S).tar.gz      /mnt/data/ambari-metrics-collector/hbase  Restart AMS using Ambari Recommended Steps for Kafka Broker Process Perform restart of Ambari agent. Restart Ambari agent on wn1           1. ssh into cluster and ssh into wn12. check status of Ambari agent $sudo systemctl status ambari-agent 3. stop Ambari agent and check the status $sudo systemctl stop ambari-agent $sudo systemctl status ambari-agent 4. check if there are zoombie processes $ps -ef | grep -v java | grep ambari-agent if there are other then ""grep"" process running, kill them all. 5. start Ambari agent and check the status $sudo systemctl start ambari-agent $sudo systemctl status ambari-agent 6. Check Ambari UI if there are new alerts.",,,,,,,,
1.20042E+14,35:30.4,[Azure Government] Unable to get storage account integrated with MSI,"[Azure Government] Question: Local start time of the latest occurrence\nAnswer: {Namepii}, Apr 20, 2020, 12:00 AM EDT\n\nQuestion: Error code\nAnswer: HTTP 400\n\nQuestion: Storage server Request ID\nAnswer: \n\nQuestion: Provide any additional details\nAnswer:  hdfs dfs -ls abfss://data@mothradatastore.dfs.core.usgovcloudapi.net/\nFailed to load OpenSSL. Falling back to the JSSE default.\nls: HTTP Error 400; {alphanumericpii}' AADToken: HTTP connection to http://169.254.169.254/metadata/identity/oauth2/token failed for getting token from AzureAD.; requestId=''; contentType='application/json; {alphanumericpii}'; response '{'error':'invalid_request','error_description':'Invalid authority'}'\n[{alphanumericpii} conf]$\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Storage Account {Namepii}:\nLocal start time of the latest occurrence - {ALPHANUMERICPII};\nError code - HTTP 400;\nStorage server Request ID - ;\nProvide any additional details -  hdfs dfs -ls abfss://data@mothradatastore.dfs.core.usgovcloudapi.net/\nFailed to load OpenSSL. Falling back to the JSSE default.\nls: HTTP Error 400; {alphanumericpii}' AADToken: HTTP connection to http://169.254.169.254/metadata/identity/oauth2/token failed for getting token from AzureAD.; requestId=''; contentType='application/json; {alphanumericpii}'; response '{'error':'invalid_request','error_description':'Invalid authority'}'\n[{alphanumericpii} conf]$\n;\n\n- ProblemStartTime: 04/20/2020 04:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: usgovvirginia\n- ResourceUri: /subscriptions/5465e80d-aef9-4fd1-b21c-702123aabeba/resourceGroups/mothra-workload6/providers/Microsoft.Storage/storageAccounts/mothradatastore\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Unable to get storage account integrated with MSI,86.30474098,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure Storage Management\Authentication and Authorization\Issues using Azure AD (RBAC & oAuth),Customer was receiving an error that the managed identity in self-hosted Hadoop cluster could not get the token from Azure AD.,The hdfs command was reaching out to the public endpoint when the hdfs command was being performed. Issue was taking place before ever reaching storage service.,Informed customer that this issue is unrelated to storage and due to the nature of the environment that we could not assist further into getting this working and Big Data PG as well as Azure AD did not believe this was a supported scenario and recommended using HDI.,"189,153,451,192,019,000",,,,,,,
1.20042E+14,03:11.6,Unable to login to edge node.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 21, 2020, 11:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None.\n\nQuestion: Additional details about the issue\nAnswer: IP address - {Ipaddresspii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None.;\nAdditional details about the issue - IP address - {Ipaddresspii};\n\n- ProblemStartTime: 04/21/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-NonProd/providers/Microsoft.HDInsight/clusters/dev1rxperso\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to login to edge node.,0.042527615,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Unable to login to edge node.,Here is the RCA on why you were not able to login to the edgenode ed10 on 04/21. ,We noticed that the availability set for the VM size was unavailable during the timeframe of the issue which might have caused the VM agent to go down and back up when the availability set was available to use. We apologize for the inconvenience.,187882111,,,,,,,
1.20042E+14,38:05.1,Sluggish response from application running on Edge node.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 9, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Application running on edge node is sluggish. Need your help in troubleshooting and improving the application performance.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Application running on edge node is sluggish. Need your help in troubleshooting and improving the application performance.;\n\n- ProblemStartTime: 04/09/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sluggish response from application running on Edge node.,0.122648981,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Sluggish response from application running on Edge node.,Sluggish response from application running on Edge node.,Engaged Linux Engineer with regards to customer ask on measuring performance from within the VM and Linux Engineer had shared the requested details with customer. Customer confirmed to close the case.,,,,,,,,
1.20042E+14,39:30.1,Cluster creation with VNET from different subscription in the same region fails,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: ghdwiceberg\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: I'm trying to create HDInsight cluster that uses VNET from different subscription that I have access. I'm getting error:\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'code\\': \\'BadRequest\\',\\r\\n \\'message\\': \\'Virtual Network '/subscriptions/bad9be90-617a-40e7-a65b-185a43a1e0d2/resourceGroups/rg-prod-expressroute/providers/Microsoft.Network/virtualNetworks/vnet-prod-eastus' or Subnet '/subscriptions/bad9be90-617a-40e7-a65b-185a43a1e0d2/resourceGroups/rg-prod-expressroute/providers/Microsoft.Network/virtualNetworks/vnet-prod-eastus/subnets/HDInsightSubnet' is not in user subscription 'e1bffa34-c852-4370-8200-af9c73de8b20'\\'\\r{uncpii}\n\nVNET and cluster are in the same region just in different subscriptions.\n\nI can't move my cluster to the same as VNET due to security and billing requirements\nI don't see anything in the docs thta prohibits that creation: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#existingvnet\nI had no problem to use the same approach for Storage accoutn and SQL DB with that VNET \n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - ghdwiceberg;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - I'm trying to create HDInsight cluster that uses VNET from different subscription that I have access. I'm getting error:\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'code\\': \\'BadRequest\\',\\r\\n \\'message\\': \\'Virtual Network '/subscriptions/bad9be90-617a-40e7-a65b-185a43a1e0d2/resourceGroups/rg-prod-expressroute/providers/Microsoft.Network/virtualNetworks/vnet-prod-eastus' or Subnet '/subscriptions/bad9be90-617a-40e7-a65b-185a43a1e0d2/resourceGroups/rg-prod-expressroute/providers/Microsoft.Network/virtualNetworks/vnet-prod-eastus/subnets/HDInsightSubnet' is not in user subscription 'e1bffa34-c852-4370-8200-af9c73de8b20'\\'\\r{uncpii}\n\nVNET and cluster are in the same region just in different subscriptions.\n\nI can't move my cluster to the same as VNET due to security and billing requirements\nI don't see anything in the docs thta prohibits that creation: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#existingvnet\nI had no problem to use the same approach for Storage accoutn and SQL DB with that VNET \n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GitHub - Prod - Data Platform - GitHub Data Warehouse\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster creation with VNET from different subscription in the same region fails,0.110206672,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Cluster creation with VNET from different subscription in the same region fails.,NA,If you are creating HDInsight cluster in VNET. VNET and cluster should be in the same subscription.,,,,,,,,
1.20042E+14,18:01.0,Unable to create external table in hive,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 20, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 20, 2020, 11:00 PM MST\n\nQuestion: Connection string used\nAnswer: beeline -u 'jdbc:hive2://zk1-sprk01.petsmartazureds.com:2181,zk3-sprk01.petsmartazureds.com:2181,zk5-sprk01.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2'\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We just created new {ALPHANUMERICPII} cluster on {Alphanumericpii} and have all access policies in place for all the users. I am trying to one external table in one of the database to which this service account has access to, but failing with the below error.\n\n0: {alphanumericpii} CREATE EXTERNAL TABLE raw.days\n0: {alphanumericpii} (\n0: {alphanumericpii}   day_dt timestamp,\n0: {alphanumericpii}   business_day_flag string,\n0: {alphanumericpii}   holiday_flag string,\n0: {alphanumericpii}   day_of_wk_name string,\n0: {alphanumericpii}   day_of_wk_name_abbr string,\n0: {alphanumericpii}   day_of_wk_nbr int,\n0: {alphanumericpii}   cal_day_of_mo_nbr int,\n0: {alphanumericpii}   cal_day_of_yr_nbr int,\n0: {alphanumericpii}   cal_wk int,\n0: {alphanumericpii}   cal_wk_nbr int,\n0: {alphanumericpii}   cal_mo int,\n0: {alphanumericpii}   cal_mo_nbr int,\n0: {alphanumericpii}   cal_mo_name string,\n0: {alphanumericpii}   cal_mo_name_abbr string,\n0: {alphanumericpii}   cal_qtr int,\n0: {alphanumericpii}   cal_qtr_nbr int,\n0: {alphanumericpii}   cal_half int,\n0: {alphanumericpii}   cal_yr int,\n0: {alphanumericpii}   fiscal_day_of_mo_nbr int,\n0: {alphanumericpii}   fiscal_day_of_yr_nbr int,\n0: {alphanumericpii}   fiscal_wk int,\n0: {alphanumericpii}   fiscal_wk_nbr int,\n0: {alphanumericpii}   fiscal_mo int,\n0: {alphanumericpii}   fiscal_mo_nbr int,\n0: {alphanumericpii}   fiscal_mo_name string,\n0: {alphanumericpii}   fiscal_mo_name_abbr string,\n0: {alphanumericpii}   fiscal_qtr int,\n0: {alphanumericpii}   fiscal_qtr_nbr int,\n0: {alphanumericpii}   fiscal_half int,\n0: {alphanumericpii}   fiscal_yr int,\n0: {alphanumericpii}   lyr_week_dt timestamp,\n0: {alphanumericpii}   lwk_week_dt timestamp,\n0: {alphanumericpii}   week_dt timestamp,\n0: {alphanumericpii}   est_time_conv_amt double,\n0: {alphanumericpii}   est_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   cst_time_conv_amt double,\n0: {alphanumericpii}   cst_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   mst_time_conv_amt double,\n0: {alphanumericpii}   mst_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   pst_time_conv_amt double,\n0: {alphanumericpii}   pst_time_conv_hrs int\n0: {alphanumericpii}   )\n0: {alphanumericpii} ROW FORMAT DELIMITED\n0: {alphanumericpii}   FIELDS TERMINATED BY '|'\n0: {alphanumericpii} STORED AS textfile\n0: {alphanumericpii} LOCATION\n0: {alphanumericpii}   'abfs://advancedanalytics@ngaadlsgen2prod.dfs.core.windows.net/PROD/raw/netezza/days/data/'\n0: {alphanumericpii} ;\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [svc-hdi_azure_aa] does not have [READ] privilege on [abfs://advancedanalytics@ngaadlsgen2prod.dfs.core.windows.net/PROD/raw/netezza/days/data] ({alphanumericpii})\n\n\nI am seeing this service account has RWX on this location and also has correct ranges policy in place. Still giving this error. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nConnection string used - beeline -u 'jdbc:hive2://zk1-sprk01.petsmartazureds.com:2181,zk3-sprk01.petsmartazureds.com:2181,zk5-sprk01.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2';\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - We just created new {ALPHANUMERICPII} cluster on {Alphanumericpii} and have all access policies in place for all the users. I am trying to one external table in one of the database to which this service account has access to, but failing with the below error.\n\n0: {alphanumericpii} CREATE EXTERNAL TABLE raw.days\n0: {alphanumericpii} (\n0: {alphanumericpii}   day_dt timestamp,\n0: {alphanumericpii}   business_day_flag string,\n0: {alphanumericpii}   holiday_flag string,\n0: {alphanumericpii}   day_of_wk_name string,\n0: {alphanumericpii}   day_of_wk_name_abbr string,\n0: {alphanumericpii}   day_of_wk_nbr int,\n0: {alphanumericpii}   cal_day_of_mo_nbr int,\n0: {alphanumericpii}   cal_day_of_yr_nbr int,\n0: {alphanumericpii}   cal_wk int,\n0: {alphanumericpii}   cal_wk_nbr int,\n0: {alphanumericpii}   cal_mo int,\n0: {alphanumericpii}   cal_mo_nbr int,\n0: {alphanumericpii}   cal_mo_name string,\n0: {alphanumericpii}   cal_mo_name_abbr string,\n0: {alphanumericpii}   cal_qtr int,\n0: {alphanumericpii}   cal_qtr_nbr int,\n0: {alphanumericpii}   cal_half int,\n0: {alphanumericpii}   cal_yr int,\n0: {alphanumericpii}   fiscal_day_of_mo_nbr int,\n0: {alphanumericpii}   fiscal_day_of_yr_nbr int,\n0: {alphanumericpii}   fiscal_wk int,\n0: {alphanumericpii}   fiscal_wk_nbr int,\n0: {alphanumericpii}   fiscal_mo int,\n0: {alphanumericpii}   fiscal_mo_nbr int,\n0: {alphanumericpii}   fiscal_mo_name string,\n0: {alphanumericpii}   fiscal_mo_name_abbr string,\n0: {alphanumericpii}   fiscal_qtr int,\n0: {alphanumericpii}   fiscal_qtr_nbr int,\n0: {alphanumericpii}   fiscal_half int,\n0: {alphanumericpii}   fiscal_yr int,\n0: {alphanumericpii}   lyr_week_dt timestamp,\n0: {alphanumericpii}   lwk_week_dt timestamp,\n0: {alphanumericpii}   week_dt timestamp,\n0: {alphanumericpii}   est_time_conv_amt double,\n0: {alphanumericpii}   est_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   cst_time_conv_amt double,\n0: {alphanumericpii}   cst_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   mst_time_conv_amt double,\n0: {alphanumericpii}   mst_time_conv_hrs int,\n0: {alphanumericpii}   {alphanumericpii} double,\n0: {alphanumericpii}   {alphanumericpii} int,\n0: {alphanumericpii}   pst_time_conv_amt double,\n0: {alphanumericpii}   pst_time_conv_hrs int\n0: {alphanumericpii}   )\n0: {alphanumericpii} ROW FORMAT DELIMITED\n0: {alphanumericpii}   FIELDS TERMINATED BY '|'\n0: {alphanumericpii} STORED AS textfile\n0: {alphanumericpii} LOCATION\n0: {alphanumericpii}   'abfs://advancedanalytics@ngaadlsgen2prod.dfs.core.windows.net/PROD/raw/netezza/days/data/'\n0: {alphanumericpii} ;\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [svc-hdi_azure_aa] does not have [READ] privilege on [abfs://advancedanalytics@ngaadlsgen2prod.dfs.core.windows.net/PROD/raw/netezza/days/data] ({alphanumericpii})\n\n\nI am seeing this service account has RWX on this location and also has correct ranges policy in place. Still giving this error. ;\n\n- ProblemStartTime: 04/21/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to create external table in hive,7.991712864,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,Unable to create external table,Unable to create external table in hive,Updated the “ranger.plugin.hive.service.name” with service name “sprk01-prod-eastus2_hive” and then added the “svc-hdi_azure_aa” account to the “all – url” policy in Ranger,,,,,,,,
1.20042E+14,27:00.1,Unable to install HUE application to the existing cluster,"Question: What time did the problem begin?\nAnswer: Wed, Apr 22, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to install HUE application, taking longer time than expected and gets failed to create\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Other, don't know or not applicable;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - Unable to install HUE application, taking longer time than expected and gets failed to create;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/21/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/698a551a-d866-4efc-8411-2f6a9972341a/resourceGroups/USEPFSOFINRSG05/providers/Microsoft.HDInsight/clusters/usepfsofinhdi03\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to install HUE application to the existing cluster,0.246515447,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie",Unable to install HUE application to the existing cluster,The old Hue installation did not get deleted successfully causing new installations to fail.,We were able to deploy HUE to an existing cluster on an edgenode successfully. The old Hue installation did not get deleted successfully causing new installations to fail. We were able to get past this by renaming our Hue app. ,,,,,,,,
1.20042E+14,50:08.7,HDI is getting provisioned with incorrect size worker nodes,"Question: What time did the problem begin?\nAnswer: Fri, Apr 17, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: prdemacortexspark\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: We were having issues with provisioning before due to allocation issues in Europe and we were told to provision with differnt size and we provisioned with {Alphanumericpii} size worker node. Last week we got an email from MS saying allocation issues should be good now so we tried re-provisioning it with our size requirement {AlphanumericPII} worker nodes but now we are seeing that its still getting provisioned with {AlphanumericPII} size worker nodes only \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - prdemacortexspark;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - We were having issues with provisioning before due to allocation issues in Europe and we were told to provision with differnt size and we provisioned with {Alphanumericpii} size worker node. Last week we got an email from MS saying allocation issues should be good now so we tried re-provisioning it with our size requirement {AlphanumericPII} worker nodes but now we are seeing that its still getting provisioned with {AlphanumericPII} size worker nodes only ;\n\n- ProblemStartTime: 04/16/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/62c1dd5c-d918-4a4d-b0ee-18d5e7d5071b/resourceGroups/App-Cortex-PaaS-EMA-PRD-RG/providers/Microsoft.HDInsight/clusters/prdemacortexspark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI is getting provisioned with incorrect size worker nodes,2.147329597,Root Cause : HDInsight Service\Bug\HDInsight SDK,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,120042222002739 HDI is getting provisioned with incorrect size worker nodes,The New-AzHDInsightClusterConfig command was passing the default worker node size to the HDInsight cluster create request.,Pass the -WorkerNodeSize parameter in the New-AzHDInsightClusterConfig command to override the default worker node size.,,,,,,,,
1.20042E+14,59:14.6,Head node 0 is unhealthy with multiple alerts,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 21, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We tried restartng the services\n\nQuestion: Additional details about the issue\nAnswer: We have mutliple alerts on the head node 0 on the HDFS.Name node checkpoint has not happened for last 19 hours.\ncan you please check and assist on the same ?\nthanks\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We tried restartng the services;\nAdditional details about the issue - We have mutliple alerts on the head node 0 on the HDFS.Name node checkpoint has not happened for last 19 hours.\ncan you please check and assist on the same ?\nthanks;\n\n- ProblemStartTime: 04/21/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head node 0 is unhealthy with multiple alerts,13.18838391,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Head node 0 is unhealthy with multiple alerts,Headnode not worked out,Rebooted on hn and AMS data clear,"185,108,421,185,272,000,000,000,000",,,,,,,
1.20042E+14,19:15.2,deployment failure,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Trying to create a Spark cluster and it is failing with a conflict\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Trying to create a Spark cluster and it is failing with a conflict;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",deployment failure,0.037127229,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,deployment failureand Yarn RM UI not accessible. ,I see that the cluster deployment is failing since there are DNS entries already present in the Vnet that have the cluster name  (atleast the first 6 characters of the clustername) /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-infosec-p02-cus-rg/providers/Microsoft.Network/virtualNetworks/pep-infosec-p02-cus-vnet. Issue 2: Since the cluster deployment got succeeded you were having issues accessing the yarn UI.We noticed that both the RMs were in standby state causing the UI to be not accessible.,Solution1 : Can you please try redeploying the cluster with unique first 6 characters Solution2: Since the cluster deployment got succeeded you were having issues accessing the yarn UI.We noticed that both the RMs were in standby state causing the UI to be not accessible. From the error messageorg.apache.hadoop.ha.ServiceFailedException: RM could not transition to ActiveCaused by: org.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: BP-528327077-172.20.251.30-1587589774957:blk_1073743379_2555 file=/yarn/node-labels/nodelabel.mirror Yarn was looking for a file that was corrupted because of a recent scale down. Usually when using autoscale we recommend using minimum 3 nodes to prevent the cluster getting stuck in Safemode because of Insufficient file replication. (Refer doc) We were able to successfully remove the corrupted file to get past the issue.,,,,,,,,
1.20042E+14,20:26.8,Unable to change group ownership of files in Gen2 storage account.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 21, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Through Gateway\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: hdfs dfs -chgrp grp-cvs-hdpadm abfs://data@sartlrxpersoqa.dfs.core.windows.net/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT\nchgrp: changing ownership of 'abfs://data@sartlrxpersoqa.dfs.core.windows.net/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT': Operation failed: 'The owner or group is not valid.', 400, PUT, https://sartlrxpersoqa.dfs.core.windows.net/data/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT?action=setAccessControl&timeout=90, InvalidOwner, 'The owner or group is not valid. {AlphanumericPII} {AlphanumericPII}'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - Yes;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Through Gateway;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - hdfs dfs -chgrp grp-cvs-hdpadm abfs://data@sartlrxpersoqa.dfs.core.windows.net/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT\nchgrp: changing ownership of 'abfs://data@sartlrxpersoqa.dfs.core.windows.net/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT': Operation failed: 'The owner or group is not valid.', 400, PUT, https://sartlrxpersoqa.dfs.core.windows.net/data/qa/rtl_pharmacy/archive/rxdw/managed/file/external/AETNA_AO_RT?action=setAccessControl&timeout=90, InvalidOwner, 'The owner or group is not valid. {AlphanumericPII} {AlphanumericPII}';\n\n- ProblemStartTime: 04/21/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to change group ownership of files in Gen2 storage account.,0.053787241,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",Unable to change group ownership of files in Gen2 storage account.,Unable to change group ownership of files in Gen2 storage account.,Customer was able to change the ownership of the parent folder and child using “Object ID” of the group rather using group names,,,,,,,,
1.20042E+14,05:07.6,Spark Unable to Read/Write to Hive Transactional Tables,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Spark-shell with basic config\n\nQuestion: Additional details about the issue\nAnswer: Spark is unable to read/write to hive transactional tables after migrating to new cluster with {alphanumericpii} storage.  version 2.4.0.3.1.2.2-1 is the latest version.\n\nWas able to be read and write in the previous version (version 2.1.1.2.6.2.2-5).\n\nObservations:\n* Unable to read transaction tables (ex: imdl_irdp_test.raw_acs_var_def) \n* Created a transational table from hive and inserted data from hive\n* Able to read data from Hive\n* Unable to read from spark (empty records)\n* Same table performed insert overwrite from spark (changed the owner from spn to user)\n* Able to read the data from spark after insert overwrite from spark\n* Unable to read the data from hive after insert overwrite from spark\nError:\nSQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n  SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n    SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n      SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n        java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n          java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n            java.lang.IllegalArgumentException: bucketId out of range: -1\n              bucketId out of range: -1\n              bucketId out of range: -1\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - Spark-shell with basic config;\nAdditional details about the issue - Spark is unable to read/write to hive transactional tables after migrating to new cluster with {alphanumericpii} storage.  version 2.4.0.3.1.2.2-1 is the latest version.\n\nWas able to be read and write in the previous version (version 2.1.1.2.6.2.2-5).\n\nObservations:\n* Unable to read transaction tables (ex: imdl_irdp_test.raw_acs_var_def) \n* Created a transational table from hive and inserted data from hive\n* Able to read data from Hive\n* Unable to read from spark (empty records)\n* Same table performed insert overwrite from spark (changed the owner from spn to user)\n* Able to read the data from spark after insert overwrite from spark\n* Unable to read the data from hive after insert overwrite from spark\nError:\nSQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n  SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n    SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n      SQL Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n        java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n          java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1\n            java.lang.IllegalArgumentException: bucketId out of range: -1\n              bucketId out of range: -1\n              bucketId out of range: -1;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Unable to Read/Write to Hive Transactional Tables,0.032781998,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Spark,120042221002138 - Spark Unable to Read/Write to Hive Transactional Tables HDInsight Service,LLAP must be enabled to use the Hive Warehouse Connector to read the transactional tables from Spark,Duplicate of case# 120041621002071,,,,,,,,
1.20042E+14,15:04.6,HDI Services Not Coming up,"Question: What time did the problem begin?\nAnswer: Wed, Apr 22, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Hi,\nSince we are seeing issues on our HDI cluste we tried to restart services. Services are not coming up now. Could you please look in to it and help us to resolve the isssues.\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: PFA log\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Hi,\nSince we are seeing issues on our HDI cluste we tried to restart services. Services are not coming up now. Could you please look in to it and help us to resolve the isssues.;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - PFA log;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/22/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MRC Lower PLAT_TST\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e2553d79-7aba-4d88-956f-99380ce3f546/resourceGroups/RG_Enterprise_DataHub_qa/providers/Microsoft.HDInsight/clusters/mrcazedhhditeqa\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI Services Not Coming up,8.934772677,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,HDI Services Not coming up,Node or Service Reboot,Customer is in the process of rebuilding the cluster.,185443315,,,,,,,
1.20042E+14,36:07.9,can't run spark jobs,"Question: What time did the problem begin?\nAnswer: Wed, Apr 22, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: restarted various services in ambari. That didn't help.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - restarted various services in ambari. That didn't help.;\n\n- ProblemStartTime: 04/22/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BST Test Azure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Developer\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Developer\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",can't run spark jobs,0.85165574,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Can't run spark jobs,timed out when connecting to Ambari during the ApplyManifestChangesOnClusterActivity step in the workflow,Re-create the cluster for workaround as the cluster is in UpdatingError state.,185733307,,,,,,,
1.20042E+14,53:21.6,UNIFIED PERF || Azure HDInsight Service || Restricting public network access to SSH Services.,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 1, 2020, 12:00 AM PST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We are looking for some assistance on understanding how can control/prevent access to HDL {Namepii} SSH services over public interent.  We have the cluster deployed on an internal vnet, but we are unsure if the solution for 'isloating' the cluster from the public internet  applies to both https and ssh ports.  Reference this documenation:  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#networktraffic\n\nQuestion: Additional details about the issue\nAnswer: We need assistance/guidance to ensure that we can prevent public SSH access to the HDI {Namepii}, but still allow management consoles (such as Ambari) to connect over SSH.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We are looking for some assistance on understanding how can control/prevent access to HDL {Namepii} SSH services over public interent.  We have the cluster deployed on an internal vnet, but we are unsure if the solution for 'isloating' the cluster from the public internet  applies to both https and ssh ports.  Reference this documenation:  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment#networktraffic;\nAdditional details about the issue - We need assistance/guidance to ensure that we can prevent public SSH access to the HDI {Namepii}, but still allow management consoles (such as Ambari) to connect over SSH.;\n\n- ProblemStartTime: 03/01/2020 08:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: eb-devtest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cfcf3d4d-e1c9-4252-a7b3-f6cfb461ed79/resourceGroups/edpRgd001/providers/Microsoft.HDInsight/clusters/edphdisprkd001\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",UNIFIED PERF || Azure HDInsight Service || Restricting public network access to SSH Services.,43.92848811,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Restricting public network access to SSH Services.,NA,"Successfully added NSG Rules on port 22-23 and port 443 to restrict public access but still allow internal private network traffic.But in the above process we had to whitelist the subnet IPaddress exclusively to achieve provisioning of cluster through Automation account, which when discussed with PG Team turned out to be a BUG on NSG validation from HDInsight.Had filed an ICM as mentioned in the case notes and also raised a work item .","190,057,418,191,489,000",,,,,,,
1.20042E+14,11:17.0,TimeoutException - while running hive query in prod dm05,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: {Namepii}:   rs05e2piphdidm05-int.azurehdinsight.net\n \nSET {alphanumericpii};\nSET {AlphanumericPII};\nset hive.vectorized.execution.enabled=false;\nset hive.vectorized.execution.reduce.enabled=false;\n\nSelect * \nfrom cdm.lylty_card\nwhere bnnr_id = 1000\nAND lylty_crd_nbr = {Phonenumberpii}\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: exception/error we are getting -\n\n java.util.concurrent.TimeoutException: deadline passed\n\njava.util.concurrent.TimeoutException: deadline passed\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - {Namepii}:   rs05e2piphdidm05-int.azurehdinsight.net\n \nSET {alphanumericpii};\nSET {AlphanumericPII};\nset hive.vectorized.execution.enabled=false;\nset hive.vectorized.execution.reduce.enabled=false;\n\nSelect * \nfrom cdm.lylty_card\nwhere bnnr_id = 1000\nAND lylty_crd_nbr = {Phonenumberpii}\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - exception/error we are getting -\n\n java.util.concurrent.TimeoutException: deadline passed\n\njava.util.concurrent.TimeoutException: deadline passed\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05e2piphdidm05\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",TimeoutException - while running hive query in prod dm05,2.573205563,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Query runs into a vertex error.,Tables were not partitioned correctly and had skewed partitions.,Changed table file format and and recreated the tables with even partitions.,"187,166,272,187,319,000,000,000,000",,,,,,,
1.20042E+14,47:49.3,"both headnodes are down, I cant get them to start up","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: attempted to restart the node but doesnt seem to get anywhere\n\nQuestion: Additional details about the issue\nAnswer: this started about 10 hours ago, it looked like there was a health event from what the portal says but I cant seem to get the node to come back up\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - attempted to restart the node but doesnt seem to get anywhere;\nAdditional details about the issue - this started about 10 hours ago, it looked like there was a health event from what the portal says but I cant seem to get the node to come back up;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/48f10876-7183-46da-a5f7-33a9ce21f189/resourceGroups/RG-AP-SoutheastAsia-Prod-CEPA/providers/Microsoft.HDInsight/clusters/hdisomprod-ap-southeastasia-cepa\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","both headnodes are down, I cant get them to start up",0.360910445,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,"both headnodes are down, I can’t get them to start up. Name nodes were down. ",This issue occurs when there are to many operations to name nodes and also whenwriting to hdfs quite often. ,Increasing java heap size to 6 GB have helped name node and other services to bring up. ,185290068,,,,,,,
1.20042E+14,03:10.5,How to change SSH key post-cluster creation,I created this cluster with SSH Public key. How Can I reset SSK key to a new file. I see the option to reset SSH Password but how can we change SSH Key.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Unifi Field\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a0020070-6516-4e49-b8a4-dffcf772d63c/resourceGroups/rg-hdicluster-dev/providers/Microsoft.HDInsight/clusters/uf4hdi\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,How to change SSH key post-cluster creation,0.10682297,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,How to change SSH key post-cluster creation.,How to change SSH key post-cluster creation,"Open your ssh client and make sure you have a valid connection to cluster using ssh sshuser@HOSTNAME-ssh.azurehdinsight.netAfter check you have access to it, close the connection typing exitType in your local ssh client the followed command, to create a new 2048-bit RSA key pairssh-keygen -f ~/.ssh/yourNewKeyName-key-rsa -t rsa -b 2048 After create the new key pair, copy it into the cluster using the command:ssh-copy-id -i ~/.ssh/yourNewKeyName-key-rsa sshuser@HOSTNAME-ssh.azurehdinsight.netThen, try to connect the cluster by typing;ssh sshuser@HOSTNAME-ssh.azurehdinsight.net",,,,,,,,
1.20042E+14,24:34.3,Enable SSL for Hive Connection,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: !connect {AlphanumericPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We want to make Hive connection to SSL and currently its using non-ssl connection. Can you please guide us and share steps to enable Hive SSL connection?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - !connect {AlphanumericPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - We want to make Hive connection to SSL and currently its using non-ssl connection. Can you please guide us and share steps to enable Hive SSL connection?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Enable SSL for Hive Connection,0.062149076,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,JDBC Hive connection string not working to enable SSL for Hive and Qlikview connectivty guidance,JDBC connection string was not correct and Enable SSL is only Supported for Kafka at this point        ,"Resolution: To enable SSL for hive, we will have to hit gateway nodes, which is technically doable but not recommended from Micrsoft. JDBC connection string was provided to make a successful beeline connection and below guidance around Qlikview connectivity. Applications that use Azure services such as HDinsight need to trust the Baltimore CyberTrust root certificate. Almost all applications have their corresponding trust stores already configured with this root certificate (all browsers,  java , etc..). I suspect Qlik uses the windows trust store which already trusts the root certificate -  but if its hosting java components (i.e., jdbc classes, etc..). a java trust store most likely needs to be created and the Baltimore root certificate inserted if, for some reason, it doesn't already exist. Qlik also has a trust store, but it's used for ODBC. If you are looking to create/host your own cacerts store  and not reuse the existing java trust store, the following article provides location details to obtain the root certificate --> https://docs.microsoft.com/en-us/azure/developer/java/sdk/java-sdk-add-certificate-ca-store",,,,,,,,
1.20042E+14,40:32.9,Azure monitor integration not working,"HDInsight cluster Azure Monitor integration not working HDInsight Service\n\nI tried and enable Azure Monitor integration for our 3 Production clusters and 2 out of 3 are having issues:\n \n{alphanumericpii}: I enabled Azure Monitor for the first time on the cluster, the Ambari steps completed successfully, but no data is showing in the table. I then checked and we are getting the same 401 auth error for the hdiwatchdog user. So seems the removal and re-sync of hdiwatchdog user is necessary.\n \n{alphanumericpii}: Azure Monitor on portal shows disabled but logs already showing up in table, so seems it was attempted to be enabled before and like we saw with Prep the previous enable steps must have failed. I also confirmed no persisted script action. I first tried just enabling to see what would happen, and seems the oms install on some of the nodes are getting stuck. This one might require running the uninstall script action and then re-install. However, for the 1 node it is stuck on ({alphanumericpii}), I am trying to ssh into it and can’t get in and get permission denied errors as if my password is wrong, but it is not.\n\nWe faced the same issue in non-prod (case {Phonenumberpii}) and now are opening new case for Prod.  {Namepii} Kola will be picking up this case and working with me\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/04af94d4-74f4-4642-b571-5b48a42b979f/resourceGroups/ITS-APPOPS-EDL-PROD-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/PHBS01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Azure monitor integration not working,0.18842658,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\Azure Log Analytics Integration,"phbs01adlbatch: I enabled Azure Monitor for the first time on the cluster, the Ambari steps completed successfully, but no data is showing in the table. I then checked and we are getting the same 401 auth error for the hdiwatchdog user. So seems the removal and re-sync of hdiwatchdog user is necessary.   phsp02adlspark: Azure Monitor on portal shows disabled but logs already showing up in table, so seems it was attempted to be enabled before and like we saw with Prep the previous enable steps must have failed. I also confirmed no persisted script action. I first tried just enabling to see what would happen, and seems the oms install on some of the nodes are getting stuck. This one might require running the uninstall script action and then re-install. However, for the 1 node it is stuck on (wn39), I am trying to ssh into it and can’t get in and get permission denied errors as if my password is wrong, but it is not.  We faced the same issue in non-prod (case 120040824005545) and now are opening new case for Prod.  Aditya Kola will be picking up this case and working with me",401 auth issue on one cluster and a problematic node issue on the other cluster. ,"We were able to resolve the issue by manually removing the hdinsightwatchdog domain user and adding it back again with Ambari Admin access for the cluster with 401 issue (phbs01adlbatch), and regarding the other cluster (phsp02adlspark) where the OMS installation was failing on a particual node we were able to restart the node in question and get past the blocker. ",,,,,,,,
1.20042E+14,47:24.4,"HDInsight service redeployed lb gateway 5 hours ago. Since then Yarn, Livy & all other endpoints cannot be reached through -int gateway","Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 23, 2020, 7:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Attempted to reboot all cluster services in Ambari. Gaateway endpoints for internal components are still inaccessible.\n\nQuestion: Additional details about the issue\nAnswer: This issue is persistant as of this morning, ever since the  HDInsight service updated the load balancers.\n\nWe can access the Ambari UI only from the internal endpoint of https://rs-dev-spark-int.azurehdinsight.net\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Attempted to reboot all cluster services in Ambari. Gaateway endpoints for internal components are still inaccessible.;\nAdditional details about the issue - This issue is persistant as of this morning, ever since the  HDInsight service updated the load balancers.\n\nWe can access the Ambari UI only from the internal endpoint of https://rs-dev-spark-int.azurehdinsight.net;\n\n- ProblemStartTime: 04/23/2020 11:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EA Development - Prism\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/928a77fe-5eca-48fe-a2fb-b1271a48c266/resourceGroups/US-AZU02-PRISM-DEV-HDINSIGHT-RG/providers/Microsoft.HDInsight/clusters/rs-dev-spark\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","HDInsight service redeployed lb gateway 5 hours ago. Since then Yarn, Livy & all other endpoints cannot be reached through -int gateway",0.172414496,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to run Spark jobs on the cluster.  Active ResourceManager using between 200 and 300 percent CPU,"ATS was configured with two versions; the newest of which uses HBase as the timeline store.  However, the cluster wasn't configured to use HBase as a timeline store, which caused thousands of ZK exceptions.","Changed yarn.timeline-service.versions parameter to exclude the 2.0f version, and restarted ATS",,,,,,,,
1.20042E+14,26:19.0,Spark Job failing,"Question: What time did the problem begin?\nAnswer: Wed, Apr 22, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: {AlphanumericPII}'\n{EmailPII}@SGAZUREPRD.ONMICROSOFT.COM\nQUEUE=default\nMASTER=yarn\nMODE=client\n{ALPHANUMERICPII}\n{ALPHANUMERICPII}\n{ALPHANUMERICPII}\n\nQuestion: Additional details about the issue\nAnswer: Spark jobs are failing dur to this error:\n\nCaused by: Operation failed: 'This request is not authorized to perform this operation.', 403, PUT, https://fy36manichd7rk4spprivate.dfs.core.windows.net/\n\nIt seems like a token renewal issue, restarting the job does not resolve the issue anymore\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - {AlphanumericPII}'\n{EmailPII}@SGAZUREPRD.ONMICROSOFT.COM\nQUEUE=default\nMASTER=yarn\nMODE=client\n{ALPHANUMERICPII}\n{ALPHANUMERICPII}\n{ALPHANUMERICPII};\nAdditional details about the issue - Spark jobs are failing dur to this error:\n\nCaused by: Operation failed: 'This request is not authorized to perform this operation.', 403, PUT, https://fy36manichd7rk4spprivate.dfs.core.windows.net/\n\nIt seems like a token renewal issue, restarting the job does not resolve the issue anymore;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/21/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bb2d7f3e-9ba8-448e-8a3a-2c0c8068df59/resourceGroups/dat-drm-i2r-1-PROD-spark-i2r-creditrisk-prd-1-Automation-HDI/providers/Microsoft.HDInsight/clusters/n72Cb4L3tC-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Job failing,0.160127619,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Spark Job failing,Spark Job failing,Customer confirmed that they found bug on their end and working on fixing the bug and confirmed to close the case.,,,,,,,,
1.20042E+14,56:11.0,***Advisory Case***Azure HDInsight Cluster connectivity from SAS EG Server,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 2, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Connection string being used\nAnswer: NA\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: No\n\nQuestion: Additional details about the issue\nAnswer: Please provide us with the drivers and steps on how to connect to Azure HDInight {Namepii} from a SAS Enterprise Guide Server.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - Yes;\nConnection string being used - NA;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - No;\nAdditional details about the issue - Please provide us with the drivers and steps on how to connect to Azure HDInight {Namepii} from a SAS Enterprise Guide Server.;\n\n- ProblemStartTime: 04/02/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/71aacd49-ff43-4567-9a08-b93980f13225/resourceGroups/Common01-PROD/providers/Microsoft.HDInsight/clusters/ana02spark36datahubpr01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",***Advisory Case***Azure HDInsight Cluster connectivity from SAS EG Server,0.029456044,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to standard cluster,***Advisory Case***Azure HDInsight Cluster connectivity from SAS EG Server,NA,MS Azure doesn't support the integrity of SAS DB at this time.,,,,,,,,
1.20042E+14,00:22.7,Production HDI cluster ambari UI and metrics missing/slow,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 23, 2020, 10:55 AM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted ambari metrics on head node 01.  \n\nQuestion: Additional details about the issue\nAnswer: This issue has cropped up intermittently, trying to find a long term solution.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted ambari metrics on head node 01.  ;\nAdditional details about the issue - This issue has cropped up intermittently, trying to find a long term solution.;\n\n- ProblemStartTime: 04/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Allocation-Prod/providers/Microsoft.HDInsight/clusters/prdalh-azwus-prd-allocation-hdihbase001\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Production HDI cluster ambari UI and metrics missing/slow,0.032781719,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Metrics are missing\Hbase,Production HDI cluster ambari UI and metrics missing/slow,Metrics collector heap size issue,"You can increase the metrics collector heap size by going to Ambari > Ambari metrics > configs > search for ""metrics_collector_heapsize"" >> change the heap to 3072 (+1 gb)  ",,,,,,,,
1.20042E+14,02:30.3,"node wn0-pro-ka(192.168.15.12) is unreachable, no ssh acces, no ping response, ambari shows node as heartbeat lost","Question: What time did the problem begin?\nAnswer: jue., 23 de abr. de 2020 15:25 {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: node worker is unreachable wn0-pro-ka(192.168.15.12), no ssh or ping response. ambari shows node as unreachable\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - node worker is unreachable wn0-pro-ka(192.168.15.12), no ssh or ping response. ambari shows node as unreachable;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/23/2020 18:25:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Fastdata\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1303336b-a198-4847-90f3-be74f817474d/resourceGroups/Pro-Novum-Net-RG/providers/Microsoft.HDInsight/clusters/pro-kafka-uru\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","node wn0-pro-ka(192.168.15.12) is unreachable, no ssh acces, no ping response, ambari shows node as heartbeat lost",0.020007646,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,"120042321002261 - node wn0-pro-ka(192.168.15.12) is unreachable, no ssh acces, no ping response, ambari shows node as heartbeat lost HDInsight Service",Wn0 had gone unresponsive,Performed a reboot of the worker node 0 and the zookeeper node 0 as both were showing heartbeat lost,,,,,,,,
1.20042E+14,23:31.6,Error getting while accessing tokenmanager end point,"Question: What time did the problem begin?\nAnswer: Wed, Apr 22, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 22, 2020, 11:00 PM MST\n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: No\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: This shell script is working fine when i just ran from the command line but not from oozie service. When I am running using oozie service, getting the below error. \n\n\n20/04/23 18:14:18 ERROR secure.AbstractCredentialServiceCaller: Error while authenticating with endpoint: https://hn1-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM\norg.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: https://hn1-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII} Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(Unknown Source)\nat com.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1570)\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1567)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}.submit({Namepii}.java:1567)\nat org.apache.hadoop.mapreduce.{Namepii}.waitForCompletion({Namepii}.java:1588)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 38 more\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 39 more\n20/04/23 18:14:18 ERROR tool.ImportTool: Import failed: java.io.IOException: Authentication Failed: \nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII} Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(Unknown Source)\nat com.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1570)\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1567)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}.submit({Namepii}.java:1567)\nat org.apache.hadoop.mapreduce.{Namepii}.waitForCompletion({Namepii}.java:1588)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - No;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - This shell script is working fine when i just ran from the command line but not from oozie service. When I am running using oozie service, getting the below error. \n\n\n20/04/23 18:14:18 ERROR secure.AbstractCredentialServiceCaller: Error while authenticating with endpoint: https://hn1-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM\norg.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: https://hn1-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM\nat {AlphanumericPII} Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII} Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(Unknown Source)\nat com.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1570)\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1567)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}.submit({Namepii}.java:1567)\nat org.apache.hadoop.mapreduce.{Namepii}.waitForCompletion({Namepii}.java:1588)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 38 more\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\n... 39 more\n20/04/23 18:14:18 ERROR tool.ImportTool: Import failed: java.io.IOException: Authentication Failed: \nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII} Source)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat com.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(Unknown Source)\nat com.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(Unknown Source)\nat {AlphanumericPII} Source)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1570)\nat org.apache.hadoop.mapreduce.{Namepii}$11.run({Namepii}.java:1567)\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.mapreduce.{Namepii}.submit({Namepii}.java:1567)\nat org.apache.hadoop.mapreduce.{Namepii}.waitForCompletion({Namepii}.java:1588)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n;\n\n- ProblemStartTime: 04/23/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error getting while accessing tokenmanager end point,0.046717524,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Throws GSS excepttion when running for OozieCaused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt),Error getting while accessing tokenmanager end point,Recommended to use to kinit step at the beginning shell script and after that it  is started wokring fine,,,,,,,,
1.20042E+14,25:45.6,Adding Additiional Storage Account to exisitng Cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: We want to add additional storage account {Alphanumericpii} to existing cluster and need help on this\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We want to add additional storage account {Alphanumericpii} to existing cluster and need help on this\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - We want to add additional storage account {Alphanumericpii} to existing cluster and need help on this;\nMitigating actions taken so far - ;\nAdditional details about the issue - We want to add additional storage account {Alphanumericpii} to existing cluster and need help on this;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MRC Lower PLAT_TST\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e2553d79-7aba-4d88-956f-99380ce3f546/resourceGroups/RG_Enterprise_DataHub_qa/providers/Microsoft.HDInsight/clusters/mrcazedhhditeqa\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Adding Additiional Storage Account to exisitng Cluster,0.220189237,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in standard cluster",Adding Additiional Storage Account to exisitng Cluster,NA,"It's not possible to add additional storage such as Azure data lake storage Gen1 and azure data lake storage Gen2 to existing HDInsight cluster. But if you want, you can redeploy the cluster with additional storage.",,,,,,,,
1.20042E+14,46:32.9,Cluster scaling failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} scaling fails after running for couple of hours\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} scaling fails after running for couple of hours;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9e254b18-ae43-4b5c-be18-7ff89944d165/resourceGroups/xlc-azu-eus2-poc-edssbx-rg-computeesp-infa/providers/Microsoft.HDInsight/clusters/eds99poc-computeesp-cluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster scaling failing,20.66311406,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to scale up.  Either scale up happened and new node is removed.  Also keytab was not being copied over.  ,Cluster scaling is not able to be scaled using python script.,Requested customer to scale using portal and also remove the extra tool installation on their side.  Once the extra too installation was removed scaling was successful.  Also scaling from portal was successful as well.  Keytab for new cluster was successfully copied to new node.,187170536,,,,,,,
1.20042E+14,50:56.3,name node checkpoint errors in HDI cluster,"Question: What time did the problem begin?\nAnswer: Fri, Apr 24, 2020, 10:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Check https://etl-a-cas-hdi-spark-sec.azurehdinsight.net/ for detail.component_name                                         |definition_name               |host_name\n------------------------------------------------------------------------------------------------\nNAMENODE                                               |namenode_last_checkpoint      |hn0-etl-a.2zcwnjh1ab2edf4gydorgotlib.gx.internal.cloudapp.net\nNAMENODE                                               |namenode_last_checkpoint      |hn1-etl-a.2zcwnjh1ab2edf4gydorgotlib.gx.internal.cloudapp.net\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Check https://etl-a-cas-hdi-spark-sec.azurehdinsight.net/ for detail.component_name                                         |definition_name               |host_name\n------------------------------------------------------------------------------------------------\nNAMENODE                                               |namenode_last_checkpoint      |hn0-etl-a.2zcwnjh1ab2edf4gydorgotlib.gx.internal.cloudapp.net\nNAMENODE                                               |namenode_last_checkpoint      |hn1-etl-a.2zcwnjh1ab2edf4gydorgotlib.gx.internal.cloudapp.net;\n\n- ProblemStartTime: 04/24/2020 04:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsRG-sec/providers/Microsoft.HDInsight/clusters/etl-a-cas-hdi-spark-sec\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",name node checkpoint errors in HDI cluster,0.495436003,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Service unhealthy\Hadoop,name node checkpoint alerts in AMbari,name node checkpoint is not happening,"Recommended to run the manual checkpoint reset by making sure both Namenodes are running state,hdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode enterhdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -saveNamespacehdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode leave",,,,,,,,
1.20042E+14,42:56.8,App team not able to run their webjobs,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 23, 2020, 8:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: App team not able to restart the web jobs and giving errors that unable to make a connection with zookeeper.\nPFA logs for datalogger and trends webjob.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - {Namepii};\nAdditional details about the issue - App team not able to restart the web jobs and giving errors that unable to make a connection with zookeeper.\nPFA logs for datalogger and trends webjob.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/23/2020 14:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT Integration\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/840e8a25-1606-485e-9525-6b4c49bb954f/resourceGroups/int-vims-cat-rg-01/providers/Microsoft.HDInsight/clusters/int-ts-vims-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",App team not able to run their webjobs,11.17860145,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hbase,App team not able to restart the web jobs and giving errors that unable to make a connection with zookeeper.PFA logs for datalogger and trends webjob. ,The customer has degraded Azure App services tier from Standard to Basic which removed VNet Integration needed to connect to HDInsight VNet and Zookeeper nodes from webjobs.,"Upgrading App services tier to Standard and reconfiguring VNet Integration resolved the connectivity issue.More info:https://docs.microsoft.com/en-us/azure/app-service/web-sites-integrate-with-vnetThe VNet Integration features:Require a Standard, Premium, PremiumV2, or Elastic Premium pricing plan.Support TCP and UDP.Work with Azure App Service apps and function apps. ","185,484,275,185,934,000,000,000,000",,,,,,,
1.20042E+14,43:31.6,Unable to create HDInsight Hadoop Cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: edfnparchive\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: HDInsight Hadoop cluster deployment fails with below status. Couldn't fine any additional information. \n\n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'FailedToConnectWithClusterErrorCode',\n                'message': 'Unable to connect to cluster management endpoint. Please retry later.'\n            }\n        ]\n    }\n}\n\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - edfnparchive;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - HDInsight Hadoop cluster deployment fails with below status. Couldn't fine any additional information. \n\n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'FailedToConnectWithClusterErrorCode',\n                'message': 'Unable to connect to cluster management endpoint. Please retry later.'\n            }\n        ]\n    }\n}\n\n\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/08f86b81-3c2e-4e01-9fd0-1561ccfdf88f/resourceGroups/EDH-HDInsight/providers/Microsoft.HDInsight/clusters/edfnparchive\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to create HDInsight Hadoop Cluster,0.237331102,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to access the Ambari UI,Unable to access the cluster due to missing IP addresses in route table,"Recommended to specify in a route to allow outbound traffic from the virtual network to the all 6 IPs with the next hop set to ""Internet"" like mentioned in the following link - https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses",,,,,,,,
1.20042E+14,38:01.0,Failed to submit job,"Question: What time did the problem begin?\nAnswer: Fri, Apr 17, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Message,'LogId,SubmitJobInternal_MeetException,,LogTime,2020-04-24 16:17:59.786,LogOrder,216746,{Namepii},lh001-prodcushdis1,JobId,e94772a69be84f1a8adbede5b93bbb19_1_1_3_1,Error,System.AggregateException: One or more errors occurred. System.AggregateException: One or more errors occurred.  Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: The job is submitted using HDinsight SDK, below is the full error message. Same error also happen on another cluster {alphanumericpii} in this subscription. \n\nMessage,'LogId,SubmitJobInternal_MeetException,,LogTime,2020-04-24 16:17:59.786,LogOrder,216746,{Namepii},lh001-prodcushdis1,JobId,e94772a69be84f1a8adbede5b93bbb19_1_1_3_1,Error,System.AggregateException: One or more errors occurred. System.AggregateException: One or more errors occurred. Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations.SubmitHiveJobAsyncd__2.MoveNext()\n --- End of inner exception stack trace ---\n at {AlphanumericPII} waitCompletionNotification)\n at Microsoft.Office.Compliance.ComputingPlatform.HiveJobSubmitter.SubmitJob()\n at {AlphanumericPII}()\n at System.Threading.Tasks.Task.Execute()\n --- End of inner exception stack trace ---\n at {Alphanumericpii} millisecondsTimeout. CancellationToken cancellationToken)\n at {Alphanumericpii} millisecondsTimeout)\n at Microsoft.Office.Compliance.ComputingPlatform.HdiComputingJobMgtClient.SubmitJobInternal(BaseJobSubmitter jobSubmitter)\n at Microsoft.Office.Compliance.ComputingPlatform.HdiComputingJobMgtClient.SubmitJob(ComputingJobResource jobResources. JobDescription jobDescription. {AlphanumericPII} jobParams. {AlphanumericPII} defines. {AlphanumericPII} additionalParams)\n (Inner Exception #0) System.AggregateException: One or more errors occurred. ---  Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations. SubmitHiveJobAsync {AlphanumericPII}()\n --- End of inner exception stack trace ---\n at {AlphanumericPII} waitCompletionNotification)\n at Microsoft.Office.Compliance.ComputingPlatform.HiveJobSubmitter.SubmitJob()\n at {AlphanumericPII}()\n at System.Threading.Tasks.Task.Execute()\n (Inner Exception #0) Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations. SubmitHiveJobAsync {AlphanumericPII}()\n\n',{AlphanumericPII}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Message,'LogId,SubmitJobInternal_MeetException,,LogTime,2020-04-24 16:17:59.786,LogOrder,216746,{Namepii},lh001-prodcushdis1,JobId,e94772a69be84f1a8adbede5b93bbb19_1_1_3_1,Error,System.AggregateException: One or more errors occurred. System.AggregateException: One or more errors occurred.  Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''};\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - The job is submitted using HDinsight SDK, below is the full error message. Same error also happen on another cluster {alphanumericpii} in this subscription. \n\nMessage,'LogId,SubmitJobInternal_MeetException,,LogTime,2020-04-24 16:17:59.786,LogOrder,216746,{Namepii},lh001-prodcushdis1,JobId,e94772a69be84f1a8adbede5b93bbb19_1_1_3_1,Error,System.AggregateException: One or more errors occurred. System.AggregateException: One or more errors occurred. Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations.SubmitHiveJobAsyncd__2.MoveNext()\n --- End of inner exception stack trace ---\n at {AlphanumericPII} waitCompletionNotification)\n at Microsoft.Office.Compliance.ComputingPlatform.HiveJobSubmitter.SubmitJob()\n at {AlphanumericPII}()\n at System.Threading.Tasks.Task.Execute()\n --- End of inner exception stack trace ---\n at {Alphanumericpii} millisecondsTimeout. CancellationToken cancellationToken)\n at {Alphanumericpii} millisecondsTimeout)\n at Microsoft.Office.Compliance.ComputingPlatform.HdiComputingJobMgtClient.SubmitJobInternal(BaseJobSubmitter jobSubmitter)\n at Microsoft.Office.Compliance.ComputingPlatform.HdiComputingJobMgtClient.SubmitJob(ComputingJobResource jobResources. JobDescription jobDescription. {AlphanumericPII} jobParams. {AlphanumericPII} defines. {AlphanumericPII} additionalParams)\n (Inner Exception #0) System.AggregateException: One or more errors occurred. ---  Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations. SubmitHiveJobAsync {AlphanumericPII}()\n --- End of inner exception stack trace ---\n at {AlphanumericPII} waitCompletionNotification)\n at Microsoft.Office.Compliance.ComputingPlatform.HiveJobSubmitter.SubmitJob()\n at {AlphanumericPII}()\n at System.Threading.Tasks.Task.Execute()\n (Inner Exception #0) Hyak.Common.CloudException: {''error'':''Submit job request got timed out. Please wait for some time before retrying the operation. Please refer to the config templeton.job.submit.timeout to configure job request time out.''}\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\n at Microsoft.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccess(Task task)\n at Microsoft.Azure.Management.HDInsight.{Namepii}.JobOperations. SubmitHiveJobAsync {AlphanumericPII}()\n\n',{AlphanumericPII};\n\n- ProblemStartTime: 04/17/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6badb839-6f75-4bd8-8500-cc74edea278d/resourceGroups/ResourceGroup-PRODCUSHDIS1/providers/Microsoft.HDInsight/clusters/lh000-prodcushdis1\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failed to submit job,3.162384572,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,Failed to submit job.,NA,We have cleaned up the zookeeper issues and the cluster is healthy now.,,,,,,,,
1.20043E+14,11:39.9,OOM and Java heap size issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: ODBC/JDBC\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: OOM and {Namepii} heap size issues\n\nQuestion: Additional details about the issue\nAnswer: OOM and {Namepii} heap size issues\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - ODBC/JDBC;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - OOM and {Namepii} heap size issues;\nAdditional details about the issue - OOM and {Namepii} heap size issues;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps020sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",OOM and Java heap size issues,0.439156594,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,"Vertex failed, vertexName=Map 9, vertexId=vertex_1587680811081_0480_1_02, diagnostics=[Task failed, taskId=task_1587680811081_0480_1_02_000003, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : java.lang.RuntimeException: Map operator initialization failed",OOM and Java heap size issues,Recommended to set hive.auto.convert.join to false,,,,,,,,
1.20043E+14,09:51.0,exporting HDI Cluster TEZ view logs,"We would like to know the possible ways to export the TEZ view logs for HDI cluster as a report and understand if there are any other logs that could help determine the number queries being handled by the cluster, time taken to run etc.\nYou could submit this mentioning any of our production cluster as scope.\n\n\nProblem start date and time\nFri, Apr 24, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/23/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",exporting HDI Cluster TEZ view logs,1.771782646,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,advisory,advisory, I understand we currently do not have this feature to download the tezview UI entries as a report so please go ahead and close this case,,,,,,,,
1.20043E+14,09:32.4,Data injestion LockExceptions ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted)\n\nQuestion: Additional details about the issue\nAnswer: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted);\nAdditional details about the issue - org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted);\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq040sparkfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Data injestion LockExceptions ,0.003028317,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Spark,Data injestion LockExceptions:,hive.direct.sql.max.elements.in.clause=1000hive.direct.sql.max.elements.values.clause=1000,Removed and re-added the below configs in Ambari Hive Advanced config setting. hive.direct.sql.max.elements.in.clause=100hive.direct.sql.max.elements.values.clause=100,,,,,,,,
1.20043E+14,36:29.8,Unable to connect to beeline ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 23, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: beeline -u 'jdbc:hive2://zk1-chsp90.domainservices.ncr.com:2181,zk2-chsp90.domainservices.ncr.com:2181,zk4-chsp90.domainservices.ncr.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2'\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to connect  to beeline \nError:\nInitiating client connection, connectString=zk1-chsp90.domainservices.ncr.com:2181,zk2-chsp90.domainservices.ncr.com:2181,zk4-chsp90.domainservices.ncr.com:2181 {AlphanumericPII} {AlphanumericPII}\n20/04/27 12:30:43 INFO ClientCnxn: Opening socket connection to server zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181. Will not attempt to authenticate using SASL (unknown error)\n20/04/27 12:30:43 INFO ClientCnxn: Socket connection established, initiating session, client: /{Alphanumericpii}, server: zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181\n20/04/27 12:30:43 INFO ClientCnxn: Session establishment complete on server zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181, sessionid = {Alphanumericpii}, negotiated timeout = 60000\n20/04/27 12:30:43 INFO ConnectionStateManager: State change: CONNECTED\n20/04/27 12:30:43 INFO CuratorFrameworkImpl: backgroundOperationsLoop exiting\n20/04/27 12:30:43 INFO ZooKeeper: Session: {Alphanumericpii} closed\n20/04/27 12:30:43 INFO ClientCnxn: EventThread shut down\n20/04/27 12:30:43 INFO Utils: Resolved authority: hn1-chsp90.domainservices.ncr.com:10001\n20/04/27 12:30:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - beeline -u 'jdbc:hive2://zk1-chsp90.domainservices.ncr.com:2181,zk2-chsp90.domainservices.ncr.com:2181,zk4-chsp90.domainservices.ncr.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2';\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - Unable to connect  to beeline \nError:\nInitiating client connection, connectString=zk1-chsp90.domainservices.ncr.com:2181,zk2-chsp90.domainservices.ncr.com:2181,zk4-chsp90.domainservices.ncr.com:2181 {AlphanumericPII} {AlphanumericPII}\n20/04/27 12:30:43 INFO ClientCnxn: Opening socket connection to server zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181. Will not attempt to authenticate using SASL (unknown error)\n20/04/27 12:30:43 INFO ClientCnxn: Socket connection established, initiating session, client: /{Alphanumericpii}, server: zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181\n20/04/27 12:30:43 INFO ClientCnxn: Session establishment complete on server zk1-chsp90.domainservices.ncr.com/135.137.100.149:2181, sessionid = {Alphanumericpii}, negotiated timeout = 60000\n20/04/27 12:30:43 INFO ConnectionStateManager: State change: CONNECTED\n20/04/27 12:30:43 INFO CuratorFrameworkImpl: backgroundOperationsLoop exiting\n20/04/27 12:30:43 INFO ZooKeeper: Session: {Alphanumericpii} closed\n20/04/27 12:30:43 INFO ClientCnxn: EventThread shut down\n20/04/27 12:30:43 INFO Utils: Resolved authority: hn1-chsp90.domainservices.ncr.com:10001\n20/04/27 12:30:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/23/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHSP90ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect to beeline ,31.21223588,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,unable to connect to cluster,Corrupted Zookeepr configs shown to have been done by user,drop and recreate cluster,,,,,,,,
1.20043E+14,54:18.0,Cluster Deployments are failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: 2 separate issues - the gateway issue was fixed {Phonenumberpii} and has returned the VM issue appears to be new.\n\nSee attached for cluster id and errors\n\nThis is intermittent and does not happen all the time but enough to cause production issues.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} {Namepii} Chakrapani (EEE) suggested this frequently has to do with the customer’s VNET and he suggested opening an SR to troubleshoot and potentially keep it from reoccurring\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - 2 separate issues - the gateway issue was fixed {Phonenumberpii} and has returned the VM issue appears to be new.\n\nSee attached for cluster id and errors\n\nThis is intermittent and does not happen all the time but enough to cause production issues.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - {Namepii} {Namepii} Chakrapani (EEE) suggested this frequently has to do with the customer’s VNET and he suggested opening an SR to troubleshoot and potentially keep it from reoccurring;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Production Classic\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster Deployments are failing,2.959560081,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,HDInsight clusters periodically fail provisioning with the following error:VmGroup overprovisioning has Failed for VmGroup gateway with code = TimedOut. Status code before timeout is NotEnoughVmsHaveProvisioningAgentUp.,The failure is caused by the ProvisiongingAgent failing to start due to a timeout.  The ProvisioningAgent is a Windows service that runs on the Gateway nodes. The timeout is occurring because it sometimes takes the ProvisioningAgent more than 30 seconds to start.  Elongated startup times can occur when many services are competing for system resources when a VM first comes online and goes through startup. ,The HDInsight Engineering team have a fix ready for the issue they plan to deploy the first week of June 2020.,185875097,,,,,,,
1.20043E+14,54:18.8,Script Action is failing on HDI cluster - cmiprodllapdj,"Question: What time did the problem begin?\nAnswer: Sun, Apr 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: Any customization applied\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Script action is failing. Script Action loacated on the SA: cmiprdhdiscripts.blob.core.windows.net / prd / llapprd01djenterpriseprd.sh\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - ;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nAny customization applied - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Script action is failing. Script Action loacated on the SA: cmiprdhdiscripts.blob.core.windows.net / prd / llapprd01djenterpriseprd.sh;\n\n- ProblemStartTime: 04/25/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Prod_DR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cca3be6-ea39-4394-9aab-242213bd98e5/resourceGroups/enterprise-prd/providers/Microsoft.HDInsight/clusters/cmiprodllapdj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Script Action is failing on HDI cluster - cmiprodllapdj,0.071564325,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,Failed to validate script action at URI https://cmiprdhdiscripts.blob.core.windows.net/prd/llapprd01djenterpriseprd/llapprd01djenterpriseprd.sh?sv=2019-02-02&ss=bqtf&srt=sco&sp=rwdlacup&se=2020-04-27T05:41:19Z&sig=bj9Vg4OzL5%2BxHNfSbDrc0WfL20i5fwFnUL2V%2F7nH4CI%3D&_=1587937288360. Exception message: Script URI cannot be retrieved correctly. HTTP Status code: Forbidden.,"The storage account configuration is external to the clusters, it also has a firewall configured to be accessed only by known accounts.","Whitelist the followed IP's on the SA firewall:- 100.119.2.16- 100.118.200.28Note: It is important to mention that the origin of these IPs is unknown, it will be necessary to raise an IcM with SA team. During the troubleshooting in kusto we obtained that the SAS URL for scripts been rejected comes from these IP's directly from the storage account. These IP's can be different for each client needs to check on Kusto.",187137079,,,,,,,
1.20043E+14,39:55.3,Please upgrade cluster size to additional 7 Nodes,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 27, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: While trying to upscale am facing issues, saying there is no available cores for all the below 3 clusters:\n\n1. {alphanumericpii}\n2. {alphanumericpii}\n3. {alphanumericpii}\n\nPlease upscale the cluster size as below:\n1. {alphanumericpii} - To add 10 Nodes to current size [{ALPHANUMERICPII}]\n\n2. {alphanumericpii} - To add 28 Nodes to current size [{ALPHANUMERICPII}]\n\n3. {alphanumericpii} - To add 4 Nodes to current size [{ALPHANUMERICPII}]\n\n\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - While trying to upscale am facing issues, saying there is no available cores for all the below 3 clusters:\n\n1. {alphanumericpii}\n2. {alphanumericpii}\n3. {alphanumericpii}\n\nPlease upscale the cluster size as below:\n1. {alphanumericpii} - To add 10 Nodes to current size [{ALPHANUMERICPII}]\n\n2. {alphanumericpii} - To add 28 Nodes to current size [{ALPHANUMERICPII}]\n\n3. {alphanumericpii} - To add 4 Nodes to current size [{ALPHANUMERICPII}]\n\n\n\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/26/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/USEDFSOFINRSG02/providers/Microsoft.HDInsight/clusters/usedfsofinhdi0a\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Please upgrade cluster size to additional 7 Nodes,0.038642669,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,unable to scale up. clusters,usedfsofinhdi0a à Failed as the Subnet is full and does not have any space left to add new nodes to it. Subnet in question:  /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/NetworksFSOe/providers/Microsoft.Network/virtualNetworks/USEDADVSENVNT01/subnets/USEDFSOFINSBN04Solution: In order to create space on the virtual network please do one of the three steps below:·        Delete unused resources within the subnet opening up IP addresses that can be utilized for the cluster scaling·        Add a subnet and create a new HDInsight cluster within the newly created subnet·        Change subnet settings to the existing virtual network to include a larger address space useqfsofinhdi04 à Failed with Cores availability in East US region  (ERROR: Cannot process request for additional '20' cores in region 'East US'. Max cores allowed '250' and subscription is already using '236' cores)                                      Solution : I can put in a request to increase the cores in East US region. ,increased for HDInsight cores in the East US region for the below two subscriptions:  371211a1-ad00-47d9-bcbd-3f302dfcc9b9 – Additional 250 cores = total 500 698a551a-d866-4efc-8411-2f6a9972341a – Additional 100 cores  = total 500 ,,,,,,,,
1.20043E+14,44:10.0,HeadNode0 rebooted over the weekend caused bunch of production jobs failed,"Question: What time did the problem begin?\nAnswer: Sun, Apr 26, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sun, Apr 26, 2020, 11:00 PM MST\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: No\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: \n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have seen {alphanumericpii} been rebooted over the weekend with out any notice which caused bunch of production jobs failed with TGT errors while acessing the ADLS {Alphanumericpii} account\n\n{emailpii}@hn0-aa-esp:~$ uptime\n 18:42:19 up 2 days,  3:40, 11 users,  load average: 4.87, 5.02, 5.34\n\n\nWe need to know the RCA on why this host node restarted with out our notice and how we can stop this not happening in future. Do we have any alert mechanism we could set or send to us whenever it rebooted in future.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - No;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - ;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We have seen {alphanumericpii} been rebooted over the weekend with out any notice which caused bunch of production jobs failed with TGT errors while acessing the ADLS {Alphanumericpii} account\n\n{emailpii}@hn0-aa-esp:~$ uptime\n 18:42:19 up 2 days,  3:40, 11 users,  load average: 4.87, 5.02, 5.34\n\n\nWe need to know the RCA on why this host node restarted with out our notice and how we can stop this not happening in future. Do we have any alert mechanism we could set or send to us whenever it rebooted in future.;\n\n- ProblemStartTime: 04/27/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HeadNode0 rebooted over the weekend caused bunch of production jobs failed,0.146180001,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",120042724004133 - HeadNode0 rebooted over the weekend caused bunch of production jobs failed HDInsight Service,"Upon investigation, this unexpected occurrence was caused by a user-initiated reboot action. The reboot was triggered by an authorized user or process via either Azure Portal or Azure Resource Manager interfaces. As a result, your VM was rebooted. RDP connections to the VM, or requests to any other services running inside the VM may have failed during this time. Since the headnode has failed over multiple times within the past week, it looks like there is a resource constraint on the cluster.","Recommendations:The HDInsight Virtual Machines (VMs) are pre-configured to reboot during an out of memory scenario. If no one within your organization initiated a reboot of the headnode, then I would suggest using a memory monitoring tool such as 'free -h', Datadog, or Azure Monitor. This will allow us to see when/if the VMs are running into out-of-memory issues. Azure Monitor for HDInsight clusters:https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-oms-log-analytics-tutorial DataDog link:https://docs.datadoghq.com/integrations/azure/?tab=azurecliv20#overview Resolution:Customer is working on script to send alerts if any process/application uses more memory and schedule it to run every 1 hour.",,,,,,,,
1.20043E+14,47:58.9,Implement POSIX recursively in Gen2 using storage explorer or any  hdfs commands,"Question: What time did the problem begin?\nAnswer: Sun, Apr 26, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sun, Apr 26, 2020, 11:00 PM MST\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: \n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We need some help/process which we can use to apply POSIX on {Alphanumericpii} account recusively for all folders/childs. We are using Storage explorer but it is not applying POSIX recursivly for all child folder if we already created them in the account. \n\nPlease let us know if there is way we could apply these POSIX recursively on all folders using HDFS/Storage explorer\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - ;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We need some help/process which we can use to apply POSIX on {Alphanumericpii} account recusively for all folders/childs. We are using Storage explorer but it is not applying POSIX recursivly for all child folder if we already created them in the account. \n\nPlease let us know if there is way we could apply these POSIX recursively on all folders using HDFS/Storage explorer;\n\n- ProblemStartTime: 04/27/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Implement POSIX recursively in Gen2 using storage explorer or any  hdfs commands,0.023890604,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",cannot assign ACLs,user permissions issue,grant blob storage data owner,,,,,,,,
1.20043E+14,25:21.7,Deleted HDFS Data and need to recover ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 27, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: MapReduce\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Deleted hdfs data and needs to be recovered asap \nPlease assign to storage team \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - MapReduce;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Deleted hdfs data and needs to be recovered asap \nPlease assign to storage team ;\n\n- ProblemStartTime: 04/27/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Deleted HDFS Data and need to recover ,0.028152039,Root Cause : HDInsight Service\HDInsight Custom configuration,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie",Deleted HDFS Data and need to recover,Not related to HDInsight,Not related to HDInsight - CX opened a new case to the storage team,,,,,,,,
1.20043E+14,12:19.2,Cluster unavailable,"Question: What time did the problem begin?\nAnswer: Fri, Apr 24, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: headnode storage is full.  sshuser password expired.  unable to reset password to free up space.  all services are down.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - headnode storage is full.  sshuser password expired.  unable to reset password to free up space.  all services are down.;\n\n- ProblemStartTime: 04/24/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e56a92fa-5993-43a3-95e9-244023388b90/resourceGroups/PROD-HDINSIGHTS-GROUP/providers/Microsoft.HDInsight/clusters/prodhdiiq\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster unavailable,0.16029899,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Cluster unavailable.,NA,We have rebooted head nodes from the backend. All the services restarted and cluster is up and running.,186033543,,,,,,,
1.20043E+14,42:03.3,Jobs hanging at 100% for hours,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: create table {alphanumericpii} ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' STORED AS TEXTFILE as select TT.*, MCSG.MPI as mcsg_mpi from lab_result_filtered_managed_ts TT left join {AlphanumericPII} MCSG on TT.patient_account_id = MCSG.accid_ref where MCSG.accid_ref is not null and MCSG.accid_ref NOTEQUAL ''\n\nQuestion: Hive query explain plan if available\nAnswer: explain create table {alphanumericpii} ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' STORED AS TEXTFILE as select TT.*, MCSG.MPI as mcsg_mpi from lab_result_filtered_managed_ts TT left join {AlphanumericPII} MCSG on TT.patient_account_id = MCSG.accid_ref where MCSG.accid_ref is not null and MCSG.accid_ref @@ ''\n0: \n| Plan not optimized by CBO.                                                                                                                                                                                                                                                                                                                           |\n|                                                                                                                                                                                                                                                                                                                                                      |\n| Vertex dependency in root stage                                                                                                                                                                                                                                                                                                                      |\n| Reducer 2 @- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)                                                                                                                                                                                                                                                                                                |\n|                                                                                                                                                                                                                                                                                                                                                      |\n| {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                              |\n|    Stats-Aggr Operator                                                                                                                                                                                                                                                                                                                               |\n|       {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                        |\n|          Create Table Operator:                                                                                                                                                                                                                                                                                                                      |\n|             columns:['source string','source_type string','mpi string','lab_id string','accession_id string','laboratory_id string','unit string','range string','value string','abnormal string','status string','time string','patient_account_id string','mcsg_mpi string']                                                                       |\n|             input format:org.apache.hadoop.mapred.TextInputFormat                                                                                                                                                                                                                                                                                    |\n|             {alphanumericpii}                                                                                                                                                                                                                                                                                     |\n|             output format:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat                                                                                                                                                                                                                                                                     |\n|             {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                  |\n|                Dependency Collection{}                                                                                                                                                                                                                                                                                                               |\n|                   {Alphanumericpii}                                                                                                                                                                                                                                                                                                                            |\n|                      Reducer 2                                                                                                                                                                                                                                                                                                                       |\n|                      File Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                  |\n|                         compressed:false                                                                                                                                                                                                                                                                                                             |\n|                         Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                                  |\n|                         {alphanumericpii} format:':'org.apache.hadoop.mapred.TextInputFormat','output format:':'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat','serde:':'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'}                                                     |\n|                         Select Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                   |\n|                            outputColumnNames:['_col0','_col1','_col2','_col3','_col4','_col5','_col6','_col7','_col8','_col9','_col10','_col11','_col12','_col13']                                                                                                                                                                                   |\n|                            Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                               |\n|                            Filter Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                |\n|                               {alphanumericpii} @@ '') (type: boolean)                                                                                                                                                                                                                                                                               |\n|                               Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                            |\n|                               Merge Join Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                   |\n|                               |  condition map:[{'':'Left Outer {Alphanumericpii} to 1'}]                                                                                                                                                                                                                                                                        |\n|                               |  {alphanumericpii} (type: {alphanumericpii} (type: string)'}                                                                                                                                                                                                                                       |\n|                               |  outputColumnNames:['_col0','_col1','_col2','_col3','_col4','_col5','_col6','_col7','_col8','_col9','_col10','_col11','_col12','_col16','_col19']                                                                                                                                                                    |\n|                               |  Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                         |\n|                               |@-Map 1 [SIMPLE_EDGE]                                                                                                                                                                                                                                                                                                 |\n|                               |  Reduce Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                    |\n|                               |     key expressions:patient_account_id (type: string)                                                                                                                                                                                                                                                                |\n|                               |     Map-reduce partition columns:patient_account_id (type: string)                                                                                                                                                                                                                                                   |\n|                               |     sort order:+                                                                                                                                                                                                                                                                                                     |\n|                               |     Statistics:Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE                                                                                                                                                                                                                                      |\n|                               |     value expressions:source (type: string), source_type (type: string), mpi (type: string), lab_id (type: string), accession_id (type: string), laboratory_id (type: string), unit (type: string), range (type: string), value (type: string), abnormal (type: string), status (type: string), time (type: string)  |\n|                               |     TableScan [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                              |\n|                               |        alias:tt                                                                                                                                                                                                                                                                                                      |\n|                               |        Statistics:Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE                                                                                                                                                                                                                                   |\n|                               |@-Map 3 [SIMPLE_EDGE]                                                                                                                                                                                                                                                                                                 |\n|                                  Reduce Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                    |\n|                                     key expressions:accid_ref (type: string)                                                                                                                                                                                                                                                                         |\n|                                     Map-reduce partition columns:accid_ref (type: string)                                                                                                                                                                                                                                                            |\n|                                     sort order:+                                                                                                                                                                                                                                                                                                     |\n|                                     Statistics:Num rows: 19201477 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                      |\n|                                     value expressions:mpi (type: string)                                                                                                                                                                                                                                                                             |\n|                                     TableScan [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                              |\n|                                        alias:mcsg                                                                                                                                                                                                                                                                                                    |\n|                                        Statistics:Num rows: 19201477 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                   |\n|             {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                  |\n|                Move Operator                                                                                                                                                                                                                                                                                                                         |\n|                    Please refer to the previous {Alphanumericpii}                                                                                                                                                                                                                                                                                              \n\n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} hangs at 100% for hours - need a way to see why it is hanging and to understand what I can do to avoid the hanging.\n\nPlease email me first to schedule a meeting for any discovery or recommendations.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - create table {alphanumericpii} ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' STORED AS TEXTFILE as select TT.*, MCSG.MPI as mcsg_mpi from lab_result_filtered_managed_ts TT left join {AlphanumericPII} MCSG on TT.patient_account_id = MCSG.accid_ref where MCSG.accid_ref is not null and MCSG.accid_ref NOTEQUAL '';\nHive query explain plan if available - explain create table {alphanumericpii} ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' STORED AS TEXTFILE as select TT.*, MCSG.MPI as mcsg_mpi from lab_result_filtered_managed_ts TT left join {AlphanumericPII} MCSG on TT.patient_account_id = MCSG.accid_ref where MCSG.accid_ref is not null and MCSG.accid_ref @@ ''\n0: \n| Plan not optimized by CBO.                                                                                                                                                                                                                                                                                                                           |\n|                                                                                                                                                                                                                                                                                                                                                      |\n| Vertex dependency in root stage                                                                                                                                                                                                                                                                                                                      |\n| Reducer 2 @- Map 1 (SIMPLE_EDGE), Map 3 (SIMPLE_EDGE)                                                                                                                                                                                                                                                                                                |\n|                                                                                                                                                                                                                                                                                                                                                      |\n| {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                              |\n|    Stats-Aggr Operator                                                                                                                                                                                                                                                                                                                               |\n|       {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                        |\n|          Create Table Operator:                                                                                                                                                                                                                                                                                                                      |\n|             columns:['source string','source_type string','mpi string','lab_id string','accession_id string','laboratory_id string','unit string','range string','value string','abnormal string','status string','time string','patient_account_id string','mcsg_mpi string']                                                                       |\n|             input format:org.apache.hadoop.mapred.TextInputFormat                                                                                                                                                                                                                                                                                    |\n|             {alphanumericpii}                                                                                                                                                                                                                                                                                     |\n|             output format:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat                                                                                                                                                                                                                                                                     |\n|             {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                  |\n|                Dependency Collection{}                                                                                                                                                                                                                                                                                                               |\n|                   {Alphanumericpii}                                                                                                                                                                                                                                                                                                                            |\n|                      Reducer 2                                                                                                                                                                                                                                                                                                                       |\n|                      File Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                  |\n|                         compressed:false                                                                                                                                                                                                                                                                                                             |\n|                         Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                                  |\n|                         {alphanumericpii} format:':'org.apache.hadoop.mapred.TextInputFormat','output format:':'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat','serde:':'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'}                                                     |\n|                         Select Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                   |\n|                            outputColumnNames:['_col0','_col1','_col2','_col3','_col4','_col5','_col6','_col7','_col8','_col9','_col10','_col11','_col12','_col13']                                                                                                                                                                                   |\n|                            Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                               |\n|                            Filter Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                                |\n|                               {alphanumericpii} @@ '') (type: boolean)                                                                                                                                                                                                                                                                               |\n|                               Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                            |\n|                               Merge Join Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                   |\n|                               |  condition map:[{'':'Left Outer {Alphanumericpii} to 1'}]                                                                                                                                                                                                                                                                        |\n|                               |  {alphanumericpii} (type: {alphanumericpii} (type: string)'}                                                                                                                                                                                                                                       |\n|                               |  outputColumnNames:['_col0','_col1','_col2','_col3','_col4','_col5','_col6','_col7','_col8','_col9','_col10','_col11','_col12','_col16','_col19']                                                                                                                                                                    |\n|                               |  Statistics:Num rows: 21121625 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                               ",,,,,,,,,,,,,,,
                                                         |\n|                               |@-Map 1 [SIMPLE_EDGE]                                                                                                                                                                                                                                                                                                 |\n|                               |  Reduce Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                    |\n|                               |     key expressions:patient_account_id (type: string)                                                                                                                                                                                                                                                                |\n|                               |     Map-reduce partition columns:patient_account_id (type: string)                                                                                                                                                                                                                                                   |\n|                               |     sort order:+                                                                                                                                                                                                                                                                                                     |\n|                               |     Statistics:Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE                                                                                                                                                                                                                                      |\n|                               |     value expressions:source (type: string), source_type (type: string), mpi (type: string), lab_id (type: string), accession_id (type: string), laboratory_id (type: string), unit (type: string), range (type: string), value (type: string), abnormal (type: string), status (type: string)," time (type: string)  |\n|                               |     TableScan [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                              |\n|                               |        alias:tt                                                                                                                                                                                                                                                                                                      |\n|                               |        Statistics:Num rows: 1 Data size: 0 Basic stats: PARTIAL Column stats: NONE                                                                                                                                                                                                                                   |\n|                               |@-Map 3 [SIMPLE_EDGE]                                                                                                                                                                                                                                                                                                 |\n|                                  Reduce Output Operator [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                    |\n|                                     key expressions:accid_ref (type: string)                                                                                                                                                                                                                                                                         |\n|                                     Map-reduce partition columns:accid_ref (type: string)                                                                                                                                                                                                                                                            |\n|                                     sort order:+                                                                                                                                                                                                                                                                                                     |\n|                                     Statistics:Num rows: 19201477 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                      |\n|                                     value expressions:mpi (type: string)                                                                                                                                                                                                                                                                             |\n|                                     TableScan [{ALPHANUMERICPII}]                                                                                                                                                                                                                                                                                              |\n|                                        alias:mcsg                                                                                                                                                                                                                                                                                                    |\n|                                        Statistics:Num rows: 19201477 Data size: {Ssnpii} Basic stats: COMPLETE Column stats: NONE                                                                                                                                                                                                                   |\n|             {Alphanumericpii}                                                                                                                                                                                                                                                                                                                                  |\n|                Move Operator                                                                                                                                                                                                                                                                                                                         |\n|                    Please refer to the previous {Alphanumericpii}                                                                                                                                                                                                                                                                                              \n;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - {Namepii} hangs at 100% for hours - need a way to see why it is hanging and to understand what I can do to avoid the hanging.\n\nPlease email me first to schedule a meeting for any discovery or recommendations.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA Team\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/twoprocesshistorical\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n""",Jobs hanging at 100% for hours,0.918468251,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Hive Jobs hanging at 100% for hours,Query was not good to execute.,Was able to allow the table to run by making one of the tables distinct with a select distinct * from table name after that it ran fine.
1.20043E+14,37:47.6,Root file system are getting filled with Credential service logs.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Root file system are getting filled with Credential service logs.\n\nQuestion: Additional details about the issue\nAnswer: Root file system are getting filled with Credential service logs.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Root file system are getting filled with Credential service logs.;\nAdditional details about the issue - Root file system are getting filled with Credential service logs.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Root file system are getting filled with Credential service logs.,0.815676272,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,Root file system are getting filled with Credential service logs.,Its a bug from jersey 1.9 version,"Edit the file /etc/hdinsight-credentialservice/conf/log4j.properties and add the below line at the end of it,log4j.logger.com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator=OFFRestart the credential service one after the other (give a gap of 1 min) from ambari after the log4j.properties file is updated.",186011877,,,,,,,
1.20043E+14,38:06.0,Cluster is in Applying Changes mode from last 5 days,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: We executed a script action to disable certain users in the cluster and cluster is in applying changes mode from last 5 days.\n\nQuestion: Additional details about the issue\nAnswer: We executed a script action to disable certain users in the cluster and cluster is in applying changes mode from last 5 days.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - We executed a script action to disable certain users in the cluster and cluster is in applying changes mode from last 5 days.;\nAdditional details about the issue - We executed a script action to disable certain users in the cluster and cluster is in applying changes mode from last 5 days.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is in Applying Changes mode from last 5 days,0.031122531,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,When running a script action cluster gets stuck in apply changes state,Cluster is unable to refresh the state to running.,Product Group had to change the state of the cluster to running.,186357240,,,,,,,
1.20043E+14,51:08.9,We are receving an alert for the Livy service on this node even though it is  in a stopped state and in matineance mode. ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 20, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: No actions have been taken.  No changes have been made to our knowledge in the last 8 days.\n\nQuestion: Additional details about the issue\nAnswer: We are receiving alerts from {ALPHANUMERICPII} in hn0 for ETL cluster in EU for the last 8 days. We are not sure why we are receiving this alert since the service is stopped. The hn0 node is the standby node and the {Alphanumericpii} service has been stopped and is in maintence mode. We were told to keep specific services stopped on the standby node by Microsoft. Please see screenshots for error.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - No actions have been taken.  No changes have been made to our knowledge in the last 8 days.;\nAdditional details about the issue - We are receiving alerts from {ALPHANUMERICPII} in hn0 for ETL cluster in EU for the last 8 days. We are not sure why we are receiving this alert since the service is stopped. The hn0 node is the standby node and the {Alphanumericpii} service has been stopped and is in maintence mode. We were told to keep specific services stopped on the standby node by Microsoft. Please see screenshots for error.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/20/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsEuRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi-eu\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are receving an alert for the Livy service on this node even though it is  in a stopped state and in matineance mode. ,0.133149629,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,We are receving an alert for the Livy service on this node even though it is in a stopped state and in matineance mode.,Custom alerting Alert is pulling logs from both the headnodes irrespective of the services kept down on purpose and in maintenance mode., Suggested the services to be left off and in maintenance mode as per HDI recommendations. Change the Alerting mechanism to be aware of HA components,,,,,,,,
1.20043E+14,15:49.4,Ambari Metrics Collector Service throwing alerts consistently ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ambari {Namepii} Collector service always throwing alerts. Not sure whether it is a genuine issues.\n\n{Namepii} Collector has been auto-started 6 times since 2020-04-28 17:25:22.\n\nConnection failed: [Errno 111] Connection refused to hn0-ahd501.azfrk.com:61310\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ambari {Namepii} Collector service always throwing alerts. Not sure whether it is a genuine issues.\n\n{Namepii} Collector has been auto-started 6 times since 2020-04-28 17:25:22.\n\nConnection failed: [Errno 111] Connection refused to hn0-ahd501.azfrk.com:61310\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Metrics Collector Service throwing alerts consistently ,0.037321254,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Ambari Metrics Collector Service throwing alerts consistently,hn0 was not responded,rebooted VM - hn0 and cleared AMS datahttps://cwiki.apache.org/confluence/display/AMBARI/Cleaning+up+Ambari+Metrics+System+Data+-+2.4.0,,,,,,,,
1.20043E+14,35:27.7,Credential token error for the service account which causing failures for production jobs,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 27, 2020, 11:00 PM {NAMEPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 27, 2020, 11:00 PM {NAMEPII}\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are getting some token errors for the production service account all of sudden which was causing all the streaming applications failing in the cluster. I am checking the credential services logs, found that service account token has been renwed at some point with out our intention. Please see the logs below. We need this to be fixed as soon as possible. \n\n2020-04-28 {Alphanumericpii} INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Token renewal for identifier: ADLS delegation token 74358 for svc-hdi_azure_aa; total currentTokens 16\n2020-04-28 {Alphanumericpii} ERROR org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager: No node in path [/{AlphanumericPII}]\n2020-04-28 {Alphanumericpii} ERROR {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider: UserProvider#getValue() failed:\norg.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 71484 for hive) can't be found in cache\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.checkToken(AbstractDelegationTokenSecretManager.java:410)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.retrievePassword(AbstractDelegationTokenSecretManager.java:422)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.verifyToken(AbstractDelegationTokenSecretManager.java:448)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGIFromToken({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGI({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.{namepii}.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:203)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)\n        at {AlphanumericPII})\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are getting some token errors for the production service account all of sudden which was causing all the streaming applications failing in the cluster. I am checking the credential services logs, found that service account token has been renwed at some point with out our intention. Please see the logs below. We need this to be fixed as soon as possible. \n\n2020-04-28 {Alphanumericpii} INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Token renewal for identifier: ADLS delegation token 74358 for svc-hdi_azure_aa; total currentTokens 16\n2020-04-28 {Alphanumericpii} ERROR org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager: No node in path [/{AlphanumericPII}]\n2020-04-28 {Alphanumericpii} ERROR {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider: UserProvider#getValue() failed:\norg.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 71484 for hive) can't be found in cache\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.checkToken(AbstractDelegationTokenSecretManager.java:410)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.retrievePassword(AbstractDelegationTokenSecretManager.java:422)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.verifyToken(AbstractDelegationTokenSecretManager.java:448)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGIFromToken({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGI({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.{namepii}.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:203)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)\n        at {AlphanumericPII});\n\n- ProblemStartTime: 04/28/2020 06:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/{NAMEPII}-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Credential token error for the service account which causing failures for production jobs,84.86737612,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Credential token error for the service account which causing failures for production jobs,Credential token error for the service account which causing failures for production jobs,"Provided a fix  through script and run it as a script action mitigated the issue Here’s  a new script: https://gregorysfixes.blob.core.windows.net/public/token-provider-test-fix.sh Just  populate script action dialog with it and select Head and Workers    If  the customer needs to fall back to the previous token provider for some reason,   just run the same script again and pass REVERT  (< all caps )  ",186034221,,,,,,,
1.20043E+14,47:07.1,[Azure Government] minimize cost on kafka-cluster (hd-insight)),"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 28, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: we want to auto shutdown kafka-cluster out side normal business hours.   can you provide method and sample code?  do we need to use automation account runbook?  can you provide sample code?  \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - we want to auto shutdown kafka-cluster out side normal business hours.   can you provide method and sample code?  do we need to use automation account runbook?  can you provide sample code?  ;\n\n- ProblemStartTime: 04/28/2020 04:00:00\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: EDAMI Prototype\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9b8b9b66-7cb5-4301-916e-09df6a33258b/resourceGroups/rg-femadex-dev/providers/Microsoft.HDInsight/clusters/kafka-femadex-dev\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] minimize cost on kafka-cluster (hd-insight)),0.017603431,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,120042824005793 - [Azure Government] Customer wants to use a start/stop feature in order to minimize cost on Kafka cluster,Cost savings,"There is no stop/start feature in HDInsight. The recommendation is to create / delete the Kafka cluster.My recommendations:•	Azure Runbooks is the recommended solution for this type of automation.Document reference:https://docs.microsoft.com/en-us/azure/hdinsight/manage-clusters-runbooks•	Before automating the Azure Runbook, you should test the Kafka cluster create and delete scripts in Powershell to make sure they work. The following document contains a sample Kafka cluster create template:https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-quickstart-powershell",,,,,,,,
1.20043E+14,04:27.2,prod: kp01sparkadfhdiprodusc01: spark2 server down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 28, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii} history server down\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii} history server down;\n\n- ProblemStartTime: 04/28/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kp01sparkadfhdiprodusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prod: kp01sparkadfhdiprodusc01: spark2 server down,1.132764442,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,Spark2 history server goes down with out of memory issue,kp01sparkadfhdiprodusc01: spark2 history server down,Restarted the Hive metastore service which is in bad state on HN0 and HN1. Also fixed the hivemetastore.log file issue by changing the permissions,,,,,,,,
1.20043E+14,13:26.2,unable to query storage account,"Question: What time did the problem begin?\nAnswer: Sun, Apr 26, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Secondary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:~$ hadoop fs -ls  wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*\nls: `wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*': No such file or directory\n{alphanumericpii}:~$\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Secondary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - NA;\nAdditional details about the issue - {alphanumericpii}:~$ hadoop fs -ls  wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*\nls: `wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*': No such file or directory\n{alphanumericpii}:~$\n\n;\n\n- ProblemStartTime: 04/26/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6f043c4a-d73e-4af2-b3a9-18f26aec9466/resourceGroups/CloudLake-Analytics-QA/providers/Microsoft.HDInsight/clusters/anahd1st01hdoop36metasyncqa01test\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to query storage account,0.026629281,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\hdfs commands do not work\Azure Storage in standard cluster,sshuser@ed10-anahd1:~$ hadoop fs -ls  wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*ls: `wasbs://config@stor02spark36datahubqa01.blob.core.windows.net/Clm_Liab2_copy/Pickled_Objects/*': No such file or directorysshuser@ed10-anahd1:~$,trying to list files so not listing any files,Once we delete the files with the same name and we try to list the folder Pickled_Objects Then we successfully able to list the files.,,,,,,,,
1.20043E+14,41:01.0,[Azure Government] how to create change data capture topic for postgres DB,"[Azure Government] Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: we need to create a new kafka topic streaming live date change from a postgres DB on Azure.   can you provide some referece how to accomplish this using kafkacluster-hd-insight. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - we need to create a new kafka topic streaming live date change from a postgres DB on Azure.   can you provide some referece how to accomplish this using kafkacluster-hd-insight. ;\n\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: EDAMI Prototype\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9b8b9b66-7cb5-4301-916e-09df6a33258b/resourceGroups/rg-femadex-dev/providers/Microsoft.HDInsight/clusters/kafka-femadex-dev\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] how to create change data capture topic for postgres DB,0.008819621,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Unexpected result\Kafka,120042824006120 [Azure Government] how to create change data capture topic for postgres DB HDInsight Service,Postgres DB does not save transcations customer would like to stream it using Kafka,The Debezium connector from Confluent is the best recommendation for this use case. Documentation provided:https://debezium.io/blog/2017/09/25/streaming-to-another-database/,,,,,,,,
1.20043E+14,54:31.5,Ambari is not loading.. too slow,Ambari in {ALPHANUMERICPII} environment is very slow. not able to access amabri by devleopes causing in delay in the project.\n\nhttps://idmcluster01-int.azurehdinsight.net/#/main/alerts/25\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Ambari is not loading.. too slow,0.920665555,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Virtual Appliance\Others,Sluggish Ambari Server performance,Ambari Server running on both headnodes.  Ambari Server database capacity depleted,Shut down Ambari Server on hn1.  hn0 was headnodehost.,,,,,,,,
1.20043E+14,17:01.3,Ranger HDFS setup,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: 'This request is not authorized to perform this operation using this permission.', 403, GET, https://benchadls2esp.dfs.core.windows.net/hivebench40?upn=true&resource=filesystem&maxResults=500&timeout=90&recursive=false, AuthorizationPermissionMismatch\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Through Gateway\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I have 2 exact same hdi 4.0 clusters. One has ESP and other does not. This is only a problem with the cluster with ESP.\n\nI ssh with this command: ssh {emailpii}@kcllap40adls2esp-ssh.azurehdinsight.net\n\nDo I have to setup some hdfs ranger policy?\n\nThis is blocking me in that I need access to modify, write, ect using hdfs and hadoop commands to do my work. Please do whatever you need with the cluster. There is nothing inside it right now.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - 'This request is not authorized to perform this operation using this permission.', 403, GET, https://benchadls2esp.dfs.core.windows.net/hivebench40?upn=true&resource=filesystem&maxResults=500&timeout=90&recursive=false, AuthorizationPermissionMismatch;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Through Gateway;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I have 2 exact same hdi 4.0 clusters. One has ESP and other does not. This is only a problem with the cluster with ESP.\n\nI ssh with this command: ssh {emailpii}@kcllap40adls2esp-ssh.azurehdinsight.net\n\nDo I have to setup some hdfs ranger policy?\n\nThis is blocking me in that I need access to modify, write, ect using hdfs and hadoop commands to do my work. Please do whatever you need with the cluster. There is nothing inside it right now.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HDI_TIP_RC\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f5d3a199-7c91-4db1-b074-8b45561beadb/resourceGroups/kcheung-TIP/providers/Microsoft.HDInsight/clusters/kcllap40adls2esp\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ranger HDFS setup,0.971686859,Root Cause : HDInsight Service\Configuration\HDInsight SDK,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",Ranger HDFS setup,Identified that the actual user who is trying to access the ADLS GEN 2 storage account.Actual User: rsadmin2 ErrorDetailRBAC Authorization Failed : :Data Action permission Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read not present. StatusAuthorizationPermissionMismatch|This request is not authorized to perform this operation using this permission. ,The actual user rsadmin2 did not have the sufficient permissions on the storage account.Provided  user managed identity role permissions to the Owner and Contributor level both at user and subscription level.Provided the user with storage account owner/contributor/Reader Roles to access the ADLS storage account.when we granted the Read/write/Execute permissions customer was able to access the blobs under the storage container. ,,,,,,,,
1.20043E+14,05:39.0,kps025sparkfdsbwus401-Spark-DynamicAllocation-Not working despite of cluster free with 800GB,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: ODBC/JDBC\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Issue : Current {AlphanumericPII}) has {ALPHANUMERICPII} yarn overall memory but with dynamic allocation it’s not launching more executors despite it’s totally free.\n\nAnalysis : After increasing --conf {AlphanumericPII} to --conf {AlphanumericPII}, same job which was failing with {Namepii} heap space error, got completed in 1 min.\n\nSpark Submit With issue Having minExecutor =1 : \n\nsh -c 'spark-submit --deploy-mode cluster --conf spark.custom.tag.producerName=ONELINK_NATL --class org.kp.soi.manager.cdc.hbase.delete.ADFBatchDeleteCDC --conf spark.yarn.submit.waitAppCompletion=false --executor-memory 2G --driver-memory 2G --conf {AlphanumericPII} --conf spark.shuffle.service.enabled=true --master yarn --conf {AlphanumericPII} --conf spark.dynamicAllocation.enabled=true --name {AlphanumericPII} abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/jars/adfdataprocessor.jar -kvUrl https://kpkvfdsbwus201.vault.azure.net/ -kvCId {guidpii} -kvCK {AlphanumericPII} -cts {ALPHANUMERICPII} -cs {ALPHANUMERICPII} -ca false -hblkp true -cbs 100000 -cff ORC -cac false -cfp abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/drsuccess/PS_KP_GL_SJL_ENTRY/2020/04/application_1588014608030_0279 -hiveTopic ADF_HIVE_TOPIC -batchId {guidpii} -sourceFile PS_KP_GL_SJL_ENTRY -hbasezk 10.10.196.33,10.10.196.32,10.10.196.31 --{namepii} azkv -delete true -cdcId 385 -{namepii} ._ina -pmId 33 -dsId 312 -dId 310 -sdId 312 '\n\nSpark Submit with MinExecutor 50 : \n\nsh -c 'spark-submit --deploy-mode cluster --conf spark.custom.tag.producerName=ONELINK_NATL --class org.kp.soi.manager.cdc.hbase.delete.ADFBatchDeleteCDC --conf spark.yarn.submit.waitAppCompletion=false --executor-memory 2G --driver-memory 2G --conf {AlphanumericPII} --conf spark.shuffle.service.enabled=true --master yarn --conf {AlphanumericPII} --conf spark.dynamicAllocation.enabled=true --name {AlphanumericPII} abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/jars/adfdataprocessor.jar -kvUrl https://kpkvfdsbwus201.vault.azure.net/ -kvCId {guidpii} -kvCK {AlphanumericPII} -cts {ALPHANUMERICPII} -cs {ALPHANUMERICPII} -ca false -hblkp true -cbs 100000 -cff ORC -cac false -cfp abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/drsuccess/PS_KP_GL_SJL_ENTRY/2020/04/application_1588014608030_0279 -hiveTopic ADF_HIVE_TOPIC -batchId {guidpii} -sourceFile PS_KP_GL_SJL_ENTRY -hbasezk 10.10.196.33,10.10.196.32,10.10.196.31 --{namepii} azkv -delete true -cdcId 385 -{namepii} ._ina -pmId 33 -dsId 312 -dId 310 -sdId 312 '\n\nFailed Spark Application ID : https://kps025sparkfdsbwus401-int.azurehdinsight.net/yarnui/hn/cluster/app/application_1588014608030_0280 \n\nSuccess in 1 min : https://kps025sparkfdsbwus401-int.azurehdinsight.net/yarnui/hn/cluster/app/application_1588014608030_1817 \n\n\n\nQuestion: Additional details about the issue\nAnswer: Spark-DynamicAllocation-Not working despite of cluster free with {ALPHANUMERICPII}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - ODBC/JDBC;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Issue : Current {AlphanumericPII}) has {ALPHANUMERICPII} yarn overall memory but with dynamic allocation it’s not launching more executors despite it’s totally free.\n\nAnalysis : After increasing --conf {AlphanumericPII} to --conf {AlphanumericPII}, same job which was failing with {Namepii} heap space error, got completed in 1 min.\n\nSpark Submit With issue Having minExecutor =1 : \n\nsh -c 'spark-submit --deploy-mode cluster --conf spark.custom.tag.producerName=ONELINK_NATL --class org.kp.soi.manager.cdc.hbase.delete.ADFBatchDeleteCDC --conf spark.yarn.submit.waitAppCompletion=false --executor-memory 2G --driver-memory 2G --conf {AlphanumericPII} --conf spark.shuffle.service.enabled=true --master yarn --conf {AlphanumericPII} --conf spark.dynamicAllocation.enabled=true --name {AlphanumericPII} abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/jars/adfdataprocessor.jar -kvUrl https://kpkvfdsbwus201.vault.azure.net/ -kvCId {guidpii} -kvCK {AlphanumericPII} -cts {ALPHANUMERICPII} -cs {ALPHANUMERICPII} -ca false -hblkp true -cbs 100000 -cff ORC -cac false -cfp abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/drsuccess/PS_KP_GL_SJL_ENTRY/2020/04/application_1588014608030_0279 -hiveTopic ADF_HIVE_TOPIC -batchId {guidpii} -sourceFile PS_KP_GL_SJL_ENTRY -hbasezk 10.10.196.33,10.10.196.32,10.10.196.31 --{namepii} azkv -delete true -cdcId 385 -{namepii} ._ina -pmId 33 -dsId 312 -dId 310 -sdId 312 '\n\nSpark Submit with MinExecutor 50 : \n\nsh -c 'spark-submit --deploy-mode cluster --conf spark.custom.tag.producerName=ONELINK_NATL --class org.kp.soi.manager.cdc.hbase.delete.ADFBatchDeleteCDC --conf spark.yarn.submit.waitAppCompletion=false --executor-memory 2G --driver-memory 2G --conf {AlphanumericPII} --conf spark.shuffle.service.enabled=true --master yarn --conf {AlphanumericPII} --conf spark.dynamicAllocation.enabled=true --name {AlphanumericPII} abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/jars/adfdataprocessor.jar -kvUrl https://kpkvfdsbwus201.vault.azure.net/ -kvCId {guidpii} -kvCK {AlphanumericPII} -cts {ALPHANUMERICPII} -cs {ALPHANUMERICPII} -ca false -hblkp true -cbs 100000 -cff ORC -cac false -cfp abfs://kps025sparkfdsbwus401-cluster@kpadlsgen2adfsb01uscn01.dfs.core.windows.net/adf/drsuccess/PS_KP_GL_SJL_ENTRY/2020/04/application_1588014608030_0279 -hiveTopic ADF_HIVE_TOPIC -batchId {guidpii} -sourceFile PS_KP_GL_SJL_ENTRY -hbasezk 10.10.196.33,10.10.196.32,10.10.196.31 --{namepii} azkv -delete true -cdcId 385 -{namepii} ._ina -pmId 33 -dsId 312 -dId 310 -sdId 312 '\n\nFailed Spark Application ID : https://kps025sparkfdsbwus401-int.azurehdinsight.net/yarnui/hn/cluster/app/application_1588014608030_0280 \n\nSuccess in 1 min : https://kps025sparkfdsbwus401-int.azurehdinsight.net/yarnui/hn/cluster/app/application_1588014608030_1817 \n\n;\nAdditional details about the issue - Spark-DynamicAllocation-Not working despite of cluster free with {ALPHANUMERICPII};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-{namepii}-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps025sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kps025sparkfdsbwus401-Spark-DynamicAllocation-Not working despite of cluster free with 800GB,0.619629369,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Spark,kps025sparkfdsbwus401-Spark-DynamicAllocation-Not working despite of cluster free with 800GB,kps025sparkfdsbwus401-Spark-DynamicAllocation-Not working despite of cluster free with 800GB,Worked with customer and tried multiple options. Below config had worked for customer and Spark dynamic allocation is working as expected for customer.--conf spark.hadoop.fs.azure.write.request.size=1096 spark.hadoop.fs.azure.read.request.size=1096,186305283,,,,,,,
1.20043E+14,24:08.3,Trouble to deploy Presto app in HDInsight both with terraforms and from Azure portal. ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 28, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: vagdevprestotest\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Can't deploy presto; attached an image with more details\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - vagdevprestotest;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Can't deploy presto; attached an image with more details;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/27/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/77a86a91-50fd-4d32-b194-db4079e64beb/resourceGroups/vag-dev/providers/Microsoft.HDInsight/clusters/vagdevprestotest\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Trouble to deploy Presto app in HDInsight both with terraforms and from Azure portal. ,1.514846133,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Can't deploy presto; attached an image with more details,"I am working with the HDinsight product team who is working with Starburst, and I have learned that Starburst is moving away from the ISV(independent software vendors) model that HDinsight has ( like an add on) to an AKS(Azure Kubernetes Services) based installation. We are currently working to remove Starburst from the HDInsight ISV list. ",You may choose to deploy Starburst Presto on VMs or HDinsight Clusters manually (tarball/rpm) and our team will be able to support the core functionality of Presto.Please refer to the documentation on Starburst on Azure.https://docs.starburstdata.com/latest/installation/azure.html,186291769,,,,,,,
1.20043E+14,31:41.1,Cluster is not working,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is not running and unable to access.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} is not running and unable to access.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: QA Test 01 (S08)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/af77a77b-b079-4996-89d4-e314a74e94a2/resourceGroups/RS08UE2QInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs08ue2qiphdidm03\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is not working,0.071144457,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Cluster Unhealthy,S0 Ambari DB hitting 100%,"Suggested cx to clean the zk shapshots, perform the ambari purge and create a cluster per use case with S2 ambari db",,,,,,,,
1.20043E+14,03:02.8,Unable to add non admin user in Ambari UI,"We are trying to create one non admin user for other teams access due to some security reason but unable to login with that user.\n\nError:\norg.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: Wrong current password provided\n\n\n\nProblem start date and time\nWed, Apr 29, 2020, 8:00 PM GMT+5:30\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 04/29/2020 14:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT Integration\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/840e8a25-1606-485e-9525-6b4c49bb954f/resourceGroups/int-hlt-cat-rg-01/providers/Microsoft.HDInsight/clusters/intg-hlt-mh-ussc-cat-storm-02\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to add non admin user in Ambari UI,1.080048794,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Unable to add non admin user in Ambari UI,Cluster is 3 years out of date causing gateway issues,suggested Recreate cluster,186148052,,,,,,,
1.20043E+14,08:30.9,Container exited with a non-zero exit code 50. Error file: prelaunch.err.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 28, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: #!/usr/bin/env bash\n\nsource $(dirname '$0')/../../env.sh\neggs=$(find ${DEPLOY_DIR}/dist/*.egg | awk -vORS=, '{ print $1 }' | sed 's/,$//')\neggspath=$(find ${DEPLOY_DIR}/dist/*.egg | awk -vORS=: '{ print $1 }' | sed 's/:$//')\necho $eggs\nif [ $CLUSTER_TYPE == hdinsight ]; then\n    echo ${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/bin/python\n    PYTHONPATH=${PYTHONPATH}:${eggspath} \\\n    PYSPARK_PYTHON=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/bin/python \\\n    PYSPARK_DRIVER_PYTHON=${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/bin/python \\\n    R_HOME=${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/lib/R \\\n    SPARK_HOME=${SPARK_HOME} ${SPARK_HOME}/bin/spark-submit \\\n        --archives ${CONDA_ENV_BASE}/${WORKER_CONDA_ENV}.zip#${WORKER_ENV_TAG} \\\n        --driver-memory 30g \\\n        --master yarn-client \\\n        --conf spark.executorEnv.R_HOME=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R \\\n        --conf spark.executorEnv.RHOME=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV} \\\n        --conf spark.executorEnv.R_SHARE_DIR=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R/share \\\n        --conf spark.executorEnv.R_INCLUDE_DIR=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R/include \\\n        --conf {AlphanumericPII} \\\n        --py-files  ${eggs}\\\n            '$@'\nelse\n    PYTHONPATH=${PYTHONPATH}:${eggspath} \\\n    PYSPARK_PYTHON='//.pyenv/versions/`pyenv global`/bin/python' \\\n    PYSPARK_DRIVER_PYTHON='//.pyenv/versions/`pyenv global`/bin/python' \\\n    SPARK_HOME=${SPARK_HOME} ${SPARK_HOME}/bin/spark-submit \\\n        --master spark://`hostname`:7077 \\\n        --driver-memory 30g \\\n        --conf {AlphanumericPII} \\\n        --py-files  ${eggs}\\\n            '$@'\nfi\n\n------\n\nbash ./bin/entrypoint.sh \\\n    --num-executors 150 \\\n    --executor-memory 30G \\\n    --executor-cores 4 \\\n    --packages {alphanumericpii} \\\n    --conf 'spark.python.worker.reuse=false' \\\n    --conf '{AlphanumericPII}' \\\n    run_preprocessing.py \\\n    --user ${user} \\\n    --deployenv ${deployenv} \\\n    --inputdatapath ${inputdatapath} \\\n    --inputschemapath ${inputschemapath} \\\n    --workspace ${workspace} \\\n    --datadate ${datadate} \\\n    --datesuffix ${obsdate} \\\n    --processingconfigure ${processingconfigure} \\\n    & ${logdir}/${modeltype}_preprocessing.log\n\nQuestion: Additional details about the issue\nAnswer: I'm attaching a text file with the error log.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Python;\nSpark configuration details - #!/usr/bin/env bash\n\nsource $(dirname '$0')/../../env.sh\neggs=$(find ${DEPLOY_DIR}/dist/*.egg | awk -vORS=, '{ print $1 }' | sed 's/,$//')\neggspath=$(find ${DEPLOY_DIR}/dist/*.egg | awk -vORS=: '{ print $1 }' | sed 's/:$//')\necho $eggs\nif [ $CLUSTER_TYPE == hdinsight ]; then\n    echo ${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/bin/python\n    PYTHONPATH=${PYTHONPATH}:${eggspath} \\\n    PYSPARK_PYTHON=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/bin/python \\\n    PYSPARK_DRIVER_PYTHON=${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/bin/python \\\n    R_HOME=${CONDA_ENV_BASE}/${DRIVER_CONDA_ENV}/lib/R \\\n    SPARK_HOME=${SPARK_HOME} ${SPARK_HOME}/bin/spark-submit \\\n        --archives ${CONDA_ENV_BASE}/${WORKER_CONDA_ENV}.zip#${WORKER_ENV_TAG} \\\n        --driver-memory 30g \\\n        --master yarn-client \\\n        --conf spark.executorEnv.R_HOME=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R \\\n        --conf spark.executorEnv.RHOME=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV} \\\n        --conf spark.executorEnv.R_SHARE_DIR=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R/share \\\n        --conf spark.executorEnv.R_INCLUDE_DIR=./${WORKER_ENV_TAG}/${WORKER_CONDA_ENV}/lib/R/include \\\n        --conf {AlphanumericPII} \\\n        --py-files  ${eggs}\\\n            '$@'\nelse\n    PYTHONPATH=${PYTHONPATH}:${eggspath} \\\n    PYSPARK_PYTHON='//.pyenv/versions/`pyenv global`/bin/python' \\\n    PYSPARK_DRIVER_PYTHON='//.pyenv/versions/`pyenv global`/bin/python' \\\n    SPARK_HOME=${SPARK_HOME} ${SPARK_HOME}/bin/spark-submit \\\n        --master spark://`hostname`:7077 \\\n        --driver-memory 30g \\\n        --conf {AlphanumericPII} \\\n        --py-files  ${eggs}\\\n            '$@'\nfi\n\n------\n\nbash ./bin/entrypoint.sh \\\n    --num-executors 150 \\\n    --executor-memory 30G \\\n    --executor-cores 4 \\\n    --packages {alphanumericpii} \\\n    --conf 'spark.python.worker.reuse=false' \\\n    --conf '{AlphanumericPII}' \\\n    run_preprocessing.py \\\n    --user ${user} \\\n    --deployenv ${deployenv} \\\n    --inputdatapath ${inputdatapath} \\\n    --inputschemapath ${inputschemapath} \\\n    --workspace ${workspace} \\\n    --datadate ${datadate} \\\n    --datesuffix ${obsdate} \\\n    --processingconfigure ${processingconfigure} \\\n    & ${logdir}/${modeltype}_preprocessing.log;\nAdditional details about the issue - I'm attaching a text file with the error log.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/28/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-bpeng-Shared-HDInsight/providers/Microsoft.HDInsight/clusters/cccmstaging\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Container exited with a non-zero exit code 50. Error file: prelaunch.err.,0.036771774,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,eContainer exited with a non-zero exit code 50. Error file: prelaunch.err.,eContainer exited with a non-zero exit code 50. Error file: prelaunch.err.,Customer fixed the issue by increasing the container heap size,"186,141,097,186,141,000",,,,,,,
1.20043E+14,45:49.1,Unexpected cluster delete,"Question: What time did the problem begin?\nAnswer: Wed, Apr 29, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: N/A\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Our '{alphanumericpii}' cluster was scheduled to delete at 4PM EST, but it is being deleted earlier. Can you please share backend details on how the delete request was submitted, what time was the delete request submitted, what method was used to delete the cluster, etc. We would like to avoid this unexpected cluster delete again.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - N/A;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Our '{alphanumericpii}' cluster was scheduled to delete at 4PM EST, but it is being deleted earlier. Can you please share backend details on how the delete request was submitted, what time was the delete request submitted, what method was used to delete the cluster, etc. We would like to avoid this unexpected cluster delete again.;\n\n- ProblemStartTime: 04/29/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unexpected cluster delete,0.123529408,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unexpected cluster delete,Not known ,"I have checked backend logs and I see that there is a delete request workflow started on 2020-04-29 15:42:00.8251482 (11:42 AM Thursday)  The cluster creation request has been started on 2020-04-29 04:45:58.9556204 UTC  The delete request has been performed by  2020-04-29 15:42:16.3584269 Microsoft.HDInsight/clusters/delete    /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark    ""s-ndj-clusterCreator""    ""69.25.204.165"" The ip-address is 69.25.204.165",,,,,,,,
1.20043E+14,45:39.0,Fail HDInsight,"Question: What time did the problem begin?\nAnswer: Wed, Apr 29, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Apr 29, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Problema com cluster HDI “{alphanumericpii}”,  \n\nPipeline da fato “carteira-cartão” – {Namepii} pipe não vem funcionando corretamente com o autoscale ligado, tentei desabilitá-lo e executar com uma quantidade de nós fixos.\n\nAo tentar desabilitar o autoscale e salvar as alterações, apareceu o seguinte erro:\n\n“{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.”\n\nO cluster não permite o mais alterar a quantidade de nós após este erro\n\nFoi tentado excluir o cluster para recriar, mas retorna outro erro:\n\n“Error deleting cluster: {alphanumericpii}\n\n{'code':'Conflict','message':'Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.'}”.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Problema com cluster HDI “{alphanumericpii}”,  \n\nPipeline da fato “carteira-cartão” – {Namepii} pipe não vem funcionando corretamente com o autoscale ligado, tentei desabilitá-lo e executar com uma quantidade de nós fixos.\n\nAo tentar desabilitar o autoscale e salvar as alterações, apareceu o seguinte erro:\n\n“{Namepii} is in 'Updating Error' state. Only disabling autoscale is allowed.”\n\nO cluster não permite o mais alterar a quantidade de nós após este erro\n\nFoi tentado excluir o cluster para recriar, mas retorna outro erro:\n\n“Error deleting cluster: {alphanumericpii}\n\n{'code':'Conflict','message':'Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.'}”.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/29/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: BHS Sni - Olé Consignado\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Fail HDInsight,0.072696854,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,"“Error deleting cluster: hdi001prd  {'code':'Conflict','message':'Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.'}”.",Scale down - scale up failure,Rise an IcM to ask PG to delete the cluster in bad state. (https://icm.ad.msft.net/imp/v3/incidents/details/186336406/home ),186336406,,,,,,,
1.20043E+14,55:07.1,HiveInteractive service and Zookeeper Cancelled Key exceptions issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: HiveInteractive service and Zookeeper Cancelled Key exceptions issues\n\nQuestion: Interactive query explain plan if available\nAnswer: HiveInteractive service and Zookeeper Cancelled Key exceptions issues\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: HiveInteractive service and Zookeeper Cancelled Key exceptions issues\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - HiveInteractive service and Zookeeper Cancelled Key exceptions issues;\nInteractive query explain plan if available - HiveInteractive service and Zookeeper Cancelled Key exceptions issues;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - HiveInteractive service and Zookeeper Cancelled Key exceptions issues;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HiveInteractive service and Zookeeper Cancelled Key exceptions issues,0.020322639,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,ERROR [CommitProcessor:1:NIOServerCnxn@178] - Unexpected Exception:java.nio.channels.CancelledKeyException, HiveInteractive service and Zookeeper Cancelled Key exceptions issues,Recommended to cleanup the ZooKeeper data directory snapshots using following link - https://docs.microsoft.com/bs-latn-ba/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-fails#resolution,,,,,,,,
1.20043E+14,36:38.4,Not able to run parallel sqoop jobs,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Sqoop\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Oozie workflows with sqoop actions cannot run in parallel successfully.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Sqoop;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - Oozie workflows with sqoop actions cannot run in parallel successfully.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/USEQFSOPENRSG02/providers/Microsoft.HDInsight/clusters/USEQFSOPENHDI01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to run parallel sqoop jobs,0.858039541,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie",Issues with running sqoop jobs in parallel.,cx configuration,"Able to run the jobs parallelly, after increasing the user-limit-factor for the job’s in yarn queue from 2 to 10. ",,,,,,,,
1.20043E+14,43:46.9,install python packages for all worker nodes,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: export {AlphanumericPII}\n\nQuestion: Additional details about the issue\nAnswer: I followed the instruction from Microsoft documation below to install the packages, but failed.\n'https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-python-package-installation'\nI got error message saying 'No such file or directory'.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Python;\nSpark configuration details - export {AlphanumericPII};\nAdditional details about the issue - I followed the instruction from Microsoft documation below to install the packages, but failed.\n'https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-python-package-installation'\nI got error message saying 'No such file or directory'.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02spark-as-p02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",install python packages for all worker nodes,0.367107345,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,"/05/01 00:23:56 INFO BlockManagerMasterEndpoint: Registering block manager wn0-askaka.kld1xygk2rgutj3nnqhysmnatd.bx.internal.cloudapp.net:39293 with 1458.6 MB RAM, BlockManagerId(1, wn0-askaka.kld1xygk2rgutj3nnqhysmnatd.bx.internal.cloudapp.net, 39293, None) 20/05/01 00:23:56 INFO BlockManagerMasterEndpoint: Registering block manager wn0-askaka.kld1xygk2rgutj3nnqhysmnatd.bx.internal.cloudapp.net:34409 with 1458.6 MB RAM, BlockManagerId(2, wn0-askaka.kld1xygk2rgutj3nnqhysmnatd.bx.internal.cloudapp.net, 34409, None) 20/05/01 00:23:56 INFO SparkEntries: Created Spark session (with Hive support). 20/05/01 00:24:03 WARN Session: Fail to start interpreter pyspark java.io.IOException: Cannot run program ""/usr/bin/anaconda/envs/py35new/bin/python"": error=2, No such file or directory 	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) 	at org.apache.livy.repl.PythonInterpreter$.apply(PythonInterpreter.scala:75) 	at org.apache.livy.repl.Session.liftedTree1$1(Session.scala:106) 	at org.apache.livy.repl.Session.interpreter(Session.scala:98) 	at org.apache.livy.repl.Session.org$apache$livy$repl$Session$$setJobGroup(Session.scala:353) 	at org.apache.livy.repl.Session$$anonfun$execute$1.apply$mcV$sp(Session.scala:164) 	at org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163) 	at org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163) 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: error=2, No such file or directory 	at java.lang.UNIXProcess.forkAndExec(Native Method) 	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247) 	at java.lang.ProcessImpl.start(ProcessImpl.java:134)", install python packages for all worker nodes,Recommended to run script actions on your cluster for all nodes to create a Python virtual environment.,,,,,,,,
1.20043E+14,00:41.6,Ambari pages not loading,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: This is a new cluster we just created. Some of the Ambari pages can't be loaded. For example,\nhttps://p02spark-as-p02.azurehdinsight.net/yarnui/hn/ui2/index.html#/yarn-app/application_1588025340501_0039/attempts\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - This is a new cluster we just created. Some of the Ambari pages can't be loaded. For example,\nhttps://p02spark-as-p02.azurehdinsight.net/yarnui/hn/ui2/index.html#/yarn-app/application_1588025340501_0039/attempts\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02spark-as-p02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari pages not loading,35.97559474,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Ambari UI is not loading,"Based on the logs, it seems the Yarn UI version 2 is trying to reach timeline server V2 which is not running our clusters and is currently unsupported. Recommended continue using Yarn UI version 1.",YARN UI V2 pages not loading,"Based on the logs, it seems the Yarn UI version 2 is trying to reach timeline server V2 which is not running our clusters and is currently unsupported. Recommended continue using Yarn UI version 1.",190597041,,,,,,,
1.20043E+14,08:48.7,Need help on deploying hdinisight cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: hdidrtest\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Need someone help to build HDInsight cluster. We are facing issues while deploying cluster and planning to integrate cluster with Active Directory. \nMy shift timings are 2 PM to 11 PM. \nCan someone be available to build cluster with us?\n\nThanks\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - hdidrtest;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Need someone help to build HDInsight cluster. We are facing issues while deploying cluster and planning to integrate cluster with Active Directory. \nMy shift timings are 2 PM to 11 PM. \nCan someone be available to build cluster with us?\n\nThanks\n{Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AMD-GIS_DataAnalytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need help on deploying hdinisight cluster,22.43368447,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,Need help on deploying hdinisight cluster,incorrect rights,corrected rights issue,,,,,,,,
1.20043E+14,21:14.8,Ubable to login to Ambari,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 28, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: Yes\n\nQuestion: Are the accounts federated?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Yes\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: After entering creds the security popup does not error but just appears again. I am able to login with local 'admin account.  The cluster admin account {emailpii}@attdatalake.com does not work in Ambari but does work via KInit.   Accounts are cloud only accounts, not federated.   I am able to login to azure portal with cluster admin account and jdierk account is synced.  {Namepii} environment has been working for weeks.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - Yes;\nAre the accounts federated? - Other, don't know or not applicable;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - Yes;\nDoes authentication fail even for the cluster admin account? - Yes;\nHave you logged in to Ambari as local admin and verified the users have been synced? - Yes;\nAdditional details about the issue - After entering creds the security popup does not error but just appears again. I am able to login with local 'admin account.  The cluster admin account {emailpii}@attdatalake.com does not work in Ambari but does work via KInit.   Accounts are cloud only accounts, not federated.   I am able to login to azure portal with cluster admin account and jdierk account is synced.  {Namepii} environment has been working for weeks.;\n\n- ProblemStartTime: 04/28/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/66d6093c-2dac-4eaa-ae4f-fe18bcd3a6cd/resourceGroups/hdipoc-dnstest-hdi001-rg/providers/Microsoft.HDInsight/clusters/hdidns101\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ubable to login to Ambari,0.07597469,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Ubable to login to Ambari,Ubable to login to Ambari,Customer was using Conditional Access policy that was preventing customer to login. Customer fixed the conditional access policy and now able to login to cluster,,,,,,,,
1.20043E+14,54:21.0,Error while accessing Hive tables from ODBC connection from Excel,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: UDP-Hdinsight-int.azurehdinsight.net:443/default\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are trying to access Hive table data from Excel, we created ODBC connection and while accessing tables from Excel it;s failing with - \n\nDataSource.Error: ODBC: ERROR [HY000] [Microsoft][Hardy] (61) Server returned error with no error message during operation: GetTables('%') \n    TStatus.statusCode=ERROR_STATUS\n    TStatus.infoMessages='*java.nio.BufferUnderflowException:null:35:34''java.nio.Buffer:nextGetIndex:Buffer.java:506''java.nio.HeapByteBuffer:getLong:HeapByteBuffer.java:412''org.apache.hive.service.cli.HandleIdentifier:init:HandleIdentifier.java:46''org.apache.hive.service.cli.Handle:init:Handle.java:38''org.apache.hive.service.cli.SessionHandle:init:SessionHandle.java:45''org.apache.hive.service.cli.SessionHandle:init:SessionHandle.java:41''org.apache.hive.service.cli.thrift.ThriftCLIService:GetTables:ThriftCLIService.java:570''org.apache.hive.service.cli.thrift.TCLIService$Processor$GetTables:getResult:TCLIService.java:1457''org.apache.hive.service.cli.thrift.TCLIService$Processor$GetTables:getResult:TCLIService.java:1442''org.apache.thrift.ProcessFunction:process:ProcessFunction.java:39''org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39''org.apache.thrift.server.TServlet:doPost:TServlet.java:83''org.apache.hive.service.cli.thrift.ThriftHttpServlet:doPost:ThriftHttpServlet.java:206''javax.servlet.http.HttpServlet:service:HttpServlet.java:727''javax.servlet.http.HttpServlet:service:HttpServlet.java:820''org.eclipse.jetty.servlet.ServletHolder:handle:ServletHolder.java:565''org.eclipse.jetty.servlet.ServletHandler:doHandle:ServletHandler.java:479''org.eclipse.jetty.server.session.SessionHandler:doHandle:SessionHandler.java:225''org.eclipse.jetty.server.handler.ContextHandler:doHandle:ContextHandler.java:1031''org.eclipse.jetty.servlet.ServletHandler:doScope:ServletHandler.java:406''org.eclipse.jetty.server.session.SessionHandler:doScope:SessionHandler.java:186''org.eclipse.jetty.server.handler.ContextHandler:doScope:ContextHandler.java:965''org.eclipse.jetty.server.handler.ScopedHandler:handle:ScopedHandler.java:117''org.eclipse.jetty.server.handler.HandlerWrapper:handle:HandlerWrapper.java:111''org.eclipse.jetty.server.Server:handle:Server.java:345''org.eclipse.jetty.server.AbstractHttpConnection:handleRequest:AbstractHttpConnection.java:449''org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler:content:AbstractHttpConnection.java:925''org.eclipse.jetty.http.HttpParser:parseNext:HttpParser.java:857''org.eclipse.jetty.http.HttpParser:parseAvailable:HttpParser.java:235''org.eclipse.jetty.server.AsyncHttpConnection:handle:AsyncHttpConnection.java:76''org.eclipse.jetty.io.nio.SelectChannelEndPoint:handle:SelectChannelEndPoint.java:609''org.eclipse.jetty.io.nio.SelectChannelEndPoint$1:run:SelectChannelEndPoint.java:45''java.util.concurrent.ThreadPoolExecutor:runWorker:ThreadPoolExecutor.java:1149''java.util.concurrent.ThreadPoolExecutor$Worker:run:ThreadPoolExecutor.java:624''java.lang.Thread:run:Thread.java:748'\n    TStatus.sqlState=\n    TStatus.errorCode=0\n    TStatus.errorMessage=''\n    TStatus.__isset.errorCode: false\n    TStatus.__isset.errorMessage: false\n    TStatus.__isset.infoMessages: true\n    TStatus.__isset.sqlState: false\nDetails:\n    DataSourceKind=Odbc\n    DataSourcePath=dsn=Hive ODBC Connection\n    OdbcErrors=[Table]\n\n\n\n<Start:Agent_Additional_Properties_Do_Not_Edit>\nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - UDP-Hdinsight-int.azurehdinsight.net:443/default;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - We are trying to access Hive table data from Excel, we created ODBC connection and while accessing tables from Excel it;s failing with - \n\nDataSource.Error: ODBC: ERROR [HY000] [Microsoft][Hardy] (61) Server returned error with no error message during operation: GetTables('%') \n    TStatus.statusCode=ERROR_STATUS\n    TStatus.infoMessages='*java.nio.BufferUnderflowException:null:35:34''java.nio.Buffer:nextGetIndex:Buffer.java:506''java.nio.HeapByteBuffer:getLong:HeapByteBuffer.java:412''org.apache.hive.service.cli.HandleIdentifier:init:HandleIdentifier.java:46''org.apache.hive.service.cli.Handle:init:Handle.java:38''org.apache.hive.service.cli.SessionHandle:init:SessionHandle.java:45''org.apache.hive.service.cli.SessionHandle:init:SessionHandle.java:41''org.apache.hive.service.cli.thrift.ThriftCLIService:GetTables:ThriftCLIService.java:570''org.apache.hive.service.cli.thrift.TCLIService$Processor$GetTables:getResult:TCLIService.java:1457''org.apache.hive.service.cli.thrift.TCLIService$Processor$GetTables:getResult:TCLIService.java:1442''org.apache.thrift.ProcessFunction:process:ProcessFunction.java:39''org.apache.thrift.TBaseProcessor:process:TBaseProcessor.java:39''org.apache.thrift.server.TServlet:doPost:TServlet.java:83''org.apache.hive.service.cli.thrift.ThriftHttpServlet:doPost:ThriftHttpServlet.java:206''javax.servlet.http.HttpServlet:service:HttpServlet.java:727''javax.servlet.http.HttpServlet:service:HttpServlet.java:820''org.eclipse.jetty.servlet.ServletHolder:handle:ServletHolder.java:565''org.eclipse.jetty.servlet.ServletHandler:doHandle:ServletHandler.java:479''org.eclipse.jetty.server.session.SessionHandler:doHandle:SessionHandler.java:225''org.eclipse.jetty.server.handler.ContextHandler:doHandle:ContextHandler.java:1031''org.eclipse.jetty.servlet.ServletHandler:doScope:ServletHandler.java:406''org.eclipse.jetty.server.session.SessionHandler:doScope:SessionHandler.java:186''org.eclipse.jetty.server.handler.ContextHandler:doScope:ContextHandler.java:965''org.eclipse.jetty.server.handler.ScopedHandler:handle:ScopedHandler.java:117''org.eclipse.jetty.server.handler.HandlerWrapper:handle:HandlerWrapper.java:111''org.eclipse.jetty.server.Server:handle:Server.java:345''org.eclipse.jetty.server.AbstractHttpConnection:handleRequest:AbstractHttpConnection.java:449''org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler:content:AbstractHttpConnection.java:925''org.eclipse.jetty.http.HttpParser:parseNext:HttpParser.java:857''org.eclipse.jetty.http.HttpParser:parseAvailable:HttpParser.java:235''org.eclipse.jetty.server.AsyncHttpConnection:handle:AsyncHttpConnection.java:76''org.eclipse.jetty.io.nio.SelectChannelEndPoint:handle:SelectChannelEndPoint.java:609''org.eclipse.jetty.io.nio.SelectChannelEndPoint$1:run:SelectChannelEndPoint.java:45''java.util.concurrent.ThreadPoolExecutor:runWorker:ThreadPoolExecutor.java:1149''java.util.concurrent.ThreadPoolExecutor$Worker:run:ThreadPoolExecutor.java:624''java.lang.Thread:run:Thread.java:748'\n    TStatus.sqlState=\n    TStatus.errorCode=0\n    TStatus.errorMessage=''\n    TStatus.__isset.errorCode: false\n    TStatus.__isset.errorMessage: false\n    TStatus.__isset.infoMessages: true\n    TStatus.__isset.sqlState: false\nDetails:\n    DataSourceKind=Odbc\n    DataSourcePath=dsn=Hive ODBC Connection\n    OdbcErrors=[Table];\n\n- Cloud: Azure\n- AzureProductSubscriptionID: 26501947-30f8-46ad-8b80-555d125d0e5c\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: 1003BFFD9B3AFE6F\n- Tenant Id: b9921086-ff77-4d0d-828a-cb3381f678e2\n- Object Id: 0bf267d4-c949-4dd4-9a63-82e8e8a75eb2\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n<End:Agent_Additional_Properties_Do_Not_Edit>\n",Error while accessing Hive tables from ODBC connection from Excel,0.349942036,Root Cause : HDInsight Service\Configuration\HDInsight SDK,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,Error while accessing Hive tables from ODBC connection from Excel,"Since the HDInsight Gateway was performing a case-sensitive comparison, this caused the HDInsight Gateway to fail to find the cookie, and route the request using the aforementioned round-robin algorithm without using the information in the JSESSIONID cookie to route the request; which lead to various failures.",TSG:https://supportability.visualstudio.com/AzureHDinsight/_wiki/wikis/AzureHDinsight/315085/Hive-2.6.7-ODBC-driver-fails-to-connect-to-Hadoop-cluster,,,,,,,,
1.20043E+14,22:18.9,Create fails with 'Deployment 'HDInsight__2020-04-30T16.36.51.790Z' xpm-hdi-rg was not found.',"Question: What time did the problem begin?\nAnswer: Wed, Apr 29, 2020, 12:00 AM GMT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Create fails with:\n\n{ 'shellProps': { 'sessionId': '{Muidpii}', 'extName': 'HubsExtension', 'contentName': '{AlphanumericPII}', 'code': 404 }, 'error': { 'message': 'Deployment '{AlphanumericPII}' xpm-hdi-rg was not found.', 'code': 404 }}\n\n{Namepii} appears in the portal, but:\n\nError code\nFailedToConnectWithClusterErrorCode\nError message\nUnable to connect to cluster management endpoint. Please retry later.\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Create fails with:\n\n{ 'shellProps': { 'sessionId': '{Muidpii}', 'extName': 'HubsExtension', 'contentName': '{AlphanumericPII}', 'code': 404 }, 'error': { 'message': 'Deployment '{AlphanumericPII}' xpm-hdi-rg was not found.', 'code': 404 }}\n\n{Namepii} appears in the portal, but:\n\nError code\nFailedToConnectWithClusterErrorCode\nError message\nUnable to connect to cluster management endpoint. Please retry later.\n\n;\n\n- ProblemStartTime: 04/29/2020 00:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Sbox-{Namepii}-Sub\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Create fails with 'Deployment 'HDInsight__2020-04-30T16.36.51.790Z' xpm-hdi-rg was not found.',0.164226089,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Create fails with 'Deployment 'HDInsight__2020-04-30T16.36.51.790Z' xpm-hdi-rg was not found.',"Create fails with: { 'shellProps': { 'sessionId': '0094eb945a3942e39640efc45cce1fbc', 'extName': 'HubsExtension', 'contentName': 'DeploymentDetailsOverviewV2Blade', 'code': 404 }, 'error': { 'message': 'Deployment 'HDInsight__2020-04-30T16.36.51.790Z' xpm-hdi-rg was not found.', 'code': 404 }} Cluster appears in the portal, but: Error codeFailedToConnectWithClusterErrorCodeError messageUnable to connect to cluster management endpoint. Please retry later.","Recreate a cluster without Vnet and deployed successfully.to create a cluster in a Vnet please refer to the below Microsoft documentationhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment Also, some required IP management to configure in the NSG and UDR, please refer to https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses",,,,,,,,
1.20043E+14,38:45.2,Kerberos token not working properly,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: Prdiwsecure\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: This cluster is build with the ESP package.We have one domain user named as 'infoworks-user'.\nWhen we tried klist it shows the ticket is valid but kerberos token got expired and because of the token expired we are unable to login to the hive shell it shows that GSS initiate exception. But we are able to access the hdfs command with the same user on the same cluster and we have other 2 to 3 different ESP enabled cluster with the same domain and we observe that the same user is working fine on the other cluster there are no issue with the kerberos token. We are only observing kerberos token failure issue on prdiwsecure cluster.\nPlease find attached detailed log with command output in the attachement section\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - Prdiwsecure;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - This cluster is build with the ESP package.We have one domain user named as 'infoworks-user'.\nWhen we tried klist it shows the ticket is valid but kerberos token got expired and because of the token expired we are unable to login to the hive shell it shows that GSS initiate exception. But we are able to access the hdfs command with the same user on the same cluster and we have other 2 to 3 different ESP enabled cluster with the same domain and we observe that the same user is working fine on the other cluster there are no issue with the kerberos token. We are only observing kerberos token failure issue on prdiwsecure cluster.\nPlease find attached detailed log with command output in the attachement section;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 03/29/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdasecure-cus-01-rg/providers/Microsoft.HDInsight/clusters/prdiwsecure\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kerberos token not working properly,0.216259544,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,This cluster is build with the ESP package.We have one domain user named as 'infoworks-user'. When we tried klist it shows the ticket is valid but kerberos token got expired and because of the token expired we are unable to login to the hive shell it shows that GSS initiate exception. But we are able to access the hdfs command with the same user on the same cluster and we have other 2 to 3 different ESP enabled cluster with the same domain and we observe that the same user is working fine on the other cluster there are no issue with the kerberos token. We are only observing kerberos token failure issue on prdiwsecure cluster.,Kerberos token not  working properly,Recommended to  schedule a cronjob for infoworks-user,187326199,,,,,,,
1.20043E+14,19:10.7,prdsup : kp08tntncapsparknsprdsup01 : Spark service down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 30, 2020, 11:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: prdsup : {alphanumericpii} : Spark service down\n\nSpark shell is running more than 40 mins however no response. Also application jobs were failed after hour with below error message:\n\n20/04/30 05:51:35 ERROR log: Got exception: org.apache.thrift.transport.TTransportException java.net.SocketTimeoutException: Read timed out\norg.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: Read timed out\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - prdsup : {alphanumericpii} : Spark service down\n\nSpark shell is running more than 40 mins however no response. Also application jobs were failed after hour with below error message:\n\n20/04/30 05:51:35 ERROR log: Got exception: org.apache.thrift.transport.TTransportException java.net.SocketTimeoutException: Read timed out\norg.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: Read timed out;\n\n- ProblemStartTime: 04/30/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp08tntncapsparknsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prdsup : kp08tntncapsparknsprdsup01 : Spark service down,0.070755303,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,prdsup : kp08tntncapsparknsprdsup01 : Spark service down,prdsup : kp08tntncapsparknsprdsup01 : Spark service down,"Issue was seeing GC pauses on the metastore service and the nodes do not have sufficient RAM. Suggested customer to try fixing (reduce heap usage) the HiveServer2 (like ask applications to use “hive.fetch.task.conversion=none”) and reduce heap size of HiveServer2, there by they would get memory to increase heap size for metastore..",,,,,,,,
1.20043E+14,00:47.9,Autoscale makes the cluster to go into an unstable state,The cluster goes into unstable state when autoscale takes effect. \nError Message: Application Master is out of sync with Resource Manager.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Payouts PayoutJournal Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb075b87-16bb-42c1-9e6a-1338cc47f6e2/resourceGroups/payoutjournal_prod_eastus_spark/providers/Microsoft.HDInsight/clusters/sparkclusterprodeastus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Autoscale makes the cluster to go into an unstable state,0.100800152,Root Cause : HDInsight Service\By Design\Other,,Autoscale makes the cluster to go into an unstable state,You have  autoscale turned on (Load based) and scaleup/down is happening every 10 min to 12 min based on your workload. So as the autoscale is happening Quite oftenso some times it takes time for cluster to bring up cluster configurations as it is when there is scale up/down opearation. This may be the cause of the issue. This is not a exact RCA because customer deleted cluster we do not have exact information to troubleshoot. ,"recommendations would be below1) set up a cluster with fixed number of nodes according to your workloads but as you said that this will work in their scenario because you have jobs scheduled 24/7 and workload differs and you cannot have fixed number of nodes.2) the next recommendation is Please file a SEV-A ticket as this is in production  and Please do not delete the cluster,so that we can do more investigation.3) Also you can scale up autoscale on scheduled basis but as you have informed this will also applicable to your need.",,,,,,,,
1.20043E+14,38:42.5,Livy service down for several minutes,"Question: What time did the problem begin?\nAnswer: Wed, Apr 29, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi, we are submitting spark jobs to the cluster via {Namepii} API (we use internal URI because the cluster is deployed within our vNet). We have noticed failures due to livy service endpoint (http://hn0-comput:8998/batches and http://hn1-comput:8998/batches) being down for several minutes. \nWe know that services sometime switch from one headnode to another, but at least one headnode should have the service running all the time. That's why we try both headnodes before failing the request. What we are seeing is that for a few minutes, livy service is not running on either headnode.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi, we are submitting spark jobs to the cluster via {Namepii} API (we use internal URI because the cluster is deployed within our vNet). We have noticed failures due to livy service endpoint (http://hn0-comput:8998/batches and http://hn1-comput:8998/batches) being down for several minutes. \nWe know that services sometime switch from one headnode to another, but at least one headnode should have the service running all the time. That's why we try both headnodes before failing the request. What we are seeing is that for a few minutes, livy service is not running on either headnode.;\n\n- ProblemStartTime: 04/29/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/97b07783-4db1-431d-8061-031f604fa724/resourceGroups/RgComputeUs1Usc/providers/Microsoft.HDInsight/clusters/computeus1usc\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Livy service down for several minutes,27.13124466,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,HDFS checkpoint alerts are not cleared when manually saving and livy server intermittently going down are surface symptoms. In the leader election logs we see that there are issues selecting a leader sometimes. Note that since the zookeeper issue is intermittent most of the other issues may also be intermittent.,"Unhealthy zookeepers can cause HDFS issues and on this case we believe it was causing issues with active head node re-election which can intermittently cause livy server to go down. Livy runs on the active head node, so in this case it appears that zookeeper health caused the re-election to partially fail so the service failed to transition and was moved back to the original head node. During that time, the service on the original node would have been turned off with maintenance mode enabled. This would mean the service is off at that time in both head nodes until it is returned to the original head node. During that time API requests will fail since there is no server running to process the request. It seems most of these issues are due to resource constraints since the zookeeper nodes are deployed as the minimum size because they are offered free of charge to the customer. They only have 4 GB of memory to work with but run lots of critical processes that keep the cluster running.","Product team provided some recommendations to help with zookeepers, mainly to increase the zookeeper heap from 1 GB to 1.5 GB and to stagger the hourly cron job in /etc/crontab# m h dom mon dow user  command17 *    * * *   root    cd / && run-parts --report /etc/cron.hourlyThe number under the ""m"" column should differ on each zookeeper node, for instance this one is 17 so you may set another zk node to 9 and the other to 23 as an example.",187834490,,,,,,,
1.20043E+14,41:26.9,Can not scale up,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 30, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Apr 30, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: cluster can not scale up due to RM issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - cluster can not scale up due to RM issue;\n\n- ProblemStartTime: 04/30/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-DEV-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/is24cccmcaidev\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can not scale up,0.105938706,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to scaleup,Cannot scale up,"Recommend you to keep the replication factor as “1” and in case of these issues, please run “hdfs fsck hdfs://mycluster/ -delete""  if landed on the same issue again",,,,,,,,
1.20043E+14,09:13.7,Slow performance ,"Question: What time did the problem begin?\nAnswer: Fri, Apr 17, 2020, 12:00 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: 2 core\n3 ex\n5g driver\n10g excu\n\nQuestion: Additional details about the issue\nAnswer: Slow performance and dashboard isn't updating with job resouce \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Scala;\nSpark configuration details - 2 core\n3 ex\n5g driver\n10g excu;\nAdditional details about the issue - Slow performance and dashboard isn't updating with job resouce ;\n\n- ProblemStartTime: 04/17/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Level 3 IT BCSS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Slow performance ,1.000443283,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,Slow performance.,Cluster don’t have enough worker nodes to complete the jobs which customer is running. ,As cluster don’t have enough worker nodes to complete the jobs which customer is running. Suggested customer to Increase the number of worker nodes to match resources required for the number of requests made.,,,,,,,,
1.20043E+14,40:48.2,HDInsight accessing {for READ} ADLS Gen2 storage,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 27, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We've used ABFS but still not gaining access, we get 'Configuration property wefanalyticsdatagen2.dfs.core.windows.net not found' error\n\nQuestion: Additional details about the issue\nAnswer: We have a HDInsight cluster setup to use a local subscription storage account and an adsl {alphanumericpii} storage.\n\nWe have been told that for us to access for READ {not write} an ADLS {Namepii} 2 we have to rebuild our cluster with an ADSL {Alphanumericpii} for storage.\n\nWhy can we not connect to an ADLS {Alphanumericpii} {for read} from a HDInsight cluster setup for ADSL {Alphanumericpii} and local storage?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - We've used ABFS but still not gaining access, we get 'Configuration property wefanalyticsdatagen2.dfs.core.windows.net not found' error;\nAdditional details about the issue - We have a HDInsight cluster setup to use a local subscription storage account and an adsl {alphanumericpii} storage.\n\nWe have been told that for us to access for READ {not write} an ADLS {Namepii} 2 we have to rebuild our cluster with an ADSL {Alphanumericpii} for storage.\n\nWhy can we not connect to an ADLS {Alphanumericpii} {for read} from a HDInsight cluster setup for ADSL {Alphanumericpii} and local storage?;\n\n- ProblemStartTime: 04/27/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT DSRE SIE Data Intelligence\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2c2f9288-5f33-4d39-a955-054ac29d7768/resourceGroups/{Namepii}-HDI-RG/providers/Microsoft.HDInsight/clusters/darwin-hdi\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight accessing {for READ} ADLS Gen2 storage,0.035911839,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in standard cluster",HDInsight accessing {for READ} ADLS Gen2 storage,This is by our current design.,As per the current design customer cannot read the file from ADLS gen 2 because it will be using a different driver on the cluster as customer is  using ADLS gen 1 as  primary storage in their hdinsight cluster.So our recommendation would be if they want to access ADLS gen 2 account they would  need to add adls gen 2  to their cluster and then access it.,,,,,,,,
1.20043E+14,52:54.3,"not able run queries from Ambari  - Hive View  , using HiveServer2 Interactive","Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=admin\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer:  beeline -u 'jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicros                   oft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2'\nConnecting to jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicrosoft.com:2181/;ser                   {AlphanumericPII}\nError: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper ({alphanumericpii})\nBeeline version 1.2.1000.2.6.5.3009-43 by {Namepii} Hive\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {AlphanumericPII}: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=admin;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue -  beeline -u 'jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicros                   oft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2'\nConnecting to jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicrosoft.com:2181/;ser                   {AlphanumericPII}\nError: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper ({alphanumericpii})\nBeeline version 1.2.1000.2.6.5.3009-43 by {Namepii} Hive\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph13sprkprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","not able run queries from Ambari  - Hive View  , using HiveServer2 Interactive",0.048585031,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,"org.apache.ambari.view.hive20.internal.ConnectionException: Cannot open a hive connection with connect string jdbc:hive2://zk0-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk1-kpph13.kpaaddsprod.onmicrosoft.com:2181,zk3-kpph13.kpaaddsprod.onmicrosoft.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2;hive.server2.proxy.user=admin  Question: Interactive query explain plan if available",Checked the hive logs and root cause of the issue is due to the connection are not established with zookeeper which contributed the hive issue. By restarting hiverserv2 on Headnode resolved the issue. We have clearly documented the this issue in our public documentationhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/interactive-query-troubleshoot-inaccessible-hive-view,Checked the hive logs and root cause of the issue is due to the connection are not established with zookeeper which contributed the hive issue. By restarting hiverserv2 on Headnode resolved the issue. We have clearly documented the this issue in our public documentationhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/interactive-query-troubleshoot-inaccessible-hive-view,186848462,,,,,,,
1.2005E+14,24:58.1,Dashboard Analytics does not work,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: I am following the learning path for creating a HD interactive query:\n\nhttps://docs.microsoft.com/en-us/learn/modules/perform-zero-etl-analytics-hdinsight-interactive-query/5-exercise-upload-query-data-hdinsight\n\nI created the HDinsight cluster, and Ambari works via the browser. (so it is running).\n\nI did attach the script to the head node for getting the Dashboard working.\n\nBut when I go to the url for the dashboard, i get a blank screen. Here are the error from the Chrome browser:\n\ngoto url: https://ktg2cluster.azurehdinsight.net/das\n\nQuestion: Additional details about the issue\nAnswer: \nThese are the errors I get from the data analytics dashboard when loading:\n\nDevTools failed to parse SourceMap: chrome-extension://hdokiejnpimakedhajhdlcegeplioahd/sourcemaps/onloadwff.js.map\n{alphanumericpii} Refused to apply style from 'https://ktg2cluster.azurehdinsight.net/assets/vendor.css' because its MIME type ('text/plain') is not a supported stylesheet MIME type, and strict MIME checking is enabled.\n{alphanumericpii} Refused to apply style from 'https://ktg2cluster.azurehdinsight.net/assets/hivestudio.css' because its MIME type ('text/plain') is not a supported stylesheet MIME type, and strict MIME checking is enabled.\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/vendor.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/hivestudio.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/autocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlParseSupport.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlStatementsParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlSyntaxParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/globalSearchParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sql.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlUtils.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/colors.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlFunctions.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleteParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter2.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter3.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/join-report-lazy.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/pollyfills.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/geo-no-antarctica.json net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/vendor.js net::ERR_ABORTED 404\nDevTools failed to parse SourceMap: chrome-extension://hdokiejnpimakedhajhdlcegeplioahd/sourcemaps/onloadwff.js.map\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/hivestudio.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/autocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlParseSupport.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlStatementsParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlSyntaxParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/globalSearchParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sql.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlUtils.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/colors.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlFunctions.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleteParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter2.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter3.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/join-report-lazy.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/pollyfills.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/geo-no-antarctica.json net::ERR_ABORTED 404\n{alphanumericpii} Channel: Error in handleResponse UNK/UNK tabClipper initCompleted\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Uncaught (in promise) Error: {}\n    at Function.fromAny ({alphanumericpii})\n    at Channel._handleResponsePromise ({alphanumericpii})\n    at Channel._handleDispatchResponse ({alphanumericpii})\n    at Channel._handleMessage ({alphanumericpii})\n    at _listener ({alphanumericpii})\nClipperError @ {alphanumericpii}\nfromAny @ {alphanumericpii}\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Channel: Error in handleResponse UNK/UNK tabClipper getCurrentTheme\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Uncaught (in promise) Error: {}\n    at Function.fromAny ({alphanumericpii})\n    at Channel._handleResponsePromise ({alphanumericpii})\n    at Channel._handleDispatchResponse ({alphanumericpii})\n    at Channel._handleMessage ({alphanumericpii})\n    at _listener ({alphanumericpii})\nClipperError @ {alphanumericpii}\nfromAny @ {alphanumericpii}\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\nPromise.then (async)\nEe @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\nPromise.then (async)\nupdate @ {alphanumericpii}\nOptionsUpdateHandler @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n__webpack_require__ @ {alphanumericpii}\ncheckDeferredModules @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/images/favicon.ico 404\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - I am following the learning path for creating a HD interactive query:\n\nhttps://docs.microsoft.com/en-us/learn/modules/perform-zero-etl-analytics-hdinsight-interactive-query/5-exercise-upload-query-data-hdinsight\n\nI created the HDinsight cluster, and Ambari works via the browser. (so it is running).\n\nI did attach the script to the head node for getting the Dashboard working.\n\nBut when I go to the url for the dashboard, i get a blank screen. Here are the error from the Chrome browser:\n\ngoto url: https://ktg2cluster.azurehdinsight.net/das;\nAdditional details about the issue - \nThese are the errors I get from the data analytics dashboard when loading:\n\nDevTools failed to parse SourceMap: chrome-extension://hdokiejnpimakedhajhdlcegeplioahd/sourcemaps/onloadwff.js.map\n{alphanumericpii} Refused to apply style from 'https://ktg2cluster.azurehdinsight.net/assets/vendor.css' because its MIME type ('text/plain') is not a supported stylesheet MIME type, and strict MIME checking is enabled.\n{alphanumericpii} Refused to apply style from 'https://ktg2cluster.azurehdinsight.net/assets/hivestudio.css' because its MIME type ('text/plain') is not a supported stylesheet MIME type, and strict MIME checking is enabled.\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/vendor.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/hivestudio.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/autocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlParseSupport.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlStatementsParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlSyntaxParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/globalSearchParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sql.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlUtils.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/colors.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlFunctions.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleteParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter2.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter3.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/join-report-lazy.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/pollyfills.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/geo-no-antarctica.json net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/vendor.js net::ERR_ABORTED 404\nDevTools failed to parse SourceMap: chrome-extension://hdokiejnpimakedhajhdlcegeplioahd/sourcemaps/onloadwff.js.map\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/hivestudio.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/autocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlParseSupport.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlStatementsParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlSyntaxParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/globalSearchParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sql.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlUtils.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/colors.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlFunctions.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleteParser.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter2.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/autocomplete/sqlAutocompleter3.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/join-report-lazy.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/pollyfills.js net::ERR_ABORTED 404\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/js/geo-no-antarctica.json net::ERR_ABORTED 404\n{alphanumericpii} Channel: Error in handleResponse UNK/UNK tabClipper initCompleted\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Uncaught (in promise) Error: {}\n    at Function.fromAny ({alphanumericpii})\n    at Channel._handleResponsePromise ({alphanumericpii})\n    at Channel._handleDispatchResponse ({alphanumericpii})\n    at Channel._handleMessage ({alphanumericpii})\n    at _listener ({alphanumericpii})\nClipperError @ {alphanumericpii}\nfromAny @ {alphanumericpii}\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Channel: Error in handleResponse UNK/UNK tabClipper getCurrentTheme\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\n{alphanumericpii} Uncaught (in promise) Error: {}\n    at Function.fromAny ({alphanumericpii})\n    at Channel._handleResponsePromise ({alphanumericpii})\n    at Channel._handleDispatchResponse ({alphanumericpii})\n    at Channel._handleMessage ({alphanumericpii})\n    at _listener ({alphanumericpii})\nClipperError @ {alphanumericpii}\nfromAny @ {alphanumericpii}\n_handleResponsePromise @ {alphanumericpii}\n_handleDispatchResponse @ {alphanumericpii}\n_handleMessage @ {alphanumericpii}\n_listener @ {alphanumericpii}\nPromise.then (async)\nEe @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\nPromise.then (async)\nupdate @ {alphanumericpii}\nOptionsUpdateHandler @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n__webpack_require__ @ {alphanumericpii}\ncheckDeferredModules @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n(anonymous) @ {alphanumericpii}\n{alphanumericpii} GET https://ktg2cluster.azurehdinsight.net/assets/images/favicon.ico 404;\n\n- ProblemStartTime: 04/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: YSG Azure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Developer\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Developer\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Dashboard Analytics does not work,0.131734769,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Dashboard Analytics does not work,It may because of intermittent issues ,We have created a new cluster and Data Analytics studio worked.  ,,,,,,,,
1.2005E+14,54:37.2,NodeManager decommissioning is not working through ambari UI,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We're not able to decommission the nodemanager as per the operational doc provided to Adobe for the scaledown operation. \n\nEx: wn9-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net\n\nIts not going to 'Decommissioned' state. Its been 3 days. I tried again today on other node. Looks like NodeManager decommissioning is not working or stuck somewhere.  Could you help resolve this issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - ;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We're not able to decommission the nodemanager as per the operational doc provided to Adobe for the scaledown operation. \n\nEx: wn9-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net\n\nIts not going to 'Decommissioned' state. Its been 3 days. I tried again today on other node. Looks like NodeManager decommissioning is not working or stuck somewhere.  Could you help resolve this issue.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",NodeManager decommissioning is not working through ambari UI,20.87021761,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hbase,NodeManager decommissioning is not working through ambari UI,NodeManager decommissioning is not working through ambari UI,Checked and engaged product group on this and product group confirmed that there is no issue with continuing the process shared with customer with regards to removing node from the cluster with the state of nodemanager on the cluster.,186512159,,,,,,,
1.2005E+14,47:23.8,Spark2 thrift servers went down and are not starting up,"Question: What time did the problem begin?\nAnswer: Sun, May 3, 2020, 8:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: We have added additional yarn queues and distributed the cluster resources among the queues. \n\nDue to previous experiences, post the queue creation we ensured that the timeline service version is {Alphanumericpii} in configs and also have stopped the service, put them in maintenance mode on both the head nodes.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We've tried restarting the thrift server from the nodes, even tried restarting all components of {alphanumericpii} cluster as well. Nothing worked\n\nQuestion: Additional details about the issue\nAnswer: We have added additional yarn queues and distributed the cluster resources among the queues. \n\nDue to previous experiences, post the queue creation we ensured that the timeline service version is {Alphanumericpii} in configs and also have stopped the service, put them in maintenance mode on both the head nodes.\n\nApart from above when ever we tried restarting the {alphanumericpii} server from the head nodes pages in ambari. On one of the nodes (hn1) we get 'Command completed successfully!' without any errors in the ambari console logs. On the other node (hn0) we still get the above but in the middle there are some errors with regards to some .inprogress file not found in the {alphanumericpii} folder. \n\nAttaching both the nodes service restart logs below for reference ({alphanumericpii} has the error)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - We have added additional yarn queues and distributed the cluster resources among the queues. \n\nDue to previous experiences, post the queue creation we ensured that the timeline service version is {Alphanumericpii} in configs and also have stopped the service, put them in maintenance mode on both the head nodes.;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We've tried restarting the thrift server from the nodes, even tried restarting all components of {alphanumericpii} cluster as well. Nothing worked;\nAdditional details about the issue - We have added additional yarn queues and distributed the cluster resources among the queues. \n\nDue to previous experiences, post the queue creation we ensured that the timeline service version is {Alphanumericpii} in configs and also have stopped the service, put them in maintenance mode on both the head nodes.\n\nApart from above when ever we tried restarting the {alphanumericpii} server from the head nodes pages in ambari. On one of the nodes (hn1) we get 'Command completed successfully!' without any errors in the ambari console logs. On the other node (hn0) we still get the above but in the middle there are some errors with regards to some .inprogress file not found in the {alphanumericpii} folder. \n\nAttaching both the nodes service restart logs below for reference ({alphanumericpii} has the error);\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/03/2020 14:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: vorta-apps\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/89af8e50-7425-4733-995a-bb923ceeae76/resourceGroups/vdp-dev-rg/providers/Microsoft.HDInsight/clusters/vdp-hdispark-dev\n- Location: southindia\n- Location: South India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark2 thrift servers went down and are not starting up,0.989851613,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,Spark2 thrift servers went down and are not starting up,"Most of the time job is spent in wholestagecodegen where query tried to use ""concat"" function",Steps performed on both the headnode  Step-1: check the PID running on port 10002sudo lsof -i:10002Step-2: Kill the PIDsudo kill -9 20230 Step-3: Start the spark thrift service from Ambari.,186756654,,,,,,,
1.2005E+14,57:28.6,Datastore access issue while running spark action through oozie,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 4, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you tried kinit command or logged in using AAD credential?\nAnswer: No\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Storage account\n\nQuestion: Detail of the changes\nAnswer: Trying to run oozie spark action in HDInsight ckuster with spark 2.4 and getting below error.\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Attached file with workflow and error details\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you tried kinit command or logged in using AAD credential? - No;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Storage account;\nDetail of the changes - Trying to run oozie spark action in HDInsight ckuster with spark 2.4 and getting below error.;\nMitigating actions taken so far - ;\nAdditional details about the issue - Attached file with workflow and error details;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/04/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: dsar-rqns\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/352ff61a-3020-4199-af5a-24b34eaaf95a/resourceGroups/opsihdi-rg/providers/Microsoft.HDInsight/clusters/optum-hdinsight1-opsi\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Datastore access issue while running spark action through oozie,0.041242514,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\hdfs commands do not work\WASB in cluster with Enterprise Security Package,Archive functionality is not archiving folder and subfolder in command line through spark submit as well it it working only through rest API call. ,limitation,Archive functionality is not archiving folder and subfolder in command line through spark submit as well it it working only through rest API call. But it would be nice if it works in command line and through oozie. May be instead of calling it a issue we can raise it as a requirement. Meanwhile we did a workaround and changed code to use Hadoop fs api to read the required configuration/property files. This is not a blocker of now but it would be helpful if we can get it addressed in near future.,187000371,,,,,,,
1.2005E+14,25:42.6,node  hn0-dev-sp unresponsive,"Question: What time did the problem begin?\nAnswer: lun., 4 de may. de 2020 16:00 {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: ssh connects to port 22 but doesnt complete authentication:\nConnection established.\nTo escape to local shell, press 'Ctrl+Alt+]'.\n\nnode is unresponsive from ambari\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - ssh connects to port 22 but doesnt complete authentication:\nConnection established.\nTo escape to local shell, press 'Ctrl+Alt+]'.\n\nnode is unresponsive from ambari;\n\n- ProblemStartTime: 05/04/2020 19:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Fastdata\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1303336b-a198-4847-90f3-be74f817474d/resourceGroups/novum-storage-rg/providers/Microsoft.HDInsight/clusters/dev-spark-uru\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",node  hn0-dev-sp unresponsive,0.061625207,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,headnodes unresponsive,Heartbeat loss on headnodes    ,Restarted headnode(s),186860674,,,,,,,
1.2005E+14,30:32.6,Added additional Node and getting alerts on web UIs,"Question: What time did the problem begin?\nAnswer: Wed, Apr 15, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Added 5 Additionals Nodes to the cluster \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: {Namepii} bunch of restarts but throwing connection failures\nYarn Node Managers show alive but alerts show its affected. \n\nQuestion: Additional details about the issue\nAnswer: This alert is triggered if the number of down NodeManagers in the cluster is greater than the configured critical threshold. It aggregates the results of NodeManager process checks.\n\nConnection failed to http://wn26-chsp96.domainservices.ncr.com:1022 (Execution of '/usr/bin/kinit -c /{alphanumericpii} -kt /etc/security/keytabs/smokeuser.headless.keytab {EmailPII}@DOMAINSERVICES.NCR.COM  /dev/null' returned 1. kinit: Keytab contains no suitable keys for {EmailPII}@DOMAINSERVICES.NCR.COM while getting initial credentials)\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Added 5 Additionals Nodes to the cluster ;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - {Namepii} bunch of restarts but throwing connection failures\nYarn Node Managers show alive but alerts show its affected. ;\nAdditional details about the issue - This alert is triggered if the number of down NodeManagers in the cluster is greater than the configured critical threshold. It aggregates the results of NodeManager process checks.\n\nConnection failed to http://wn26-chsp96.domainservices.ncr.com:1022 (Execution of '/usr/bin/kinit -c /{alphanumericpii} -kt /etc/security/keytabs/smokeuser.headless.keytab {EmailPII}@DOMAINSERVICES.NCR.COM  /dev/null' returned 1. kinit: Keytab contains no suitable keys for {EmailPII}@DOMAINSERVICES.NCR.COM while getting initial credentials)\n;\n\n- ProblemStartTime: 04/15/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHSP96ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Added additional Node and getting alerts on web UIs,0.04315285,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Added additional Node and getting alerts on web UIs,"I inspected the logs and see that there was an error trying to start nodemanager saying it was unable to authenticate with the keytab.   2020-04-07 16:26:12,160 ERROR nodemanager.NodeManager - Error starting NodeManagerCaused by: org.apache.hadoop.security.KerberosAuthException: failure to login: for principal: nm/wn34-chsp96.domainservices.ncr.com@DOMAINSERVICES.NCR.COM from keytab /etc/security/keytabs/nm.service.keytab javax.security.auth.login.LoginException: Unable to obtain password from user However, soon after the error was thrown the login was successful. 2020-04-07 16:26:37,170 INFO  security.UserGroupInformation - Login successful for user nm/wn34-chsp96.domainservices.ncr.com@DOMAINSERVICES.NCR.COM using keytab file /etc/security/keytabs/nm.service.keytab Both these calls have millisecond gap between them.  Looking at the scale-up I see that the scale up operation succeeded at @16:31 UTC after the service got up and running.  2020-04-07 16:31:16.0524083àchsp96adlsparkàRunning.  ",NA,,,,,,,,
1.2005E+14,01:02.7,kafka hdiinsight failed to deploy,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 4, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: created using the command attached in the files.\nError shown in the az cli is \nDeployment failed. Correlation ID: {guidpii}. Internal server error occurred while processing the request. Please retry the request or contact support.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - created using the command attached in the files.\nError shown in the az cli is \nDeployment failed. Correlation ID: {guidpii}. Internal server error occurred while processing the request. Please retry the request or contact support.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/04/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: BigDataSpain\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/11bde4d8-2282-44ee-8388-696aee98263d/resourceGroups/myresouece-dsad56/providers/Microsoft.HDInsight/clusters/kafka-iot-dsad56\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kafka hdiinsight failed to deploy,0.078660621,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,kafka hdiinsight failed to deploy,FailedToWaitForKafkaRestproxyToRespondErrorCode: Azure CLI for --kafka-management-node-size wasn't eliminated ,eliminated a line to create the cluster without REST proxy :--kafka-management-node-size in CX Azure CLI,,,,,,,,
1.20051E+14,03:33.2,Unable to view logs for in Yarn UI for finished spark jobs,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 27, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Number of executors: 64\nExecutor cores: 1\nMemory per executors: 6g\n\nQuestion: Additional details about the issue\nAnswer: 1. For finished logs, the yarn ui does not show the executor logs.\n\n2. Spark History server is not refreshed regularly. Contains logs older than a month.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - Number of executors: 64\nExecutor cores: 1\nMemory per executors: 6g;\nAdditional details about the issue - 1. For finished logs, the yarn ui does not show the executor logs.\n\n2. Spark History server is not refreshed regularly. Contains logs older than a month.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/27/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe-sp-eu01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to view logs for in Yarn UI for finished spark jobs,0.825668831,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,"Unable to view logs for in Yarn UI for finished spark jobs:  For finished logs, the      yarn UI does not show the executor logs.  Spark      History server is not refreshed regularly. Contains logs older than a      month.",The permission of temp folder ‘/var/lib/spark2/shs_db’ has been changed to ‘root:root’  which spark user could not access so that Spark History Server could refresh the data.,Reset the permission of ‘/var/lib/spark2/shs_db’ to ‘spark:hadoop’ and restart Spark History Server again.,,,,,,,,
1.20051E+14,00:14.6,Expired password for AAD admin user for HD Insights with ESP,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 4, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: Other, don't know or not applicable\n\nQuestion: Are the accounts federated?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: No\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: No\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: No\n\nQuestion: Additional details about the issue\nAnswer: Couple of month ago we've installed HDI cluster with ESP.\nSo, we created the user srv_insights in AAD for this.\n\nYesterday, when we connected by SSH to the HDI Head node, we have got this message:\n'Password for user srv_insights will expire on {Namepii} May  5 13:13:39 2020'\n\nWe tried this:\nReset password in AAD for srv_insights. \n\nThen we logged in to https://login.microsoftonline.com/ with temporary password and changed password to the same as it was before reset.\nAfter this, when we connected to the Head node again by SSH, it showed us that the password is already expired, however we have ssuccessfully connected.\n\nUnfortunately, we aren't able to login to the AMBARI web interface with srv_insights user. We receive this error: \n{'Code':'Unauthorized','Message':'Failed to get a kerberos ticket for the user: {emailpii}@agtb.com. ErrorCode:LogonDenied. Please check the username and password, make sure that the account is not locked out or {AlphanumericPII}'}\n\n\nWe've checked the srv_insights user in AAD DS - there are two check boxes marked:\n- user must change password at next logon\n- user can't change password\n\nUnfortunately, we can't uncheck these boxes because they aren't editable.\n\nThe same issue is on all our HDI clusters: Dev, QA, Staging, UAT and Production.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - Other, don't know or not applicable;\nAre the accounts federated? - Other, don't know or not applicable;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - No;\nDoes kinit for some or all users work from the Head node? - No;\nDoes authentication fail even for the cluster admin account? - Yes;\nHave you logged in to Ambari as local admin and verified the users have been synced? - No;\nAdditional details about the issue - Couple of month ago we've installed HDI cluster with ESP.\nSo, we created the user srv_insights in AAD for this.\n\nYesterday, when we connected by SSH to the HDI Head node, we have got this message:\n'Password for user srv_insights will expire on {Namepii} May  5 13:13:39 2020'\n\nWe tried this:\nReset password in AAD for srv_insights. \n\nThen we logged in to https://login.microsoftonline.com/ with temporary password and changed password to the same as it was before reset.\nAfter this, when we connected to the Head node again by SSH, it showed us that the password is already expired, however we have ssuccessfully connected.\n\nUnfortunately, we aren't able to login to the AMBARI web interface with srv_insights user. We receive this error: \n{'Code':'Unauthorized','Message':'Failed to get a kerberos ticket for the user: {emailpii}@agtb.com. ErrorCode:LogonDenied. Please check the username and password, make sure that the account is not locked out or {AlphanumericPII}'}\n\n\nWe've checked the srv_insights user in AAD DS - there are two check boxes marked:\n- user must change password at next logon\n- user can't change password\n\nUnfortunately, we can't uncheck these boxes because they aren't editable.\n\nThe same issue is on all our HDI clusters: Dev, QA, Staging, UAT and Production.;\n\n- ProblemStartTime: 05/03/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/489eee40-40dd-4904-a88f-1dd0cf0565e1/resourceGroups/SEA-PRD01-RGP-SHARED01/providers/Microsoft.HDInsight/clusters/sea-prd01-hdi01\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Expired password for AAD admin user for HD Insights with ESP,3.333013392,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Expired password for AAD admin user for HD Insights with ESP,Failed Password reset,Reset Password from AAD ,,,,,,,,
1.20051E+14,29:59.3,How to connect HD Insight cluster to PaaS SQL database,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Connection string being used\nAnswer: na\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We are trying to connect Sql PaaS DB from HD Insight {Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - Yes;\nConnection string being used - na;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Other, don't know or not applicable;\nAdditional details about the issue - We are trying to connect Sql PaaS DB from HD Insight {Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: L&T Construction - Digital\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralindia\n- Location: Central India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to connect HD Insight cluster to PaaS SQL database,0.349186707,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to standard cluster,unable to connect to a sql db to hdi,Unable to connect to Paas SQL database,Provide verbose step to customer on.-Configuring firewall correctly provided steps.-Service endpoints are the preferable option if you can meet the constraints documented in this article:https://docs.microsoft.com/en-us/azure/sql-database/sql-database-vnet-service-endpoint-rule-overview,,,,,,,,
1.20051E+14,59:44.0,We want to know which nodes will be deleted when we downscale the cluster,for eg:we have some 5 nodes which we have scaled up and made it to 10 now if we scale down the worker nodes to 7 which nodes will be deleted.\nThe nodes which we have in the starting or the nodes which we recently deleted or any other case?\nWe want a breif explanation on what nodes will get deleted when we perform a scale down.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PSG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,We want to know which nodes will be deleted when we downscale the cluster,0.167847038,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,Advisory/GuidanceWe want to know which nodes will be deleted when we downscale the ,Advisory/GuidanceWe want to know which nodes will be deleted when we downscale the cluster,"For Manual scaling it is very simple that the highest worker nodes will be decomissioned first. For instance if you are scaling from 10 to 7 then wn10, wn9 and wn8 should be decomissioned first in a decsending order. However, it is different for autoscaling. Autoscale issues a request to remove nodes based on CPU and memory requirements. The scale-down is based on the number of AM containers per node. The service also detects which nodes are candidates for removal based on current job executions. The scale down operation first decommissions the nodes with less memory utilization & memory requirements based on current job executions, and then removes them from the cluster.There is additional great information in below links on how autoscale down works and how to safely scale down a cluster. Refer to below links for further information.Infromation on how auto scale down works --> https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-autoscale-clusters#how-it-worksHow to safely scale down a cluster --> https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-scaling-best-practices#how-to-safely-scale-down-a-cluster",,,,,,,,
1.20051E+14,27:22.5,Are there any recommended configuration tuning or best practices available to reduce time taken for auto scale up/down a worker node?,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Auto scaling takes a long time to complete. Is there a way to reduce the time taken for auto scaling?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Auto scaling takes a long time to complete. Is there a way to reduce the time taken for auto scaling?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ebf92555-9049-43d9-91d9-963b798a987b/resourceGroups/rg-useast2prod-datalake-hdis/providers/Microsoft.HDInsight/clusters/hdis-datalake-prod\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Are there any recommended configuration tuning or best practices available to reduce time taken for auto scale up/down a worker node?,0.444091118,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Are there any recommended configuration tuning or best practices available to reduce time taken for auto scale up/down a worker node?,NA,we have checked your latest scaling event that has been started on 2020-05-05 14:20:46.6460653 (UTC)and we see that it took 12 minutes to run.You have requested scale up from 3 nodes to 4 nodes.020-05-05 14:20:46.6460653 --started2020-05-05 14:20:50.6740843 --> VM Configuration started2020-05-05 14:31:37.2742003 --> HDIconfig2020-05-05 14:32:23.1521437 -- completeedHere in time interval between 14.20 and 14.31 (12 minutes) we use Overprovisioning to deploy more VMs that required and we take the required # of nodes and delete the un-necessary nodes.This is to improve the reliability of the CRUD operations. Overprovisioning kicks in during cluster deployment and scaling operations.So here overprovisioning is by design when ever we scale up a hdinsight cluster. Also please note that you will be charged only for the VMS you have requested for scale up.we have checked other scale up requests as well every thing looks good.->About Scaling down the cluster our recommendation would be to have minimum of 3 workers when scale down operation is performed.Having less than 3 worker nodes would reslut the cluster to get struck in safe mode.Please check below documentation which gives you information on how to scale down your cluster safely and some issues when you face while scaling down a cluster.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-scaling-best-practices#how-to-safely-scale-down-a-cluster,,,,,,,,
1.20051E+14,44:55.9,Hive Query Performance Issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select {alphanumericpii}) from {alphanumericpii} where 1=0\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Whenever we run a query and it keep running for ever.\n\nBut if we query without count it is rendering the data\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select {alphanumericpii}) from {alphanumericpii} where 1=0;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - Whenever we run a query and it keep running for ever.\n\nBut if we query without count it is rendering the data;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/cmidevllapdj\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Query Performance Issue,0.050764922,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Hive count(*) query not working.,"A Hive query using count(*) reduces to an execution plan that avoids MapReduce and computes the result instead using table stats. When a table is created first, the statistics is written with no data rows. Thereafter any data append/change happens hive requires to update this statistics in the metadata. Depending on the circumstances hive might not be updating this real time. Specially If the table is EXTERNAL, and the underlying storage has been directly modified, the stats don't get updated. A count(*) query under these conditions will return an inaccurate value. Also, if an EXTERNAL VIEW is defined over a large dataset without computing stats explicitly, there will appear to be no data for this query","1.	You can force hive to run a MapReduce job to count the number of rows by setting fetch task conversion to none; Set hive.fetch.task.conversion=none;hive> set hive.fetch.task.conversion=none;2.	Set the property hive.compute.query.using.stats to false, restart the service, and all should be fine.Nevertheless, it's better not to disturb the properties on the statistics usage like hive.compute.query.using.stats. It impacts the way the statistics are used in your query for performance optimization and execution plans. It has tremendous influence on execution plans, the statistics stored depends on the file format as well. Therefore, definitely not a solution to change any property with regards to statistics.Therefore, running the ANALYZE command to recomputes these statistics to make this work correctly.ANALYZE TABLE test1 COMPUTE STATISTICS;",187170289,,,,,,,
1.20051E+14,45:14.8,HDInsight VM not restarting hn1-hdi6-h.zsyfhjpd5aeenlpaokbjhkihmf.bx.internal.cloudapp.net,HDI VM not restarting\n\nhn1-hdi6-h.zsyfhjpd5aeenlpaokbjhkihmf.bx.internal.cloudapp.net\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_QUOTA\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,HDInsight VM not restarting hn1-hdi6-h.zsyfhjpd5aeenlpaokbjhkihmf.bx.internal.cloudapp.net,0.035951798,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure Quota\HDInsight,HDInsight VM not restarting hn1-hdi6-h,Services were down,Restarted the VM from the Ambari but the Head node took 20-25 minute to restart all the component.,,,,,,,,
1.20051E+14,08:03.5,we are not able to see the hbase config from the ambari.,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 5, 2020, 7:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1 ) Restarted ambari server\n 2) Restarted ambari metrics\n 3) Restarted HBase services\n\nQuestion: Additional details about the issue\nAnswer: when we checked the cluster we can see HBase services required an restart . while working with MS for this case {Phonenumberpii} we are suspecting some changes done from the MS engineer {Namepii} for the Hbase configurations.\nwhen we try to compare the configurations with our old configurations (that we configured RS & Master as IP address as per MS recommendation) for solving the unknown host error. \nBut after restart of hBase we can see it again went back to FQDN instead of our earlier configurations. \nApplication web jobs are not not able to connect to HDInsight due to unknown host error.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1 ) Restarted ambari server\n 2) Restarted ambari metrics\n 3) Restarted HBase services;\nAdditional details about the issue - when we checked the cluster we can see HBase services required an restart . while working with MS for this case {Phonenumberpii} we are suspecting some changes done from the MS engineer {Namepii} for the Hbase configurations.\nwhen we try to compare the configurations with our old configurations (that we configured RS & Master as IP address as per MS recommendation) for solving the unknown host error. \nBut after restart of hBase we can see it again went back to FQDN instead of our earlier configurations. \nApplication web jobs are not not able to connect to HDInsight due to unknown host error.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/05/2020 13:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT Integration\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/840e8a25-1606-485e-9525-6b4c49bb954f/resourceGroups/int-vims-cat-rg-01/providers/Microsoft.HDInsight/clusters/int-ts-vims-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",we are not able to see the hbase config from the ambari.,0.083454618,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Metrics are missing\Hbase,Lingering PID of ambari-server on HN1,we are not able to see the hbase config from the ambari,Found that ambari-server lingering PID is causing the issue and did the ambari-server script to restart on both HN0 and HN1 hosts fixed the issue. After that able to HBase config information and recommend you to use the provided script to restart the ambari-server instead of manually.,,,,,,,,
1.20051E+14,07:05.3,Error in opening SPARKHISTORY UI,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Number of executors = 64\nMemory = 6g\n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII}: IO error: /{alphanumericpii}: No such file or directory\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - Number of executors = 64\nMemory = 6g;\nAdditional details about the issue - {AlphanumericPII}: IO error: /{alphanumericpii}: No such file or directory\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII});\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe-sp-eu01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error in opening SPARKHISTORY UI,0.211095995,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Error in opening SPARKHISTORY UI.,NA,Restarted spark history server and also customer changed permissions on this db(listing.ldb). It fixed the issue and customer is able to open spark history server web UI.,,,,,,,,
1.20051E+14,16:19.7,prodsup  clusters : With the ESP Service accounts not able to  login to Ambari  portal,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: prodsup  clusters : With the ESP Service accounts not able to  login to Ambari  portal.\n\n\nErros:\n{'Code':'ServiceUnavailable','Message':'Error while authenticating the request. Please try again after some {AlphanumericPII}'}\n\nQuestion: Interactive query explain plan if available\nAnswer: 1. The issue is with the Ambari  portal only with the svc account.\n\n{alphanumericpii} works through the nodes.\n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: {'Code':'ServiceUnavailable','Message':'Error while authenticating the request. Please try again after some {AlphanumericPII}'}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - prodsup  clusters : With the ESP Service accounts not able to  login to Ambari  portal.\n\n\nErros:\n{'Code':'ServiceUnavailable','Message':'Error while authenticating the request. Please try again after some {AlphanumericPII}'};\nInteractive query explain plan if available - 1. The issue is with the Ambari  portal only with the svc account.\n\n{alphanumericpii} works through the nodes.;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - {'Code':'ServiceUnavailable','Message':'Error while authenticating the request. Please try again after some {AlphanumericPII}'};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prodsup  clusters : With the ESP Service accounts not able to  login to Ambari  portal,0.038047795,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,prodsup clusters : With the ESP Service accounts not able to login to Ambari portal,"We noticed that credential service in hn0 is not running on this cluster or is in a bad state. This is causing login failures.  The Gateway randomizes between hn0 and hn1 and it caches the result of the user token in memory, so a restart helped to cache the result and hence the login succeeded."," Please go ahead and restart credential server on hn0 to avoid this issue./usr/lib/hdinsight-credentialservice/bin/credential-service.sh stopsudo kill -9 `sudo jps | grep -i adlcredentialserver | awk '{print $1}'`sudo su - hcs -c ""/usr/lib/hdinsight-credentialservice/bin/credential-service.sh start""",187025417,,,,,,,
1.20051E+14,27:13.9,Not able to create topics,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 30, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: Yes\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Both cluster admin user as well as contirbutor role for HDinsights are unable to create password. It throws exception that user does not ahve access\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - Yes;\nDoes the user have proper permission on the target location recursively? - Yes;\nAdditional details about the issue - Both cluster admin user as well as contirbutor role for HDinsights are unable to create password. It throws exception that user does not ahve access;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/29/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII} (HighSec)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/084971f5-dda5-4b57-9062-2e9289a1962e/resourceGroups/strpl-paas-dev-rgp-001/providers/Microsoft.HDInsight/clusters/kafka-strpl-dev-001\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to create topics,0.569283068,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Auditing,Not able to create topics,Not able to create topics,"Supported worked with Product group and confirmed to customer that since “-int” (internal) is used, check Ranger policy and validate that user with name “kafka” is present in ALL the policies.  If it is not present add it. Restart Ranger if needed.",187104795,,,,,,,
1.20051E+14,25:12.6,Ambari UI isn't accessible,"Question: What time did the problem begin?\nAnswer: Wed, May 6, 2020, 9:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Enabled ID broker\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Troubleshooting details\nIf you contact your administrator, send this info to them.\nCopy info to clipboard\nRequest Id: {Guidpii}\nCorrelation Id: {guidpii}\nTimestamp: {ALPHANUMERICPII}\nMessage: {ALPHANUMERICPII}: The request body must contain the following parameter: 'client_id'.\nAdvanced diagnostics: Enable\nIf you plan on getting support for an issue, turn this on and try to reproduce the error. This will collect additional information that will help troubleshoot the issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Enabled ID broker;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Troubleshooting details\nIf you contact your administrator, send this info to them.\nCopy info to clipboard\nRequest Id: {Guidpii}\nCorrelation Id: {guidpii}\nTimestamp: {ALPHANUMERICPII}\nMessage: {ALPHANUMERICPII}: The request body must contain the following parameter: 'client_id'.\nAdvanced diagnostics: Enable\nIf you plan on getting support for an issue, turn this on and try to reproduce the error. This will collect additional information that will help troubleshoot the issue.;\n\n- ProblemStartTime: 05/06/2020 14:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari UI isn't accessible,7.264414407,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Ambari UI isn't  accessible,Unsupported scenario - This is an issue with HDI  3.6 with WASB storage. So we would recommend to try with Gen2 or Gen1,This is an issue with HDI  3.6 with WASB storage. So we would recommend to try with Gen2 or Gen1,187731335,,,,,,,
1.20051E+14,21:11.4,Read latencies went very high when reindexing is started,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 5, 2020, 10:23 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, May 5, 2020, 11:30 PM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: More data to be processed\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Read latencies spiked up when the reindexing is started with 10K RPM. \n\nError:\n2020-05-06 {Alphanumericpii} c.a.i.b.HBaseJournalingBolt [ERROR] HBaseJournalingBolt  failed to save status into table :Queue-SC-All , exception : java.lang.RuntimeException:\n java.lang.OutOfMemoryError: unable to create new native thread\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - Other, don't know or not applicable;\nIncrease in load? - More data to be processed;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Read latencies spiked up when the reindexing is started with 10K RPM. \n\nError:\n2020-05-06 {Alphanumericpii} c.a.i.b.HBaseJournalingBolt [ERROR] HBaseJournalingBolt  failed to save status into table :Queue-SC-All , exception : java.lang.RuntimeException:\n java.lang.OutOfMemoryError: unable to create new native thread;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/06/2020 05:23:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search PRD ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/112d7591-4d06-4945-8323-c9ef2f70158a/resourceGroups/adobeidx-prod-hbase/providers/Microsoft.HDInsight/clusters/adobesearchhbaseprodva7\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Read latencies went very high when reindexing is started,14.56677829,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,Read latencies went very high when reindexing is started,"HBase will keep the written records to a write cache (memstore) and once reaches a configured size[1] or a time interval[2], it will be written (flushed) as a file on to the Azure blob storage. When the memstore is flushed, the file data will get cached to a read cache (Local SSD on VM). Occasionally such files are getting created. Once there are 3 files (this is configurable again), those will get combined (compaction) into a single bigger file. This process will evict the file data from read cache. But HBase will not cache the resultant file into the cache.  The subsequent table scan, which try to read data within a time range it might potentially match with the time range of the data in this file too. This time the scan will not be able to get data from read cache and will hit the Azure blob storage. By default HBase will cache this read data into read cache so that the subsequent reads can happen from cache.  But we have noticed that this config is turned off. [3]There is a cluster wide global config to turn this ON/OFF.  This is defaults to true and also not changed in the cluster. Also this can be turned on/off at a table level. On all the tables, this config looks to be turned off.[4]. We will provide details about tuning this and making it ON.  Also some more configs tuning which will make sure the data is mostly available on read cache. This will be the Phase 1 tuning action from Microsoft side.",PG working with Adobe directly,"187,133,876,187,133,000,000,000,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.20051E+14,33:12.5,How to clear Last Checkpoint service alert on Namenode,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 5, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: In the past, we have tried rebooting the NameNode but it did not work. \n\nQuestion: Additional details about the issue\nAnswer: Please see screenshot.  We are receiving a NameNode Last Checkpoint error. We would like to know how to resolve this error so we stop receiving alerts. We have already tried restarting the NameNode but it does not clear it.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - In the past, we have tried rebooting the NameNode but it did not work. ;\nAdditional details about the issue - Please see screenshot.  We are receiving a NameNode Last Checkpoint error. We would like to know how to resolve this error so we stop receiving alerts. We have already tried restarting the NameNode but it does not clear it.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/05/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsRG-sec/providers/Microsoft.HDInsight/clusters/etl-a-cas-hdi-spark-sec\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to clear Last Checkpoint service alert on Namenode,33.16850128,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Spark,The HDInsight cluster etl-a-cas-hdi-spark-sec is currently suffering from HDFS checkpoint error.,NA,"The HDInsight cluster etl-a-cas-hdi-spark-sec is currently suffering from HDFS checkpoint error.Recommended StepsLog onto your HDInsight clusterRestart Ambari service on the nodes listed below, using sudo service ambari-agent restartNote: If the following list is empty, this step can be skipped:[listhosts]Once both Namenodes are running, please run the following commands to reset the checkpoint:hdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode enterhdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -saveNamespacehdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode leave                 also set the checkpoint check to 3 (10800 seconds) hours rather      than 6 (21600 Seconds) would work fine.",,,,,,,,
1.20051E+14,37:38.5,hive table lock,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: show locks;\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: We have seen on couple of instances that tables were acquiring locks and not getting cleared and because of this next load on ths table is failing. We need to understand on what instances will the tables get locked and not released until we clear the locks. In continutation to that, to clear the locks, we are restarting hive services, is there any other option. we have tried few queires but no luck.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - show locks;;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - We have seen on couple of instances that tables were acquiring locks and not getting cleared and because of this next load on ths table is failing. We need to understand on what instances will the tables get locked and not released until we clear the locks. In continutation to that, to clear the locks, we are restarting hive services, is there any other option. we have tried few queires but no luck.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data and Analytics Services\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hive table lock,0.091267258,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Hive,hive tables were acquiring locks and not clearing before the next load which resulted in table failure,We have a data race bug that occurs when insert and certain kinds of select on the same table run at the same time. This is independent of spark.CX found that query like select * from t where x = (SELECT MAX(x) FROM t) causes permanent locking when another query writes to table.,Mitigation is to split the query.,188717133,,,,,,,
1.20051E+14,16:11.9,HS2I service is not starting,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Getting the error as ' Watch mode enabled and got YARN error. Retrying.'\n\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Getting the error as ' Watch mode enabled and got YARN error. Retrying.'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Getting the error as ' Watch mode enabled and got YARN error. Retrying.'\n;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Getting the error as ' Watch mode enabled and got YARN error. Retrying.';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq049llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HS2I service is not starting,7.185035714,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,HS2I is down,HS2I service is not  starting,"Saw Zk Cancelledkey  exceptions intially and recommend to update “autopurge.snapRetainCount” value  to ""3"" in  /etc/hdinsight-zookeeper/conf/zoo.cfg file and by default set to 30. Please  reopen it or open a new case,  if this  issue happen again.",187173801,,,,,,,
1.20051E+14,41:12.1,ADF job cannot submit to Spark,"Question: What time did the problem begin?\nAnswer: Wed, May 6, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restart HDInsight service\n\nQuestion: Additional details about the issue\nAnswer: Cannot submit jobs to spark. Error message:\n{\n    'errorCode': '2310',\n    'message': 'Failed to submit Spark job. Error: 'BadGateway'',\n    'failureType': 'UserError',\n    'target': 'Transactions_Reconciliation',\n    'details': []\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restart HDInsight service;\nAdditional details about the issue - Cannot submit jobs to spark. Error message:\n{\n    'errorCode': '2310',\n    'message': 'Failed to submit Spark job. Error: 'BadGateway'',\n    'failureType': 'UserError',\n    'target': 'Transactions_Reconciliation',\n    'details': []\n};\n\n- ProblemStartTime: 05/06/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Incentives Analytics Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/afcf747b-a29a-4569-ace3-3e5885b05322/resourceGroups/Incentives101_PROD_EastUS_Spark/providers/Microsoft.HDInsight/clusters/insightssparkcluster-prodeastus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF job cannot submit to Spark,0.078748984,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Service unhealthy\Spark,ADF job cannot submit to Spark,A cluster itself is accumulating the logs and snapshot in ambari-metrics-collecotor and zookeep.,Cleaned the ambari-metric collector:  https://cwiki.apache.org/confluence/display/AMBARI/Cleaning+up+Ambari+Metrics+System+Data+-+2.4.0Cleaned the zookeeper snapshots Zk nodes.sudo java -cp /usr/hdp/current/zookeeper-server/zookeeper.jar:/usr/hdp/current/zookeeper-server/lib/* org.apache.zookeeper.server.PurgeTxnLog /hadoop/zookeeper/ /hadoop/zookeeper/ 3 sudo java -cp /usr/hdp/current/zookeeper-server/zookeeper.jar:/usr/hdp/current/zookeeper-server/lib/* org.apache.zookeeper.server.PurgeTxnLog /hadoop/hdinsight-zookeeper/ /hadoop/hdinsight-zookeeper/ 3Restarted all the services,,,,,,,,
1.20051E+14,58:57.7,Livy endpoint gives 502 bad gateway.  I tried restarting livy,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: {'name': 'SparkTestEastUS.test.eastus.all_content.editorialupdate.en-us.test', 'className': 'com.microsoft.ice.editorial.EditorialUpdateJob', 'driverCores': 3, 'driverMemory': '2G', 'numExecutors': 3, 'executorCores': 2, 'executorMemory': '2G',\n\n'conf': {'spark.executorEnv.submissionTime': '{ALPHANUMERICPII}',\n'spark.yarn.appMasterEnv.submissionTime': '{ALPHANUMERICPII}',\n'Dmdm.serviceName': 'SparkDevEastUS', \n'Dmdm.endpoint': 'http://ice-eastus-test-tip.cloudapp.net/mdmtransmit',\n'{AlphanumericPII}': 'DefaultEndpointsProtocol=https;AccountName=contentservsparklogdev;AccountKey=RhfL/7IkJrb03VMBH3fZP4NqIBxFUHnCV9hZ3nSKdFxRTwxKl0UJiXaMiIuDshyxpZI+PxJc7Mw8QhKkb5ZuvQ==;EndpointSuffix=core.windows.net'\n}, \n'file': 'wasbs://icesparkdev@icesparkdev.blob.core.windows.net//SparkDevEastUS/jars/contentranker.jar',\n 'args':[ '-s', 'SparkTestEastUS',\n '--configKey', 'en-us',\n '-sse','http://ice-eastus2-prod-signal.cloudapp.net',\n '-de','https://iceciqrdev.documents.azure.com:443/','-dk','Az2tE4dSdo2kCS9u6cogGYxdQVssI2h7QBdIKGCTHcoeYUQHTxwk6mGDTLsXSrz9v2DqD7GGu2BRG9Ebfhoaaw==','-di','Liststore',\n '--oneServiceDocDBEndpoint', 'https://oneservice-eastus-int.documents.azure.com:443/',\n '--oneServiceDocDBKey', '{AlphanumericPII}==',\n '--oneServiceDocDBId', 'Liststore',\n  '--lookbackSeconds', '3600',\n  '-d', 'en-us',\n  '-rpt', '60',\n '-it', '30',\n '--rptTopicStream', '60',\n '--itTopicStream', '30'\n\n ]\n}\nhttps://sparktesteus.azurehdinsight.net/livy/batches\n\nQuestion: Additional details about the issue\nAnswer: it doesn't work, 502 error\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - {Namepii};\nSpark configuration details - {'name': 'SparkTestEastUS.test.eastus.all_content.editorialupdate.en-us.test', 'className': 'com.microsoft.ice.editorial.EditorialUpdateJob', 'driverCores': 3, 'driverMemory': '2G', 'numExecutors': 3, 'executorCores': 2, 'executorMemory': '2G',\n\n'conf': {'spark.executorEnv.submissionTime': '{ALPHANUMERICPII}',\n'spark.yarn.appMasterEnv.submissionTime': '{ALPHANUMERICPII}',\n'Dmdm.serviceName': 'SparkDevEastUS', \n'Dmdm.endpoint': 'http://ice-eastus-test-tip.cloudapp.net/mdmtransmit',\n'{AlphanumericPII}': 'DefaultEndpointsProtocol=https;AccountName=contentservsparklogdev;AccountKey=RhfL/7IkJrb03VMBH3fZP4NqIBxFUHnCV9hZ3nSKdFxRTwxKl0UJiXaMiIuDshyxpZI+PxJc7Mw8QhKkb5ZuvQ==;EndpointSuffix=core.windows.net'\n}, \n'file': 'wasbs://icesparkdev@icesparkdev.blob.core.windows.net//SparkDevEastUS/jars/contentranker.jar',\n 'args':[ '-s', 'SparkTestEastUS',\n '--configKey', 'en-us',\n '-sse','http://ice-eastus2-prod-signal.cloudapp.net',\n '-de','https://iceciqrdev.documents.azure.com:443/','-dk','Az2tE4dSdo2kCS9u6cogGYxdQVssI2h7QBdIKGCTHcoeYUQHTxwk6mGDTLsXSrz9v2DqD7GGu2BRG9Ebfhoaaw==','-di','Liststore',\n '--oneServiceDocDBEndpoint', 'https://oneservice-eastus-int.documents.azure.com:443/',\n '--oneServiceDocDBKey', '{AlphanumericPII}==',\n '--oneServiceDocDBId', 'Liststore',\n  '--lookbackSeconds', '3600',\n  '-d', 'en-us',\n  '-rpt', '60',\n '-it', '30',\n '--rptTopicStream', '60',\n '--itTopicStream', '30'\n\n ]\n}\nhttps://sparktesteus.azurehdinsight.net/livy/batches;\nAdditional details about the issue - it doesn't work, 502 error;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ICE-ContentIntelQualityRanking-Test\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c23a622-dfc8-4ab7-a957-1ec284d4f1bb/resourceGroups/sparktesteus/providers/Microsoft.HDInsight/clusters/sparktesteus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Livy endpoint gives 502 bad gateway.  I tried restarting livy,0.973800246,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,Livy endpoint gives 502 bad gateway.  I tried restarting livy.,"java.lang.OutOfMemoryError: unable to create new native thread highlights OS cannot assign more native threads to JVMs. Confirmed that this Exception is caused by the violation of per-process thread count limit.When Livy Server terminates unexpectedly, all the connections to Spark Clusters are also terminated, which means that all the jobs and related data will be lost. In HDP 2.6 session recovery mechanism was introduced, Livy stores the session details in Zookeeper to be recovered after the Livy Server is back.When large number of jobs are submitted via Livy, as part of High Availability for Livy Server stores these session states in ZK (on HDInsight clusters) and recover those sessions when the Livy service is restarted. On restart after unexpected termination, Livy creates one thread per session and this accumulates a certain number of to-be-recovered sessions causing too many threads being created.",Livy Server cannot be started on an Apache Spark [(Spark 2.1 on Linux (HDI 3.6)] and livy server logs shows this java.lang.OutOfMemoryError: unable to create new native thread ERROR. To resolve this issue connect to zookeeper and remove all the to-be-recovered sessions.,,,,,,,,
1.20051E+14,45:03.5,kpq052llapfdqawus201: multiple services are down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: {alphanumericpii}: multiple services are down\n\nQuestion: Interactive query if applicable\nAnswer: {alphanumericpii}: multiple services are down\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}: multiple services are down\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - {alphanumericpii}: multiple services are down;\nInteractive query if applicable - {alphanumericpii}: multiple services are down;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - {alphanumericpii}: multiple services are down;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq052llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kpq052llapfdqawus201: multiple services are down,0.01660269,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,ZK Cancelledkey exceptions,ZK snapshot directory issues,"Saw ZK cancelled key  exceptions and after cleanup, it works fine",,,,,,,,
1.20051E+14,39:55.8,Working and tested ARM template is return error when deployed,"Question: What time did the problem begin?\nAnswer: Wed, May 6, 2020, 7:17 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: I deployed this ARM template through Intilij to test and I was logged in with my credentials. When deploying the same template using a {Namepii} code it return an error.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: 'Invalid value for the identities '/{AlphanumericPII}'. The 'UserAssignedIdentities' property keys should only be empty json objects, null or the resource exisiting property.{Uncpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - I deployed this ARM template through Intilij to test and I was logged in with my credentials. When deploying the same template using a {Namepii} code it return an error.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - 'Invalid value for the identities '/{AlphanumericPII}'. The 'UserAssignedIdentities' property keys should only be empty json objects, null or the resource exisiting property.{Uncpii}\n\n- ProblemStartTime: 05/06/2020 23:17:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Redpoint CDP NonProd\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Working and tested ARM template is return error when deployed,34.06882137,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,ARM template is return error when deployed,Need to provide Token,Provided steps to create bearer token,,,,,,,,
1.20051E+14,26:58.9,Getting 'The remote server returned an error: (502) Bad Gateway.',"Getting error when running action script:\naz hdinsight script-action execute \\\n--resource-group helx-dev-common-hdi-eastus-rg \\\n--cluster-name {alphanumericpii} \\\n--name 'Reset Password' \\\n--roles headnode workernode zookeepernode edgenode \\\n--script-uri 'https://helxpubgrsstadevwestus.blob.core.windows.net/scripts/changepassword.sh' \\\n--script-parameters 'helixuser xxxxxx'\n\nHere is the json from activity log:\n\n{\n    'authorization': {\n        'action': 'Microsoft.HDInsight/clusters/executeScriptActions/action',\n        'scope': '/subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourceGroups/helx-dev-common-hdi-eastus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-eastus-hdis'\n    },\n    'caller': '{emailpii}@digitalaviationservices.com',\n    'channels': 'Operation',\n    'claims': {\n        'aud': 'https://management.core.windows.net/',\n        'iss': 'https://sts.windows.net/6362b077-fb81-4d5b-adf3-129cdb1b56cf/',\n        'iat': '{Phonenumberpii}',\n        'nbf': '{Phonenumberpii}',\n        'exp': '{Phonenumberpii}',\n        'http://schemas.microsoft.com/claims/authnclassreference': '1',\n        'aio': '{AlphanumericPII}==',\n        'http://schemas.microsoft.com/claims/authnmethodsreferences': 'pwd,mfa',\n        'appid': '{guidpii}',\n        'appidacr': '0',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname': '{Namepii}',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname': '{Namepii}',\n        'groups': '01343644-aa2a-47be-b69f-2249e33ea7ec,e43a96b3-1170-48e3-8c73-f5aea1fbfe3d,2ebdaa94-43a6-4597-994b-ea6445021727,83e04630-f347-431e-89a6-b56c6e4fc177,6988efa0-82c5-4197-8f29-f2e58e1b54e2,3d257657-88f7-4567-b77f-88794e8b0722,aa8cb25e-0400-49cc-8327-15bf1c9bfae8,16bbf73a-4911-423e-8e8a-ac78be27305c,a34c1402-e9d6-4bcc-b87f-d2f03e3b4e90,94631a2c-adb4-4580-bc02-ffa198b16533,747c0a8c-0e7c-43c2-aaaf-6ca852c010bc,63926265-fd1e-4275-99d8-14bc796faf1b,088c0f7c-1dc0-408b-a8c8-a54aa36aeaf7,70ea1446-76e8-4b85-beae-306c2e225525,42c07a53-60de-43c3-b620-c27603e2da25,93bec5df-054a-45be-a129-cc338642d1e9,fdff0854-f907-4da3-8fce-4f7961cf7ebe,8cf2ab84-895e-42dc-adee-cefe2053ea00,188b7d36-dee1-4c83-bb55-34fbaf6d9e4b,b33b73cf-fa26-4cb0-9911-eb1b5d2241b5,995d4a7e-bfa1-4226-ac85-0d5af24da43c,7532e791-ee4a-4e3a-929e-0838d750bffc',\n        'ipaddr': '{Ipaddresspii}',\n        'name': '{Namepii} {Namepii}',\n        'http://schemas.microsoft.com/identity/claims/objectidentifier': '{guidpii}',\n        'onprem_sid': 'S-1-5-21-2002599273-1661918056-2761417634-5741',\n        'puid': '{XUIDPII}',\n        'http://schemas.microsoft.com/identity/claims/scope': 'user_impersonation',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier': '{AlphanumericPII}',\n        'http://schemas.microsoft.com/identity/claims/tenantid': '{guidpii}',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name': '{emailpii}@digitalaviationservices.com',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/upn': '{emailpii}@digitalaviationservices.com',\n        'uti': '{AlphanumericPII}',\n        'ver': '1.0'\n    },\n    'correlationId': '{guidpii}',\n    'description': '',\n    'eventDataId': '{guidpii}',\n    'eventName': {\n        'value': 'EndRequest',\n        'localizedValue': 'End request'\n    },\n    'category': {\n        'value': 'Administrative',\n        'localizedValue': 'Administrative'\n    },\n    'eventTimestamp': '{ALPHANUMERICPII}',\n    'id': '/subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourcegroups/helx-dev-common-hdi-eastus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-eastus-hdis/events/38c39cad-c863-4593-90dd-b163362269a4/ticks/637244579554585198',\n    'level': 'Error',\n    'operationId': '{guidpii}',\n    'operationName': {\n        'value': 'Microsoft.HDInsight/clusters/action',\n        'localizedValue': 'Microsoft.HDInsight/clusters/action'\n    },\n    'resourceGroupName': 'helx-dev-common-hdi-eastus-rg',\n    'resourceProviderName': {\n        'value': 'Microsoft.HDInsight',\n        'localizedValue': 'Microsoft.HDInsight'\n    },\n    'resourceType': {\n        'value': 'Microsoft.HDInsight/clusters',\n        'localizedValue': 'Microsoft.HDInsight/clusters'\n    },\n    'resourceId': '/subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourcegroups/helx-dev-common-hdi-eastus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-eastus-hdis',\n    'status': {\n        'value': 'Failed',\n        'localizedValue': 'Failed'\n    },\n    'subStatus': {\n        'value': '',\n        'localizedValue': ''\n    },\n    'submissionTimestamp': '{ALPHANUMERICPII}',\n    'subscriptionId': '{guidpii}',\n    'tenantId': '{guidpii}',\n    'properties': {\n        'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: ScriptExecutionFailed; ErrorDescription: The remote server returned an error: (502) Bad Gateway.{Uncpii}\n    },\n    'relatedEvents': []\n}\n\nProblem start date and time\nWed, May 6, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 05/06/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: eastus\n- ResourceUri: /subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourceGroups/helx-dev-common-hdi-eastus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-eastus-hdis\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting 'The remote server returned an error: (502) Bad Gateway.',0.114653649,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,Getting 'The remote server returned an error: (502) Bad Gateway.',HN1 in bad state,restarted HN1 ,,,,,,,,
1.20051E+14,13:39.0,Service principal authentication,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 7, 2020, 10:45 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: I am raising this as a Sev A Support case because the current certificate for our 'HDISigi' service principal expires soon and we won't be able to deploy Azure HDInsight clusters, hence the impact is wide-spread and will affect all of our HDInsight users within Selective.\n\nOur HDInsight cluster's are failing to deploy due to not being able to validate our 'HDISigi' Azure service principal in Azure Active Directory.\n\nThe existing certificate for HDISigi is expiring on 5/10, so we created a new certificate with the attached '{AlphanumericPII}' Powershell script, and uploaded the newly created certificate to the HDISigi service principal in Azure Active Directory, uploaded the same certificate to our 'sigi-keyvaultqa' Azure Key Vault, and uploaded the certificate password into the same Azure Key Vault. \n\nLines {Alphanumericpii} in the attached '{AlphanumericPII}' Powershell script fetch the certificate and certificate password from the 'sigi-keyvaultqa' Azure Key Vault.\n\nWe are certain we are using the correct certificate and certificate password, but our cluster deployment is still failing.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - I am raising this as a Sev A Support case because the current certificate for our 'HDISigi' service principal expires soon and we won't be able to deploy Azure HDInsight clusters, hence the impact is wide-spread and will affect all of our HDInsight users within Selective.\n\nOur HDInsight cluster's are failing to deploy due to not being able to validate our 'HDISigi' Azure service principal in Azure Active Directory.\n\nThe existing certificate for HDISigi is expiring on 5/10, so we created a new certificate with the attached '{AlphanumericPII}' Powershell script, and uploaded the newly created certificate to the HDISigi service principal in Azure Active Directory, uploaded the same certificate to our 'sigi-keyvaultqa' Azure Key Vault, and uploaded the certificate password into the same Azure Key Vault. \n\nLines {Alphanumericpii} in the attached '{AlphanumericPII}' Powershell script fetch the certificate and certificate password from the 'sigi-keyvaultqa' Azure Key Vault.\n\nWe are certain we are using the correct certificate and certificate password, but our cluster deployment is still failing.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/07/2020 14:45:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Service principal authentication,2.263333742,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,"Following deploying in log entry we can see the internal error for the error that was thrown to the customer. External error - ""Failed to connect to AAD to validate the service principal."" Internal error - ""Invalid provider type specified""",Customer generated an invalid certificate which caused issues with the HDInsight configuration step of the deployment.,"Provided customer command from our documentation to generate a self signed cert, one noteable difference was the customer was not specifying the keyspec.$cert = New-SelfSignedCertificate -CertStoreLocation ""cert:\CurrentUser\My"" -Subject ""CN=hdinsightAdlsCert"" -KeySpec KeyExchangehttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-store#refresh-the-hdinsight-certificate-for-data-lake-storage-gen1-access",,,,,,,,
1.20051E+14,20:28.5,Unable to kinit with keytab in the ESP enabled HDInsight cluster ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: Yes\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Not able to kinit with keytab in the ESP enabled kafka\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - Yes;\nDoes the user have proper permission on the target location recursively? - Yes;\nAdditional details about the issue - Not able to kinit with keytab in the ESP enabled kafka;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII} (HighSec)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/084971f5-dda5-4b57-9062-2e9289a1962e/resourceGroups/strpl-paas-dev-rgp-001/providers/Microsoft.HDInsight/clusters/kafka-strpl-dev-001\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to kinit with keytab in the ESP enabled HDInsight cluster ,0.102795399,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Auditing,Unable to kinit with keytab in the ESP enabled HDInsight cluster,2 different issues. Creating keytab failing unable to access kafka topics from AKS,Creating keytab issue -- encryption type change helped . We were able to get past the Kerberos authentication issue by manually adding the host entries of the Kafka brokers on the /etc/hosts file of the AKS cluster and consume kafka messages respectively. ,188008001,,,,,,,
1.20051E+14,05:44.6,Ambari is not reachable,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ammbri is not loading and unable to connect to the head node through PuTTY\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ammbri is not loading and unable to connect to the head node through PuTTY;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: TAA-Axcess-cchiq-Z-Dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d9a3c7aa-60c5-47c7-8e86-84ee6d5e7504/resourceGroups/rg-dev02-cchiq-est/providers/Microsoft.HDInsight/clusters/hdpdev02cchiqest\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari is not reachable,0.06760839,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Ambari is not reachable,By Design ,We were able to access the cluster after changing the NSG rules.ADF was able to talk to the cluster as well since the integration runtime VM is in the same Vnet we were able to resolve the connection issues by pointing to the internal loadbalancer by using <clustername>-int.azurehdinsight.net. More details in the doc: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-virtual-network-architecture#basic-virtual-network-resources,,,,,,,,
1.20051E+14,49:12.5,Hive Queries failing in Zeppelin ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: No\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hive {Namepii} failing in {Namepii} \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - No;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - Hive {Namepii} failing in {Namepii} ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps024llapfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Queries failing in Zeppelin ,0.106105414,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Cx Internal too issue, Hive Queries failing in Zeppelin,Queries are running from Zeppelin and failing through an internal tool. Recommended to fix the issues on that side,,,,,,,,
1.20051E+14,58:59.8,hn0 VM not responding,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 7, 2020, 11:48 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: hn0-whitin.txt2qypmn31e1n1ywlqkq4tu3b.yx.internal.cloudapp.net is unresponsive. Does not reply to ping.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - hn0-whitin.txt2qypmn31e1n1ywlqkq4tu3b.yx.internal.cloudapp.net is unresponsive. Does not reply to ping.;\n\n- ProblemStartTime: 05/07/2020 17:48:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Base $1200 Annual Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/85b49761-8f6b-45d2-b452-c42625590aee/resourceGroups/WhitingPetroSCADA/providers/Microsoft.HDInsight/clusters/whitingpetroscadahdicls\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hn0 VM not responding,0.114666278,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,hn0 VM not responding,"Unexpected occurrence was caused by an Azure initiated host node reboot action.The host node reboot was triggered by our Azure monitoring systems detecting a potential failure condition with the physical node where the virtual machine was hosted. This caused VM to get rebooted. RDP and SSH connections to the VM, or requests to any other services running inside the VM, could have failed during this time.",Rebooted on hn-VM-0,,,,,,,,
1.20051E+14,02:05.0,PrdSup : kp08tntncapsparknsprdsup01 : Jobs are taking longer time and failing,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 7, 2020, 10:30 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: PrdSup : {alphanumericpii} : Jobs are taking longer time and failing\n\nQuestion: Additional details about the issue\nAnswer: PrdSup : {alphanumericpii} : Jobs are taking longer time and failing\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - PrdSup : {alphanumericpii} : Jobs are taking longer time and failing;\nAdditional details about the issue - PrdSup : {alphanumericpii} : Jobs are taking longer time and failing;\n\n- ProblemStartTime: 05/07/2020 17:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp08tntncapsparknsprdsup01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PrdSup : kp08tntncapsparknsprdsup01 : Jobs are taking longer time and failing,0.059907117,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,PrdSup : kp08tntncapsparknsprdsup01 : Jobs are taking longer time and failing,PrdSup : kp08tntncapsparknsprdsup01 : Jobs are taking longer time and failing,"Issue was seeing GC pauses on the metastore service and the nodes do not have sufficient RAM. Suggested customer to try fixing (reduce heap usage) the HiveServer2 (like ask applications to use “hive.fetch.task.conversion=none”) and reduce heap size of HiveServer2, there by they would get memory to increase heap size for metastore..",,,,,,,,
1.20051E+14,16:15.1,Hive metastore is failing with schema tool failed message,"Question: What time did the problem begin?\nAnswer: Wed, May 6, 2020, 11:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, May 6, 2020, 11:00 PM MST\n\nQuestion: Connection string used\nAnswer:  beeline -u 'jdbc:hive2://zk1-sprk01.petsmartazureds.com:2181,zk3-sprk01.petsmartazureds.com:2181,zk5-sprk01.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2'\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hive metastore service is failing while initializing which causing all hive jobs are failing...\n\n\n2020-05-07 {Alphanumericpii} main TRACE Using default SystemClock for timestamps.\nInitializing the schema to: 3.1.0\nMetastore connection URL: jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nMetastore Connection Driver : com.microsoft.sqlserver.jdbc.SQLServerDriver\nMetastore connection User: nextgenadmin\nStarting metastore schema initialization to 3.1.0\nInitialization script hive-schema-3.1.0.mssql.sql\nConnecting to jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nConnected to: Microsoft SQL Server (version 12.00.2000)\nDriver: Microsoft JDBC Driver 7.0 for SQL Server (version 7.0.0.0)\nTransaction isolation: TRANSACTION_READ_COMMITTED\n0: jdbc:sqlserver://nextgenanalyticssqlsvr.da !autocommit on\nAutocommit status: true\n0: jdbc:sqlserver://nextgenanalyticssqlsvr.da CREATE TABLE MASTER_KEYS ( KEY_ID \n int NOT NULL, MASTER_KEY {alphanumericpii}) NULL )\nError: There is already an object named 'MASTER_KEYS' in the database. ({AlphanumericPII})\nClosing: 0: jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nSchema initialization FAILED! Metastore state would be inconsistent!\nUnderlying cause: java.io.IOException : Schema script failed, errorcode 2\n... 8 more\n*** schemaTool failed ***\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nConnection string used -  beeline -u 'jdbc:hive2://zk1-sprk01.petsmartazureds.com:2181,zk3-sprk01.petsmartazureds.com:2181,zk5-sprk01.petsmartazureds.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2';\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Hive metastore service is failing while initializing which causing all hive jobs are failing...\n\n\n2020-05-07 {Alphanumericpii} main TRACE Using default SystemClock for timestamps.\nInitializing the schema to: 3.1.0\nMetastore connection URL: jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nMetastore Connection Driver : com.microsoft.sqlserver.jdbc.SQLServerDriver\nMetastore connection User: nextgenadmin\nStarting metastore schema initialization to 3.1.0\nInitialization script hive-schema-3.1.0.mssql.sql\nConnecting to jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nConnected to: Microsoft SQL Server (version 12.00.2000)\nDriver: Microsoft JDBC Driver 7.0 for SQL Server (version 7.0.0.0)\nTransaction isolation: TRANSACTION_READ_COMMITTED\n0: jdbc:sqlserver://nextgenanalyticssqlsvr.da !autocommit on\nAutocommit status: true\n0: jdbc:sqlserver://nextgenanalyticssqlsvr.da CREATE TABLE MASTER_KEYS ( KEY_ID \n int NOT NULL, MASTER_KEY {alphanumericpii}) NULL )\nError: There is already an object named 'MASTER_KEYS' in the database. ({AlphanumericPII})\nClosing: 0: jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300\nSchema initialization FAILED! Metastore state would be inconsistent!\nUnderlying cause: java.io.IOException : Schema script failed, errorcode 2\n... 8 more\n*** schemaTool failed ***;\n\n- ProblemStartTime: 05/07/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive metastore is failing with schema tool failed message,0.137822637,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,"2020-05-07 17:54:16,710 main TRACE Using default SystemClock for timestamps. Initializing the schema to: 3.1.0 Metastore connection URL: jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300 Metastore Connection Driver : com.microsoft.sqlserver.jdbc.SQLServerDriver Metastore connection User: nextgenadmin Starting metastore schema initialization to 3.1.0 Initialization script hive-schema-3.1.0.mssql.sql Connecting to jdbc:sqlserver://nextgenanalyticssqlsvr.database.windows.net;database=HDI4_Metastore_DB;encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300 Connected to: Microsoft SQL Server (version 12.00.2000)","Hive metastore is not able to start due to version mismatch Metastore schema version is not compatible. Hive Version: 3.1.0, Database Schema Version: 1.2.0 ",fixed the database schema version to 3.1.0 issue is resolved and hivemetastore service started successfully and able to access the beeline.Customer is creating the database and specifying the version in the databricks and updated the version to 3.0 and above issue is resolved.,187284194,,,,,,,
1.20051E+14,22:12.5,Not able to connect QA HDI cluster from ODBC but same working fine for Dev HDI Cluster.,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 7, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Connection success at ODBC.\n\nThen, we are connecting to Hive using DSN names from tools, like microstrategy or excel, etc…\n\nWe are not able to get tables and data from QA. I can run same query for QA ambary without any issue. This confirming no data access issue.\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: Issue – Not able to connect QA HDI cluster from ODBC but same working fine for Dev HDI {Namepii}.\n\nDEV HDI {Namepii} - https://hdi001dldev.azurehdinsight.net/\nQA HDI {Namepii} - https://hdi002dlqa001.azurehdinsight.net/\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Connection success at ODBC.\n\nThen, we are connecting to Hive using DSN names from tools, like microstrategy or excel, etc…\n\nWe are not able to get tables and data from QA. I can run same query for QA ambary without any issue. This confirming no data access issue.\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - Issue – Not able to connect QA HDI cluster from ODBC but same working fine for Dev HDI {Namepii}.\n\nDEV HDI {Namepii} - https://hdi001dldev.azurehdinsight.net/\nQA HDI {Namepii} - https://hdi002dlqa001.azurehdinsight.net/\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/06/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi002dlqa001\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to connect QA HDI cluster from ODBC but same working fine for Dev HDI Cluster.,0.014566414,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hive,Not able to connect QA HDI cluster from ODBC but same working fine for Dev HDI Cluster.,"Since the HDInsight Gateway was performing a case-sensitive comparison, this caused the HDInsight Gateway to fail to find the cookie, and route the request using the aforementioned round-robin algorithm without using the information in the JSESSIONID cookie to route the request; which lead to various failures.",Add a new key to the driver configuration on the client machine that specifies an HTTPAuthCookies of JSESSIONID.,,,,,,,,
1.20051E+14,03:09.8,Edge node heartbeat lost.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: After scaling down the cluster heartbeat of egde {alphanumericpii}) lost.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - After scaling down the cluster heartbeat of egde {alphanumericpii}) lost.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaprdhadoop-cus-01-rg/providers/Microsoft.HDInsight/clusters/prdithadoop\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge node heartbeat lost.,20.90795323,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Edgenode lost heartbeat,Found Ambari agent was running but the Hosts file was pointing to incorrect HN (HN1),checked and Failover controller was not running so it did not update the file Enabled and started failover controller on Edgenode systemctl enable slave-failover-controller.servicesystemctl status slave-failover-controller.servicesystemctl start slave-failover-controller.service systemctl status slave-failover-controller.service,"187,313,068,187,325,000",,,,,,,
1.20051E+14,12:55.6,Automação do HDInsight através do ARM,"Pergunta: A que horas começou o problema?\nResposta: qui., 7 de mai. de 2020 19:49 BRT\n\nPergunta: Hora aproximado em que o problema deixou de ocorrer. {Namepii} o problema ainda estiver ocorrendo, deixe esse campo em branco\nResposta: \n\nPergunta: Nome do cluster\nResposta: {alphanumericpii}\n\nPergunta: O problema é novo ou já ocorreu antes?\nResposta: Nunca funcionou\n\nPergunta: O cluster foi criado em uma VNET?\nResposta: Outro, desconhecido ou não aplicável\n\nPergunta: A Integração do Azure Active Directory Domain Services está envolvida?\nResposta: Não\n\nPergunta: Como a solicitação CRUD foi enviada?\nResposta: Modelo do ARM\n\nPergunta: Detalhes adicionais sobre o problema\nResposta: Estamos tentando aplicar o ARM para criar o HDInsight através de uma aplicação {Namepii} com o Azure SDK e o ARM copiando os modelos que já foram criados na Azure.\n\nO ID da Operação é a \n/subscriptions/6f951f49-53ea-4442-b3cb-619e08aa0a08/resourceGroups/DEV_CORF/providers/Microsoft.Resources/deployments/IcrIacApiDeploy/operations/52476E6F200F9208\n\nO Erro foi\nId de rastreamento\n{Guidpii}\nInternalServerError\n\n{\n    'Message': 'An error has occurred.'\n}\n\nTentei por {Namepii} de uma vez.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\nA que horas começou o problema? - {ALPHANUMERICPII};\nHora aproximado em que o problema deixou de ocorrer. {Namepii} o problema ainda estiver ocorrendo, deixe esse campo em branco - ;\nNome do cluster - {alphanumericpii};\nO problema é novo ou já ocorreu antes? - Nunca funcionou;\nO cluster foi criado em uma VNET? - Outro, desconhecido ou não aplicável;\nA Integração do Azure Active Directory Domain Services está envolvida? - Não;\nComo a solicitação CRUD foi enviada? - Modelo do ARM;\nDetalhes adicionais sobre o problema - Estamos tentando aplicar o ARM para criar o HDInsight através de uma aplicação {Namepii} com o Azure SDK e o ARM copiando os modelos que já foram criados na Azure.\n\nO ID da Operação é a \n/subscriptions/6f951f49-53ea-4442-b3cb-619e08aa0a08/resourceGroups/DEV_CORF/providers/Microsoft.Resources/deployments/IcrIacApiDeploy/operations/52476E6F200F9208\n\nO Erro foi\nId de rastreamento\n{Guidpii}\nInternalServerError\n\n{\n    'Message': 'An error has occurred.'\n}\n\nTentei por {Namepii} de uma vez.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/07/2020 22:49:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DEV_CORE_TI - {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Automação do HDInsight através do ARM,0.92300228,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Provisioning via Java SDK failed with error:""Server Error""",Validation failures:Required Management addresses not allowed inbound by NSG configured for subnetInsufficient free IP addresses to provision cluster in subnet,Fixed both of the above issues,,,,,,,,
1.20051E+14,35:45.9,Edge node issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We are unable to deploy second edge on hdinsight cluster. could you please help on this?\n\nThanks\n{Namepii} \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We are unable to deploy second edge on hdinsight cluster. could you please help on this?\n\nThanks\n{Namepii} ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AMD-GIS_DataAnalytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d3d998c-abd9-4369-9f7a-9fc9a69ea4e4/resourceGroups/pcue2-hadoop-dr-rg/providers/Microsoft.HDInsight/clusters/hdi2drtest\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge node issue,0.200278821,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,Edge node issue,Edge node issue,"Had call with customer and helped with below steps to provision Edge node successfully. Started powershell on Azure Portal.Ran below cmdlets/steps - Select-azSubscription -subscriptionId <subID of HDInsight cluster>Open ""vi"" editor and copied json content from link - https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-hdinsight-linux-add-edge-node/azuredeploy.jsonUpdated variable ""applicationname"" to different than already provisioned edgenodes of that cluster.Saved file as ""edgenode.json""On powershell of Azure Portal - 1.     $TemplateFileText = [System.IO.File]::ReadAllText(""/home/ramganji/edgenode.json"")2.     $TemplateObject = ConvertFrom-Json $TemplateFileText -AsHashtable3.     New-AzResourceGroupDeployment -ResourceGroupName pcue2-hadoop-dr-rg -TemplateObject $TemplateObject","185,440,583,187,384,000",,,,,,,
1.20051E+14,51:17.7,we are facing issue in signing to HDI public Prod url. After entering the credentials it is still popping up to enter the credentials again.,"Issue: we are facing issue in signing to HDI public Prod url. After entering the credentials it is still popping up to enter the credentials again.\nHDI {Namepii} - https://hdi003dlprod001.azurehdinsight.net\nRG - {AlphanumericPII}\n\n\nProblem start date and time\nFri, May 8, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 05/07/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi003dlprod001\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",we are facing issue in signing to HDI public Prod url. After entering the credentials it is still popping up to enter the credentials again.,0.286184511,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,we are facing issue in signing to HDI public Prod url. After entering the credentials it is still popping up to enter the credentials again.,NA,we have rebooted gateway nodes from our end and  you were able to log into ambary.,187400711,,,,,,,
1.20051E+14,00:50.0,Looking to tune MDSD Process on Edge Node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Looking to see if there is a way to tune the MDSD process on our edge nodes.  We see on a regular basis where the MDSD is consuming a majority of our CPU causing apps to slow and access to the servers to slow to a crawl.  \n\nCurrently we are seeing 700% of the CPU being consumed by the MDSD process on our Dev edge node and around the 200% of the CPU on our prod edge node.  On our prod cluster we have seen it consume over 1100%. \n\nWe know this is for logging and other things but this causing our apps to have issues, hanging, crashing, needing to be restarted on a regular basis.\n\nLooking for some assistance with possible ways to tune this.\n\nI can attache addtional screen shots after the ticket is opened since it only allows 1 attachment\n\n{alphanumericpii} is our prod edge node\n{alphanumericpii} is our dev edge node\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Looking to see if there is a way to tune the MDSD process on our edge nodes.  We see on a regular basis where the MDSD is consuming a majority of our CPU causing apps to slow and access to the servers to slow to a crawl.  \n\nCurrently we are seeing 700% of the CPU being consumed by the MDSD process on our Dev edge node and around the 200% of the CPU on our prod edge node.  On our prod cluster we have seen it consume over 1100%. \n\nWe know this is for logging and other things but this causing our apps to have issues, hanging, crashing, needing to be restarted on a regular basis.\n\nLooking for some assistance with possible ways to tune this.\n\nI can attache addtional screen shots after the ticket is opened since it only allows 1 attachment\n\n{alphanumericpii} is our prod edge node\n{alphanumericpii} is our dev edge node;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: 9885 - Decision Support Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/816a4b01-2bf2-44ce-9e31-b1fec9095726/resourceGroups/DS3_DEVResourceGroup_Central/providers/Microsoft.HDInsight/clusters/p3ncsparkstrm01\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Looking to tune MDSD Process on Edge Node,0.281493472,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,"Apps are having issues, like hanging, crashing, needing to be restarted on a regular basis.",MDSD is consuming a majority of our CPU causing apps to slow and access to the servers to slow to a crawl.,"There is two options to deal with this issue:1. Move to a newer HDInsight cluster. your cluster is dated from 2018, so it doesn't have the latest patches and upgrades for services that improves performance significantly.2. If the first option doesn't work for you, you can just turn of the service for the machine were is causing the issue, the implication of doing this is we are going to lose a little bit of telemetry of how this machine is performing, in your case are the edge nodes. For that you will need to access the machine via SSH session and by simply doing:sudo systemctl stop mdsd.",,,,,,,,
1.20051E+14,34:06.8,Newly added AD group is not showing in Ranger,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: {AlphanumericPII}# cat groups.txt\nAZHDI-AHDALL-OPS,AZHDI-IM-ADMIN,AZHDI-IM-ENGINEERS,IM_DATALAKE_ESG_USERS_DEV,AZHDI-IM-USERS\n{AlphanumericPII}#\n\n\nQuestion: Additional details about the issue\nAnswer: Newly added AD group IM_DATALAKE_ESG_USERS_DEV shows in Ambari but not in Ranger.\n\n{AlphanumericPII}# cat groups.txt\nAZHDI-AHDALL-OPS,AZHDI-IM-ADMIN,AZHDI-IM-ENGINEERS,IM_DATALAKE_ESG_USERS_DEV,AZHDI-IM-USERS\n{AlphanumericPII}#\n\nambari-server sync-ldap --groups groups.txt\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - {AlphanumericPII}# cat groups.txt\nAZHDI-AHDALL-OPS,AZHDI-IM-ADMIN,AZHDI-IM-ENGINEERS,IM_DATALAKE_ESG_USERS_DEV,AZHDI-IM-USERS\n{AlphanumericPII}#\n;\nAdditional details about the issue - Newly added AD group IM_DATALAKE_ESG_USERS_DEV shows in Ambari but not in Ranger.\n\n{AlphanumericPII}# cat groups.txt\nAZHDI-AHDALL-OPS,AZHDI-IM-ADMIN,AZHDI-IM-ENGINEERS,IM_DATALAKE_ESG_USERS_DEV,AZHDI-IM-USERS\n{AlphanumericPII}#\n\nambari-server sync-ldap --groups groups.txt;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Newly added AD group is not showing in Ranger,0.0688678,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Service unhealthy\Spark,Newly added AD group is not showing in Ranger,New group was missing from usersearchfilter,"After manually adding the group to usersearchfilter, the new group azhdi-esg-users-dev sync'd to ranger",187855769,,,,,,,
1.20051E+14,06:37.2,Head Nodes are node accessible and the cluster is hung.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: Headnode issue\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - ;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - HBase shell;\nAdditional details about the issue - Headnode issue\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps071hbasefdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head Nodes are node accessible and the cluster is hung.,0.047069837,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,Head Nodes are node accessible and the cluster is hung.,"Inspected the top putput for hn1 and ed21 and seems like starting at 15:00 UTC there are multiple instances of password expiry alert scripts being run on both the nodes exactly during the time of restart at around ~15:24 UTC – I noticed ~19,64 PIDs running the same script(on hn1 and ed21). 124289 root      20   0   11324   1840   1556 S   0.0  0.0   0:00.00 /bin/sh -c /home/sshuser/passwdexpiryalertscript/passwdexpiryalertscript.sh We noticed that the script when ran manually is spinning up multiple processes and crashing the VM in the end.Script location : /home/sshuser/passwdexpiryalertscript/passwdexpiryalertscript.sh",We have temporarily disabled the cron job as a mitigation.,"187,393,724,187,405,000",,,,,,,
1.20051E+14,45:00.6,"Can we Install Red cloak, Cylance, Splunk on HDI VM's ","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We want know if we can install {Namepii} cloak, Cylance, Splunk  Security Software on HDI {Namepii} VM's.\nOur Security team raised concern to install these security softwares. Let me know if it's ok to install.\n\nQuestion: Additional details about the issue\nAnswer: We want know if we can install {Namepii} cloak, Cylance, Splunk  Security Software on HDI {Namepii} VM's.\nOur Security team raised concern to install these security softwares. Let me know if it's ok to install.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We want know if we can install {Namepii} cloak, Cylance, Splunk  Security Software on HDI {Namepii} VM's.\nOur Security team raised concern to install these security softwares. Let me know if it's ok to install.;\nAdditional details about the issue - We want know if we can install {Namepii} cloak, Cylance, Splunk  Security Software on HDI {Namepii} VM's.\nOur Security team raised concern to install these security softwares. Let me know if it's ok to install.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Can we Install Red cloak, Cylance, Splunk on HDI VM's ",0.103186958,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,"Can we Install Red cloak, Cylance, Splunk on HDI VM's",NA,The recommendation is that any additional softwares installed on the HDInsight cluster is at customer's own risk as we won't be able to troubleshoot further if any of the services starts breaking on the cluster.Hence as mentioned in the below emails that if you notice any services breaking on the cluster after the security softwares are installed we would recommend you to redeploy a cluster.,,,,,,,,
1.20051E+14,13:47.8,"Spark cluster is down, no jobs running","Question: What time did the problem begin?\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Increased number of jobs\n\nQuestion: Mitigating actions taken so far\nAnswer: running some important jobs on dev cluster\n\nQuestion: Additional details about the issue\nAnswer: https://sparkprodwus.azurehdinsight.net/yarnui/hn/cluster will not load\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Increased number of jobs;\nMitigating actions taken so far - running some important jobs on dev cluster;\nAdditional details about the issue - https://sparkprodwus.azurehdinsight.net/yarnui/hn/cluster will not load;\n\n- ProblemStartTime: 05/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ICE-ContentIntelQualityRanking-WestUS-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b3677378-cdc0-4be7-899c-f737799c092a/resourceGroups/sparkprodwus/providers/Microsoft.HDInsight/clusters/sparkprodwus\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Spark cluster is down, no jobs running",0.224875563,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Service unhealthy\Spark,Cx worked with another engineer on a similar issue and this was the resolution for that issue.,Possible cause is stale livy batches exhausting threads due to zk storing livy session states.,"Asked cx to reboot head nodes and try clearing zk snapshots, however, it seems the issue was resolved by running rmr /livy/v1/batch",,,,,,,,
1.20051E+14,24:36.2,Issues with  services after the scale up,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Issues with  services after the scale up. The issues is happening for  all the clusters wehnever we do the scale up.\\:\n\nThe issues are:\n{Alphanumericpii} resource manager. Both the nodes  going to stand by mode.\n2. HDFS name node issue. Both the nodes  going to stand by mode.\n3. ZKfaileovercontroller not starting.\n4. Corrupted Kerberos issues.\n\n\nThe issue is common for Ineractive query, Spark and Hbase clusters.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Issues with  services after the scale up. The issues is happening for  all the clusters wehnever we do the scale up.\\:\n\nThe issues are:\n{Alphanumericpii} resource manager. Both the nodes  going to stand by mode.\n2. HDFS name node issue. Both the nodes  going to stand by mode.\n3. ZKfaileovercontroller not starting.\n4. Corrupted Kerberos issues.\n\n\nThe issue is common for Ineractive query, Spark and Hbase clusters.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Issues with  services after the scale up,11.22100468,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,After scaledown and both RM goes to standby state,"both RM standby issue For  both RM standby issue - You can check -  $ hdfs fsck  hdfs://mycluster/  (from any cluster (HNo or HN1 or  etc) node)If it says some files are under  replica, or there're missing blocks in hdfs. You can run - $ hdfs fsck hdfs://mycluster/  -delete  (from any cluster (HNo or HN1 or  etc) node)to forcefully clean up the hdfs.  After this you should be able to get rid of the standby RM issue.Then restart the YARN servcie, if  needed. If the  above is not the case, please reach us out.Why both RM went  standby?It could be due to the node-label.mirror file  missing from HDFS issue. We introduced node-label recently which is using the  hdfs to maintain the node-label store. However, during the scale down event,  this file might lost. HDFS would reject all the request until this missing block  is recovered.","For  both RM standby issue - You can check -  $ hdfs fsck  hdfs://mycluster/  (from any cluster (HNo or HN1 or  etc) node)If it says some files are under  replica, or there're missing blocks in hdfs. You can run - $ hdfs fsck hdfs://mycluster/  -delete  (from any cluster (HNo or HN1 or  etc) node)to forcefully clean up the hdfs.  After this you should be able to get rid of the standby RM issue.Then restart the YARN servcie, if  needed. If the  above is not the case, please reach us out.Why both RM went  standby?It could be due to the node-label.mirror file  missing from HDFS issue. We introduced node-label recently which is using the  hdfs to maintain the node-label store. However, during the scale down event,  this file might lost. HDFS would reject all the request until this missing block  is recovered.Why is  HDFS file /yarn/node-labels/nodelabel.mirror in CORRUPT state after scale down  ?HDFS replication factor  for local HDFS is set to 1 by default in HDInsight. This is because we recommend  customer to use remote storage (WASB, ADLS, ABFS) for customer data and the  availability of those is taken care of by the storage team. However, in the case of  node labels, the file nodelabel.mirror is stored in local HDFS in YARN. During  scaledown, if decommissioning of HDFS node (where nodelabel.mirror stays) fails,  then we lose the only replica of the file. This unavailability of this file  seems to cause YARN RM to go into  standby.In terms of prevention there are 2  options:If you use any custom script  actions, Then in that case ""hdfs dfs -setrep -R 3 hdfs://mycluster/yarn/node-labels/"" is already done during scale up  activity would reduce landing on this issue.If you doesn't have any script  actions, Then we recommend to manually try   ""hdfs dfs -setrep -R 3 hdfs://mycluster/yarn/node-labels/"" Turn off node labels feature  ambari (yarn configs) and restart required  services",,,,,,,,
1.20051E+14,36:56.8,Timeline servcies issues in the HDI clusters,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: Yes\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Timeline servcies issues in the HDI clusters.\n\nMultiple versions  are  being used in the clustr as {Alphanumericpii} and 2.0 f.\n\nWhat is the MSFT recommendation and correct version?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - Yes;\nDoes the user have proper permission on the target location recursively? - Yes;\nAdditional details about the issue - Timeline servcies issues in the HDI clusters.\n\nMultiple versions  are  being used in the clustr as {Alphanumericpii} and 2.0 f.\n\nWhat is the MSFT recommendation and correct version?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Timeline servcies issues in the HDI clusters,0.031704118,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Auditing,Timeline service version 2.0 issues,Timeline services issues in the HDI clusters,"We would recommend  you to set yarn.timeline-service.versions to “1.5f"" on HDI 4.0 cluster(s) as a  workaround because it is leading to Ambari configuring some components  incorrectly (impact timeline service component only).  We do plan to enable ATS v2 in near future  and that work is already in progress. Once after we enable this in future, you  would set it like following yarn.timeline-service.versions to  “1.5f,2.0f"".",,,,,,,,
1.20051E+14,04:50.8,Hive Major Compaction does  not delete delta files ,"Question: What time did the problem begin?\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: {Namepii} Compaction does not delete delta file \n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: When we try to do the major compaction , deleta file are not getting delete\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - {Namepii} Compaction does not delete delta file ;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - When we try to do the major compaction , deleta file are not getting delete;\n\n- ProblemStartTime: 05/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp51sparkadfhdiprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Major Compaction does  not delete delta files ,0.168139203,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,Hive Major Compaction does not delete delta files,Hive Major Compaction does not delete delta files,Product group was engaged and they advised that compactor/cleaner process should be running only on 1 node as customer is using shared metastore. Customer had disabled the same that fixed the issue.,187443011,,,,,,,
1.20051E+14,47:48.5,Corrupted Kerberos tickets on the scaled up worker nodes,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The kerberos tickets are corrupted on the scaled up workeer nodes.\n\nThe issue is happeing across all the ESP spark and Interactive Query clusters.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The kerberos tickets are corrupted on the scaled up workeer nodes.\n\nThe issue is happeing across all the ESP spark and Interactive Query clusters.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Corrupted Kerberos tickets on the scaled up worker nodes,0.849392073,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Worker Nodes following keytabs are not generated properly with incorrect file size:  smokeuser.headless.keytab,Corrupted Kerberos tickets on the scaled up worker  nodes,Hitting following bug - https://issues.apache.org/jira/browse/AMBARI-25333 and tracking it under another case #120061621002574,187769918,,,,,,,
1.20051E+14,05:13.2,"WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException java.util.concurrent.TimeoutException","Question: What time did the problem begin?\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, May 8, 2020, 12:30 AM PDT\n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: Other, don't know or not applicable\n\nQuestion: Are the accounts federated?\nAnswer: ADFS\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: No\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: No\n\nQuestion: Additional details about the issue\nAnswer: Some logs from stderr:\nhttps://dtspwsuwsparkcluster1a.azurehdinsight.net/yarnui/jobhistory/logs/wn7574-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net/port/30050/container_e602_1588918665250_0013_01_000001/container_e602_1588918665250_0013_01_000001/root/stderr/?start=0\n\n20/05/08 07:08:34 INFO RetryInvocationHandler: java.net.ConnectException: Call From wn7574-dtspws/10.20.8.12 to hn1-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationMasterProtocolPBClientImpl.finishApplicationMaster over null. Retrying after sleeping for {Alphanumericpii}.\n20/05/08 07:09:02 WARN ShutdownHookManager: ShutdownHook '${alphanumericpii}' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n20/05/08 07:09:02 ERROR Utils: Uncaught exception in thread {alphanumericpii}\njava.lang.reflect.UndeclaredThrowableException\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n20/05/08 07:09:02 INFO RetryInvocationHandler: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:866)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n, while invoking ClientNamenodeProtocolTranslatorPB.getFileInfo over hn1-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net/10.20.8.22:8020. Trying to failover immediately.\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - Other, don't know or not applicable;\nAre the accounts federated? - ADFS;\nDoes the issue affect all users or a few users? - Other, don't know or not applicable;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes authentication fail even for the cluster admin account? - No;\nHave you logged in to Ambari as local admin and verified the users have been synced? - No;\nAdditional details about the issue - Some logs from stderr:\nhttps://dtspwsuwsparkcluster1a.azurehdinsight.net/yarnui/jobhistory/logs/wn7574-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net/port/30050/container_e602_1588918665250_0013_01_000001/container_e602_1588918665250_0013_01_000001/root/stderr/?start=0\n\n20/05/08 07:08:34 INFO RetryInvocationHandler: java.net.ConnectException: Call From wn7574-dtspws/10.20.8.12 to hn1-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationMasterProtocolPBClientImpl.finishApplicationMaster over null. Retrying after sleeping for {Alphanumericpii}.\n20/05/08 07:09:02 WARN ShutdownHookManager: ShutdownHook '${alphanumericpii}' timeout, java.util.concurrent.TimeoutException\njava.util.concurrent.TimeoutException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n20/05/08 07:09:02 ERROR Utils: Uncaught exception in thread {alphanumericpii}\njava.lang.reflect.UndeclaredThrowableException\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII} Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n20/05/08 07:09:02 INFO RetryInvocationHandler: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:866)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n, while invoking ClientNamenodeProtocolTranslatorPB.getFileInfo over hn1-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net/10.20.8.22:8020. Trying to failover immediately.\n\n;\n\n- ProblemStartTime: 05/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ba4526ea-6a69-40d2-8f7b-8f7a10dbafdf/resourceGroups/gehc-datasvc-spark-01/providers/Microsoft.HDInsight/clusters/dtspwsuwsparkcluster1a\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException java.util.concurrent.TimeoutException",3.930866001,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,"Some logs from stderr:https://dtspwsuwsparkcluster1a.azurehdinsight.net/yarnui/jobhistory/logs/wn7574-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net/port/30050/container_e602_1588918665250_0013_01_000001/container_e602_1588918665250_0013_01_000001/root/stderr/?start=0 20/05/08 07:08:34 INFO RetryInvocationHandler: java.net.ConnectException: Call From wn7574-dtspws/10.20.8.12 to hn1-dtspws.vorgjpf0h2he3jil1zutnsraea.dx.internal.cloudapp.net:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationMasterProtocolPBClientImpl.finishApplicationMaster over null. Retrying after sleeping for 30000ms.20/05/08 07:09:02 WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutExceptionjava.util.concurrent.TimeoutException        at java.util.concurrent.FutureTask.get(FutureTask.java:205)        at org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)        at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)20/05/08 07:09:02 ERROR Utils: Uncaught exception in thread shutdown-hook-0java.lang.reflect.UndeclaredThrowableException        at com.sun.proxy.$Proxy24.finishApplicationMaster(Unknown Source)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","we have gone through the logs and we can confirm that RM was down during the time issue has occurred and that is why the application has retried.It seems be a transient issue and Ambari or Yarn logs do not show any specific error as why RM went down.Due to HDI failover, RM came back eventually application finished successfully. If you check the output of command that I asked you to run you see that the applicationID cannot be found in RM, it is mostly likely due to the RM is inconsistent state temporarily.As that this issue happened once, I believe it had been a transient issue and it was handled successfully by HDI fail-over ","we have gone through the logs and we can confirm that RM was down during the time issue has occurred and that is why the application has retried.It seems be a transient issue and Ambari or Yarn logs do not show any specific error as why RM went down.Due to HDI failover, RM came back eventually application finished successfully. If you check the output of command that I asked you to run you see that the applicationID cannot be found in RM, it is mostly likely due to the RM is inconsistent state temporarily.As that this issue happened once, I believe it had been a transient issue and it was handled successfully by HDI fail-over ",187842067,,,,,,,
1.20051E+14,51:41.1,/hbaserest timesout for Stage hdi cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: /hbaserest/ endpoint times out intermittently causing monitoring issues to the health checks for the /hbaserest endpoint.  It looks like some of region nodes are not working as expected. \n\n(base) {AlphanumericPII}:~ gujja$ time curl -vvv -u hdi-user:PWD https://adbeidxhbasestagenew.azurehdinsight.net/hbaserest/\n*   Trying {Alphanumericpii}...\n* TCP_NODELAY set\n* Connected to adbeidxhbasestagenew.azurehdinsight.net ({Ipaddresspii}) port 443 (#0)\n* ALPN, offering {alphanumericpii}\n* successfully set certificate verify locations:\n*   CAfile: /{alphanumericpii}\n  CApath: none\n* {AlphanumericPII} (OUT), TLS handshake, Client hello (1):\n* {AlphanumericPII} (IN), TLS handshake, Server hello (2):\n* {AlphanumericPII} (IN), TLS handshake, Certificate (11):\n* {AlphanumericPII} (IN), TLS handshake, Server key exchange (12):\n* {AlphanumericPII} (IN), TLS handshake, Server finished (14):\n* {AlphanumericPII} (OUT), TLS handshake, Client key exchange (16):\n* {AlphanumericPII} (OUT), TLS change cipher, Change cipher spec (1):\n* {AlphanumericPII} (OUT), TLS handshake, Finished (20):\n* {AlphanumericPII} (IN), TLS handshake, Finished (20):\n* SSL connection using {AlphanumericPII} / {ALPHANUMERICPII}\n* ALPN, server accepted to use {alphanumericpii}\n* Server certificate:\n*  subject: CN=*.azurehdinsight.net\n*  start date: Aug  8 23:24:06 2019 GMT\n*  expire date: Aug  8 23:24:06 2021 GMT\n*  subjectAltName: host 'adbeidxhbasestagenew.azurehdinsight.net' matched cert's '*.azurehdinsight.net'\n*  issuer: C=US; ST={Namepii}; L={Namepii}; O=Microsoft Corporation; OU=Microsoft IT; CN=Microsoft IT TLS CA 2\n*  SSL certificate verify ok.\n* Server auth using Basic with user 'hdi-user'\n GET /hbaserest/ {ALPHANUMERICPII}\n Host: adbeidxhbasestagenew.azurehdinsight.net\n Authorization: Basic {AlphanumericPII}==\n User-Agent: {alphanumericpii}\n Accept: */*\n\n\n^C\n\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n(base) {AlphanumericPII}:~ gujja$ \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - /hbaserest/ endpoint times out intermittently causing monitoring issues to the health checks for the /hbaserest endpoint.  It looks like some of region nodes are not working as expected. \n\n(base) {AlphanumericPII}:~ gujja$ time curl -vvv -u hdi-user:PWD https://adbeidxhbasestagenew.azurehdinsight.net/hbaserest/\n*   Trying {Alphanumericpii}...\n* TCP_NODELAY set\n* Connected to adbeidxhbasestagenew.azurehdinsight.net ({Ipaddresspii}) port 443 (#0)\n* ALPN, offering {alphanumericpii}\n* successfully set certificate verify locations:\n*   CAfile: /{alphanumericpii}\n  CApath: none\n* {AlphanumericPII} (OUT), TLS handshake, Client hello (1):\n* {AlphanumericPII} (IN), TLS handshake, Server hello (2):\n* {AlphanumericPII} (IN), TLS handshake, Certificate (11):\n* {AlphanumericPII} (IN), TLS handshake, Server key exchange (12):\n* {AlphanumericPII} (IN), TLS handshake, Server finished (14):\n* {AlphanumericPII} (OUT), TLS handshake, Client key exchange (16):\n* {AlphanumericPII} (OUT), TLS change cipher, Change cipher spec (1):\n* {AlphanumericPII} (OUT), TLS handshake, Finished (20):\n* {AlphanumericPII} (IN), TLS handshake, Finished (20):\n* SSL connection using {AlphanumericPII} / {ALPHANUMERICPII}\n* ALPN, server accepted to use {alphanumericpii}\n* Server certificate:\n*  subject: CN=*.azurehdinsight.net\n*  start date: Aug  8 23:24:06 2019 GMT\n*  expire date: Aug  8 23:24:06 2021 GMT\n*  subjectAltName: host 'adbeidxhbasestagenew.azurehdinsight.net' matched cert's '*.azurehdinsight.net'\n*  issuer: C=US; ST={Namepii}; L={Namepii}; O=Microsoft Corporation; OU=Microsoft IT; CN=Microsoft IT TLS CA 2\n*  SSL certificate verify ok.\n* Server auth using Basic with user 'hdi-user'\n GET /hbaserest/ {ALPHANUMERICPII}\n Host: adbeidxhbasestagenew.azurehdinsight.net\n Authorization: Basic {AlphanumericPII}==\n User-Agent: {alphanumericpii}\n Accept: */*\n\n\n^C\n\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n(base) {AlphanumericPII}:~ gujja$ ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",/hbaserest timesout for Stage hdi cluster,3.621005522,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Service unhealthy\Hbase,/hbaserest timesout for Stage hdi cluster,"The possible cause here could be Apache HBase REST service is leaking sockets, which is especially common when the service has been running for a long time (for example, months). From the client SDK, you may see an error message similar to: “System.Net.WebException : Unable to connect to the remote server --->System.Net.Sockets.SocketException : A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond 10.0.0.19:8090”", ResolutionRestart HBase REST using the below command after SSHing to the host. You can also use script actions to restart this service on all worker nodes: sudo service hdinsight-hbrest restart,,,,,,,,
1.20051E+14,44:16.3,resource manager UI not operational,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Yarn UI is not working, found that both RM are in standby mode.\n\nhttps://optum-hdinsight1-opsi-perf.azurehdinsight.net/yarnui\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Yarn UI is not working, found that both RM are in standby mode.\n\nhttps://optum-hdinsight1-opsi-perf.azurehdinsight.net/yarnui\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: dsar-rqns\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/352ff61a-3020-4199-af5a-24b34eaaf95a/resourceGroups/opsihdi-perf/providers/Microsoft.HDInsight/clusters/optum-hdinsight1-opsi-perf\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",resource manager UI not operational,0.398723444,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Both RM standby and unable to access RM UI,both RM went to standby state because of scaledown to 1,"Both RM are went standby  state because of scaledown to one node and recommended to run ""hdfs fsck hdfs://mycluster/  -delete"" to get rid off the issue",,,,,,,,
1.20051E+14,41:44.0,"Scale up issues on  different cluster types  (HBase, spark) within the same Resource group through  azure portal","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Scale up issues on  different cluster type (HBase, spark) within the same Resource group through portal.\n\nWe are not able to scale up the two differnt cluster types   spark & Hbase at the same with in the same resource group.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Scale up issues on  different cluster type (HBase, spark) within the same Resource group through portal.\n\nWe are not able to scale up the two differnt cluster types   spark & Hbase at the same with in the same resource group.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps025sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Scale up issues on  different cluster types  (HBase, spark) within the same Resource group through  azure portal",25.58042773,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Can’t simultaneously scale up the clusters in a same resource group within the same subscription. The scale up or scale down activities has be done in a serial manner.,Known bug that has been reported ,Bug is reported and worked on by its severity and when it was reported so we will not be able to give you an ETA.The work around for this issue is to not do Scaleup/down multiple clusters simultaneously under the same Resource Group.Do the scaling for one cluster and once it is complete do the next if the clusters are in the same Resource group.,188030341,,,,,,,
1.20051E+14,05:59.0,FD Sandbox - kps027sparkespfdsbwus201 - HiveServer2 tasks,"Question: What time did the problem begin?\nAnswer: Sun, May 10, 2020, 1:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sun, May 10, 2020, 1:00 PM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Reduced no of LLAP applicatoons\n2. Restart services \n\nQuestion: Additional details about the issue\nAnswer: Attached logs\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. Reduced no of LLAP applicatoons\n2. Restart services ;\nAdditional details about the issue - Attached logs;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/10/2020 20:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps027sparkespfdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox - kps027sparkespfdsbwus201 - HiveServer2 tasks,1.801851305,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Unable to start LLAP,zookeeper snapshots need cleaning and kinit,Resolution: Cleanup snapshots on zookeeper nodesThe following command will clean up all but the last 3 snapshots (3 is the lowest supported number)zookeepersudo java -cp /usr/hdp/current/zookeeper-server/zookeeper.jar:/usr/hdp/current/zookeeper-server/lib/* org.apache.zookeeper.server.PurgeTxnLog /hadoop/zookeeper/ /hadoop/zookeeper/ 3hdinsight-zookeepersudo java -cp /usr/hdp/current/zookeeper-server/zookeeper.jar:/usr/hdp/current/zookeeper-server/lib/* org.apache.zookeeper.server.PurgeTxnLog /hadoop/hdinsight-zookeeper/ /hadoop/hdinsight-zookeeper/ 3klist -kte /etc/security/keytabs/hive.service.keytabkinit -kt /etc/security/keytabs/hive.service.keytab   < pricipal name from step 1 > ,,,,,,,,
1.20051E+14,11:33.9,Unable to install Edgenode,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Couldn't able to install Edgenode on the cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Couldn't able to install Edgenode on the cluster;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/USEDFSOFINRSG02/providers/Microsoft.HDInsight/clusters/USEDFSOFINHDI02\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to install Edgenode,2.742037957,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hive,Unable to install Edgenode,"Customer unable to add edgenode to the cluster, default hdi script on githut did not work. ",Please follow the steps below to add additional edgenodes to the cluster.Click on custom deploy template  link.Select “Build your own template in editor”Click on “edit template” and replace the contents with the template attached and save it.Next fill in the Basic cluster info and edgenode name(application name)Click agree and purchase.,187869112,,,,,,,
1.20051E+14,29:55.3,HS2I services are down.ABFS delegation token issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.\n\nQuestion: Interactive query explain plan if available\nAnswer: ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.\n\nQuestion: How was the interactive query submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.;\nInteractive query explain plan if available - ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.;\nHow was the interactive query submitted? - {Namepii};\nAdditional details about the issue - ABFS delegation token issue. {ALPHANUMERICPII} services are not coming up.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HS2I services are down.ABFS delegation token issue,0.429221317,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Unexpected result\Interactive Query,ZK is unstable and high loads on ZK hosts,HS2I services are down.ABFS delegation token issue,"The mitigation is to change following lines in zookeeper-log4j configuration using ambari and then restart affected components. this will remove .out file logging and start emitting logs that would be rotated without compressionlog4j.rootLogger=INFO, CONSOLE, ETW, FilterLog to log4j.rootLogger=INFO, ROLLINGFILE, ETW, FilterLoglog4j.appender.ROLLINGFILE.Threshold=DEBUG to log4j.appender.ROLLINGFILE.Threshold=INFOlog4j.appender.ROLLINGFILE.File=zookeeper.log to log4j.appender.ROLLINGFILE.File=/var/log/zookeeper/zookeeper.log",,,,,,,,
1.20051E+14,12:53.5,HDInsight Kafka having network issue with Golden Gate Application,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi,\n\nFirst ignore prolbem type and problem sub-type - I had to select something.\n\nOur {Namepii} Gate application is having some issues (appears to be transaction failure) with HDInsight Kafka clusters. I have attached logs that are coming from {Namepii} Gate applications. HDInsight Ambari UI log does not show any issue. The problem came around March 3rd (logs attached). It came today (May 11 morning) as well. Please check if HDInsigh Kafka clusters are functioning correctly and response from Kafka side. Let us know in case any other requirements.\n\n\nKafka {Namepii}:\n\nPRD-A: {alphanumericpii}\nPRD-B:  {alphanumericpii}\n\n\n\nRegards,\nMustafiz\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - Hi,\n\nFirst ignore prolbem type and problem sub-type - I had to select something.\n\nOur {Namepii} Gate application is having some issues (appears to be transaction failure) with HDInsight Kafka clusters. I have attached logs that are coming from {Namepii} Gate applications. HDInsight Ambari UI log does not show any issue. The problem came around March 3rd (logs attached). It came today (May 11 morning) as well. Please check if HDInsigh Kafka clusters are functioning correctly and response from Kafka side. Let us know in case any other requirements.\n\n\nKafka {Namepii}:\n\nPRD-A: {alphanumericpii}\nPRD-B:  {alphanumericpii}\n\n\n\nRegards,\nMustafiz;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: INF PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e479944e-434c-465a-a154-32e05268f875/resourceGroups/maz-cae-prdb2-dalkfk-1082-rg/providers/Microsoft.HDInsight/clusters/ceprd2mazdalkfk\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight Kafka having network issue with Golden Gate Application,0.162714221,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unexpected result\Kafka,120051124003292 HDInsight Kafka having network issue with Golden Gate Application HDInsight Service,Kafka Broker timeout,Customer restarted the Kafka brokers and also verified the Oracle consumer properties:Parameter values : buffer.memory=33554432batch.size=16384linger.ms=0The issue has not happened since then but customer will reopen the case if the issue reoccurs for further debugging.,,,,,,,,
1.20051E+14,55:07.1,PRDSUP :  kpph18llapprdsupusc01 & kp51sparkadfhdiprdsupusc01 :  DDLs  are not updating ,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 11, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: PRDSUP :  {alphanumericpii} & {alphanumericpii} :  DDLs  are not updating \n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: PRDSUP :  {alphanumericpii} & {alphanumericpii} :  DDLs  are not updating \n\nLooks like prodsup llap server sync is not happening. Please take a look at sample scenario when we created the table with date ,still abmari llap server showing previous data type as “timestamp”.\n \n \nLLAP:\nhttps://kpph18llapprdsupusc01-int.azurehdinsight.net/#/main/view/HIVE/auto_hive20_instance\n\nunsecured spark cluster for central-prodsup : https://kp51sparkadfhdiprdsupusc01-int.azurehdinsight.net/yarnui/hn/cluster\n \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - PRDSUP :  {alphanumericpii} & {alphanumericpii} :  DDLs  are not updating ;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - PRDSUP :  {alphanumericpii} & {alphanumericpii} :  DDLs  are not updating \n\nLooks like prodsup llap server sync is not happening. Please take a look at sample scenario when we created the table with date ,still abmari llap server showing previous data type as “timestamp”.\n \n \nLLAP:\nhttps://kpph18llapprdsupusc01-int.azurehdinsight.net/#/main/view/HIVE/auto_hive20_instance\n\nunsecured spark cluster for central-prodsup : https://kp51sparkadfhdiprdsupusc01-int.azurehdinsight.net/yarnui/hn/cluster\n \n;\n\n- ProblemStartTime: 05/11/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP :  kpph18llapprdsupusc01 & kp51sparkadfhdiprdsupusc01 :  DDLs  are not updating ,0.03181552,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Hive,PRDSUP : kpph18llapprdsupusc01 & kp51sparkadfhdiprdsupusc01 : DDLs are not updating,Both these clusters are using cache stores and say Metastore A caches a table and changes are made to it from a client cluster 1 and when you read the same table from cluster2 which is using a cache store as well it would continue to use the stale raw metadata. Using an Object store would prevent you from reading stale info. ,"We noticed that the LLAP cluster is using a cached store while retrieval of raw metadata objects.Could you please change it to ObjectStore and check if the table DDL updates as per your requirement. From Ambari àHive à configsàcustom hive_site and custom interactive site à add“hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore""And restart the required services and let us know how that goes. ",,,,,,,,
1.20051E+14,14:21.5,Script action to reset password failed,"Script action failed but the debug log  said everything COMPLETED.  See log:\n\nDebug information\n{\n    'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60',\n    'tasks': [\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/426',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'hn0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '426',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/427',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '427',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/428',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'wn0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '428',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/429',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'wn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '429',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/430',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'wn2-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '430',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/431',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'wn3-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '431',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/432',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'zk0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '432',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/433',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'zk2-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '433',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        },\n        {\n            'href': 'http://hn1-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net:8080/api/v1/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik/requests/60/tasks/434',\n            'Tasks': {\n                'attempt_cnt': 1,\n                'command': 'ACTIONEXECUTE',\n                'command_detail': 'run_customscriptaction ACTIONEXECUTE',\n                'end_time': {Phonenumberpii},\n                'error_log': '/{alphanumericpii}',\n                'exit_code': 0,\n                'host_name': 'zk3-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net',\n                'id': '434',\n                'output_log': '/{alphanumericpii}',\n                'request_id': '60',\n                'role': 'run_customscriptaction',\n                'stage_id': '0',\n                'start_time': {Phonenumberpii},\n                'status': 'COMPLETED',\n                'stderr': null,\n                'stdout': null,\n                'structured_out': null\n            }\n        }\n    ]\n}\n\nProblem start date and time\n{Namepii}, May 11, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 05/11/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a548e950-33a3-489b-94b3-29b5ad6030bc/resourceGroups/helx-prod-dataingest-wds-hdi-westus-rg/providers/Microsoft.HDInsight/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Script action to reset password failed,2.773339529,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,"Unable to reset password using script action and along with following characters "" ' ` / \ < % ~ | $ & !  in  password ",Script action to reset password failed,"Recommended not to use following characters "" ' ` / \ < % ~ | $ & !  in your password - https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-the-ssh-user-password-or-public-key",,,,,,,,
1.20051E+14,03:35.7,Daployment failed and unable to connect to cluster management endpoint. ,"Question: What time did the problem begin?\nAnswer: Fri, May 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'FailedToConnectWithClusterErrorCode',\n        'message': 'Unable to connect to cluster management endpoint. Please retry later.'\n      }\n    ]\n  }\n\nRG: {alphanumericpii} \n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'FailedToConnectWithClusterErrorCode',\n        'message': 'Unable to connect to cluster management endpoint. Please retry later.'\n      }\n    ]\n  }\n\nRG: {alphanumericpii} \n\n\n;\n\n- ProblemStartTime: 05/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/4a007414-fdfa-44a6-af25-b022ddda599a/resourceGroups/g-rsg-2s-commerce01-personalization-marketing-pas-01/providers/Microsoft.HDInsight/clusters/ghdh2spas05\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Daployment failed and unable to connect to cluster management endpoint. ,0.429887946,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Daployment failed and unable to connect to cluster management endpoint.,Daployment failed and unable to connect to cluster management endpoint.,Reviewed customer environment and found one of the management IP is missing on UDR rules. Customer had fixed the same and able to provision cluster successfully,,,,,,,,
1.20051E+14,59:50.4,Hive Queries sporadically fail after executing a number of tasks with queries failing with DIGEST-MD5 error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,\n\nQuestion: Interactive query explain plan if available\nAnswer: Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,\n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,;\nInteractive query explain plan if available - Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Hive {Namepii} sporadically fail after executing a number of tasks. Hive queries failing with {ALPHANUMERICPII}: digest response format violation. Mismatched response error.\n\nERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 2, {AlphanumericPII}, diagnostics=[Task failed, {AlphanumericPII}, diagnostics=[TaskAttempt 0 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 1 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 2 failed, info=[org.apache.hadoop.ipc.RemoteException(javax.security.sasl.SaslException): {ALPHANUMERICPII}: digest response format violation. Mismatched response.], TaskAttempt 3 failed,;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Queries sporadically fail after executing a number of tasks with queries failing with DIGEST-MD5 error,0.52378015,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,We see this behavior because of ZK high loads,Hive Queries sporadically fail after executing a number of tasks with queries failing with DIGEST-MD5 error,"We see this behavior because of ZK high loads, The mitigation is to change following lines in zookeeper-log4j configuration using ambari and then restart affected components. this will remove .out file logging and start emitting logs that would be rotated without compressionlog4j.rootLogger=INFO, CONSOLE, ETW, FilterLog to log4j.rootLogger=INFO, ROLLINGFILE, ETW, FilterLoglog4j.appender.ROLLINGFILE.Threshold=DEBUG to log4j.appender.ROLLINGFILE.Threshold=INFOlog4j.appender.ROLLINGFILE.File=zookeeper.log to log4j.appender.ROLLINGFILE.File=/var/log/zookeeper/zookeeper.log ",187855137,,,,,,,
1.20051E+14,18:25.2,Need performance tunning in HDI cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: We have noticed slowness in the hive job execution.\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: We run the query through command line as well as through ADF. It will be good if we get engineer in UTC timezone.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - We have noticed slowness in the hive job execution.;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - We run the query through command line as well as through ADF. It will be good if we get engineer in UTC timezone.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SDO - Big Data Program\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/23c0c9e6-02a0-43fa-b7b7-71dca8da4585/resourceGroups/RG-Prod2-{Namepii}-DDP/providers/Microsoft.HDInsight/clusters/hdi2sprod-ddp\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need performance tunning in HDI cluster,6.327914396,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Customer wanted to know if their cluster could be scaled down,N/A,"Use Ambari metrics to decide whether cluster can be comfortably scaled to a smaller size.  Auto scaling would seem to present the best solution, but it depends how long resource spikes are sustained for",,,,,,,,
1.20051E+14,44:23.4,Python 3.7 on HDI Cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: None\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Need to have Python 3.7 installed on HDI {Namepii} during the creation.\nCan you please check and update the backend scripts or provide the officical ppa to install the same.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - None;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Need to have Python 3.7 installed on HDI {Namepii} during the creation.\nCan you please check and update the backend scripts or provide the officical ppa to install the same.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Python 3.7 on HDI Cluster,0.099625239,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Need to have Python 3.7 installed on HDI Cluster during the creation.Can you please check and update the backend scripts or provide the officical ppa to install the same.,advisory,"Including Python 3.7 as part of HDI cluster deployment is not in road map right now. With that being said, alternate approach is well articulated in this section of the doc https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-python-package-installation#safely-install-external-python-packages, it shows how to create a Python virtual environment with different version and change environment variables/configs for Spark, Livy and Jupyter to point to the new created Python virtual environment.",,,,,,,,
1.20051E+14,13:11.2,Cluster is unable to determine the number of nodes,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 11, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Deleted a node from Ambari console.\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Tried restarting ambari service for few times.\n\nQuestion: Additional details about the issue\nAnswer: Deleted a worker as well as edge node from Ambari console.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Deleted a node from Ambari console.;\nIncrease in load? - ;\nMitigating actions taken so far - Tried restarting ambari service for few times.;\nAdditional details about the issue - Deleted a worker as well as edge node from Ambari console.;\n\n- ProblemStartTime: 05/11/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is unable to determine the number of nodes,0.018435193,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Deleted a worker as well as edge node from Ambari console.,"Deleting of edge was failed because I have checked the backend logs and I see there is conflict and failed with the below error{""{\""error\"":{\""code\"":\""ScopeLocked\"",\""message\"":\""The scope '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl/applications/rxpersoproden3' cannot perform delete operation because following scope(s) are locked: '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl'. Please remove the lock and try again.\""}}""} Resolution:Remove the lock and start deleting the edge node from portal.","Deleting of edge was failed because I have checked the backend logs and I see there is conflict and failed with the below error{""{\""error\"":{\""code\"":\""ScopeLocked\"",\""message\"":\""The scope '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl/applications/rxpersoproden3' cannot perform delete operation because following scope(s) are locked: '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-QA/providers/Microsoft.HDInsight/clusters/rxp02-qa-hdi-rtl'. Please remove the lock and try again.\""}}""} Resolution:Remove the lock and start deleting the edge node from portal.",187862895,,,,,,,
1.20051E+14,23:27.2,guidance on installing KAfka connect,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We would like to enable/install kafka connect to utilize the splunk Kafka connector. can you provide some guidance or documentation to install the Kafka connect for HDinsight cluster?\n\nCurrently, I don't see Kafka connect on the cluster\n\n{alphanumericpii}:~# curl {alphanumericpii}/ | jq\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     {Alphanumericpii}: (7) Failed to connect to localhost port 8083: Connection refused\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - We would like to enable/install kafka connect to utilize the splunk Kafka connector. can you provide some guidance or documentation to install the Kafka connect for HDinsight cluster?\n\nCurrently, I don't see Kafka connect on the cluster\n\n{alphanumericpii}:~# curl {alphanumericpii}/ | jq\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     {Alphanumericpii}: (7) Failed to connect to localhost port 8083: Connection refused\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02lak01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",guidance on installing KAfka connect,0.133307453,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Kafka,guidance on installing KAfka  connect,guidance on installing KAfka  connect,Provided document which could  help on how to  enable/create kafka connect but we don't debug/support connectors to other  system. Link: https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-connector-iot-hub,,,,,,,,
1.20051E+14,40:19.0,Frequent Hive metastore alerts and the service issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: HMS issues\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Hive metastore issues are happening very frequently and we are not able to execute any jobs.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - HMS issues;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Hive metastore issues are happening very frequently and we are not able to execute any jobs.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Free\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Basic Support\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Frequent Hive metastore alerts and the service issue,0.13104206,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Hivemetastore alert on HN0 host and unable to estabish communication with port 9083,"Frequent Hive metastore alerts and the service issue. If it happen again, please let us know to collect the heap and thread dumps to provide the RCA ","We logged on HN0 and found that hivemetastore PID is not establishing the communication with 9083 port, validated the same on HN1 and which looks good. Then we killed the hivemetastore PID and after start of new one worked fine. If it happen again, please let us know to collect the heap and thread dumps to provide the RCA",,,,,,,,
1.20051E+14,18:50.8,I cannot read the logs,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: n/a\n\nQuestion: Additional details about the issue\nAnswer: I cannot view the logs of my spark jobs. Every time I try, I get 404 not found from the spark portal.\nhttps://sparkprodwus.azurehdinsight.net/yarnui/hn/cluster/apps/RUNNING\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - {Namepii};\nSpark configuration details - n/a;\nAdditional details about the issue - I cannot view the logs of my spark jobs. Every time I try, I get 404 not found from the spark portal.\nhttps://sparkprodwus.azurehdinsight.net/yarnui/hn/cluster/apps/RUNNING;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ICE-ContentIntelQualityRanking-Test\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c23a622-dfc8-4ab7-a957-1ec284d4f1bb/resourceGroups/sparktesteus/providers/Microsoft.HDInsight/clusters/sparktesteus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I cannot read the logs,0.056136863,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,120051221001901 Cannot read Spark container logs in the YARN UI,Issues with the Gateway. Spark streaming logs are too big to return before a timeout happens. Redirect URLs not functioning in the Gateway.,"Recommendations:  Use the command line to pull the application logs:yarn logs -applicationId <yourapplicationid> -containerId <yourcontainerid>   Access the Spark application logs from the  Blob storage      container:wasb://sparktesteus@sparktesteus.blob.core.windows.net/hdp/spark2-events/<yourapplicationid>   Setup the ssh tunnel to view the logs in the browser.  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-linux-ambari-ssh-tunnel#useputty   Recreate the HDInsight cluster using HDInsight 4.0 /      Spark 2.4 because these Gateway issues have been fixed in the newer versions.       Also, HDInsight 3.6 is out of support on 12/31/2020. HDInsight 3.6 / Spark      2.1 and Spark 2.2 is out of support at the end of June 2020. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning#available-versions",,,,,,,,
1.20051E+14,23:58.3,LLAP app 'llap0' deployment unsuccessful.,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 12, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted the YARN and hive , Still LLAP is not RUNNING.\n\nQuestion: Additional details about the issue\nAnswer: INFO cli.LlapStatusServiceDriver: LLAP status finished\n2020-05-12 {Alphanumericpii} - LLAP app '{alphanumericpii}' in 'RUNNING_PARTIAL' state. Live Instances : '2'. Desired Instances : '6' after {Phonenumberpii} secs.\n2020-05-12 {Alphanumericpii} - App state is RUNNING_PARTIAL. Live Instances : '2', Desired Instance : '6'\n2020-05-12 {Alphanumericpii} - LLAP app '{alphanumericpii}' deployment unsuccessful.\n2020-05-12 {Alphanumericpii} - Stopping LLAP\n2020-05-12 {Alphanumericpii} - call[['slider', 'stop', {alphanumericpii}']] {'logoutput': True, 'user': 'hive', 'stderr': -1}\n2020-05-12 {Alphanumericpii} [main] INFO  tools.SliderUtils - JVM initialized into secure mode with kerberos realm ACTIVENETWORK.ONMICROSOFT.COM\n2020-05-12 {Alphanumericpii} [main] INFO  client.AHSProxy - Connecting to Application History server at hn0-prodhd.activenetwork.onmicrosoft.com/10.37.25.26:10200\n2020-05-12 {Alphanumericpii} [main] ERROR secure.AbstractCredentialServiceCaller - Connection refused (Connection refused)\n2020-05-12 {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Looking for the active RM in [rm1, rm2]...\n2020-05-12 {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Found active RM [rm2]\n2020-05-12 {Alphanumericpii} [main] INFO  util.ExitUtil - Exiting with status 0\n2020-05-12 {Alphanumericpii} - call returned (0, '2020-05-12 {Alphanumericpii} [main] INFO  tools.SliderUtils - JVM initialized into secure mode with kerberos realm ACTIVENETWORK.ONMICROSOFT.COM{uncpii} {Alphanumericpii} [main] INFO  client.AHSProxy - Connecting to Application History server at hn0-prodhd.activenetwork.onmicrosoft.com/10.37.25.26:10200\\n2020-05-12 {Alphanumericpii} [main] ERROR secure.AbstractCredentialServiceCaller - Connection refused (Connection refused){uncpii} {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Looking for the active RM in [rm1, rm2]...{uncpii} {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Found active RM [rm2]{uncpii} {Alphanumericpii} [main] INFO  util.ExitUtil - Exiting with status 0', '')\n2020-05-12 {Alphanumericpii} - Stopped {alphanumericpii} application on Slider successfully\n2020-05-12 {Alphanumericpii} - Execute[('slider', 'destroy', {alphanumericpii}', '--force')] {'ignore_failures': True, 'user': 'hive', 'timeout': 30}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted the YARN and hive , Still LLAP is not RUNNING.;\nAdditional details about the issue - INFO cli.LlapStatusServiceDriver: LLAP status finished\n2020-05-12 {Alphanumericpii} - LLAP app '{alphanumericpii}' in 'RUNNING_PARTIAL' state. Live Instances : '2'. Desired Instances : '6' after {Phonenumberpii} secs.\n2020-05-12 {Alphanumericpii} - App state is RUNNING_PARTIAL. Live Instances : '2', Desired Instance : '6'\n2020-05-12 {Alphanumericpii} - LLAP app '{alphanumericpii}' deployment unsuccessful.\n2020-05-12 {Alphanumericpii} - Stopping LLAP\n2020-05-12 {Alphanumericpii} - call[['slider', 'stop', {alphanumericpii}']] {'logoutput': True, 'user': 'hive', 'stderr': -1}\n2020-05-12 {Alphanumericpii} [main] INFO  tools.SliderUtils - JVM initialized into secure mode with kerberos realm ACTIVENETWORK.ONMICROSOFT.COM\n2020-05-12 {Alphanumericpii} [main] INFO  client.AHSProxy - Connecting to Application History server at hn0-prodhd.activenetwork.onmicrosoft.com/10.37.25.26:10200\n2020-05-12 {Alphanumericpii} [main] ERROR secure.AbstractCredentialServiceCaller - Connection refused (Connection refused)\n2020-05-12 {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Looking for the active RM in [rm1, rm2]...\n2020-05-12 {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Found active RM [rm2]\n2020-05-12 {Alphanumericpii} [main] INFO  util.ExitUtil - Exiting with status 0\n2020-05-12 {Alphanumericpii} - call returned (0, '2020-05-12 {Alphanumericpii} [main] INFO  tools.SliderUtils - JVM initialized into secure mode with kerberos realm ACTIVENETWORK.ONMICROSOFT.COM{uncpii} {Alphanumericpii} [main] INFO  client.AHSProxy - Connecting to Application History server at hn0-prodhd.activenetwork.onmicrosoft.com/10.37.25.26:10200\\n2020-05-12 {Alphanumericpii} [main] ERROR secure.AbstractCredentialServiceCaller - Connection refused (Connection refused){uncpii} {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Looking for the active RM in [rm1, rm2]...{uncpii} {Alphanumericpii} [main] INFO  client.RequestHedgingRMFailoverProxyProvider - Found active RM [rm2]{uncpii} {Alphanumericpii} [main] INFO  util.ExitUtil - Exiting with status 0', '')\n2020-05-12 {Alphanumericpii} - Stopped {alphanumericpii} application on Slider successfully\n2020-05-12 {Alphanumericpii} - Execute[('slider', 'destroy', {alphanumericpii}', '--force')] {'ignore_failures': True, 'user': 'hive', 'timeout': 30};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/12/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {Xuidpii}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e56a92fa-5993-43a3-95e9-244023388b90/resourceGroups/PROD-HDINSIGHTS-GROUP/providers/Microsoft.HDInsight/clusters/prodhdiiq\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",LLAP app 'llap0' deployment unsuccessful.,8.905042686,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,LLAP app 'llap0' deployment unsuccessful.,"It looks like that the status of llap daemon in worknode0,5,6,7 have a wrong status  and they are not killed properly. ",Kill all the llap daemon in worknodes above. Restart the llap service and hive server2 service ,,,,,,,,
1.20051E+14,28:28.7,connection error,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 12, 2020, 3:00 PM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: AMBARI_METRICS\nCRITICAL {Namepii} Collector Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:6188 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nCRITICAL {Namepii} Collector - HBase Master Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:61310 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nHDFS\nCRITICAL NameNode Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:30070 ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nCRITICAL ZooKeeper Failover Controller Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:8019 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nOOZIE\nCRITICAL Oozie Server Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:11000/oozie/?user.name=oozie ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nYARN\nCRITICAL ResourceManager Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:8088 ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \n{ALPHANUMERICPII}\nCRITICAL {Alphanumericpii} History Server \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:18080 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - AMBARI_METRICS\nCRITICAL {Namepii} Collector Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:6188 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nCRITICAL {Namepii} Collector - HBase Master Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:61310 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nHDFS\nCRITICAL NameNode Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:30070 ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nCRITICAL ZooKeeper Failover Controller Process \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:8019 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nOOZIE\nCRITICAL Oozie Server Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:11000/oozie/?user.name=oozie ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \nYARN\nCRITICAL ResourceManager Web UI \nConnection failed to http://hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:8088 ('NoneType' object has no attribute 'split') \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \n{ALPHANUMERICPII}\nCRITICAL {Alphanumericpii} History Server \nConnection failed: 'NoneType' object has no attribute 'split' to hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net:18080 \n{Namepii}: {alphanumericpii} \nHost: hn0-p02las.naygignl0faevcmh3dqqy1bagc.gx.internal.cloudapp.net \n;\n\n- ProblemStartTime: 05/12/2020 20:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02las01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",connection error,0.427133637,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,connection error on AMS,"We noticed that all the alerts were coming from headnode0 and spot checking a few services showed that there were warnings when trying to connect to metrics collector,", we then rebooted the headnode to get past this issue. ,,,,,,,,
1.20051E+14,47:52.7,YARN stops after queue config change,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 12, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Change in queue config\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Tried restarting several times\n\nQuestion: Additional details about the issue\nAnswer: YARN RM stops with the following error:\n\n2020-05-13 {Alphanumericpii} INFO  resourcemanager.ResourceManager - Transitioning to standby state\n2020-05-13 {Alphanumericpii} INFO  resourcemanager.ResourceManager - Transitioned to standby state\n2020-05-13 {Alphanumericpii} FATAL resourcemanager.ResourceManager - Error starting ResourceManager\njava.lang.IllegalArgumentException: Illegal capacity of 0.0 for children of queue root for label=initializing\n        at {AlphanumericPII})\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager.parseQueue(CapacitySchedulerQueueManager.java:287)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager.initializeQueues(CapacitySchedulerQueueManager.java:158)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Change in queue config;\nIncrease in load? - ;\nMitigating actions taken so far - Tried restarting several times;\nAdditional details about the issue - YARN RM stops with the following error:\n\n2020-05-13 {Alphanumericpii} INFO  resourcemanager.ResourceManager - Transitioning to standby state\n2020-05-13 {Alphanumericpii} INFO  resourcemanager.ResourceManager - Transitioned to standby state\n2020-05-13 {Alphanumericpii} FATAL resourcemanager.ResourceManager - Error starting ResourceManager\njava.lang.IllegalArgumentException: Illegal capacity of 0.0 for children of queue root for label=initializing\n        at {AlphanumericPII})\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager.parseQueue(CapacitySchedulerQueueManager.java:287)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager.initializeQueues(CapacitySchedulerQueueManager.java:158)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII});\n\n- ProblemStartTime: 05/12/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe02-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe02-sp-wu01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",YARN stops after queue config change,0.522213592,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,YARN stops after queue config change,YARN stops after queue config change,"I would recommend/suggest to revert back the YARN chanages to its earlier version to resume YARN RM. Additionally, I am sharing an article, which has very good insight into YARN capacity configurations and their ramifications --> https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html#Setting_up_queues",,,,,,,,
1.20051E+14,15:19.0,Adding Ad groups and users to ranger user sync and group sync ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii}\n\nQuestion: Hive query explain plan if available\nAnswer: Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii}\n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii};\nHive query explain plan if available - Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii};\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Team,\nI am trying to sync AD groups and users on ranger and facing error while trying to sync. Please guid on how this can be done. \nThanks,\n{Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/04af94d4-74f4-4642-b571-5b48a42b979f/resourceGroups/ITS-APPOPS-EDL-PROD-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/PHBS01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Adding Ad groups and users to ranger user sync and group sync ,0.056897797,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hive,Issues Adding Ad groups and users  to ranger user sync and group sync,Adding Ad groups and users to ranger user sync and group sync,Provided following  link - https://docs.microsoft.com/en-us/azure/hdinsight/domain-joined/ldap-sync,,,,,,,,
1.20051E+14,21:26.2,Could not use Python 3 in cluster,"Question: What time did the problem begin?\nAnswer: Wed, May 13, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: Hello {Namepii}, we installed a conda package called 'fastavro' and when we run a pipeline in ADF to use {alphanumericpii} with this package we are getting many errors (attached). Could you please give us some help?\nI have attached the error.\nScript to install the package: https://azredlake.blob.core.windows.net/scriptaction/analytics-v3.sh\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Python;\nSpark configuration details - N/A;\nAdditional details about the issue - Hello {Namepii}, we installed a conda package called 'fastavro' and when we run a pipeline in ADF to use {alphanumericpii} with this package we are getting many errors (attached). Could you please give us some help?\nI have attached the error.\nScript to install the package: https://azredlake.blob.core.windows.net/scriptaction/analytics-v3.sh;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/13/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {Namepii} - Desenvolvimento\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/715a8512-1a2a-4027-8bd3-397b42e369f7/resourceGroups/DevelopmentAnalyticsResources/providers/Microsoft.HDInsight/clusters/homspksim\n- Location: brazilsouth\n- Location: {Namepii} South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Could not use Python 3 in cluster,0.302451562,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Unexpected result\Spark,Could not use Python 3 in cluster,"There are two Python installations in the cluster, Anaconda Python 2.7 and Python 3.5 and the default set to 2.7.","Mitigations and workarounds:Expand Advanced livy2-env, add below statements at bottom. If you installed the virtual environment with a different prefix, change the path correspondingly.export PYSPARK_PYTHON=/usr/bin/anaconda/envs/py35/bin/pythonexport PYSPARK_DRIVER_PYTHON=/usr/bin/anaconda/envs/py35/bin/python Expand Advanced spark2-env, replace the existing export PYSPARK_PYTHON statement at bottom. If you installed the virtual environment with a different prefix, change the path correspondingly.export PYSPARK_PYTHON=${PYSPARK_PYTHON:-/usr/bin/anaconda/envs/py35/bin/python} More Info: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-python-package-installation#understand-default-python-installation",,,,,,,,
1.20051E+14,44:17.7,"http messages unable to process , connector giving time out","Question: What time did the problem begin?\nAnswer: {Namepii}, May 7, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: REST API\n\nQuestion: Additional details about the issue\nAnswer: from the rest api\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - REST API;\nAdditional details about the issue - from the rest api;\n\n- ProblemStartTime: 05/06/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: VSSM\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/81c297e4-0014-4f3d-9a81-270e9a38cbf0/resourceGroups/vssm_cloud_tool/providers/Microsoft.HDInsight/clusters/vssm-kafka\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","http messages unable to process , connector giving time out",1.086832063,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Hbase,Messages not pushed by Kafka to Splunk cluster,Splunk Kafka Connector in bad state,Restarted connector,188095488,,,,,,,
1.20051E+14,11:43.4,Ambari can not connect to zk2-hbase as well as SSH to zk2-hbase is not working,"Question: What time did the problem begin?\nAnswer: sob., 25 kwi 2020, 22:07 CEST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Zookeeper node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: There have been a try to manage by Ambari but now Ambari is not connected to zk2-hbase.kfc0guhoogqurheqjug5a4zi0d.ax.internal.cloudapp.net . There have been a try to connect via SSH but {alphanumericpii} is not responding.\n\n\nQuestion: Additional details about the issue\nAnswer: Ambari is not connected to zk2-hbase.kfc0guhoogqurheqjug5a4zi0d.ax.internal.cloudapp.net , {alphanumericpii} is not responding for SSH connection.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Zookeeper node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - There have been a try to manage by Ambari but now Ambari is not connected to zk2-hbase.kfc0guhoogqurheqjug5a4zi0d.ax.internal.cloudapp.net . There have been a try to connect via SSH but {alphanumericpii} is not responding.\n;\nAdditional details about the issue - Ambari is not connected to zk2-hbase.kfc0guhoogqurheqjug5a4zi0d.ax.internal.cloudapp.net , {alphanumericpii} is not responding for SSH connection.;\n\n- ProblemStartTime: 04/25/2020 20:07:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SENT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6053976-8936-4892-8397-0500cd7aac44/resourceGroups/sent-gps-hdi-rg/providers/Microsoft.HDInsight/clusters/hbase-sent-geo-cl\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari can not connect to zk2-hbase as well as SSH to zk2-hbase is not working,0.24118786,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Ambari can not connect to zk2-hbase as well as SSH to zk2-hbase is not working.,NA,"Rebooted zookeeper nodes and clean up the snapshots. Since the node wn0 have the issue (read-only mode), we have removed wn0 from the cluster and then you can scale up the cluster again according to your business needs.",188139025,,,,,,,
1.20051E+14,37:21.0,Ambari Metric Not showing ,"Question: What time did the problem begin?\nAnswer: Fri, May 1, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, May 13, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe are not able to monitor the CPU usage as amabri Metric service is not up and running. Also we have observed all the nodes were going down continously. \n\nPlease look into the issue and let us know the fix steps to be perfromed.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi {Namepii},\n\nWe are not able to monitor the CPU usage as amabri Metric service is not up and running. Also we have observed all the nodes were going down continously. \n\nPlease look into the issue and let us know the fix steps to be perfromed.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/01/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Prod_DR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cca3be6-ea39-4394-9aab-242213bd98e5/resourceGroups/eaasedl-prd/providers/Microsoft.HDInsight/clusters/sdbox1rservereaasedl\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Metric Not showing ,0.058981597,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Metrics are missing\Hadoop,Ambari Metric Not showing,head nodes were not responded and connection failure,Rebooted hn0 and hn1,,,,,,,,
1.20051E+14,04:59.1,West prdsup - kpps83sparkespprdsupwus201 - Hive warehouce config failing with Spak submit in cluster mode,"Question: What time did the problem begin?\nAnswer: Wed, May 13, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, May 13, 2020, 10:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Spark jobs failing when deploy mode is  'cluster' Working in 'client' mode. \n\nExample job tested\n spark-submit --jars /usr/hdp/3.1.2.2-1/hive_warehouse_connector/hive-warehouse-connector-assembly-1.0.0.3.1.2.2-1.jar --class com.spark.hivewarehouse.SparkWriteReadHIVETable --deploy-mode cluster /{alphanumericpii}\n\nOutput \nlogs attached. \n\n\nQuestion: Hive query explain plan if available\nAnswer: not applicable\n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: logs attached. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Spark jobs failing when deploy mode is  'cluster' Working in 'client' mode. \n\nExample job tested\n spark-submit --jars /usr/hdp/3.1.2.2-1/hive_warehouse_connector/hive-warehouse-connector-assembly-1.0.0.3.1.2.2-1.jar --class com.spark.hivewarehouse.SparkWriteReadHIVETable --deploy-mode cluster /{alphanumericpii}\n\nOutput \nlogs attached. \n;\nHive query explain plan if available - not applicable;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - logs attached. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/13/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",West prdsup - kpps83sparkespprdsupwus201 - Hive warehouce config failing with Spak submit in cluster mode,0.731283482,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,HWC Spark-submit fails with cluster mode when spark.security.credentials.hiveserver2.enabled=false,Hive warehouce config failing with Spark submit in cluster mode,We recommend you set spark.security.credentials.hiveserver2.enabled=false for client mode and cluster mode should set spark.security.credentials.hiveserver2.enabled=true,,,,,,,,
1.20051E+14,09:48.5,Not receiving Ambari alerts,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Alert notifications used to work in the old cluster. After we migrated to the new cluster, I don't see the alerts being sent for the configured email id in the alert notifications. \n\nEarlier it used to work with out a send grid account etc.. but now its not working. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Alert notifications used to work in the old cluster. After we migrated to the new cluster, I don't see the alerts being sent for the configured email id in the alert notifications. \n\nEarlier it used to work with out a send grid account etc.. but now its not working. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not receiving Ambari alerts,0.661649795,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hbase,Not receiving Ambari alerts,Not receiving Ambari alerts,Shared below link with customer to setup the same and customer confirmed that it is working as expected.https://docs.microsoft.com/en-us/azure/hdinsight/apache-ambari-email,,,,,,,,
1.20051E+14,26:52.5,High WAL sync latencies in Staging,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 12, 2020, 3:22 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, May 12, 2020, 3:23 PM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: WAL latency went above 50 secs for a minute.\n\n\n2020-05-12 {Alphanumericpii} INFO  [{alphanumericpii}] wal.FSHLog: Slow sync cost: 69104 ms, current pipeline: [{AlphanumericPII}], {AlphanumericPII}], {AlphanumericPII}]]\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - WAL latency went above 50 secs for a minute.\n\n\n2020-05-12 {Alphanumericpii} INFO  [{alphanumericpii}] wal.FSHLog: Slow sync cost: 69104 ms, current pipeline: [{AlphanumericPII}], {AlphanumericPII}], {AlphanumericPII}]]\n;\n\n- ProblemStartTime: 05/12/2020 22:22:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",High WAL sync latencies in Staging,0.932737265,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,"WAL latency went above 50 secs for a minute 2020-05-12 22:23:02,165 INFO  [sync.4] wal.FSHLog: Slow sync cost: 69104 ms, current pipeline: [DatanodeInfoWithStorage[10.67.6.144:30010,DS-80163b21-d86b-4abc-83f4-cc22e24aeb04,DISK], DatanodeInfoWithStorage[10.67.6.161:30010,DS-92dd28df-6a69-45b4-9210-1e7a7717cd41,DISK], DatanodeInfoWithStorage[10.67.6.159:30010,DS-101927c6-3d03-42de-8290-a714d9ac0025,DISK]]  Root Cause:","We have checked the logs and noticed that this was due to the VM host failures in the backend and due to which you are seeing the latencies. To get the deeper investigation on these we have engaged the compute teamPlease find the detailed root cause regarding this latency. In accelerated cluster the WAL file is backed by HDFS and every file will be replicated in 3 DNs. This is known as HDFS pipeline. The DN in wn8 was part of some WAL file's pipeline.As the VM and DN became unavailable for quite some time, some of the WAL writes were delayed at wn8 DN. In pipeline, one DN writes to this wn8 DN. This socket write itself will fail at Java level after the socket timeout. The socket time out default value is 60 secs.  The other DN which writes to wn8 will wait for this much time and after that fail the op to client (RS). After this the HDFS client will create a new pipeline excluding this problematic DN and this time the write will succeed fast.  At any DN side there can be many parallel writer threads present and for any such writes this wn8 might be in pipeline. Once this DN finds the DN in wn8 is faulty (after 60sec timeout), the other waiting writers also will be fast failed. But till then it would have spent time.  That is why we had some 50+ sec (<60 sec) slow sync also. ","We have checked the logs and noticed that this was due to the VM host failures in the backend and due to which you are seeing the latencies. To get the deeper investigation on these we have engaged the compute teamPlease find the detailed root cause regarding this latency. In accelerated cluster the WAL file is backed by HDFS and every file will be replicated in 3 DNs. This is known as HDFS pipeline. The DN in wn8 was part of some WAL file's pipeline.As the VM and DN became unavailable for quite some time, some of the WAL writes were delayed at wn8 DN. In pipeline, one DN writes to this wn8 DN. This socket write itself will fail at Java level after the socket timeout. The socket time out default value is 60 secs.  The other DN which writes to wn8 will wait for this much time and after that fail the op to client (RS). After this the HDFS client will create a new pipeline excluding this problematic DN and this time the write will succeed fast.  At any DN side there can be many parallel writer threads present and for any such writes this wn8 might be in pipeline. Once this DN finds the DN in wn8 is faulty (after 60sec timeout), the other waiting writers also will be fast failed. But till then it would have spent time.  That is why we had some 50+ sec (<60 sec) slow sync also. ","188,129,379,188,144,000",,,,,,,
1.20051E+14,52:42.5,Trying to create a new cluster with ADLS Gen 1 as secondary storage ,"Question: What time did the problem begin?\nAnswer: Fri, May 1, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: msndnikylin\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Unable to create/add ADLS {Namepii} 1 as secondary storage to HDI 4.0 Spark cluster.\n\n{emailpii}@microsoft.com\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - msndnikylin;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Unable to create/add ADLS {Namepii} 1 as secondary storage to HDI 4.0 Spark cluster.\n\n{emailpii}@microsoft.com\n;\n\n- ProblemStartTime: 05/01/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DnI Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Trying to create a new cluster with ADLS Gen 1 as secondary storage ,0.53217003,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to create a 4.0 HDI cluster in the portal using Blob storage as primary storage and ADLS Gen 1 as secondary storage,This configuration is not supported as stated here:  https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-compare-storage-options ,We had a screenshare to walk through the issue and found that there was a bug within the UI. I have sent this information to the product group for resolution.Shared documentation on the current storage configurations that are supported for an 4.0 HDI cluster.,,,,,,,,
1.20051E+14,15:38.2,Cluster is hanging on custom script action and cannot be deleted,"Question: What time did the problem begin?\nAnswer: Wed, May 13, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Error I receive is:\n\n{'code':'Conflict','message':'Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.'}\n\nPlease ensure we are not charged for the cluster since I issued the delete request.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Error I receive is:\n\n{'code':'Conflict','message':'Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.'}\n\nPlease ensure we are not charged for the cluster since I issued the delete request.;\n\n- ProblemStartTime: 05/13/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SilviaTerra Pay-As-You-Go\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/15788394-4a53-4ca5-a1f3-9be9fde89fbd/resourceGroups/SilviaTerraEastUS/providers/Microsoft.HDInsight/clusters/python3-testing\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is hanging on custom script action and cannot be deleted,0.341641033,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Cluster is hanging on custom script action and cannot be deleted,Tried to delete the cluster when the script action was in progress,"When you apply a script to a cluster, the cluster state changes from Running to Accepted. Then it changes to HDInsight configuration and, finally, back to Running for successful scripts. It is not recommended to delete while running script action because they are two are conflicting operations; script action is applying changes to nodes; whereas, delete operation is deprovisioning the nodes. There is additional general information in below link regarding script action on a running cluster.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-cluster-linux#script-action-on-a-running-clusterUnfortunately, there is no option to force delete while running a script action. If you are making changes via script action, it will show ""applying changes"" on Portal and you will be able to delete afterwards. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-faq#how-do-i-delete-an-existing-hdinsight-cluster --> Try to leave at least 30 to 60 minutes for smooth deletions after cluster is back in running state (in your case when script action completes). ",,,,,,,,
1.20051E+14,33:45.7,[HDI]Error in LLAP cluster when we changed the ADDS certificate,Caught exception running LDAP sync. simple bind failed: pcloudplatform.co.uk:636; nested exception is javax.naming.CommunicationException: simple bind failed: pcloudplatform.co.uk:636 [{Namepii} exception is javax.net.ssl.SSLHandshakeException: {namepii}.security.validator.ValidatorException: PKIX path building failed: {namepii}.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target]\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: REBUS_PRODUCTION\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,[HDI]Error in LLAP cluster when we changed the ADDS certificate,62.47570981,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,cannot access Ambari UI,LDAP ysnc was failing,"After pushing the new cert to all nodes, we restored the Ambari config back to the original configuration and restarted ambari server. ",195593564,,,,,,,
1.20051E+14,15:36.5,webHDFS configuration to access Sotrage Container,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 14, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: For our hdinsight cluster sparktestrlrazdev we have Storage container that is used for hadoop file system. Is it possible to access this storage using webHDFS? If yes, what should the configuration be?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - For our hdinsight cluster sparktestrlrazdev we have Storage container that is used for hadoop file system. Is it possible to access this storage using webHDFS? If yes, what should the configuration be?;\n\n- ProblemStartTime: 05/13/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: rlr-az-dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/707c9542-a365-4d05-a045-ead8088d42e2/resourceGroups/rlr-az-dev/providers/Microsoft.HDInsight/clusters/sparktestrlrazdev\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",webHDFS configuration to access Sotrage Container,0.219149475,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\hdfs commands do not work\Azure Storage in standard cluster,webHDFS configuration to access Sotrage Container,NA,"Web HDFS is not supported in HDInsight because we use remote storage. Although there is an option to enable web hdfs through the Ambari UI, you would be accessing the local HDFS and not your blob storage account.The supported way to access the storage files is to use the Azure Blob Rest API.Documentation:https://docs.microsoft.com/en-us/rest/api/storageservices/blob-service-rest-apiThe architecture of HDInsight is designed in a way that it does not support accessing blob storage through webHDFS.Hence as recommended by our PG we don't have future plans implementing the same.",,,,,,,,
1.20051E+14,59:34.2,Can I add same Azure blob storage to two different HDInsight Clusters,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: hdistg\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Map Azure Storage to 2 different Blob Storage\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - hdistg;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Map Azure Storage to 2 different Blob Storage;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SDO - Big Data Program\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/23c0c9e6-02a0-43fa-b7b7-71dca8da4585/resourceGroups/HDIStgCluster/providers/Microsoft.HDInsight/clusters/hdisstg-ddp\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can I add same Azure blob storage to two different HDInsight Clusters,0.033886255,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Client ask if they can add same Azure Blob Storage to two different HDInsight Cluster.,Client ask if they can add same Azure Blob Storage to two different HDInsight Cluster.,"It is important that each cluster use a unique default container, because temporary files used to maintain state of the system and the output logs used cannot be shared. Having a separate folder/container for the primary cluster storage (even in the same storage account is fine) makes that safely isolated from each other.You can have multiple clusters using different containers in the same Blob Storage.",,,,,,,,
1.20051E+14,21:26.9,Unable to connect from on premise to Azure hive in provided resource,"Question: What time did the problem begin?\nAnswer: Wed, May 6, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Unable to connect from on premise to Azure hive in provided resource\n\nError: Could not establish connection to jdbc:hive2://hdihddemandforecastpsprod.azurehdinsight.net:443/;ssl=true;transportMode=http;httpPath=/hive2: HTTP Response code: 403 ({AlphanumericPII})\nBeeline version 1.2.1000.2.5.3.75-2 by {Namepii} Hive\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Unable to connect from on premise to Azure hive in provided resource\n\nError: Could not establish connection to jdbc:hive2://hdihddemandforecastpsprod.azurehdinsight.net:443/;ssl=true;transportMode=http;httpPath=/hive2: HTTP Response code: 403 ({AlphanumericPII})\nBeeline version 1.2.1000.2.5.3.75-2 by {Namepii} Hive\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Unable to connect from on premise to Azure hive in provided resource\n\nError: Could not establish connection to jdbc:hive2://hdihddemandforecastpsprod.azurehdinsight.net:443/;ssl=true;transportMode=http;httpPath=/hive2: HTTP Response code: 403 ({AlphanumericPII})\nBeeline version 1.2.1000.2.5.3.75-2 by {Namepii} Hive;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Unable to connect from on premise to Azure hive in provided resource\n\nError: Could not establish connection to jdbc:hive2://hdihddemandforecastpsprod.azurehdinsight.net:443/;ssl=true;transportMode=http;httpPath=/hive2: HTTP Response code: 403 ({AlphanumericPII})\nBeeline version 1.2.1000.2.5.3.75-2 by {Namepii} Hive;\n\n- ProblemStartTime: 05/05/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-psdemandforecast-prod-001/providers/Microsoft.HDInsight/clusters/hdihddemandforecastpsprod\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect from on premise to Azure hive in provided resource,0.236528929,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Hive,120051423002522 - unable to connect to beeline from on premise machine,The Ambari Server process had stopped on headnode 0 ,"Rebooted headnode 0 to failover the services to hn1. After the reboot, the beeline connection started working on the cluster and from the on-premise machine.",,,,,,,,
1.20051E+14,04:06.7,Not able to delete HDInsight,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Never worked\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Script actions get stuck and not able to delete hdinsight cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Never worked;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Script actions get stuck and not able to delete hdinsight cluster;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: msteams.nonprod.pub.msft.telemetry.backfill\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/989cea72-5d17-4de2-8d41-6a426409d315/resourceGroups/presto-poc/providers/Microsoft.HDInsight/clusters/prestohdicluster\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to delete HDInsight,0.085524051,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Delete HDInsight cluster,Not able to delete HDInsight,The delete is not being accepted because the cluster state is HDIConfiguration and the delete workflow is failing with retry error.,The delete is not being accepted because the cluster state is HDIConfiguration and the delete workflow is failing with retry error. PG force deleted the cluster.,188146255,,,,,,,
1.20051E+14,36:10.4,"delete cluster failed, whch leaked our cores","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: manual delete\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Data Factory Activity\n\nQuestion: Additional details about the issue\nAnswer: {\n    'authorization': {\n        'action': 'Microsoft.HDInsight/clusters/delete',\n        'scope': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c'\n    },\n    'caller': '{guidpii}',\n    'channels': 'Operation',\n    'claims': {\n        'aud': 'https://management.azure.com/',\n        'iss': 'https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/',\n        'iat': '{Phonenumberpii}',\n        'nbf': '{Phonenumberpii}',\n        'exp': '{Phonenumberpii}',\n        'aio': '{AlphanumericPII}==',\n        'appid': '{guidpii}',\n        'appidacr': '1',\n        'groups': '{guidpii}',\n        'http://schemas.microsoft.com/identity/claims/identityprovider': 'https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/',\n        'http://schemas.microsoft.com/identity/claims/objectidentifier': '{guidpii}',\n        'rh': '{AlphanumericPII}.',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier': '{guidpii}',\n        'http://schemas.microsoft.com/identity/claims/tenantid': '{Guidpii}',\n        'uti': 'jWXYx-FWbEqXr-GlygMFAA',\n        'ver': '1.0'\n    },\n    'correlationId': '{guidpii}',\n    'description': '',\n    'eventDataId': '{guidpii}',\n    'eventName': {\n        'value': 'EndRequest',\n        'localizedValue': 'End request'\n    },\n    'category': {\n        'value': 'Administrative',\n        'localizedValue': 'Administrative'\n    },\n    'eventTimestamp': '{ALPHANUMERICPII}',\n    'id': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c/events/cdf3ac89-fa9f-433f-b2e3-8d2bb7e5564e/ticks/637249433151302499',\n    'level': 'Error',\n    'operationId': '{guidpii}',\n    'operationName': {\n        'value': 'Microsoft.HDInsight/clusters/delete',\n        'localizedValue': 'Delete {Namepii}'\n    },\n    'resourceGroupName': 'ADF',\n    'resourceProviderName': {\n        'value': 'Microsoft.HDInsight',\n        'localizedValue': 'Microsoft.HDInsight'\n    },\n    'resourceType': {\n        'value': 'Microsoft.HDInsight/clusters',\n        'localizedValue': 'Microsoft.HDInsight/clusters'\n    },\n    'resourceId': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c',\n    'status': {\n        'value': 'Failed',\n        'localizedValue': 'Failed'\n    },\n    'subStatus': {\n        'value': '499',\n        'localizedValue': '499'\n    },\n    'submissionTimestamp': '{ALPHANUMERICPII}',\n    'subscriptionId': '{guidpii}',\n    'tenantId': '{Guidpii}',\n    'properties': {\n        'statusCode': '499',\n        'serviceRequestId': null,\n        'statusMessage': '{{uncpii}\':{\\'code\\':\\'ClientClosedRequest\\',\\'message\\':{Uncpii} connection has been closed by the client while the server is still processing its request for 'Microsoft.HDInsight'.{Uncpii}\n    },\n    'relatedEvents': []\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Not new, happened before;\nPrevious solution if applicable - manual delete;\nHow was the CRUD request submitted? - Azure Data Factory Activity;\nAdditional details about the issue - {\n    'authorization': {\n        'action': 'Microsoft.HDInsight/clusters/delete',\n        'scope': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c'\n    },\n    'caller': '{guidpii}',\n    'channels': 'Operation',\n    'claims': {\n        'aud': 'https://management.azure.com/',\n        'iss': 'https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/',\n        'iat': '{Phonenumberpii}',\n        'nbf': '{Phonenumberpii}',\n        'exp': '{Phonenumberpii}',\n        'aio': '{AlphanumericPII}==',\n        'appid': '{guidpii}',\n        'appidacr': '1',\n        'groups': '{guidpii}',\n        'http://schemas.microsoft.com/identity/claims/identityprovider': 'https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/',\n        'http://schemas.microsoft.com/identity/claims/objectidentifier': '{guidpii}',\n        'rh': '{AlphanumericPII}.',\n        'http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier': '{guidpii}',\n        'http://schemas.microsoft.com/identity/claims/tenantid': '{Guidpii}',\n        'uti': 'jWXYx-FWbEqXr-GlygMFAA',\n        'ver': '1.0'\n    },\n    'correlationId': '{guidpii}',\n    'description': '',\n    'eventDataId': '{guidpii}',\n    'eventName': {\n        'value': 'EndRequest',\n        'localizedValue': 'End request'\n    },\n    'category': {\n        'value': 'Administrative',\n        'localizedValue': 'Administrative'\n    },\n    'eventTimestamp': '{ALPHANUMERICPII}',\n    'id': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c/events/cdf3ac89-fa9f-433f-b2e3-8d2bb7e5564e/ticks/637249433151302499',\n    'level': 'Error',\n    'operationId': '{guidpii}',\n    'operationName': {\n        'value': 'Microsoft.HDInsight/clusters/delete',\n        'localizedValue': 'Delete {Namepii}'\n    },\n    'resourceGroupName': 'ADF',\n    'resourceProviderName': {\n        'value': 'Microsoft.HDInsight',\n        'localizedValue': 'Microsoft.HDInsight'\n    },\n    'resourceType': {\n        'value': 'Microsoft.HDInsight/clusters',\n        'localizedValue': 'Microsoft.HDInsight/clusters'\n    },\n    'resourceId': '/subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/e2eondemand02fe61c9-bc6a-4e93-ad02-b29541383b2c',\n    'status': {\n        'value': 'Failed',\n        'localizedValue': 'Failed'\n    },\n    'subStatus': {\n        'value': '499',\n        'localizedValue': '499'\n    },\n    'submissionTimestamp': '{ALPHANUMERICPII}',\n    'subscriptionId': '{guidpii}',\n    'tenantId': '{Guidpii}',\n    'properties': {\n        'statusCode': '499',\n        'serviceRequestId': null,\n        'statusMessage': '{{uncpii}\':{\\'code\\':\\'ClientClosedRequest\\',\\'message\\':{Uncpii} connection has been closed by the client while the server is still processing its request for 'Microsoft.HDInsight'.{Uncpii}\n    },\n    'relatedEvents': []\n};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ADF Test sub - App Model V2\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0ee78edb-a0ad-456c-a0a2-901bf542c102/resourceGroups/ADF/providers/Microsoft.HDInsight/clusters/E2EOnDemand02fe61c9-bc6a-4e93-ad02-b29541383b2c\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","delete cluster failed, whch leaked our cores",0.036500488,Root Cause : HDInsight Service\Windows Azure PowerShell/SDK,Routing Azure HDInsight V5\Delete HDInsight cluster,On-Demand cluster intermittent auto delete failure ,Request is not reaching HDI RP. Request failed at ARM with 499 status code.     ,"Customer is using HDI SDK which handles the response from ARM and did not pass back to ADF. HDI SDK Team provided that when operation fails at ARM; SDK will throw ""ErrorResponseException"" exception. Per Client, currently ADF does not handle ""ErrorResponseException"" from SDK. A new exception handling logic will be deployed at client's end to verify SDK response. So if ARM returns ErrorResponseException from SDK, ADF will retry instead of failing the activity. ",,,,,,,,
1.20051E+14,46:20.4,auto scale in,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 14, 2020, 12:45 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No Changes done. Scale out and scale in is being done manually. It has worked earlier this week, but has stopped now\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I am trying to scale up the HDInsight worker nodes from 1 to 5. I submit this on Azure portal. It takes over 2 hours with no notification. I check in Ambari that additional worker nodes are provisioned, but on page refresh, I see that the ones provisioned are deleted and the operation is shown as failed in the Azure portal. I tried it again and this time the worker nodes were available for additional time. I submit a large data processing job and after a few minutes, I don't see the nodes in Ambari. It is back to 1 node. I check in Azure portal and it says that the cluster operation has failed. Please check on the reason for worker nodes getting deleted and operation failing. I am attaching the screenshot from Azure portal on the failure.\n\nNote that this is in the test environment and is impacting the timelines for application testing.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No Changes done. Scale out and scale in is being done manually. It has worked earlier this week, but has stopped now;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I am trying to scale up the HDInsight worker nodes from 1 to 5. I submit this on Azure portal. It takes over 2 hours with no notification. I check in Ambari that additional worker nodes are provisioned, but on page refresh, I see that the ones provisioned are deleted and the operation is shown as failed in the Azure portal. I tried it again and this time the worker nodes were available for additional time. I submit a large data processing job and after a few minutes, I don't see the nodes in Ambari. It is back to 1 node. I check in Azure portal and it says that the cluster operation has failed. Please check on the reason for worker nodes getting deleted and operation failing. I am attaching the screenshot from Azure portal on the failure.\n\nNote that this is in the test environment and is impacting the timelines for application testing.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/14/2020 16:45:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LXK.DigitalTransformation.BigDecisions.Non-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/27f2890d-6e16-464f-853b-ae7f681978d5/resourceGroups/qa-bigd-rg/providers/Microsoft.HDInsight/clusters/qaentanalyticshdinsight\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",auto scale in,4.742842403,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Manual scale up failed twice in a row and took 2 - 3 hours to fail.,"Unknown, intermittent issue","Asked cx to retry manual scale up and it was successful, no issues reported since.",,,,,,,,
1.20051E+14,30:43.1,Unable to ssh into the cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 14, 2020, 12:00 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to shh into \n\nssh {emailpii}@helx1-dev-common-hdi-eastus-hdis-ssh.azurehdinsight.net\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to shh into \n\nssh {emailpii}@helx1-dev-common-hdi-eastus-hdis-ssh.azurehdinsight.net;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/14/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-dev\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c81ef06-ea16-4618-9d44-af9fcf6d8f4e/resourceGroups/helx-dev-common-hdi-eastus-rg/providers/Microsoft.HDInsight/clusters/helx1-dev-common-hdi-eastus-hdis\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to ssh into the cluster,0.640265101,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,Unable to ssh into the cluster,Unable to ssh into the cluster,Suggested customer to evaluate NSG rules if he is allowed to login from the source VM. Customer confirmed to close the case.,,,,,,,,
1.20051E+14,53:05.1,Edge Node Unreachable,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 14, 2020, 5:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Removed Node from the application\n\nQuestion: Additional details about the issue\nAnswer: We cannot SSH or reach this VM, ambari thinks it's fine but our app is not able to reach it. \n\ned30-cortex.rruelcdwpsuu5i02inwuz054jf.cx.internal.cloudapp.net\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Removed Node from the application;\nAdditional details about the issue - We cannot SSH or reach this VM, ambari thinks it's fine but our app is not able to reach it. \n\ned30-cortex.rruelcdwpsuu5i02inwuz054jf.cx.internal.cloudapp.net\n;\n\n- ProblemStartTime: 05/14/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: US_AUDIT_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8c71ef53-4473-4862-af36-bae6e40451b2/resourceGroups/App-Cortex-AME-PRD-RG/providers/Microsoft.HDInsight/clusters/cortexaapsprdspark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Edge Node Unreachable,0.076283309,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Unable to SSH and all looks good in Ambari UI for this host,Unable to SSH in to ed30 and kusto backend logs looks good,Rebooted the ed30  node,188183509,,,,,,,
1.20052E+14,19:23.1,yarn.resourcemanager.am.max-attempts,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: {alphanumericpii}\n\nQuestion: Additional details about the issue\nAnswer: The default value of yarn.resourcemanager.am.max-attempts is 5 during an HDInsight cluster deployment. This means when a SPARK job fails, it is re-executed 4 more times. This can be problematic if our jobs partially run multiple times. We changed this parameter to 1, and our job was not re-executed when it failed the first time.\n\nCan you please help us understand how this parameter influences the cluster’s ability to handle fail-overs of Spark’s sessions, what is the parameter meant for, and the impact of changing to 1.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Python;\nSpark configuration details - {alphanumericpii};\nAdditional details about the issue - The default value of yarn.resourcemanager.am.max-attempts is 5 during an HDInsight cluster deployment. This means when a SPARK job fails, it is re-executed 4 more times. This can be problematic if our jobs partially run multiple times. We changed this parameter to 1, and our job was not re-executed when it failed the first time.\n\nCan you please help us understand how this parameter influences the cluster’s ability to handle fail-overs of Spark’s sessions, what is the parameter meant for, and the impact of changing to 1.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",yarn.resourcemanager.am.max-attempts,0.289327178,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Query or Job Failure\Spark,"The Cx changed this parameter to 1, and their  job was not re-executed when it failed the first time.","Questions regarding yarn.resourcemanager.am.max-attempts parameter: How this parameter influences the cluster’s ability to handle fail-overs of Spark’s sessions, what the parameter is meant for, and the impact of changing it to 1.",Shared documentation on the use of the parameter as well as how to set this parameter at an application level to reduce impact to other Spark jobs.,,,,,,,,
1.20052E+14,14:07.2,Hive Interactiveser2 is down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: HIve interactive server is down. Looks like ambari is ubale to talk to the servive when i try to bring it up. \n\nQuestion: Additional details about the issue\nAnswer: HIve interactive server is down. Looks like ambari is ubale to talk to the servive when i try to bring it up. We are unable to connect to sql tool to hive and i suspect this may be the reason. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - HIve interactive server is down. Looks like ambari is ubale to talk to the servive when i try to bring it up. ;\nAdditional details about the issue - HIve interactive server is down. Looks like ambari is ubale to talk to the servive when i try to bring it up. We are unable to connect to sql tool to hive and i suspect this may be the reason. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-BATCH01-RG/providers/Microsoft.HDInsight/clusters/CHBP01ADLBATCH\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Interactiveser2 is down,7.071397772,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Hive Interactiveser2 is down,Hive Interactiveser2 is down,"Worked with customer on multiple clusters  - for cluster: chsp90adlspark, it was observed that zookeeper was corrupted and all znodes/namespaces were lost on the zookeeper quorum. For another cluster: phsp02adlspark, observed that LLAP was not throwing any errors for the failures and advised customer to increase ""Number of retries while checking LLAP app status"" to 40. Customer told that he would plan this after 2 weeks and agreed to close the case.",,,,,,,,
1.20052E+14,48:59.1,Class org.apache.hadoop.fs.adl.HdiAdlFileSystem not found,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: MapReduce\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe are getting below error in the workder nodes \n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: \nClass org.apache.hadoop.fs.adl.HdiAdlFileSystem not found\n\nThanks\n{Namepii} \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - MapReduce;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nAdditional details about the issue - Hi {Namepii},\n\nWe are getting below error in the workder nodes \n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: \nClass org.apache.hadoop.fs.adl.HdiAdlFileSystem not found\n\nThanks\n{Namepii} ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AMD-GIS_DataAnalytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d3d998c-abd9-4369-9f7a-9fc9a69ea4e4/resourceGroups/pcue2-hadoop-dr-rg/providers/Microsoft.HDInsight/clusters/hdi2drtest\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Class org.apache.hadoop.fs.adl.HdiAdlFileSystem not found,0.094107854,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie", Class org.apache.hadoop.fs.adl.HdiAdlFileSystem not found,Updated some configs by Customer,"Recommended to revert the ""fs.adl.impl"" to default setting.","188,249,027,188,249,000",,,,,,,
1.20052E+14,41:50.7,Cluster stuck in hdinsight configuration step,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: CLuster stuck in HDINsight configuration step\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - CLuster stuck in HDINsight configuration step;\n\n- ProblemStartTime: 05/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp05-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster stuck in hdinsight configuration step,0.130061475,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Cluster stuck in configurations,Two issues here:-- Deleting overprovisioning nodes took 25 mins --- Adding the add user ambari as Ranger Admin  failed - more time  retried and got successful.,Two issues here:-- Deleting overprovisioning nodes took 25 mins --- Adding the add user ambari as Ranger Admin  failed - more time  retried and got successful.,,,,,,,,
1.20052E+14,31:38.6,Need help adding disks to hdinsight kafka nodes,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Because of the data we are sending we ran out of disk space on the cluster. Need help adding disks to the Kafka brokers\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - Because of the data we are sending we ran out of disk space on the cluster. Need help adding disks to the Kafka brokers;\n\n- ProblemStartTime: 05/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Lumada Manufacturing Insights - Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need help adding disks to hdinsight kafka nodes,18.90654444,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Kafka,Need help adding disks to hdinsight kafka nodes ,"Currently, adding more disks to an existing cluster isn't supported.","Recreate a cluster with premium SSD Managed disks as they are high performance Solid State Drive (SSD) based Storage designed to support I/O intensive workloads with significantly high throughput and low latency. The Premium SSD are supported by DS-series, DSv2-series, FS-series, and GS-series VM sizes which are specifically targeted for Premium SSD Managed Disks.",,,,,,,,
1.20052E+14,28:29.0,Public Outgoing IP,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: How can we get the outgoing public IP address used for all worker nodes? We need this IP to be added to a third party API in its network security that our spark cluster calls. Right now, the only thing I could find is SSH into each worker node and run 'curl bot.whatismyipaddress.com', but that is super fragile if we scale cluster, etc. For VMSS, you have a single public IP that makes whitelisting access from spark easy. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - How can we get the outgoing public IP address used for all worker nodes? We need this IP to be added to a third party API in its network security that our spark cluster calls. Right now, the only thing I could find is SSH into each worker node and run 'curl bot.whatismyipaddress.com', but that is super fragile if we scale cluster, etc. For VMSS, you have a single public IP that makes whitelisting access from spark easy. ;\n\n- ProblemStartTime: 05/15/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Compute\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c33b07d0-b4f6-4b88-8e14-51342fc1b897/resourceGroups/spark-prod-westus/providers/Microsoft.HDInsight/clusters/moesif-spark-westus\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Public Outgoing IP,0.113761662,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Public Outgoing IP.,NA,We don't support on whitelisting each worker node public IP as it is unpredictable. As a work around I would suggest you to try VNet peering to resolve your issue. You can check below documents which walks you through VNet peering approach. https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-vnet-vnet-resource-manager-portal ,,,,,,,,
1.20052E+14,14:29.3,hiveserver2 interactive critical alert,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, May 15, 2020, 12:00 AM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The application reported a 'NOT RUNNING' state. Check took {Alphanumericpii}\n\nThis alert is triggered if the LLAP Application cannot be determined to be up and responding to requests. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The application reported a 'NOT RUNNING' state. Check took {Alphanumericpii}\n\nThis alert is triggered if the LLAP Application cannot be determined to be up and responding to requests. ;\n\n- ProblemStartTime: 05/15/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph13sprkprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hiveserver2 interactive critical alert,0.755888092,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Hive,HS2I goes down and see a hiveserver2 interactive critical alert on Ambari UI,"Less LLAP daemons caused llap0 application to go ""NOT RUNNING"" state",Restart of HS2I service is worked fine. Recommended to have 5 and above LLAP daemons to avoid landing on this issue(s),,,,,,,,
1.20052E+14,48:05.5,FD Sandbox - kps025sparkfdsbwus401 - Hive connections down,"Question: What time did the problem begin?\nAnswer: Sat, May 16, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, May 16, 2020, 12:00 AM PDT\n\nQuestion: Connection string used\nAnswer: From Ambari\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: ISSUE :\n1. Stale connection - Hive connections not allowed and jobs are stuck without getting processed. Even though only 1 or 2 jobs runing , still beeline or hive wouldn't connect \n2. Cannot start - Restarting of hive services fails\n3. Edge nodes complaining of hdp select  - Edge nodes show errors when cluster services are restarted \n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nConnection string used - From Ambari;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - ISSUE :\n1. Stale connection - Hive connections not allowed and jobs are stuck without getting processed. Even though only 1 or 2 jobs runing , still beeline or hive wouldn't connect \n2. Cannot start - Restarting of hive services fails\n3. Edge nodes complaining of hdp select  - Edge nodes show errors when cluster services are restarted \n\n;\n\n- ProblemStartTime: 05/16/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps025sparkfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox - kps025sparkfdsbwus401 - Hive connections down,0.58919541,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,FD Sandbox - kps025sparkfdsbwus401 - Hive connections down,"Issues Seen:We noticed quite a lot of Authentication errors on the Hive metastore logs, these errors were pointing to the ADLS (old location) the tables were updated to use ABFS. Also noticed quite a few java OOM on the hive metastore. Also noticed that the backend SQL database is hitting around 98% DTU consumption.", Resolution : 1. DB cleanup -- removed old ADLS tables from the backend Metastore2.Diabled Compaction and increased HMS heap3. increased the backend sql metastore SKU size to have more DTUs.,,,,,,,,
1.20052E+14,10:22.0,FD Sandbox - kps071hbasefdsbwus201 - Hive connections not available,"Question: What time did the problem begin?\nAnswer: Sat, May 16, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, May 16, 2020, 12:00 AM PDT\n\nQuestion: Connection string used\nAnswer: From Ambari\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: 1. Stale connection - Hive connections  not succeding \n2. Cannot start  Services cannot start \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nConnection string used - From Ambari;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - 1. Stale connection - Hive connections  not succeding \n2. Cannot start  Services cannot start \n;\n\n- ProblemStartTime: 05/16/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps071hbasefdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD Sandbox - kps071hbasefdsbwus201 - Hive connections not available,0.634687421,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,FD Sandbox - kps071hbasefdsbwus201 - Hive connections not available,"Issues Seen:We noticed quite a lot of Authentication errors on the Hive metastore logs, these errors were pointing to the ADLS (old location) the tables were updated to use ABFS. Also noticed quite a few java OOM on the hive metastore. Also noticed that the backend SQL database is hitting around 98% DTU consumption.",=================== Resolution : 1. DB cleanup -- removed old ADLS tables from the backend Metastore2.Diabled Compaction and increased HMS heap3. increased the backend sql metastore SKU size to have more DTUs.,,,,,,,,
1.20052E+14,59:57.6,"Cluster not Scaling Up, Yarn not Accessible","Question: What time did the problem begin?\nAnswer: Sun, May 17, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: None\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} scale up failing for our production job. The scale up is triggered through azure cli in our production environment. Tried scaling up through portal, stuck at that for the past 2 hours. Unable to access yarn, getting HTTP Error 502.3 - Bad Gateway.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - None;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - {Namepii} scale up failing for our production job. The scale up is triggered through azure cli in our production environment. Tried scaling up through portal, stuck at that for the past 2 hours. Unable to access yarn, getting HTTP Error 502.3 - Bad Gateway.;\n\n- ProblemStartTime: 05/17/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-PROD-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24customeraiprod\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Cluster not Scaling Up, Yarn not Accessible",0.759413998,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,"Cluster scale up failing for our production job. The scale up is triggered through azure cli in our production environment. Tried scaling up through portal, stuck at that for the past 2 hours. Unable to access yarn, getting HTTP Error 502.3 - Bad Gateway.",intermittent issue ,Now able to access the Ambari UI and Yarn UI .,"188,482,520,188,482,000,000,000,000",,,,,,,
1.20052E+14,26:41.8,Hive Error while accessing data from Qlik ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: jdbc:hive2://UDP-Hdinsight-int.azurehdinsight.net:443/default\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: QVX_UNEXPECTED_END_OF_DATA: SQL##f - SqlState: {Alphanumericpii}, ErrorCode: 35, ErrorMsg: [Microsoft][{Namepii}] (35) Error from server: error code: '0' error message: 'Invalid OperationHandle: OperationHandle [opType=EXECUTE_STATEMENT, {AlphanumericPII}]'.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - jdbc:hive2://UDP-Hdinsight-int.azurehdinsight.net:443/default;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - QVX_UNEXPECTED_END_OF_DATA: SQL##f - SqlState: {Alphanumericpii}, ErrorCode: 35, ErrorMsg: [Microsoft][{Namepii}] (35) Error from server: error code: '0' error message: 'Invalid OperationHandle: OperationHandle [opType=EXECUTE_STATEMENT, {AlphanumericPII}]'.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Error while accessing data from Qlik ,0.038092089,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,120051822000128 - Hive Error while accessing data from Qlik,Unknown,Test the Hive query using Beeline on the cluster. This was successful.Engage Qlik support to work with Microsoft on possible configuration issues / updates that could mitigate the error.Reopen the Microsoft support case if further support is needed on this issue.,,,,,,,,
1.20052E+14,56:31.9,unable to create hdinsight cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 18, 2020, 10:30 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hi , The cluster is in deletion phase for a very long time and unable to delete it. please delete it from your end.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hi , The cluster is in deletion phase for a very long time and unable to delete it. please delete it from your end.;\n\n- ProblemStartTime: 05/18/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Project Audience Measurement\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/4e0be25d-2501-46ce-b71b-36ad4d34c88e/resourceGroups/amdi-dev-rg/providers/Microsoft.HDInsight/clusters/am-dev-dataint-hdi\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to create hdinsight cluster,2.340070678,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,unable to create hdinsight cluster,Cluster stuck in Error State           ,PG deleted it from backend,188554444,,,,,,,
1.20052E+14,17:13.7,need IP v6 disabled on Gateway nodes,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Reference ticket. {Phonenumberpii}\nLast time we created HDI clusters, MSFT disabled IPv6 on the gateway nodes. Our conditional access policies do not support IPv6. Ambari Authentication is failing with conditional access failures.\nWe have other subnets where we need to create new HDI clusters. How can we do this. Do we open a ticket to disable IP v6 after created a new cluster everytime. Please let us know if there is an alternative.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - Reference ticket. {Phonenumberpii}\nLast time we created HDI clusters, MSFT disabled IPv6 on the gateway nodes. Our conditional access policies do not support IPv6. Ambari Authentication is failing with conditional access failures.\nWe have other subnets where we need to create new HDI clusters. How can we do this. Do we open a ticket to disable IP v6 after created a new cluster everytime. Please let us know if there is an alternative.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp07-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",need IP v6 disabled on Gateway nodes,9.173869097,Root Cause : HDInsight Service\Documentation bug,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Unable to log into cluster created in newer vnets.,Due to changes  that use ipv6 addresses for vnet traffic.,"Due to changes  that use ipv6 addresses for vnet traffic.Resolution: The solution was to delete service endpoint ( Microsoft.AzureActiveDirectory ) from VNET , so you will see outbound ip roll back to ipv4 instead of ipv6 and whitelist the ipv4 addresses to the gateways.To obtain the IP address of the gateways (there are 2, 1 for HTTPS and one for SSH) the easiest way to do it is to ping the FQDN addresses.Ping rxp07-prod-hdi-rtl.azurehdinsight.netPing rxp07-prod-hdi-rtl-ssh.azurehdinsight.net""   (notice the added -ssh)So <clustername>.azurehdinsight.net And <clustername>-ssh.azurehdinsight.net","188,570,106,188,738,000",,,,,,,
1.20052E+14,05:45.6,Not able to bind the same storage account to the newly created cluster ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to bind the cluster with existing storage account \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to bind the cluster with existing storage account ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: WHQ CBM Development\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/35fe533f-162d-410a-999e-23da73fdd173/resourceGroups/Mosaic-CHINA-DEV-Primary/providers/Microsoft.HDInsight/clusters/hdincldpdevchina03\n- Location: eastasia\n- Location: East {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to bind the same storage account to the newly created cluster ,0.207736616,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Cluster provisioning failed and reported STS would not start.  While investigating, noticed Hive metastore service was not up",Tried to create an HDI 4.0 (Hive 3) with an HDI 3.6 (Hive 1.2.1) metastore that had not been upgraded,Created a backup of the 3.6 metastore and upgraded it to Hive 3,,,,,,,,
1.20052E+14,46:17.5,  HDInsight cluster hdi-466ab726-61be-4677-adbb-1fdd8ab94c4d cannot be deleted; additional problems highlighted in the 'Details section',"Question: What time did the problem begin?\nAnswer: {Namepii}, May 18, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Experiencing several problems in this subscription. Besides already described HDInsight cluster:\n\n- Virtual Machine spm-common-proxy cannot start\n- Storage accounts bound to private link cannot be reached\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Experiencing several problems in this subscription. Besides already described HDInsight cluster:\n\n- Virtual Machine spm-common-proxy cannot start\n- Storage accounts bound to private link cannot be reached;\n\n- ProblemStartTime: 05/17/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/8ef663c0-f57d-4a86-89b9-79254dda629a/resourceGroups/spm-dev/providers/Microsoft.HDInsight/clusters/hdi-466ab726-61be-4677-adbb-1fdd8ab94c4d\n- Location: centralindia\n- Location: Central India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",  HDInsight cluster hdi-466ab726-61be-4677-adbb-1fdd8ab94c4d cannot be deleted; additional problems highlighted in the 'Details section',0.014959423,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Delete HDInsight cluster,Experiencing several problems in this subscription. Besides already described HDInsight cluster: - Virtual machine spm-common-proxy cannot start- Storage accounts bound to private link cannot be reached,"Summary of Impact: Between 12:41 UTC on 18 May 2020 and 08:30 UTC on 19 May 2020, customers may have experienced difficulties connecting to resources hosted in Central India. A number of Storage scale units had gone offline, impacting Virtual Machines and other Azure services with dependencies on these.Preliminary Root Cause: A power issue with the regional utility power provider caused a Central India datacenter to transfer to generator power. This transition to generators worked as designed for all infrastructure systems except for a number of air handling units in two of the data centers ' internal zones (Colos). As a result, internal temperatures for these two Colos rose above operational thresholds, alerts were triggered, and automation began shutting down network and storage resources to protect data.Mitigation: Engineers undertook various workstreams to bring back connectivity. First, technicians isolated the unhealthy air handling units and restored power, returning temperatures to operational levels.  Once temperatures were below the threshold, technicians started to physically recover Storage scale units. With Storage and Networking restored, dependent Compute scale units began to recover. As Compute nodes became healthy, reliant Virtual Machines and other dependent Azure services also recovered.Next Steps: A formal root cause analysis (RCA) for this incident will be published within three business days – in Azure Service Health (within the management portal) for impacted customers as well as on the Azure status page. Stay informed about Azure service issues by creating custom service health alerts: https://aka.ms/ash-videos for video tutorials and https://aka.ms/ash-alerts for how-to documentation.","Summary of Impact: Between 12:41 UTC on 18 May 2020 and 08:30 UTC on 19 May 2020, customers may have experienced difficulties connecting to resources hosted in Central India. A number of Storage scale units had gone offline, impacting Virtual Machines and other Azure services with dependencies on these.Preliminary Root Cause: A power issue with the regional utility power provider caused a Central India datacenter to transfer to generator power. This transition to generators worked as designed for all infrastructure systems except for a number of air handling units in two of the data centers ' internal zones (Colos). As a result, internal temperatures for these two Colos rose above operational thresholds, alerts were triggered, and automation began shutting down network and storage resources to protect data.Mitigation: Engineers undertook various workstreams to bring back connectivity. First, technicians isolated the unhealthy air handling units and restored power, returning temperatures to operational levels.  Once temperatures were below the threshold, technicians started to physically recover Storage scale units. With Storage and Networking restored, dependent Compute scale units began to recover. As Compute nodes became healthy, reliant Virtual Machines and other dependent Azure services also recovered.Next Steps: A formal root cause analysis (RCA) for this incident will be published within three business days – in Azure Service Health (within the management portal) for impacted customers as well as on the Azure status page. Stay informed about Azure service issues by creating custom service health alerts: https://aka.ms/ash-videos for video tutorials and https://aka.ms/ash-alerts for how-to documentation.",188579684,,,,,,,
1.20052E+14,01:11.3,Hive jobs running indefinitely,"Question: What time did the problem begin?\nAnswer: Sun, May 17, 2020, 5:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: create table pc_aar.tda_call_center_growth as \nselect a.fsc_week, a.generation, a.calls, a.call_wrp,a.call_ps,a.call_st,\n({alphanumericpii}) as `% call_wrp`,\n({alphanumericpii}) as `% calls`,\n({alphanumericpii}) as `% call_ps`,\n({alphanumericpii}) as `% call_st`\n        from pc_aar.tda_call_center_cw a left join pc_aar.tda_call_center_lw b \n        on a.prev_week=b.fsc_week and a.generation = b.generation\n\nQuestion: Hive query explain plan if available\nAnswer: This is just one of the problematic queries. Hive queries on Hive view and also Hive jobs on Azure Data Factory are running indefinitely, not failing.  There is one job that is executing for 36 hours.\n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: No error text, jobs not failing or erroring.\n\nNot sure if it's related but one job failed with this error:\n\n'Operation on target datpc_dynamic_partition failed: Hadoop job failed with exit code '0'. See 'wasbs://adfjobs@dathdiblob01.blob.core.windows.net/HiveQueryJobs/6b11679f-d9ea-4a18-995a-0a6bd2989cb3/18_05_2020_07_12_44_677/Status/stderr' for more details. Alternatively, open the Ambari UI on the HDI cluster and find the logs for the job '{alphanumericpii}'. Contact HDInsight team for further support.'\n\n\nOther jobs are still running.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - create table pc_aar.tda_call_center_growth as \nselect a.fsc_week, a.generation, a.calls, a.call_wrp,a.call_ps,a.call_st,\n({alphanumericpii}) as `% call_wrp`,\n({alphanumericpii}) as `% calls`,\n({alphanumericpii}) as `% call_ps`,\n({alphanumericpii}) as `% call_st`\n        from pc_aar.tda_call_center_cw a left join pc_aar.tda_call_center_lw b \n        on a.prev_week=b.fsc_week and a.generation = b.generation;\nHive query explain plan if available - This is just one of the problematic queries. Hive queries on Hive view and also Hive jobs on Azure Data Factory are running indefinitely, not failing.  There is one job that is executing for 36 hours.;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - No error text, jobs not failing or erroring.\n\nNot sure if it's related but one job failed with this error:\n\n'Operation on target datpc_dynamic_partition failed: Hadoop job failed with exit code '0'. See 'wasbs://adfjobs@dathdiblob01.blob.core.windows.net/HiveQueryJobs/6b11679f-d9ea-4a18-995a-0a6bd2989cb3/18_05_2020_07_12_44_677/Status/stderr' for more details. Alternatively, open the Ambari UI on the HDI cluster and find the logs for the job '{alphanumericpii}'. Contact HDInsight team for further support.'\n\n\nOther jobs are still running.\n;\n\n- ProblemStartTime: 05/17/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SleepNumber_QA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/66a4623b-3f8e-4b88-ac27-863f74a4223c/resourceGroups/rg-dat-hdinsight/providers/Microsoft.HDInsight/clusters/dathdicluster01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive jobs running indefinitely,0.038874328,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Hive jobs running indefinitely,"The problem was with YARN Queue Manager, it was accepting jobs but not allocating resources to them","realocated more memory to it, and then SSH-ing into the cluster for clearing accepted and pending jobs.",,,,,,,,
1.20052E+14,20:14.7,"test ticket, please close","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: NA\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Python;\nSpark configuration details - NA;\nAdditional details about the issue - NA;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","test ticket, please close",0.04135802,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Test Ticket,Test Ticket,Test Ticket,,,,,,,,
1.20052E+14,45:20.7,Not able to delete the cluster again.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to delete  hdinsight cluster 'prestohdinsightcluster'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to delete  hdinsight cluster 'prestohdinsightcluster';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: msteams.nonprod.pub.msft.telemetry.backfill\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/989cea72-5d17-4de2-8d41-6a426409d315/resourceGroups/presto-poc/providers/Microsoft.HDInsight/clusters/prestohdinsightcluster\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to delete the cluster again.,0.063498329,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to delete an HDI cluster in the portal,"{""code"":""Conflict"",""message"":""Exception of type 'Microsoft.ClusterServices.RDFEProvider.ResourceTypes.Models.RdfeResourceHandlerException' was thrown.""}",Escalated to the product group to delete the cluster.,188836783,,,,,,,
1.20052E+14,08:48.3,one data node is dead,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: wn1 is seems to be down, I tried with restart but didnt work\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - wn1 is seems to be down, I tried with restart but didnt work;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EMEA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/31b2ba9a-0826-4a10-ab4e-f239517ec26f/resourceGroups/Mosaic-EMEA-Prod-Primary/providers/Microsoft.HDInsight/clusters/omweeitcbmprodemea01\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",one data node is dead,0.113456881,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,one data node is dead,headnode was downed and worker node was not responded,"Scaling cluster downed and up, and rebooted hn0, hn1 and worker node, and the components ",,,,,,,,
1.20052E+14,11:49.2,HDI deploy with Azure CLI and Gen2 ADLS,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: sigitestspark\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: As per the previous support case {Phonenumberpii}, Azure CLI is the ONLY automated option for deploying an Azure HDInsight cluster. Can you please assist us with migrating the attached Powershell script from using Azure Powershell modules to using Azure CLI instead? We are having trouble converting line 90 (New-AzHDInsightClusterConfig) so it is accepted by line 107 (az hdinsight create). Our configuration in the New-AzHDInsightClusterConfig command contains different customized values for the Ambari configuration our SQL external HIVE metastore and we would like to keep these customizations so they're applied during cluster creation.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - sigitestspark;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - As per the previous support case {Phonenumberpii}, Azure CLI is the ONLY automated option for deploying an Azure HDInsight cluster. Can you please assist us with migrating the attached Powershell script from using Azure Powershell modules to using Azure CLI instead? We are having trouble converting line 90 (New-AzHDInsightClusterConfig) so it is accepted by line 107 (az hdinsight create). Our configuration in the New-AzHDInsightClusterConfig command contains different customized values for the Ambari configuration our SQL external HIVE metastore and we would like to keep these customizations so they're applied during cluster creation.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGIhdisandbox\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI deploy with Azure CLI and Gen2 ADLS,7.020877401,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,HDI deploy with Azure CLI and Gen2 ADLS,NA,Provided the ARM template with the customizations included as requested by customer.,,,,,,,,
1.20052E+14,24:45.5,Zookeeper instability prevent tables to be created in HBASE,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Our spark application failed to write to HBASE due to instability in zookeeper. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Our spark application failed to write to HBASE due to instability in zookeeper. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e9e4e73-7585-4c5c-8618-c69e755a12d3/resourceGroups/3uk-paas/providers/Microsoft.HDInsight/clusters/hbase-cluster3uk-e2e\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zookeeper instability prevent tables to be created in HBASE,55.00941596,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Service unhealthy\Hbase,Unable to run reach hbase cluster from spark cluster.,Versions of hbase was not compatible,Created shaded jar with the correct version,189694038,,,,,,,
1.20052E+14,50:20.5,Unable to login Ambari Portal,"Question: What time did the problem begin?\nAnswer: Fri, May 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: restarted ambari-server service\n\nQuestion: Additional details about the issue\nAnswer: Gettign below error while accessing the amabari portal:\n\nError:\n502 - Web server received an invalid response while acting as a gateway or proxy server.\nThere is a problem with the page you are looking for, and it cannot be displayed. When the Web server (while acting as a gateway or proxy) contacted the upstream content server, it received an invalid response from the content server.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - restarted ambari-server service;\nAdditional details about the issue - Gettign below error while accessing the amabari portal:\n\nError:\n502 - Web server received an invalid response while acting as a gateway or proxy server.\nThere is a problem with the page you are looking for, and it cannot be displayed. When the Web server (while acting as a gateway or proxy) contacted the upstream content server, it received an invalid response from the content server.;\n\n- ProblemStartTime: 05/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/71aacd49-ff43-4567-9a08-b93980f13225/resourceGroups/Common01-PROD/providers/Microsoft.HDInsight/clusters/ana02spark36datahubpr01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to login Ambari Portal,0.115573463,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to login Ambari Portal,Bad Gateway 502.It usually related with the active headnodehost didn’t run the ambari-server correctly and the 8080 port is not listening,Use the below commands as a fix for the clusterps -ef|grep ambari-server  to check if multiple ambari-server processessudo systemctl stop ambari-serversudo systemctl start ambari-server,,,,,,,,
1.20052E+14,50:22.6,Getting error while running oozie job,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Oozie\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Trying to run oozie job. The same job worked in different cluster but that cluster crashed and we have a ticket opened for the same ('{Phonenumberpii}')\n\nI create a new cluster and while running the job getting below error\n\n'errorMessage': '{ALPHANUMERICPII}: Cannot initialize {Namepii}. Please check your configuration for mapreduce.framework.name and the correspond server addresses.'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Oozie;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Trying to run oozie job. The same job worked in different cluster but that cluster crashed and we have a ticket opened for the same ('{Phonenumberpii}')\n\nI create a new cluster and while running the job getting below error\n\n'errorMessage': '{ALPHANUMERICPII}: Cannot initialize {Namepii}. Please check your configuration for mapreduce.framework.name and the correspond server addresses.';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: dsar-rqns\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/352ff61a-3020-4199-af5a-24b34eaaf95a/resourceGroups/opsihdiperf2/providers/Microsoft.HDInsight/clusters/optum-hdinsight1-opsi-perf1\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting error while running oozie job,0.028812636,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie",Getting error while running oozie job,Getting error while running oozie job,"Found that customer passed storage account name wrongly on Oozie configuration and as suggested, customer fixed the same and job is running fine now",,,,,,,,
1.20052E+14,04:16.5,Use empty edge nodes on Apache Hadoop clusters in HDInsight,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 19, 2020, 1:00 PM {NAMEPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: We would like to use empty edge nodes on {Namepii} Hadoop clusters in HDInsight as noted here:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node\n\nWe need to understqand the resources that are going to be built when we deploy this template as it looks like it will build a few resources that we dont need like a Gateway,Vnet and Public IP address.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - We would like to use empty edge nodes on {Namepii} Hadoop clusters in HDInsight as noted here:\nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apps-use-edge-node\n\nWe need to understqand the resources that are going to be built when we deploy this template as it looks like it will build a few resources that we dont need like a Gateway,Vnet and Public IP address.;\n\n- ProblemStartTime: 05/19/2020 20:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Use empty edge nodes on Apache Hadoop clusters in HDInsight,0.682100885,Root Cause : HDInsight Service\Azure portal related issues,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Use empty edge nodes on Apache Hadoop clusters in HDInsight,Use empty edge nodes on Apache Hadoop clusters in HDInsight,"Provisioning failed thru steps/template shared on Azure documentation, Shared alternate steps with customer to provision edgenode and it completed successfully. Customer confirmed to close the case.",,,,,,,,
1.20052E+14,14:48.4,Workernode 24 is down in dev-offprev-hdispark-cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Workernode 24 is down in dev-offprev-hdispark-cluster. I have attached the error screenshot. Please resolve this issue ASAP and also provide the root cause since this issue is happening repeatedly. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Workernode 24 is down in dev-offprev-hdispark-cluster. I have attached the error screenshot. Please resolve this issue ASAP and also provide the root cause since this issue is happening repeatedly. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Workernode 24 is down in dev-offprev-hdispark-cluster,0.119798782,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Workernode 24 is down in dev-offprev-hdispark-cluster,Workernode 24 is down in dev-offprev-hdispark-cluster,"Support checked and found ""no space found on the device"" messages on the logs. On customer confirmation, support restarted the workernode and connectivity is restored. Advised customer to verify and add the configs as on the link: https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/hdinsight-troubleshoot-out-disk-space",,,,,,,,
1.20052E+14,13:22.1,ahd649dj - edge node ed10-ahd649 is getting rebooted everyday,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {ALPHANUMERICPII} edge node ed10-ahd649.azfrk.com {Ipaddresspii} is getting rebooted everyday.\n\n(base) {AlphanumericPII}# uptime\n03:31:06 up  1:47,  1 user,  load average: 0.58, 0.82, 0.70\n(base) {AlphanumericPII}#\n\nreboot   system boot  4.15.0-1082-azur Wed May 20 01:43   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 19 00:40   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 18 00:09   still running\nreboot   system boot  4.15.0-1082-azur Sun May 17 00:23   still running\nreboot   system boot  4.15.0-1082-azur Fri May 15 23:29   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 14 23:24   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 14 00:49   still running\nreboot   system boot  4.15.0-1082-azur Wed May 13 00:58   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 12 01:03   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 11 00:17   still running\nreboot   system boot  4.15.0-1082-azur Sun May 10 00:44   still running\nreboot   system boot  4.15.0-1082-azur Sat May  9 01:30   still running\n\nwtmp begins Fri May  1 01:06:04 2020\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {ALPHANUMERICPII} edge node ed10-ahd649.azfrk.com {Ipaddresspii} is getting rebooted everyday.\n\n(base) {AlphanumericPII}# uptime\n03:31:06 up  1:47,  1 user,  load average: 0.58, 0.82, 0.70\n(base) {AlphanumericPII}#\n\nreboot   system boot  4.15.0-1082-azur Wed May 20 01:43   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 19 00:40   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 18 00:09   still running\nreboot   system boot  4.15.0-1082-azur Sun May 17 00:23   still running\nreboot   system boot  4.15.0-1082-azur Fri May 15 23:29   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 14 23:24   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 14 00:49   still running\nreboot   system boot  4.15.0-1082-azur Wed May 13 00:58   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 12 01:03   still running\nreboot   system boot  4.15.0-1082-azur {Namepii} May 11 00:17   still running\nreboot   system boot  4.15.0-1082-azur Sun May 10 00:44   still running\nreboot   system boot  4.15.0-1082-azur Sat May  9 01:30   still running\n\nwtmp begins Fri May  1 01:06:04 2020\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ahd649dj - edge node ed10-ahd649 is getting rebooted everyday,0.046942824,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,reboot   system boot  4.15.0-1082-azur Wed May 20 01:43   still runningreboot   system boot  4.15.0-1082-azur Tue May 19 00:40   still runningreboot   system boot  4.15.0-1082-azur Mon May 18 00:09   still runningreboot   system boot  4.15.0-1082-azur Sun May 17 00:23   still runningreboot   system boot  4.15.0-1082-azur Fri May 15 23:29   still runningreboot   system boot  4.15.0-1082-azur Thu May 14 23:24   still runningreboot   system boot  4.15.0-1082-azur Thu May 14 00:49   still runningreboot   system boot  4.15.0-1082-azur Wed May 13 00:58   still runningreboot   system boot  4.15.0-1082-azur Tue May 12 01:03   still runningreboot   system boot  4.15.0-1082-azur Mon May 11 00:17   still runningreboot   system boot  4.15.0-1082-azur Sun May 10 00:44   still runningreboot   system boot  4.15.0-1082-azur Sat May  9 01:30   still running,ahd649dj - edge node ed10-ahd649 is getting rebooted everyday,"The evidence shows that the script managed_patching_reboot.sh trigger the VM reboot process, from logs we were able to get the followed information Details 1: Unplanned.ContainerFault.GuestOSCrashRCA details: HyperVEvent""18590*(MSVM_GUEST_CRASH_REPORT); BugCheckCode:()Category: CustomerInitiated  Details 2: CustomerInitiated.ContainerOperation.GuestOsInternalShutdownRCA details: GuestOsInternalShutdown Event 18514Category: Crash The timestamp suggested that some script or interaction triggered the reboot process as ""Unplanned.ContainerFault.GuestOSCrash” which states as customer initiated followed by “CustomerInitiated.ContainerOperation.GuestOsInternalShutdown""",189555191,,,,,,,
1.20052E+14,41:24.3,ahd501dj HDFS alerts on storage usage,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The variance for this alert is {ALPHANUMERICPII} which is 96% of the {ALPHANUMERICPII} average ({ALPHANUMERICPII} is the limit)\n\nThe variance for this alert is {ALPHANUMERICPII} which is 97% of the {ALPHANUMERICPII} average ({ALPHANUMERICPII} is the limit)\n\n{alphanumericpii}$ hdfs dfs -df -h\nFilesystem                                          Size  Used  Available  Use%\nabfs://ahd501@azuscvdls00501.dfs.core.windows.net  8.0 E     0      8.0 E    0%\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - The variance for this alert is {ALPHANUMERICPII} which is 96% of the {ALPHANUMERICPII} average ({ALPHANUMERICPII} is the limit)\n\nThe variance for this alert is {ALPHANUMERICPII} which is 97% of the {ALPHANUMERICPII} average ({ALPHANUMERICPII} is the limit)\n\n{alphanumericpii}$ hdfs dfs -df -h\nFilesystem                                          Size  Used  Available  Use%\nabfs://ahd501@azuscvdls00501.dfs.core.windows.net  8.0 E     0      8.0 E    0%\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ahd501dj HDFS alerts on storage usage,0.094961882,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,HDFS Storage usage alert firing in ambari, HDFS Storage usage increase.,Disabled the alert,,,,,,,,
1.20052E+14,46:36.2,Latency in pulling the metadata for the queries,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n\n\nQuestion: Interactive query explain plan if available\nAnswer: Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n\n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n;\nInteractive query explain plan if available - Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Attached the log for outr for the metadata pull for our queries.  It is consistently {Alphanumericpii} seconds for this query, but this query has a lot of tables in it.  \n\nEven Small {Namepii} like  have just one table and they take 4-5 seconds on the metadata pull for that one table. \nIn both cases, the time spent pulling the metadata is about 10x what it should be.  \n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Latency in pulling the metadata for the queries,16.07778704,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Interactive Query,Latency in pulling  the metadata for the queries,"CBO was trying to  fetch constraints such as PK, FK, UK, NN etc. Also, they are trying to fetch it  multiple times. It is related to https://issues.apache.org/jira/browse/HIVE-22782 which  is still open and even there are duplicate get_table calls which also not yet  fixed in open source.","CBO was trying to  fetch constraints such as PK, FK, UK, NN etc. Also, they are trying to fetch it  multiple times. It is related to https://issues.apache.org/jira/browse/HIVE-22782 which  is still open and even there are duplicate get_table calls which also not yet  fixed in open source.1. Enable  CachedStore hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.cache.CachedStore2. Convert  both the Virtual Views to Materialized Views.3. We can  also try with hive.cbo.enable=false. It speed up compilation but probably  slow down the execution",189253326,,,,,,,
1.20052E+14,51:56.5,Ranger permission issues . User is  not able to view the permitted tables through beeline ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: No\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Ranger permkission issues.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - No;\nDoes the user have proper permission on the target location recursively? - Yes;\nAdditional details about the issue - Ranger permkission issues.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps024llapfdsbwus401\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ranger permission issues . User is  not able to view the permitted tables through beeline ,0.023084404,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Enforcement,Ranger permission  issues,User is not able to view the permitted tables through beeline,"Please remove  ""soi-adf-ncap"" from ""Exclude from Allow Conditions"" and put it under ""Allow  Conditions"". It worked and able to see the databases",,,,,,,,
1.20052E+14,06:02.6,Hive Interactive is not enabled on HDI4.0,"HIve Server 2 Interactive is not enabled in the {ALPHANUMERICPII} and so spark-sql is not able to pull the databases whatever we have created in the hvie metastore.\n\nand aslo {alphanumericpii} intepreter from zeppelin is not working in the new cluster, guessing it is may be becuase of interactive server is not enabled. Both are pointing to /hive/warehouse folders.\n\nProblem start date and time\n{Namepii}, May 19, 2020, 11:00 PM MST\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 05/20/2020 06:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Interactive is not enabled on HDI4.0,1.770722275,Root Cause : HDInsight Service\By Design\Hadoop - HDP,,Hive Interactive is  not enabled on HDI4.0,Unable to access the Hive tables because of the HDP design,"Explained the  behavior and it’s because of the design from HDP 3.x onwards and recommended to  use HWC. But  can achieve the one you are looking for by following below process but we  recommend to use HiveWarehouse Connector, Tweaking a  configuration would help to list out hive databases (connect/route  to hive metastore) using spark-sql and through Zeppelin (specific  to %livy2.sql). See below, spark-sql  --conf spark.hadoop.metastore.catalog.default=hive In  Zeppelin-livy2 also, you can try update it like below under livy2 interpreter  settings.  livy.spark.hadoop.metastore.catalog.default=hive In order to  access Hive external tables using the Spark API, do not change  metastore.catalog.default from spark to hive in the spark-defaults config file,  but instead override its value at job level, for example:spark-shell --conf  spark.hadoop.metastore.catalog.default=hiveAny other use  case, has not been thoroughly tested and should not be used in  production.If access is  required for both  Managed and External tables on the same application, use  HiveWarehouseConnector, HiveServer2Interactive, and HiveWarehouseSession. This  is suggested for maintainability purposes, it is less prone to mistakes. On the  other hand it is also possible to carefully use HiveWarehouseSession for Managed  tables and SparkSession for External tables.Using the  HiveWarehouseConnector, therefore the HiveWarehoueSession API, is how Hive ACID  tables must be accessed from Spark regardless of the default metastore catalog  value.The Spark API,  will access only the catalog that it has configured as per the property  metastore.catalog.default in /etc/spark2/conf/hive-site.xml, by  default:<property>       <name>metastore.catalog.default</name>       <value>spark</value></property> Spark: As you  probably understood, the main changes introduced in Spark influence the way we  can access Hive data. First, Hive and Spark will now have independent catalogs  that allow you to access table data or for example, register a temporary table.  Ensure your Spark configuration is pointing to the correct catalog before  deploying your applications. The setting is controlled by the property  metastore.catalog.default , and can be set to “hive” or “spark”. Hive Warehouse  Connector: The other big  change, is the fact that the SparkSQL interface is not able to read ACID table  v2. For this task, you can rely on a new Spark interface to Hive Tables called  “Hive Warehouse Connector” (from now on HWC) that can work seamlessly with  SparkSQL. The HWC comes  with some limitations:Hive Server  Interactive is needed;the  Spark-thrift server is not supported;can be used  only for ORC tables. But,  please make sure about your use case and tweak or use these accordingly. As I  stated in my previous email, we would not recommend to use Hive Interactive and  Spark services in the same cluster. If you want it both services, please create  a distinct clusters then integrate HDI Spark type and HDI Hive with  HWC. Here  is the link for the same- https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector",,,,,,,,
1.20052E+14,42:22.9,Altering PK Constraint - Phoenix Table,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 21, 2020, 2:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: We need an expert advice on this below:\n\nThis table is huge table and has 470+ Millions or rows and has 730 days TTL.\n\nTable Name : LOCATION_DETAIL_X\nPrimaryKey : {Alphanumericpii}   - Both are bigInt type\n\nScenarios :\n\n{Alphanumericpii} a new column (bigInt type) and add that part of PrimaryKey combination.\na.This will be a new column like an auto generated field \n\n{Alphanumericpii} an existing column (bigInt type) to the Primary Key combination.\na.This will be X7 – bigInt  (Existing column)\nb.This column has null values now, So we need to replace the null values with a default value, and the same will be handled in code as well.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - {Namepii};\nAdditional details about the issue - We need an expert advice on this below:\n\nThis table is huge table and has 470+ Millions or rows and has 730 days TTL.\n\nTable Name : LOCATION_DETAIL_X\nPrimaryKey : {Alphanumericpii}   - Both are bigInt type\n\nScenarios :\n\n{Alphanumericpii} a new column (bigInt type) and add that part of PrimaryKey combination.\na.This will be a new column like an auto generated field \n\n{Alphanumericpii} an existing column (bigInt type) to the Primary Key combination.\na.This will be X7 – bigInt  (Existing column)\nb.This column has null values now, So we need to replace the null values with a default value, and the same will be handled in code as well.\n;\n\n- ProblemStartTime: 05/21/2020 08:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT QA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cf1875c-b039-4bdc-b79d-68639d76f700/resourceGroups/qa-hlt-cat-rg-00/providers/Microsoft.HDInsight/clusters/qa-pmd-mh-hlt-usnc-hbase-01\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Altering PK Constraint - Phoenix Table,0.098346217,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,Altering PK Constraint - Phoenix Table,Altering PK Constraint - Phoenix Table,"Worked with customer and Engaged product group on this and Product group suggested –  Requested customer to test before moving to production -Add a new column as primary key in the table.ALTER TABLE ""<table name>"" ADD <column name> <data type> primary key;",189221104,,,,,,,
1.20052E+14,48:24.4,Not able to access the server.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 21, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, May 21, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 1. we are not able to open the ambari and yarn. getting the error.\n2. i have attached screenshort for the error.\n3. I have seen Resource health from last month its getting health event(s). \n4. may i know the resion why it is getting health event(s)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - 1. we are not able to open the ambari and yarn. getting the error.\n2. i have attached screenshort for the error.\n3. I have seen Resource health from last month its getting health event(s). \n4. may i know the resion why it is getting health event(s);\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 04/20/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}-Embibe\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/435eb2d9-454e-43d7-bef5-36be114edbb4/resourceGroups/rg-tech-vnet/providers/Microsoft.HDInsight/clusters/user-profiling-research-temp\n- Location: centralindia\n- Location: Central India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to access the server.,0.154706574,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Getting 502 bad gateway error while accessing Ambari,HTTP 502 status code means that Ambari server is not running correctly on the active headnode   ,Restarted headnodes and zookeeper nodes,188978652,,,,,,,
1.20052E+14,15:03.4,Permission error (hive user) trying to create table from Spark Dataframe. Config option “Run as end user instead of Hive user” is set,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Python\n\nQuestion: Spark configuration details\nAnswer: {AlphanumericPII}, 'browser_fingerprint').option('path', 'wasbs://altdata-tables@xpmfldata.blob.core.windows.net/fl_altdata_partial').saveAsTable('fl_altdata_partial')\n\nQuestion: Additional details about the issue\nAnswer: 20/05/21 13:55:50 ERROR Hive: MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='wasbs://altdata-tables@xpmfldata.blob.core.windows.net/fl_altdata_partial/date=2017-09-01':sshuser:supergroup:drwxr-xr-x)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Python;\nSpark configuration details - {AlphanumericPII}, 'browser_fingerprint').option('path', 'wasbs://altdata-tables@xpmfldata.blob.core.windows.net/fl_altdata_partial').saveAsTable('fl_altdata_partial');\nAdditional details about the issue - 20/05/21 13:55:50 ERROR Hive: MetaException(message:java.security.AccessControlException: Permission denied: user=hive, path='wasbs://altdata-tables@xpmfldata.blob.core.windows.net/fl_altdata_partial/date=2017-09-01':sshuser:supergroup:drwxr-xr-x);\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Sbox-{Namepii}-Sub\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5177e132-5768-4b39-a1fa-283aa0025ab2/resourceGroups/xpm-hdi-rg/providers/Microsoft.HDInsight/clusters/xpm-spark-hdi2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Permission error (hive user) trying to create table from Spark Dataframe. Config option “Run as end user instead of Hive user” is set,0.335643262,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,Permission error (hive user) trying to create table from Spark Dataframe. Config option “Run as end user instead of Hive user” is set.,NA," The table location is owned by sshuser so hive cannot write to it.-->Change permissions on the table location to 777 -->or chown to hivePlease disable using Run as end user, you will have to change the permissions to 777 so any user can write to the hive table",,,,,,,,
1.20052E+14,20:32.0,hn0 cannot start services,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 21, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: reboot of hn0\n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii}, the service namenode was down. we try to restart this service but was unsuccessfull. So we try to reboot all HN0 nut now all services are down. Can you help us?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - reboot of hn0;\nAdditional details about the issue - Hi {Namepii}, the service namenode was down. we try to restart this service but was unsuccessfull. So we try to reboot all HN0 nut now all services are down. Can you help us?;\n\n- ProblemStartTime: 05/21/2020 03:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Avanade - SIM Frontend\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7f6c65a5-ebfd-48d2-80bf-f6f2cdbaa32b/resourceGroups/az-rg-analytics-use-prd/providers/Microsoft.HDInsight/clusters/azhdisimuseprd\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hn0 cannot start services,0.031910095,Root Cause : HDInsight Service\User Environment/Platforms\Non-Windows platforms issue,Routing Azure HDInsight V5\Service unhealthy\Spark,Services were stopped after a reboot of hn0. as client ,Hard restart on head node 0,"After checking with the client, it was confirmed that the cluster recovered from the failed state, after restarting it.Sometimes it takes to restore services after a restart takes time, especially if the services were running on hn1.",,,,,,,,
1.20052E+14,18:59.6,Unavailable to SSH into the cluster : Gateway Connectivity Failure,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 18, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Not able to SSH into the cluster using 'ssh {emailpii}@dpfsparkcluster2-ssh.azurehdinsight.net'. \n\nNot able to open Ambari UI.\n\nHDInsight shows Unavailable : Gateway Connectivity Failure\nAt Monday, May 18, 2020, 11:51:03 PM EDT, the Azure monitoring system received the following information regarding your HDInsight clusters:\nExternal connectivity to your HDInsight cluster is currently not working. If you have configured your cluster to block external connections, you can ignore this.\nRecommended Steps\nCheck back here for status updates. \nIf you are experiencing problems you believe are caused by Azure, contact support .\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Not able to SSH into the cluster using 'ssh {emailpii}@dpfsparkcluster2-ssh.azurehdinsight.net'. \n\nNot able to open Ambari UI.\n\nHDInsight shows Unavailable : Gateway Connectivity Failure\nAt Monday, May 18, 2020, 11:51:03 PM EDT, the Azure monitoring system received the following information regarding your HDInsight clusters:\nExternal connectivity to your HDInsight cluster is currently not working. If you have configured your cluster to block external connections, you can ignore this.\nRecommended Steps\nCheck back here for status updates. \nIf you are experiencing problems you believe are caused by Azure, contact support .;\n\n- ProblemStartTime: 05/18/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Platform Fabricator\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: RHC\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Service Health\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: westus\n- ResourceUri: /subscriptions/ec85c503-a7b2-4eb3-846e-c923bc79f643/resourceGroups/dv-us-test-infra/providers/Microsoft.HDInsight/clusters/dpfsparkcluster2\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unavailable to SSH into the cluster : Gateway Connectivity Failure,0.13170618,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Unavailable to SSH into the cluster : Gateway Connectivity Failure,"NSG Rules are blocking inbound/outbound traffic as shown below: {""ResponseStatusCode"":400,""Errors"":[{""ErrorCode"":400,""HdInsightErrorCode"":2,""ErrorMessage"":""The security rules in the Network Security Group '/subscriptions/ec85c503-a7b2-4eb3-846e-c923bc79f643/resourceGroups/dv-us-test-infra/providers/Microsoft.Network/networkSecurityGroups/dv-us-testing-infra-private-allow-ingress' configured with subnet '/subscriptions/ec85c503-a7b2-4eb3-846e-c923bc79f643/resourceGroups/dv-us-test-infra/providers/Microsoft.Network/virtualNetworks/dv-us-testing-infra/subnets/dv-us-subnet-1' does not allow required inbound and/or outbound",Adding a security rule that unblocked ports 22 and 443.,,,,,,,,
1.20052E+14,54:15.5,Alerts on Different UIs,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: We don’t use the UIs like JobHistory UI, Data Node Web UI, JMX and after checking the logs on different instances I see that below error. I am trying to see whether we can disable these UI and enable back when we want to use it in the future. \n\nLogs :\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n\n\nQuestion: Additional details about the issue\nAnswer: We don’t use the UIs like JobHistory UI, Data Node Web UI, JMX and after checking the logs on different instances I see that below error. I am trying to see whether we can disable these UI and enable back when we want to use it in the future. \n\nLogs :\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - We don’t use the UIs like JobHistory UI, Data Node Web UI, JMX and after checking the logs on different instances I see that below error. I am trying to see whether we can disable these UI and enable back when we want to use it in the future. \n\nLogs :\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n;\nAdditional details about the issue - We don’t use the UIs like JobHistory UI, Data Node Web UI, JMX and after checking the logs on different instances I see that below error. I am trying to see whether we can disable these UI and enable back when we want to use it in the future. \n\nLogs :\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n2020-05-21 {Alphanumericpii} WARN  {AlphanumericPII} - User ambari-qa is unauthorized to access the page /jmx.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHSP96ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Alerts on Different UIs,0.07093206,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Alerts on Different UIs,Alerts on Different UIs,Worked with customer and validated that there was no Ambari alert at the time notified on log Analytics alert. Customer told that he would work with his backend team to validate the queries and fix the same.,,,,,,,,
1.20052E+14,29:33.2,Unable to access ambari UI.,"Question: What time did the problem begin?\nAnswer: Sun, May 17, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Load balancer URL doesnt work however if i replace URL with load balancer IP address then it loads up just fine.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Load balancer URL doesnt work however if i replace URL with load balancer IP address then it loads up just fine.;\n\n- ProblemStartTime: 05/17/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp07-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access ambari UI.,0.026166667,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to access ambari UI,Unable to access ambari UI,Customer observed inconsistent network connectivity behavior during the issue and resolved after sometime which mitigated access issues for customer. Customer agreed to close the case.,,,,,,,,
1.20052E+14,24:07.3,Internal server error occurred while processing the request. Please retry the request or contact support.,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 21, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.;\n\n- ProblemStartTime: 05/21/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: msteams.nonprod.pub.msft.telemetry.backfill\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/989cea72-5d17-4de2-8d41-6a426409d315/resourceGroups/hdi-drill-proto/providers/Microsoft.HDInsight/clusters/hdi-drill-proto-wus2\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Internal server error occurred while processing the request. Please retry the request or contact support.,0.133839689,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster creation fail,NSG hdi-drill-proto-nsg the IP management address is not been added to set the inbound rule for the HDI cluster,"Add this hdi IP’s in Inbound rule.For more info please refer to - https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses Also, please check if you have enabled service end point in Vnet hdi-drill-proto-wus2-vnet for storage and SQL as shown in snip.Please check notes for more info",,,,,,,,
1.20052E+14,45:50.8, Spark on Hive config is not enforcing Ranger permissions while trying to access a hive table from spark shell,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 21, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Do you see an audit entry for access denied?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user have proper permission on the target location recursively?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We are trying to enforce a Shared  metastore between Hive and Spark, by changing the property metastore.catalog.default to hive in ESP Spark cluster , howevar while trying to access spark-shell , a user can access all the data bases/tables (external tables) though user not having any permissions in Ranger .\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDo you see an audit entry for access denied? - Other, don't know or not applicable;\nDoes the user have proper permission on the target location recursively? - Other, don't know or not applicable;\nAdditional details about the issue - We are trying to enforce a Shared  metastore between Hive and Spark, by changing the property metastore.catalog.default to hive in ESP Spark cluster , howevar while trying to access spark-shell , a user can access all the data bases/tables (external tables) though user not having any permissions in Ranger .;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/20/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n", Spark on Hive config is not enforcing Ranger permissions while trying to access a hive table from spark shell,0.092467769,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Authorization Failures\Ranger Policy Enforcement,Unable to honor Ranger policies when using  --conf spark.hadoop.metastore.catalog.default=hive,Spark on Hive config  is not enforcing Ranger permissions while trying to access a hive table from  spark shell,"I do see that you  achieved accessing the hive tables by updating the ""metastore.catalog.default""  (default set to spark"") to hive but not honor(s) the Ranger polocies. We would  recommend you to use HiveWarehouseConnector (HWC) to achieve it. In order to access Hive  external tables using the Spark API, do not change metastore.catalog.default  from spark to hive in the spark-defaults config file, but instead override its  value at job level, for example: spark-shell --conf  spark.hadoop.metastore.catalog.default=hive If access is required for  both  Managed and External tables on the  same application, use HiveWarehouseConnector, HiveServer2Interactive, and  HiveWarehouseSession. This is suggested for maintainability purposes, it is less  prone to mistakes. On the other hand it is also possible to carefully use  HiveWarehouseSession for Managed tables and SparkSession for External  tables.Using the  HiveWarehouseConnector, therefore the HiveWarehoueSession API, is how Hive ACID  tables must be accessed from Spark regardless of the default metastore catalog  value. We recommend you to use the  HWC and which honor(s) the Ranger policies.  The HWC comes with some  limitations:Hive Server Interactive is  needed;the Spark-thrift server is  not supported;can be used only for ORC  tables. We would not recommend to use  Hive Interactive and Spark services in the same cluster (in your case, Spark  type cluster). If you want to use both services, please create distinct clusters  then integrate HDI Spark type and HDI Hive with HWC. Here is the link for the  same- https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector",,,,,,,,
1.20052E+14,31:31.4,hdinsightwatchdog stopping YARN Services,"Question: What time did the problem begin?\nAnswer: Sat, May 23, 2020, 4:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, May 23, 2020, 5:45 PM GMT+5:30\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: hdinsightwatchdog user restarted the host components and that stopped YARN services (Timeline Server, History Server and {Alphanumericpii} {Namepii} Server) that were manually restarted.\n\nEverytime we started the services hdinsightwatchdog auto-started the host components and that stopped YARN services.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted the services manually.\n\nQuestion: Additional details about the issue\nAnswer: Timeline Server, History Server and {Alphanumericpii} {Namepii} Server were stopped, that stopped the job processing.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - hdinsightwatchdog user restarted the host components and that stopped YARN services (Timeline Server, History Server and {Alphanumericpii} {Namepii} Server) that were manually restarted.\n\nEverytime we started the services hdinsightwatchdog auto-started the host components and that stopped YARN services.;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted the services manually.;\nAdditional details about the issue - Timeline Server, History Server and {Alphanumericpii} {Namepii} Server were stopped, that stopped the job processing.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/23/2020 10:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hdinsightwatchdog stopping YARN Services,10.08630354,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,hdinsightwatchdog stopping YARN Services,hdinsightwatchdog stopping YARN Services,Shared customer with logrotate script to change log rotate schedule on HDInsight zookeeper nodes.,"189,364,288,189,399,000,000,000,000",,,,,,,
1.20053E+14,20:28.1,Dead Data Node,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 25, 2020, 6:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: We received an error that a data node had failed on our cluster.  I tried looking for documentation on how to fix this, restart the node, etc, but I could not find anything. What is the procedure to fix a dead node?\n\n---------- ALERT ---------\nDecommission Status : Normal\nConfigured Capacity: {Puidpii} (392.60 GB)\nDFS Used: {Ssnpii} (619.07 MB)\nNon DFS Used: {Phonenumberpii} (20.14 GB)\nDFS Remaining: {Puidpii} (351.71 GB)\nDFS Used%: 0.15%\nDFS Remaining%: 89.59%\nConfigured {Namepii} Capacity: 0 (0 B)\n{Namepii} Used: 0 (0 B)\n{Namepii} Remaining: 0 (0 B)\n{Namepii} Used%: 100.00%\n{Namepii} Remaining%: 0.00%\nXceivers: 2\nLast contact: {Namepii} May 25 22:19:01 UTC 2020\nLast Block Report: {Namepii} May 25 19:53:52 UTC 2020\nDead datanodes (1):\nName: {Alphanumericpii} (wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net)\nHostname: wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net\nDecommission Status : Normal\nConfigured Capacity: 0 (0 B)\nDFS Used: 0 (0 B)\nNon DFS Used: {Phonenumberpii} (43.72 GB)\nDFS Remaining: 0 (0 B)\nDFS Used%: 100.00%\nDFS Remaining%: 0.00%\nConfigured {Namepii} Capacity: 0 (0 B)\n{Namepii} Used: 0 (0 B)\n{Namepii} Remaining: 0 (0 B)\n{Namepii} Used%: 100.00%\n{Namepii} Remaining%: 0.00%\nXceivers: 0\nLast contact: {Namepii} May 25 21:44:57 UTC 2020\nLast Block Report: {Namepii} May 25 19:35:41 UTC 2020\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None;\nAdditional details about the issue - We received an error that a data node had failed on our cluster.  I tried looking for documentation on how to fix this, restart the node, etc, but I could not find anything. What is the procedure to fix a dead node?\n\n---------- ALERT ---------\nDecommission Status : Normal\nConfigured Capacity: {Puidpii} (392.60 GB)\nDFS Used: {Ssnpii} (619.07 MB)\nNon DFS Used: {Phonenumberpii} (20.14 GB)\nDFS Remaining: {Puidpii} (351.71 GB)\nDFS Used%: 0.15%\nDFS Remaining%: 89.59%\nConfigured {Namepii} Capacity: 0 (0 B)\n{Namepii} Used: 0 (0 B)\n{Namepii} Remaining: 0 (0 B)\n{Namepii} Used%: 100.00%\n{Namepii} Remaining%: 0.00%\nXceivers: 2\nLast contact: {Namepii} May 25 22:19:01 UTC 2020\nLast Block Report: {Namepii} May 25 19:53:52 UTC 2020\nDead datanodes (1):\nName: {Alphanumericpii} (wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net)\nHostname: wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net\nDecommission Status : Normal\nConfigured Capacity: 0 (0 B)\nDFS Used: 0 (0 B)\nNon DFS Used: {Phonenumberpii} (43.72 GB)\nDFS Remaining: 0 (0 B)\nDFS Used%: 100.00%\nDFS Remaining%: 0.00%\nConfigured {Namepii} Capacity: 0 (0 B)\n{Namepii} Used: 0 (0 B)\n{Namepii} Remaining: 0 (0 B)\n{Namepii} Used%: 100.00%\n{Namepii} Remaining%: 0.00%\nXceivers: 0\nLast contact: {Namepii} May 25 21:44:57 UTC 2020\nLast Block Report: {Namepii} May 25 19:35:41 UTC 2020;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/25/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsEuRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi-eu\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Dead Data Node,0.010913741,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Ambari agent  cannot send heartbeat for node : wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net,"Because of high CPU usage on the below node, ambari agent on the node was unable to attain resource to process heatbeat request.wn8-cas-sp.1rfmscas145e5kc4xr2mhmegza.ax.internal.cloudapp.net","Once the CPU utilization is reduced, Ambari agent on the node wn8 was able process heart beat requests. Links to refer: https://docs.microsoft.com/azure/hdinsight/hadoop/apache-ambari-troubleshoot-heartbeat-issues","189,460,562,189,460,000",,,,,,,
1.20053E+14,41:24.2,IO Cache not installed and not an available option in 'Stack and Versions',"Question: What time did the problem begin?\nAnswer: {Namepii}, May 25, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: HNs were rebooted 5 days ago\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Noticed that IO {Namepii} was not installed and I do not see the option to install it in the Stack and Versions panel\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - HNs were rebooted 5 days ago;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Noticed that IO {Namepii} was not installed and I do not see the option to install it in the Stack and Versions panel;\n\n- ProblemStartTime: 05/25/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-STG-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7d6cb240-e4ab-4df6-acbc-6b2fddc8f8ed/resourceGroups/mscosmuse2sephtspipelinesparkrg/providers/Microsoft.HDInsight/clusters/sstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",IO Cache not installed and not an available option in 'Stack and Versions',0.084083589,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,Unable to find IO Cache in the cluster,HDI image did not have IO Cache feature installed,Deploy a new cluster which will have IO Cache installed by default,,,,,,,,
1.20053E+14,52:54.1,Not able to connect to cluster endpoint https://CLUSTERNAME-int.azurehdinsight.net from Head Node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Network\n\nQuestion: Detail of the changes\nAnswer: I have applied an NSG to my vnet. Although I have only blocked Traffic from internet, its still not able to connect to the internal private endpoint of cluster.\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I am trying to execute curl from head node to the cluster endpoint to fetch kafka and ZK hostnames. After applying an NSG to my VNET, the curl command times out. Although I have created rules to deny inbound traffic with 'internet' as source.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Network;\nDetail of the changes - I have applied an NSG to my vnet. Although I have only blocked Traffic from internet, its still not able to connect to the internal private endpoint of cluster.;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I am trying to execute curl from head node to the cluster endpoint to fetch kafka and ZK hostnames. After applying an NSG to my VNET, the curl command times out. Although I have created rules to deny inbound traffic with 'internet' as source.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/PSDK DEV ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/101d561b-b297-42e5-9b2c-63cb1db868a6/resourceGroups/{Namepii}-RTA-{Namepii}-Project/providers/Microsoft.HDInsight/clusters/{Namepii}-RTA-Kafka-Dev\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to connect to cluster endpoint https://CLUSTERNAME-int.azurehdinsight.net from Head Node,0.016005878,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Not able to connect to cluster endpoint https://CLUSTERNAME-int.azurehdinsight.net from Head Node using Curl,Because of Inbound security rules,"Updated the AllowVnetInbound(VNET to VNET) inbound rule priority. Because172.x.x.x is in public internet range and is blocked and with VNET to VNET and call would be first verified against vnet rule and since you added it as ""allowed"" then that stops checks there.",,,,,,,,
1.20053E+14,04:03.9,Hive view is not accessible from Ambari,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 26, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Hive query if applicable\nAnswer: Not applicable\n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hive view is not loading with ATS check fail error\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - Other, don't know or not applicable;\nHive query if applicable - Not applicable;\nDoes the same query work through Beeline from the Headnode? - Other, don't know or not applicable;\nAdditional details about the issue - Hive view is not loading with ATS check fail error;\n\n- ProblemStartTime: 05/26/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Novelis Global\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5f5c5be9-a2dd-49c9-bfa1-77d4db790171/resourceGroups/GlobalDAPPROD/providers/Microsoft.HDInsight/clusters/glprodhdcluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive view is not accessible from Ambari,0.033993951,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Client tool issue\Hive View,Hive view is not accessible from Ambari,The reason Hive View was failing the ATS check was because the Timeline Server and History Server were both stopped on hn1 (the active headnode),We restarted the Timeline Server and History Server services using Ambari and then Hive view was able to load and run a query,,,,,,,,
1.20053E+14,09:08.4,Pipeline run failed. We see very weird error. [CSAT Impacting],"Issue – Pipeline run failed. We see very weird error.\n\nADF - {namepii}-Prod-DataIngestionFramework\nHDI - https://hdi003dlprod001.azurehdinsight.net/\n\n\nProblem start date and time\n{Namepii}, {Namepii} 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/25/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/{namepii}-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi003dlprod001\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Pipeline run failed. We see very weird error. [CSAT Impacting],66.16798167,Root Cause : HDInsight Service\Configuration\Simba Hive ODBC Driver,Routing Azure HDInsight V5\Client tool issue\HDInsight SDK,ADF jobs were failing intermittently,"gateway timeout, ODBC timeout, and DTU was lower","Increased gateway timeout, ODBC timeout and increased DTU",190472679,,,,,,,
1.20053E+14,46:47.1,smbd services confusing the qualys scan. Do you see any potential issue with hdinisght cluster or services if we stop the service?,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 26, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: There is no spark configuration details. Couldn't find the correctly categorize this issue.\n\nQuestion: Additional details about the issue\nAnswer: All the nodes of HDINsight cluster have nmbd and smbd services running and confusing Qualys scan system which due to presence of these services, considers this box a windows box and tries to login using familiar authentication methods to windows and consequently failing. \n\nI am trying to find whether or not there is any potential impact to HDInsight cluster or cluster services if we stopped aforesaid services.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - There is no spark configuration details. Couldn't find the correctly categorize this issue.;\nAdditional details about the issue - All the nodes of HDINsight cluster have nmbd and smbd services running and confusing Qualys scan system which due to presence of these services, considers this box a windows box and tries to login using familiar authentication methods to windows and consequently failing. \n\nI am trying to find whether or not there is any potential impact to HDInsight cluster or cluster services if we stopped aforesaid services.;\n\n- ProblemStartTime: 05/26/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",smbd services confusing the qualys scan. Do you see any potential issue with hdinisght cluster or services if we stop the service?,0.030566367,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,smbd services confusing the qualys scan. Do you see any potential issue with hdinisght cluster or services if we stop the service?,smbd services confusing the qualys scan. Do you see any potential issue with hdinisght cluster or services if we stop the service?,"Support checked with product and confirmed to customer if there is no customer application dependency, these services can be stopped on the cluster(s). Customer confirmed to close the case.",190004115,,,,,,,
1.20053E+14,27:30.5,Worker nodes down,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 26, 2020, 12:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: wn2 and {alphanumericpii} have connectivity issues\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - wn2 and {alphanumericpii} have connectivity issues;\n\n- ProblemStartTime: 05/26/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsEuRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi-eu\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Worker nodes down,1.324773768,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Worker nodes down,Worker nodes down,Rebooting worker nodes mitigated the issue. Root cause and prevention steps will track under 120062124000676,"189,561,984,189,562,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.20053E+14,27:13.6,Cert expiry for App registration that controls access to ADLS Gen1,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 26, 2020, 1:00 PM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: Other, don't know or not applicable\n\nQuestion: Are the accounts federated?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We have a cert that is expiring for the service princiapl that the HDI cluster uses to get access to ADLS {Alphanumericpii}. We have a few questions about how to handle that as last year we had a very long outage for the same event. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - Other, don't know or not applicable;\nAre the accounts federated? - Other, don't know or not applicable;\nDoes the issue affect all users or a few users? - Other, don't know or not applicable;\nDoes the user account work with other Azure services? - Other, don't know or not applicable;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes authentication fail even for the cluster admin account? - Other, don't know or not applicable;\nHave you logged in to Ambari as local admin and verified the users have been synced? - Other, don't know or not applicable;\nAdditional details about the issue - We have a cert that is expiring for the service princiapl that the HDI cluster uses to get access to ADLS {Alphanumericpii}. We have a few questions about how to handle that as last year we had a very long outage for the same event. ;\n\n- ProblemStartTime: 05/26/2020 20:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/AdvancedAnalytics/providers/Microsoft.HDInsight/clusters/AA-ESP-HDISpark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cert expiry for App registration that controls access to ADLS Gen1,0.646497625,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Cert expiry for App registration that controls access to ADLS Gen1,Cert expiry for App registration that controls access to ADLS Gen1,Had call with customer and shared steps to be followed to update the cert. Customer confirmed to close the case.,,,,,,,,
1.20053E+14,50:27.7,Spark Cluster creation failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No, we have not changed anything in script as we are using ARM template provided by MSFT to create cluster.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Spark type {Namepii} creation failed, getting below message \n\n{ALPHANUMERICPII} [hdi-create.sh] hdi creation for cluster {alphanumericpii} is: Running Sleeping for 10 sec Elaspsed Time till now is 2390\n2020-05-26T07:32:19,/cs/admin/hdi-create.sh,m79jq6-infra-200521-creg-dr-hdi,53.100,Running,spark,2,n208876,dr,gm_cloudreg_dr-workload-rg\nFinished[#############################################################]  {Alphanumericpii}%\n{\n  'etag': '\\'{AlphanumericPII}\\'',\n  'lastModified': '{ALPHANUMERICPII}'\n}\n{ALPHANUMERICPII} [hdi-create.sh] ----{Namepii} Creation Completed ----\n{ALPHANUMERICPII} [hdi-create.sh] Clusters created: {alphanumericpii}\n{ALPHANUMERICPII} [hdi-create.sh] Deployments Created: {alphanumericpii}\n{ALPHANUMERICPII} [hdi-create.sh] ----{Namepii} deletion started ----\n{ALPHANUMERICPII} [hdi-create.sh] {Namepii} count to be deleted: 1\n{ALPHANUMERICPII} [hdi-create.sh] {Namepii} deletion flag is set to: n\n{ALPHANUMERICPII} [hdi-create.sh] hdi creation status is not Succeeded.\n{Namepii} May 26 07:32:21 UTC 2020\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No, we have not changed anything in script as we are using ARM template provided by MSFT to create cluster.;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Spark type {Namepii} creation failed, getting below message \n\n{ALPHANUMERICPII} [hdi-create.sh] hdi creation for cluster {alphanumericpii} is: Running Sleeping for 10 sec Elaspsed Time till now is 2390\n2020-05-26T07:32:19,/cs/admin/hdi-create.sh,m79jq6-infra-200521-creg-dr-hdi,53.100,Running,spark,2,n208876,dr,gm_cloudreg_dr-workload-rg\nFinished[#############################################################]  {Alphanumericpii}%\n{\n  'etag': '\\'{AlphanumericPII}\\'',\n  'lastModified': '{ALPHANUMERICPII}'\n}\n{ALPHANUMERICPII} [hdi-create.sh] ----{Namepii} Creation Completed ----\n{ALPHANUMERICPII} [hdi-create.sh] Clusters created: {alphanumericpii}\n{ALPHANUMERICPII} [hdi-create.sh] Deployments Created: {alphanumericpii}\n{ALPHANUMERICPII} [hdi-create.sh] ----{Namepii} deletion started ----\n{ALPHANUMERICPII} [hdi-create.sh] {Namepii} count to be deleted: 1\n{ALPHANUMERICPII} [hdi-create.sh] {Namepii} deletion flag is set to: n\n{ALPHANUMERICPII} [hdi-create.sh] hdi creation status is not Succeeded.\n{Namepii} May 26 07:32:21 UTC 2020\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_dr-workload-rg/providers/Microsoft.HDInsight/clusters/m79jq6-infra-200521-creg-dr-hdi\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Cluster creation failing,0.591322586,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Spark Cluster creation failing,Spark Cluster creation failing,Customer was able to mitigate the STS issue by provisioning cluster with internal metastore and by adding the metastore dependent storage account and updating the hive config after provisioining thru script action.,"189,621,297,189,659,000,000,000,000,000,000,000",,,,,,,
1.20053E+14,18:15.9,HS2I services are down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: HS2 services are not coming after scaling up the cluster.\n\nQuestion: Additional details about the issue\nAnswer: HS2 services are not coming after scaling up the cluster.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - HS2 services are not coming after scaling up the cluster.;\nAdditional details about the issue - HS2 services are not coming after scaling up the cluster.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq052llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HS2I services are down,0.556921969,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,HS2I services are down after scale up,3 nodes had ambari agent issues ,the issue was resolved after fixing the heartbeat issues on three worker nodes then reducing memory per daemon from 100GB to 90GB. ,,,,,,,,
1.20053E+14,08:38.1,QA Cluster not Auto-Scaling - hdi4qarsiapp,"{Namepii}-Scale not triggering in QA cluster since {Alphanumericpii} {Namepii}.\n\nProblem start date and time\nFri, {Namepii} 22, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/21/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",QA Cluster not Auto-Scaling - hdi4qarsiapp,0.034199791,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,QA Cluster not Auto-Scaling - hdi4qarsiapp,"Here is an RCA and the update on the Fix for autoscale. On 24th May, smart probe in hn1 hung. hn1 was the active RM in this period. This is the reason why there are no logs smart probes after 24th May. It started working fine only when smart probes was restarted on 27th May.  Since the smart probes are already restarted and there is no stack trace information, it is not possible for us to determine the exact reason why smart probes failed.  However we have a couple of fixes that would help with this kind of an issue.Timeout for all the REST API calls - adding timeout for all the rest api calls while fetching cluster metrics, so as to stop thread hanging issue.Restart smart probes if smart probes is unresponsive for more than 10 mins.", Fix #1 is already out in production(You would have to drop and recreate) and Fix#2 is set to be deployed in another couple of weeks. Customer has whitelisted PG IP and they have applied the hotfix on all their clusters. ,"189,670,854,190,018,000",,,,,,,
1.20053E+14,32:02.4,Hive ETL taking longer time,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: We are submitting hive queries via tez. It is utilizing YARN to run the resources. We have a IAAS {alphanumericpii} nodes {ALPHANUMERICPII} 80 cores). The job runs\nin 30 mins. Our Hdinsights configuration is (4 region nodes 240 GB 64 cores). The job runs for around 90 mins here. We could see that the subsequent yarn jobs\nget stuck at particular stages before comleting. There is a lot of idle time between the subsequent yarn jobs. On examing yarn logs we could see error\nrelated to timeline server(Internal server error). The errors were related to failure of zookeeper to find /ats-server/hbase/unsecure and erros of timeline server\ngetting timed out. We have attched the properties related to YARN and TEZ which we have set in our cluster.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - We are submitting hive queries via tez. It is utilizing YARN to run the resources. We have a IAAS {alphanumericpii} nodes {ALPHANUMERICPII} 80 cores). The job runs\nin 30 mins. Our Hdinsights configuration is (4 region nodes 240 GB 64 cores). The job runs for around 90 mins here. We could see that the subsequent yarn jobs\nget stuck at particular stages before comleting. There is a lot of idle time between the subsequent yarn jobs. On examing yarn logs we could see error\nrelated to timeline server(Internal server error). The errors were related to failure of zookeeper to find /ats-server/hbase/unsecure and erros of timeline server\ngetting timed out. We have attched the properties related to YARN and TEZ which we have set in our cluster.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Optumera SaaS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/45bec265-bf10-46ff-a564-a416d0f582e6/resourceGroups/rg-opt-prod-hdihbase-wus/providers/Microsoft.HDInsight/clusters/hbasehdi-opt-prod-wus\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive ETL taking longer time,36.20394216,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,120052723001910 - Hive ETL taking longer time,Compaction was failing on all the tables causing the delta files to build up and slowing down the query performance.,"Solution:Customer configured a queue for the compaction jobs called mapreduce. We found that the compaction had been failing on all of the tables due to the wrong queue name.The issue was resolved when we updated the compaction queue name property in the hive-site.xml:  hive.compactor.job.queue=mapreduce More Information:To ensure that you don’t have to manually run the compactions, you can perform the below steps: 1.          Ensure the following properties are set in your hive-site.xml configurations in Ambari. hive.compactor.initiator.on=truehive.compactor.job.queue=mapreducehive.compactor.worker.threads=<# of concurrent compactions wanted> 2.          Update Major/Minor Compaction properties in your existing transactional tables. I have provided one table as an example below: alter table master.store_specific_sku_details compact ‘MAJOR’   WITH OVERWRITE TBLPROPERTIES (""compactorthreshold.hive.compactor.delta.pct.threshold""=""0.5"");  The above will trigger major compaction if the ratio of size of delta files to the size of base files is greater than 50%. This can be decreased to trigger major compaction more often. alter table master.store_specific_sku_details compact ‘MINOR’   WITH OVERWRITE TBLPROPERTIES (""compactorthreshold.hive.compactor.delta.num.threshold""=""4""); The above will trigger minor compaction if there are more than 4 delta directories. This can also be tuned to ensure the delta files do not build up. 3.          Documentation reference: https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions ",190446175,,,,,,,
1.20053E+14,00:32.1,How to update hive from 1.2 to 1.3,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We want to upgrade Hive from 1.2 to 1.3, can you please let us know how we can upgrade Hive in HDInsight cluster?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We want to upgrade Hive from 1.2 to 1.3, can you please let us know how we can upgrade Hive in HDInsight cluster?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to update hive from 1.2 to 1.3,0.119027101,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Customer wanted to update hive from version 1.2 to 1.3 within their HDI cluster.,By design: HDI clusters are managed. ,Informed customer that this is only possible would be to create a new HDI cluster with the upgraded hive version.,,,,,,,,
1.20053E+14,05:05.3,How to enable Impala in HDInsight Cluster?,"We want to install {Namepii} Impala in HDInsight {Namepii}, Please guid us how we can add {Namepii} Impala in existing cluster ?\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to enable Impala in HDInsight Cluster?,0.035876634,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\HDInsight workload monitoring solution,Client wanted to install Apache Impala in a HDInsight cluster.,Client wanted to install Apache Impala in a HDInsight cluster.,"We don't support Apache Impala in our clusters, for similar functionality we offer the HDInsight LLAP Cluster (Apache Hive LLAP) that perform fast, interactive SQL queries at scale over structured or unstructured data.Also, since client has root access, they can install any tool they want in the cluster, but they need to have in mind we cannot help them  to troubleshoot any issue or potential failure with the rest of the components within the cluster.",,,,,,,,
1.20053E+14,16:38.1,PROD: kp02hbaseadfhdiprodusc01 : Region Server is not online/NotServingRegionException in PROD HBase cluster,"Question: What time did the problem begin?\nAnswer: Wed, May 27, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Region Server is not online/NotServingRegionException in PROD HBase cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Region Server is not online/NotServingRegionException in PROD HBase cluster;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/27/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kp02hbaseadfhdiprodusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PROD: kp02hbaseadfhdiprodusc01 : Region Server is not online/NotServingRegionException in PROD HBase cluster,1.182730677,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Unexpected result\Hbase,"We identified the “ERROR: Found lingering HFileLink” and assume that, temporary file left behind because of bulkload operation and move those files out of the region.",PROD:  kp02hbaseadfhdiprodusc01 : Region Server is not online/NotServingRegionException  in PROD HBase cluster,"We identified the “ERROR: Found  lingering HFileLink” and assume that, temporary file left behind because of  bulkload operation and move those files out of the region. To identify the file  you can simple run 'hbase hbck' this will show you the lingering files  referenceTaken a backup and moved it this  temporary file (does not contains any important data but just for safe side we  are keeping the backup)  to /tmp.Go to 'hbase shell', unassign the  region and assign it back. For example, in the above error region is  '1718de39b822699095c9ee50d990459e'hbase(main):006:0> unassign  '1718de39b822699095c9ee50d990459e', truehbase(main):006:0> assign  '1718de39b822699095c9ee50d990459e'Wait for few minutes and run  'hbase hbck' again to confirm that the issue resolved.",,,,,,,,
1.20053E+14,27:25.4,Spark Cluster is intermittently not accessible with Unauthorized Accedd ,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 26, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: The cluster Ambari is intermittently not accessible. It keeps asking for the credential. Using the same credential, sometimes it works, and sometimes it doesn't.\n\nAlso, ADF sometimes cannot submit Spark jobs to the cluster. Retries sometimes work.\n\n 'errorCode': '2310',\n    'message': 'Failed to submit Spark job. Error: 'Unauthorized to the cluster, ClusterEndpoint=https://edpcoresparksharedppe.azurehdinsight.net/'',\n    'failureType': 'UserError',\n    'target': 'EventTransformer',\n    'details': []\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - None;\nAdditional details about the issue - The cluster Ambari is intermittently not accessible. It keeps asking for the credential. Using the same credential, sometimes it works, and sometimes it doesn't.\n\nAlso, ADF sometimes cannot submit Spark jobs to the cluster. Retries sometimes work.\n\n 'errorCode': '2310',\n    'message': 'Failed to submit Spark job. Error: 'Unauthorized to the cluster, ClusterEndpoint=https://edpcoresparksharedppe.azurehdinsight.net/'',\n    'failureType': 'UserError',\n    'target': 'EventTransformer',\n    'details': []\n};\n\n- ProblemStartTime: 05/26/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EDP Core PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c9f82c25-0a2d-4788-a5bf-f4306975e892/resourceGroups/spark-p-core-rg/providers/Microsoft.HDInsight/clusters/EDPCoreSparkSharedPPE\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Cluster is intermittently not accessible with Unauthorized Accedd ,0.1233052,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,Spark Cluster is intermittently not accessible with Unauthorized Access,Intermittent Issue,As customer did not notice the issue over weekend requested for closure.,,,,,,,,
1.20053E+14,03:33.5,kpps80sparkprdsupwus201 : Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: ODBC/JDBC\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore log on {alphanumericpii} cluster.\n\nQuestion: Additional details about the issue\nAnswer: Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore log on {alphanumericpii} cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - ODBC/JDBC;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore log on {alphanumericpii} cluster.;\nAdditional details about the issue - Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore log on {alphanumericpii} cluster;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps80sparkprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kpps80sparkprdsupwus201 : Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore,14.86324652,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,kpps80sparkprdsupwus201 : Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore,kpps80sparkprdsupwus201 : Seeing numerous “java.sql.SQLException: Connection is closed” errors in Hivemetatore,Customer added below config to fix the errors on the cluster - hive.direct.sql.max.elements.values.clause=100hive.direct.sql.max.elements.in.clause=100,,,,,,,,
1.20053E+14,12:01.1,Issues while scaling the cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 25, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Cases: {Phonenumberpii},  {Phonenumberpii}\n\nWe've been facing issues with scaling process for our HDI {Namepii}: {alphanumericpii}. For the same reaosn we have opened multiple tickets earlier. Though they have provided a work around solution, we're looking for a permanent soltuion as we started facing these issues once again.\n\nPlease refer to the above mentioned tickets and let us know what best we can do to avoid them\n\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: We use an automation runbook for scaling the cluster with a frequency of 20 nodes (as suggested by MS Support). Though Scale up seems to be runnign fine, the scale down process gets stuck in between and causes the amabri services to go down letting no new jobs to be usbmitted to cluster or causing jobs to fail which are in execution already.\n\nDuring such situations, we SSH into the head node and restart the ambari-services. also look for any dead worker nodes, if they exist delete them from the ambari portal.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Cases: {Phonenumberpii},  {Phonenumberpii}\n\nWe've been facing issues with scaling process for our HDI {Namepii}: {alphanumericpii}. For the same reaosn we have opened multiple tickets earlier. Though they have provided a work around solution, we're looking for a permanent soltuion as we started facing these issues once again.\n\nPlease refer to the above mentioned tickets and let us know what best we can do to avoid them\n;\nHow was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - We use an automation runbook for scaling the cluster with a frequency of 20 nodes (as suggested by MS Support). Though Scale up seems to be runnign fine, the scale down process gets stuck in between and causes the amabri services to go down letting no new jobs to be usbmitted to cluster or causing jobs to fail which are in execution already.\n\nDuring such situations, we SSH into the head node and restart the ambari-services. also look for any dead worker nodes, if they exist delete them from the ambari portal.;\n\n- ProblemStartTime: 05/25/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/71aacd49-ff43-4567-9a08-b93980f13225/resourceGroups/Common01-PROD/providers/Microsoft.HDInsight/clusters/ana02spark36datahubpr01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Issues while scaling the cluster,0.047533597,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,"Checked script actions in scale up workflow and see one script is in progress for over 2 hourslet ClusterName = ""ana02spark36datahubpr01"";let StartTime =  datetime(2020-06-07 00:00:00);let EndTime = datetime(2020-06-07 00:00:00);cluster(""HDInsight"").database(""HDInsight"").LogEntry | where ClusterDnsName =~ trim("" "", ClusterName)| where PreciseTimeStamp  >= StartTime//|  where PreciseTimeStamp <= EndTime//| where  PreciseTimeStamp between(StartTime..EndTime)| where Class contains ""CustomizeScaleUpHostsActivity""| project PreciseTimeStamp  , TraceLevel , Class, Details, ExceptionType , ExceptionMessage | order  by PreciseTimeStamp  desc ","Customer provided script action was not completing causing issues with the scaling workflow. HDInsight does not have a timeout on the Ambari portion of the scale up workflow where script actions are run. When the script didnt complete, this in turn left worker nodes added to the cluster and the cluster did not transition to running state. Note that when this happens the new nodes are actually healthy and registered with Ambari and could potentially run work. Since the scale up workflow did not complete, it is unclear if billing is updated with the new nodes.",Customer removed persisted script actions and scale up has been successful. There was also an internal work item created for this https://msdata.visualstudio.com/HDInsight/_workitems/edit/767960,190591922,,,,,,,
1.20053E+14,47:46.3,Cluster Deployment Failed,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: f-ogqn-chc-dp-97800000-{namepii} {namepii}-0003-abd3-08d80312e266 \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: We have intetmittent issue - would like to know the reason this errored to confirm it is a known issue or a new one.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: Name : {alphanumericpii} Id : /{AlphanumericPII} -abd3-08d80312e266-stage-{namepii}/providers/Microsoft.HDInsight/clusters/f-ogqn-chc-dp-97800000-{namepii} {namepii}-0003-abd3-08d80312e266 Location : {Namepii} US 2 ClusterVersion : 3.6.1000.0 OperatingSystemType : {Namepii} ClusterTier : Standard ClusterState : Error ClusterType : Spark CoresUsed : 24 HttpEndpoint : f-ogqn-chc-dp-97800000-ffac-0003-abd3-08d80312e266.azurehdinsight.net Error : Internal server error occurred while processing the request. Please retry the request or contact support. DefaultStorageAccount : DefaultStorageContainer : DefaultStorageRootPath : ResourceGroup : chc-dp-97800000-ffac-0003-abd3-08d80312e266-stage-{namepii} AdditionalStorageAccounts : ComponentVersion : {[Spark, 2.1]} WorkerNodeDataDisksGroups : {} SecurityProfile :\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - f-ogqn-chc-dp-97800000-{namepii} {namepii}-0003-abd3-08d80312e266 ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - We have intetmittent issue - would like to know the reason this errored to confirm it is a known issue or a new one.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - Name : {alphanumericpii} Id : /{AlphanumericPII} -abd3-08d80312e266-stage-{namepii}/providers/Microsoft.HDInsight/clusters/f-ogqn-chc-dp-97800000-{namepii} {namepii}-0003-abd3-08d80312e266 Location : {Namepii} US 2 ClusterVersion : 3.6.1000.0 OperatingSystemType : {Namepii} ClusterTier : Standard ClusterState : Error ClusterType : Spark CoresUsed : 24 HttpEndpoint : f-ogqn-chc-dp-97800000-ffac-0003-abd3-08d80312e266.azurehdinsight.net Error : Internal server error occurred while processing the request. Please retry the request or contact support. DefaultStorageAccount : DefaultStorageContainer : DefaultStorageRootPath : ResourceGroup : chc-dp-97800000-ffac-0003-abd3-08d80312e266-stage-{namepii} AdditionalStorageAccounts : ComponentVersion : {[Spark, 2.1]} WorkerNodeDataDisksGroups : {} SecurityProfile :;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Stage Classic (DevTest)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/543c0572-d153-4029-b134-dae30593657e/resourceGroups/chc-dp-tracking23-stage-{namepii}/providers/Microsoft.HDInsight/clusters/f-bkch-chc-dp-tracking23\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster Deployment Failed,5.364730423,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Cluster Deployment Failed,Due to transient issue on the “VmGroup overprovisioning has Failed” and other fix on the gateway node on 3.6.67.x and 4.0.x images.,The fix was rolled out to East US 2 region with the on-going release on 25th of June regarding the major deployment error you are facing with - “VmGroup overprovisioning has Failed“ has been fixed.,,,,,,,,
1.20053E+14,59:56.2,Unable to add l8s v2 type machines as edge node in hdinsight cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 28, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: {alphanumericpii} \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: Any customization applied\nAnswer: Yes. Adding additional edge node.\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: This command is implicitly deprecated because command group 'group deployment' is deprecated and will be removed in a future release. Use 'deployment group' instead.\nDeployment failed. Correlation ID: {guidpii}. {\n  'code': 'BadRequest',\n  'message': 'The specified {NAMEPII} size [{alphanumericpii}] is not supported.'\n}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - {alphanumericpii} ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nAny customization applied - Yes. Adding additional edge node.;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - This command is implicitly deprecated because command group 'group deployment' is deprecated and will be removed in a future release. Use 'deployment group' instead.\nDeployment failed. Correlation ID: {guidpii}. {\n  'code': 'BadRequest',\n  'message': 'The specified {NAMEPII} size [{alphanumericpii}] is not supported.'\n};\n\n- ProblemStartTime: 05/28/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RedPoint CDP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to add l8s v2 type machines as edge node in hdinsight cluster,35.05674538,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,"Background: The support request was created by CVS on May 28th as they attempted to use an L8 VM as an edge node for HDInsight, and were unable to because L8 VMs are not a supported edge node type for HDInsight. The main purpose of the edge node is to run Redpoint.Investigation completed: After investigating CVS’s requirements with Redpoint, it was determined that a standard DS14 V2 VM, which is a supported edge node SKU, does meet their RAM and core needs but did not meet their 2 TB storage requirement.Feature requests made to the HDInsight product group:A feature request was made to the product group to enable CVS to mount additional SSDs to HDI edge nodes to meet the 2 TB storage requirement. This feature request was discussed by the product group, and because edge nodes are provisioned to and managed by an HDInsight internal subscription, there is no ability for the customers to mount their own SSDs to these HDInsight managed edge nodes – simply put, the plumbing does not exist to support this request. The engineering requirements to enable this functionality are not trivial and would require extensive investment from the product group.Alternatively, during recent conversations, it was suggested that an L16 VM would meet the RAM, core, and storage needs for CVS’s use of Redpoint, however L16 is also not a supported edge node type for HDInsight.Neither of these feature requests are on the roadmap at this time, and the earliest time we could start investigating implementing either ask would be CY2021.In an effort to provide guidance to CVS about how they could achieve their requirements in the near future, members of the HDInsight product group, account team, and support team held a series of meetings with Redpoint to learn about its application’s requirements, as CVS is specifically using the edge node to run Redpoint.Recommended path: Through the collaboration with Redpoint, we’ve determined that the best path forward is for CVS to deploy a Storage Optimized Virtual Machine that meets the capacity needs (Redpoint indicated an L16s or higher VM SKU would work best), add the VM to the VNet that the HDInsight cluster is in, then use Redpoints utility to grab the necessary files as a configuration from one worker node and download them to the new VM.Redpoint’s Data Manager would then be pointed to the download directory as part of the Hadoop connection configuration. In short, Redpoint will install and configure the Hadoop dependencies through Data Manager from an HDInsight worker node.This is the closest way to mimic an HDInsight edge node, while running Redpoint, and achieving maximum flexibility with the VM shape.This new VM would not be part of the HDInsight cluster, nor would it be supported by the HDInsight support staff as it is not an HDInsight managed resource, we are simply providing guidance for an alternative solution.",Cx is looking for a VM type (please call out the exact VM type instead of a series) which has at least 2 SSDs and configuration no less than 16 cores and 100 GB in memory.,"Background: The support request was created by CVS on May 28th as they attempted to use an L8 VM as an edge node for HDInsight, and were unable to because L8 VMs are not a supported edge node type for HDInsight. The main purpose of the edge node is to run Redpoint.Investigation completed: After investigating CVS’s requirements with Redpoint, it was determined that a standard DS14 V2 VM, which is a supported edge node SKU, does meet their RAM and core needs but did not meet their 2 TB storage requirement.Feature requests made to the HDInsight product group:A feature request was made to the product group to enable CVS to mount additional SSDs to HDI edge nodes to meet the 2 TB storage requirement. This feature request was discussed by the product group, and because edge nodes are provisioned to and managed by an HDInsight internal subscription, there is no ability for the customers to mount their own SSDs to these HDInsight managed edge nodes – simply put, the plumbing does not exist to support this request. The engineering requirements to enable this functionality are not trivial and would require extensive investment from the product group.Alternatively, during recent conversations, it was suggested that an L16 VM would meet the RAM, core, and storage needs for CVS’s use of Redpoint, however L16 is also not a supported edge node type for HDInsight.Neither of these feature requests are on the roadmap at this time, and the earliest time we could start investigating implementing either ask would be CY2021.In an effort to provide guidance to CVS about how they could achieve their requirements in the near future, members of the HDInsight product group, account team, and support team held a series of meetings with Redpoint to learn about its application’s requirements, as CVS is specifically using the edge node to run Redpoint.Recommended path: Through the collaboration with Redpoint, we’ve determined that the best path forward is for CVS to deploy a Storage Optimized Virtual Machine that meets the capacity needs (Redpoint indicated an L16s or higher VM SKU would work best), add the VM to the VNet that the HDInsight cluster is in, then use Redpoints utility to grab the necessary files as a configuration from one worker node and download them to the new VM.Redpoint’s Data Manager would then be pointed to the download directory as part of the Hadoop connection configuration. In short, Redpoint will install and configure the Hadoop dependencies through Data Manager from an HDInsight worker node.This is the closest way to mimic an HDInsight edge node, while running Redpoint, and achieving maximum flexibility with the VM shape.This new VM would not be part of the HDInsight cluster, nor would it be supported by the HDInsight support staff as it is not an HDInsight managed resource, we are simply providing guidance for an alternative solution.",,,,,,,,
1.20053E+14,55:40.6,Application unable to connect,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 25, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: connection using zookeeper\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Please see attaching logs\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - connection using zookeeper;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Please see attaching logs;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/25/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/4a007414-fdfa-44a6-af25-b022ddda599a/resourceGroups/g-rsg-2s-commerce01-personalization-marketing-pas-01/providers/Microsoft.HDInsight/clusters/g-hdh-2s-personalization-marketing-pas-01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Application unable to connect,0.080745165,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,Application unable to connect,For the application to be able to talk to the cluster name resolution between the machines should be working. We noticed that the App VM was not able to resolve the zookeeper node by hostname even if both the VMs are in the same Vnet/Subnet.Since we didn’t have permission to make any change on the VM (like adding host entries manually to test) you would be reaching out to the right team to look at the networking aspect.,CX networking issue. ,,,,,,,,
1.20053E+14,02:57.2,Unable to login to Ambari using batch accounts,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 28, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: Yes\n\nQuestion: Are the accounts federated?\nAnswer: ADFS\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Yes\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: No\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Able to login to azure portal, ssh to cluster nodes and can perform kinit but cannot login to Ambari using batch account.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - Yes;\nAre the accounts federated? - ADFS;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - Yes;\nDoes authentication fail even for the cluster admin account? - No;\nHave you logged in to Ambari as local admin and verified the users have been synced? - Yes;\nAdditional details about the issue - Able to login to azure portal, ssh to cluster nodes and can perform kinit but cannot login to Ambari using batch account.;\n\n- ProblemStartTime: 05/28/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp07-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to login to Ambari using batch accounts,0.737405087,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Unable to login to Ambari using batch accounts,Unable to login to Ambari using batch accounts,Customer found that those (failing) accounts do not have password hashes synchronized to AAD tenant due to routing issue between AAD and On-premise. Customer was working on changing Express Route provider that caused this gap. Customer worked with concerned team on his end and fixed the issue.,,,,,,,,
1.20053E+14,48:16.3,test,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Test\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Test;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",test,0.070065662,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Metrics are missing\Kafka,Test ticket,NA,As this is a ticket. Closing this ticket as per customer confirmation.,,,,,,,,
1.20053E+14,07:44.1,Deployment failed with an internal server error,"Question: What time did the problem begin?\nAnswer: {Namepii}, May 28, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Deployent seems to be in a loop in the task 'create or update cluster' with an internal server error.\n\nAttached the error in the activity log.\n\nCorrelation-id:  {guidpii}\n\n{Namepii} name: /subscriptions/b5064de0-abd4-4a91-9e65-2f4b03fe6bc9/resourcegroups/datalake-eastus2-hdipoc-rg/providers/Microsoft.HDInsight/clusters/hdi001ingpoc\n\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Deployent seems to be in a loop in the task 'create or update cluster' with an internal server error.\n\nAttached the error in the activity log.\n\nCorrelation-id:  {guidpii}\n\n{Namepii} name: /subscriptions/b5064de0-abd4-4a91-9e65-2f4b03fe6bc9/resourcegroups/datalake-eastus2-hdipoc-rg/providers/Microsoft.HDInsight/clusters/hdi001ingpoc\n\n\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/28/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Deployment failed with an internal server error,0.767162791,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,failed deployment,user eror,issue related to the variables being passed from the ARM template. ,,,,,,,,
1.20053E+14,39:54.1,Unable to establish connection to the cluster via ODBC,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string being used\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Yes\n\nQuestion: Connection string used from Beeline\nAnswer: jdbc:hive2://zk2-ahd501.azfrk.com:2181,zk3-ahd501.azfrk.com:2181,zk4-ahd501.azfrk.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2\n\nQuestion: Additional details about the issue\nAnswer: Unable to establish connection to the cluster via ODBC.\n\nBelow is the error we are observing while attempting to setup ODBC connection:\n\nFAILED!\n\n[Microsoft][{Namepii}] (34) Error from server: Bad Status: {ALPHANUMERICPII} 502 cannotconnect.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string being used - ;\nDoes Ambari login work? - Yes;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes hdfs dfs -ls / work? - Yes;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Yes;\nConnection string used from Beeline - jdbc:hive2://zk2-ahd501.azfrk.com:2181,zk3-ahd501.azfrk.com:2181,zk4-ahd501.azfrk.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2;\nAdditional details about the issue - Unable to establish connection to the cluster via ODBC.\n\nBelow is the error we are observing while attempting to setup ODBC connection:\n\nFAILED!\n\n[Microsoft][{Namepii}] (34) Error from server: Bad Status: {ALPHANUMERICPII} 502 cannotconnect.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to establish connection to the cluster via ODBC,0.330832006,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to cluster with Enterprise Security Package,Unable to establish connection to the cluster via ODBC,Unknown ,suddenly started working on ODBC connection without any changes made to the cluster.Cx stated that head nodes were restarted weekly basis,193237404,,,,,,,
1.20053E+14,39:50.3,"PREM | Azure HDInsight Service | Security vulnerability has been identified on all our Linux servers, Ubuntu and CentOS, IaaS and PaaS servers about anonymous user account(s) on our machines.  It doesn’t appear anything is using them since they are set to nologin but we wanted to double check and make sure no MS processes required these accounts before we remove them from our systems. HDI Nodes (Ubuntu): ehiadmin@hn0-p3ncsp:~$ cat /etc/passwd|grep nobody nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin CentOS 6 servers: [rehiadmin@p2ncmetric01 influxdb]# cat /etc/passwd|grep nobody nobody:x:99:99:Nobody:/:/sbin/nologin nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin","Security vulnerability has been identified on all our {Namepii} servers, Ubuntu and CentOS, IaaS and PaaS servers about anonymous user account(s) on our machines.  It doesn’t appear anything is using them since they are set to nologin but we wanted to double check and make sure no MS processes required these accounts before we remove them from our systems.\nHDI Nodes (Ubuntu):\n{alphanumericpii}:~$ cat /etc/passwd|grep nobody\n{alphanumericpii}\nCentOS 6 servers:\n[{alphanumericpii} influxdb]# cat /etc/passwd|grep nobody\n{AlphanumericPII}\n{AlphanumericPII} NFS User:/var/lib/nfs:/sbin/nologin","PREM | Azure HDInsight Service | Security vulnerability has been identified on all our Linux servers, Ubuntu and CentOS, IaaS and PaaS servers about anonymous user account(s) on our machines.  It doesn’t appear anything is using them since they are set to nologin but we wanted to double check and make sure no MS processes required these accounts before we remove them from our systems. HDI Nodes (Ubuntu): ehiadmin@hn0-p3ncsp:~$ cat /etc/passwd|grep nobody nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin CentOS 6 servers: [rehiadmin@p2ncmetric01 influxdb]# cat /etc/passwd|grep nobody nobody:x:99:99:Nobody:/:/sbin/nologin nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin",0.062866392,Root Cause : HDInsight Service\Lack of documentation,,"Security vulnerability has been identified on all our Linux servers, Ubuntu and CentOS, IaaS and PaaS servers about anonymous user account(s) on our machines.  It doesn’t appear anything is using them since they are set to nologin but we wanted to double check and make sure no MS processes required these accounts before we remove them from our systems. HDI Nodes (Ubuntu): ehiadmin@hn0-p3ncsp:~$ cat /etc/passwd|grep nobody nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin","Security vulnerability has been identified on all our Linux servers, Ubuntu and CentOS, IaaS and PaaS servers about anonymous user account(s) on our machines.  It doesn’t appear anything is using them since they are set to nologin but we wanted to double check and make sure no MS processes required these accounts before we remove them from our systems. HDI Nodes (Ubuntu): ehiadmin@hn0-p3ncsp:~$ cat /etc/passwd|grep nobody nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin","""Nobody"" is an optional user, designed to have the fewest permissions possible and it can't be logged into (no shell is set). As long as they have no services running under it and aren't using NFS, you can delete it. But we don't recommend it. From the HDInsight perspective, we don't use it, wouldn't affect usage of the cluster",,,,,,,,
1.20053E+14,15:20.3,Performing a simple 'Insert Into' in Hive DB take 12 seconds,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: I used to work with the performance issue but I would like to solve it definitively\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: INSERT INTO {alphanumericpii} \n(rootid, revisionno, datetransaction, statusresponsecddgig, requestfcsadatedgig, countdgig )\n{AlphanumericPII}', '1.00','2020-04-17 18:05:53.000','RESULT_Req_FCSA_Cube','2020-04-18','2.0');\n\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: I'm facing performances issue using Beeline.\nThe performance issue is the same using external tools like DBeaver.\nA simple query in Hive take more than 12 seconds, instead of less than 1 second usually (when using others DBMS)\n\nI can whitelist my cluster if you need to make some test in ssh.\nThanks a lot for support\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - I used to work with the performance issue but I would like to solve it definitively;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - INSERT INTO {alphanumericpii} \n(rootid, revisionno, datetransaction, statusresponsecddgig, requestfcsadatedgig, countdgig )\n{AlphanumericPII}', '1.00','2020-04-17 18:05:53.000','RESULT_Req_FCSA_Cube','2020-04-18','2.0');\n;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - I'm facing performances issue using Beeline.\nThe performance issue is the same using external tools like DBeaver.\nA simple query in Hive take more than 12 seconds, instead of less than 1 second usually (when using others DBMS)\n\nI can whitelist my cluster if you need to make some test in ssh.\nThanks a lot for support;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV05/providers/Microsoft.HDInsight/clusters/dsjd5sparkbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Performing a simple 'Insert Into' in Hive DB take 12 seconds,1.130413715,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Interactive Query,Performing a simple 'Insert Into' in Hive DB take 12 seconds,Config change,Settingset hive.llap.io.enabled=false;set hive.optimize.index.filter=false;set hive.exec.orc.split.strategy=BI; brought down the insert time to 7.901 seconds. Related article: https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/interactive-query-troubleshoot-query-performance,,,,,,,,
1.20053E+14,19:32.4,We had an Azure Outage TVW2-VD0 . HDI cluster is down,"Question: What time did the problem begin?\nAnswer: Sat, May 30, 2020, 6:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, May 30, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Starting at 30 May 2020 00:35 UTC you have been identified as a customer using Virtual Machines in East US who may experience connection failures when trying to access some Virtual Machines hosted in the region. These Virtual Machines may have also restarted unexpectedly. Engineers are aware of this issue and are actively investigating.\n\n\nWe are not able to connect to HDI cluster.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Starting at 30 May 2020 00:35 UTC you have been identified as a customer using Virtual Machines in East US who may experience connection failures when trying to access some Virtual Machines hosted in the region. These Virtual Machines may have also restarted unexpectedly. Engineers are aware of this issue and are actively investigating.\n\n\nWe are not able to connect to HDI cluster.;\n\n- ProblemStartTime: 05/30/2020 00:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pay-As-You-Go(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cc56733b-407e-4f9b-8dd4-995cb065eb11/resourceGroups/ProdResourceGroup1/providers/Microsoft.HDInsight/clusters/hdi6-hbase-prod-eus\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We had an Azure Outage TVW2-VD0 . HDI cluster is down,0.035585798,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Service unhealthy\Hbase,Outage caused this service to go down,HDI cluster is down HDInsight Service,Outage was controlled and the issue got resolved.,,,,,,,,
1.20053E+14,35:28.8,"Having problem with Long running queries, up scaling taking long time and unable to open hive view, Tez View giving error.","Question: What time did the problem begin?\nAnswer: Sat, May 30, 2020, 1:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Having problem with Long running queries, up scaling taking long time and unable to open hive view.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Having problem with Long running queries, up scaling taking long time and unable to open hive view.\n;\n\n- ProblemStartTime: 05/30/2020 07:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT - Tax - 01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d75945a5-535f-4626-9d68-075eedbcf430/resourceGroups/11814-OneTax-UAT-01/providers/Microsoft.HDInsight/clusters/tapuathdi\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Having problem with Long running queries, up scaling taking long time and unable to open hive view, Tez View giving error.",2.872872397,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Monitoring cluster we can observe jobs that consume all resources and take a long time to complete.,"Gateway nodes were causing issues with scaling this cluster, scaling issues were cleared after rebooting the gateway nodes per another ticket cx opened. For long running queries, cx had a single job that was consuming a majority of resources (90+%) so there were no resources available for any other jobs. Even when cx scaled the cluster up to 50 worker nodes, all yarn memory was consumed by the single running job. ",Suggested cx look into capacity scheduler to allow other jobs to run in parallel and then also look into tuning their single job for better performance.,,,,,,,,
1.20053E+14,07:16.4,we are unable to configure presto in HD Insights,"Question: Problem Start Date\nAnswer: Fri, May 29, 2020, 12:00 AM EDT\n\nQuestion: Subscription ID\nAnswer: {guidpii}\n\nQuestion: Error Message (if any)\nAnswer: i am unable to configure presto in HD Insights. \n\nQuestion: Issue description\nAnswer: In HD insights we are unable to configure presto.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Subscription Management:\nProblem Start Date - {ALPHANUMERICPII};\nSubscription ID - {guidpii};\nError Message (if any) - i am unable to configure presto in HD Insights. ;\nIssue description - In HD insights we are unable to configure presto.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 05/29/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Fulfillment Dev USC\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_SUBSCRIPTION_MANAGEMENT\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",we are unable to configure presto in HD Insights,0.025550563,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure Subscription V5\Purchase, sign up or upgrade issues\My issue is not listed above",Cannot configure Presto,Starburst is moving away from the ISV model that HDInsight has to an AKS based installation. The installation methods in HDInsight are deprecated and will be removed. ,Use the official installation method provided by Starburst.https://docs.starburstdata.com/latest/installation/azure.html,,,,,,,,
1.2006E+14,09:23.4,We need to know what IP addresses to give vendors to whitelist when they are recieving data from out HDI assets,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the issue affect all users or a few users?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We would like our partners to be able to conume data from our HDI environment and need toknow what IP's to give them so they can whitelist\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - Other, don't know or not applicable;\nDoes the issue affect all users or a few users? - Other, don't know or not applicable;\nDoes the user account work with other Azure services? - Other, don't know or not applicable;\nDoes kinit for some or all users work from the Head node? - Other, don't know or not applicable;\nDoes authentication fail even for the cluster admin account? - Other, don't know or not applicable;\nHave you logged in to Ambari as local admin and verified the users have been synced? - Other, don't know or not applicable;\nAdditional details about the issue - We would like our partners to be able to conume data from our HDI environment and need toknow what IP's to give them so they can whitelist;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We need to know what IP addresses to give vendors to whitelist when they are recieving data from out HDI assets,0.043756614,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,We need to know what IP addresses to give vendors to whitelist when they are recieving data from out HDI assets,By design,so the Public IP for ssh endpoint for the cluster  sprk01-prod-eastus2 would be -->  /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICLUSTER/providers/Microsoft.Network/publicIPAddresses/PUBLICIPHEADNODE-85BF09C7D0874B3DBC6A77959292E953 Here is the documentation that talks about the networking architecture of the HDInsight cluster. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-virtual-network-architecture,,,,,,,,
1.2006E+14,45:37.5,WN 7 & HN 0 services are down in production cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 6:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: WN 7 is down in production cluster {alphanumericpii}.\n\nHN 0 services are also down.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - WN 7 is down in production cluster {alphanumericpii}.\n\nHN 0 services are also down.;\n\n- ProblemStartTime: 06/02/2020 12:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",WN 7 & HN 0 services are down in production cluster,0.489854781,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Alerts firing on Services\Spark,WN 7 & HN 0 services are down in production cluster,High CPU utilization on WN7 and High load on the Head node.,"Recommendations: Increase the Resource Manager Java Heap size by 2GB /4GB which is under YARN -->Config-->advanced-->Resource ManagerAlso, we recommend to increase the number of worker nodes based on your work loads. Additional Information:There are many stale alerts that the Ambari server process is trying to flush. You can flush them by purging the Ambari DB  on hn1 by SSH into the cluster using the below commands. sudo service ambari-server stopsudo ambari-server db-purge-history --cluster-name=CLUSTERNAME --from-date=$(date +%Y-%m-%d -d ""15 day ago"")sudo service ambari-server start",,,,,,,,
1.2006E+14,33:38.5,"New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: Doesn't exist yet\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials. I succussfully created a HDI cluster with the same metastore credentials yesterday and it worked just fine. I then deleted the HDI cluster and attempted to build a new one and now it won't work. If I query the database separately with the same credentials it works just fine. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - Doesn't exist yet;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials. I succussfully created a HDI cluster with the same metastore credentials yesterday and it worked just fine. I then deleted the HDI cluster and attempted to build a new one and now it won't work. If I query the database separately with the same credentials it works just fine. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials",0.216116658,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials","New cluster build with external metastores for Hive, Oozie, and Ranger fails on authentication to the metastore using correct credentials",Discussed with product group on this and they suggested that the error is not blocked and customer would still be allowed to continue with the provisioning and product group is working on new UI while using existing to include all the fields required for the new UI.,,,,,,,,
1.2006E+14,58:54.8,users belonging to the ESP cluster access group are not able to login,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I HAVE created an ESP cluster and from amabri can see the Group is synced but when users are trying to login it is prompting for user name and passsword again and again.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - I HAVE created an ESP cluster and from amabri can see the Group is synced but when users are trying to login it is prompting for user name and passsword again and again.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Project UPC Cablecom - Digital Roadmap\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/21560617-5db1-4347-a7d1-648fe8e39d5d/resourceGroups/dp-datalake-upch-prd-rg/providers/Microsoft.HDInsight/clusters/upch0-h8-hdi\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",users belonging to the ESP cluster access group are not able to login,0.065835979,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,"Ambari and Ranger was showing domain user synced, kerberos authenticated but still was not able to access ambari with domain user.",Conditional Access Policy failure,"AD side excluded the ""Azure Data Lake"" app from Enterprise app gallery and customer domain user was able to access Ambari. ",,,,,,,,
1.2006E+14,39:22.4,PRDDM07 - User not able to expand the table names some tables do not expand to show the column names ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: odbc\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: User connecting through the odbc driver.  When they try to expand the table names some tables do not expand to show the column names while others do.  The ones that do not sit there and time out.   \n\nWe tried by adjusting the settings below on the LLAP cluster to 128000, but there is no use.\n \n{alphanumericpii}\n{alphanumericpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - odbc;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - User connecting through the odbc driver.  When they try to expand the table names some tables do not expand to show the column names while others do.  The ones that do not sit there and time out.   \n\nWe tried by adjusting the settings below on the LLAP cluster to 128000, but there is no use.\n \n{alphanumericpii}\n{alphanumericpii};\n\n- ProblemStartTime: 06/01/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05eau2piphdidm07\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDDM07 - User not able to expand the table names some tables do not expand to show the column names ,0.458433353,Root Cause : HDInsight Service\Configuration\Simba Hive ODBC Driver,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,120060223002752 Some users unable to run queries from Alteryx using Hive ODBC connection,ODBC driver configuration,"Enable the ""FastSQLPrepare"" option within the driver to allow Alteryx to retrieve metadata without running a query.",,,,,,,,
1.2006E+14,43:47.5,Attempting to scale the cluster to 256 nodes fail,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 3:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} was created with 4 nodes.\nScale to 256 nodes was submitted, but failed with only 85 nodes made available.\nRetried attempts have not been able to scale the cluster beyond the 85 nodes\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} was created with 4 nodes.\nScale to 256 nodes was submitted, but failed with only 85 nodes made available.\nRetried attempts have not been able to scale the cluster beyond the 85 nodes;\n\n- ProblemStartTime: 06/02/2020 19:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AG-SEVERN\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Developer\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Developer\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Attempting to scale the cluster to 256 nodes fail,0.108130413,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,scale up failed for nodes greater than 100 ,"By design, S0 ambari db cannot handle load to scale up larger nodes",use ambari db with s4 tierscale up in interval of 50 ,,,,,,,,
1.2006E+14,26:26.4,issues with cluster creation ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 6:30 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} creation command was submitted through Control M and the job failed after 3 attemps of creating cluster. uploading the logs from Control M \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - {Namepii} creation command was submitted through Control M and the job failed after 3 attemps of creating cluster. uploading the logs from Control M ;\n\n- ProblemStartTime: 06/02/2020 22:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-cat-workload-rg/providers/Microsoft.HDInsight/clusters/ck0y96-cros-20200602-cat-prod-hdi\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",issues with cluster creation ,0.68823599,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,issues with cluster creation,NA,"Looking at the cluster names provided I see that it was spun up successfully and deleted as well. ck0y96-cros-20200602-cat-prod-hdi-->Running@2020-06-02 23:23:54 and deleted@2020-06-03 01:14:33 The script you mentioned below is deploying 3 clusters is seems like (""jgfc1i-cros-20200602-cat-prod-hdi"",""ck0y96-cros-20200602-cat-prod-hdi"",""tfwc23-cros-20200602-cat-prod-hdi"") and I see that all the three clusters got created successfully and were deleted successfully as well.  TIMESTAMPClusterDnsNameState2020-06-02 23:23:54ck0y96-cros-20200602-cat-prod-hdiRunning2020-06-03 00:19:55tfwc23-cros-20200602-cat-prod-hdiRunning2020-06-03 01:14:07jgfc1i-cros-20200602-cat-prod-hdiRunning",,,,,,,,
1.2006E+14,36:41.5,authentication error for metastore during configuration,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: uatentanalyticshdinsight\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I am trying to configure a HDInsight cluster in an existing subscription via the azure portal with external metastore for hive and oozie for the HDInsight cluster, for which I have created a Sql server with 2 databases. The Sql server name is uatentanalyticshdinsightmetastore and the login is metastoreadmin. It has 2 databases, each dedicated to hive and oozie. I am able to connect to the Sql server via SSMS client, but when I try to authenticate it for HDInsight cluster setup it gives me an error such as 'Could not connect to metastore with the given credentials. Please make sure the username and password provided are valid.'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - uatentanalyticshdinsight;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I am trying to configure a HDInsight cluster in an existing subscription via the azure portal with external metastore for hive and oozie for the HDInsight cluster, for which I have created a Sql server with 2 databases. The Sql server name is uatentanalyticshdinsightmetastore and the login is metastoreadmin. It has 2 databases, each dedicated to hive and oozie. I am able to connect to the Sql server via SSMS client, but when I try to authenticate it for HDInsight cluster setup it gives me an error such as 'Could not connect to metastore with the given credentials. Please make sure the username and password provided are valid.';\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/02/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LXK.DigitalTransformation.BigDecisions.Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",authentication error for metastore during configuration,2.593293321,Root Cause : HDInsight Service\Azure portal related issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,authentication error for metastore during configuration,portal bug,"During our call, we found that you were inputting the correct username and password and that the error message was a result of a portal bug.Bug: https://msdata.visualstudio.com/HDInsight/_workitems/edit/763804",,,,,,,,
1.2006E+14,44:59.9,Error in ADLS Gen2 writing spark checkpoint,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: {Alphanumericpii}  is the  use case?\nRunning a spark job by ncap which is working fine in HDI 3.6. Takes more than 5 hrs in {ALPHANUMERICPII}. Extremely slow I/O on spark checkpoint operation.\n{Alphanumericpii} were you trying to do ? \nUsing a spark program to checkpoint a dataframe.\n\n\nQuestion: Additional details about the issue\nAnswer: {Alphanumericpii}  is the  use case?\nRunning a spark job by ncap which is working fine in HDI 3.6. Takes more than 5 hrs in {ALPHANUMERICPII}. Extremely slow I/O on spark checkpoint operation.\n{Alphanumericpii} were you trying to do ? \nUsing a spark program to checkpoint a dataframe.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - {Alphanumericpii}  is the  use case?\nRunning a spark job by ncap which is working fine in HDI 3.6. Takes more than 5 hrs in {ALPHANUMERICPII}. Extremely slow I/O on spark checkpoint operation.\n{Alphanumericpii} were you trying to do ? \nUsing a spark program to checkpoint a dataframe.\n;\nAdditional details about the issue - {Alphanumericpii}  is the  use case?\nRunning a spark job by ncap which is working fine in HDI 3.6. Takes more than 5 hrs in {ALPHANUMERICPII}. Extremely slow I/O on spark checkpoint operation.\n{Alphanumericpii} were you trying to do ? \nUsing a spark program to checkpoint a dataframe.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq044sparkespfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error in ADLS Gen2 writing spark checkpoint,19.57722329,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Error in ADLS Gen2 writing spark checkpoint,Developers were getting this error when they were trying to checkpoint some datasets in thier code​. They replaced checkpoint with persist in their code and  it was working,Developers made changes in their code and it working now.,,,,,,,,
1.2006E+14,00:13.8,Schedule Auto restart of worker nodes,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Want to schedule a auto restart for worker node fornightly for clearing out the cache at regular intervals.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Want to schedule a auto restart for worker node fornightly for clearing out the cache at regular intervals.;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer {Namepii} Platform-Trade Secrets-PRD-{NAMEPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Schedule Auto restart of worker nodes,34.54146093,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Customer wanted to understand if we have role restart on HDInsight,NA,Explained customer options on customizing reboots and work between worker nodes,,,,,,,,
1.2006E+14,16:21.2,PRDSUP - kpps83sparkespprdsupwus201 - Cluster scaling incomplete,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} did not upscale. {Namepii} for 1 hr , 30 mins\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - {Namepii} did not upscale. {Namepii} for 1 hr , 30 mins;\n\n- ProblemStartTime: 06/02/2020 19:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP - kpps83sparkespprdsupwus201 - Cluster scaling incomplete,0.443805497,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,"Cluster did not upscale. Ran for 1 hr , 30 mins","we have checked the logs and noticed that yarn node labels script took 1hr and failed.Engineering team is fixed the yarn node labels script, and noticed that during that time the script is not doing kinit for secure clusters.","we have checked the logs and noticed that yarn node labels script took 1hr and failed.Engineering team is fixed the yarn node labels script, and noticed that during that time the script is not doing kinit for secure clusters.",190743564,,,,,,,
1.2006E+14,24:44.3,Ambari Subgroup doesn't  inherited of groupAccess,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: /\n\nQuestion: Additional details about the issue\nAnswer: To synchronize our Ambari RBAC we load a group which contain a nested group (subgroup) and we notice that the group access for example the cluster administrator is only affected by the group and not the nested group. \n\nFor example : The main group st-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper is well configured with the role cluster operation, but its nested group sr-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper isn't configured.\n\nWe have synchronized groups using REST API ldap_sync_events\n\nWe have added privileges using REST API 'privileges'\n\nDo we have to add privileges to nested group also? Or there is a way to make them inherit of main group.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - /;\nAdditional details about the issue - To synchronize our Ambari RBAC we load a group which contain a nested group (subgroup) and we notice that the group access for example the cluster administrator is only affected by the group and not the nested group. \n\nFor example : The main group st-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper is well configured with the role cluster operation, but its nested group sr-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper isn't configured.\n\nWe have synchronized groups using REST API ldap_sync_events\n\nWe have added privileges using REST API 'privileges'\n\nDo we have to add privileges to nested group also? Or there is a way to make them inherit of main group.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV05/providers/Microsoft.HDInsight/clusters/dsjd5sparkbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Subgroup doesn't  inherited of groupAccess,0.229059429,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Spark,Ambari Subgroup  doesn't inherited of groupAccess,"The main group st-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper is well configured with the role cluster operation, but its nested group sr-az-ap-dgig-npd-dev-bihdi-hdi-clusteroper isn't configured.","Ambari consider both  groups as individual and even syncing should happen individually though they are  nested. So answer to your question(s), yes you need to individually assign the  roles for main & nested groups i.e nested group would not inherit the  ""Cluster Operator"" role from the parent group.",,,,,,,,
1.2006E+14,17:35.5,Not Starting,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 4, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: no standard process that we do daily.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Data Factory Activity\n\nQuestion: Additional details about the issue\nAnswer: Clusters are failing to start in the subscription:\n\nOther clusters are:\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n\nExample error message in the portal.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - no standard process that we do daily.;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Data Factory Activity;\nAdditional details about the issue - Clusters are failing to start in the subscription:\n\nOther clusters are:\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n\nExample error message in the portal.\n;\n\n- ProblemStartTime: 06/03/2020 23:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PHX - Integrate {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b82775d9-845f-408a-bd34-65310a007567/resourceGroups/idm-t4/providers/Microsoft.HDInsight/clusters/c07567b6f69284076ba1dda99fe513f4d\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not Starting,0.266475965,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Databricks Clusters are failing to start ,"Impact Summary: Between 07:45 and 16:57 UTC on 04 Jun 2020, a subset of customers across all Public Azure regions may have experienced deployment failures when attempting to create or delete certain service based resources via Azure Resource Manager (ARM) deployment and management service due to an underlying networking issue. While the related networking resources for the impacted services were actually being created or deleted during this time, ARM was not notified of the deployment status and hence was failing the service creation or deletion. This issue may have impacted some GET or READ action on the resources This issue was initially detected an hour after the impact start time and was identified and escalated by an underlying service experiencing end user impact. Once detected, multiple engineering teams were engaged to investigate the cause of the issue to understand what needed to be fixed. By 11:00 UTC, the appropriate networking team was engaged and began investigating. The underlying cause was identified by 13:00 UTC. We identified the appropriate fix and rolled it out to a single region to validate success. We confirmed success of the roll out and began deploying to other regions in 3 batches. At the end of each batch we validated the success of the fix. By 16:57 UTC, the fix was rolled out to all regions and mitigation was confirmed. Root Cause: A recent ARM deployment contained a configuration file that stores the URL endpoint that ARM connects to for operation status query calls. The configuration file had an incorrect endpoint for networking resources. Due to this wrong setting, the ARM status query for networking service management operations failed, which customers saw as failures when attempting to create or delete networking resources. The faulty configuration file was not caught prior to production because the update that caused the network resource failures was applied after testing was performed on a then healthy configuration file. When picking up the latest configuration file for deployment, the faulty file was assessed for production and not testing. The faulty configuration file was then manually rolled out without testing being performed with the newest configuration, breaking change.Mitigation: We corrected the incorrect URL endpoint within the configuration file and safely re-deployed to mitigate the issue.Next Steps: We apologize for the impact to affected customers. We are continuously taking steps to improve the Microsoft Azure Platform and our processes to help ensure such incidents do not occur in the future. In this case, this includes (but is not limited to):·         Networking service will onboard to SDP (Safe Deployment Practice) endpoint configuration rollout process immediately, to ensure enough testing is done and enough time occurs between deployment batches occurs to catch any misconfigurations or changes prior to deployment. ·         Networking service will immediately plug-in testing and monitoring holes to make sure we immediately identify an issue like this on the networking end as failures were only seen on the ARM end. ·         Networking service will work with ARM team to streamline configuration rollout process, to guard against errors that may occur with the current manual deployment process.",Outage.,"190,842,934,190,859,000",,,,,,,
1.2006E+14,18:58.6,MFA IS not working for users ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: No\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: After disabling MFA for users, the users are still able to login to Ambari ESP cluster \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - No;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - After disabling MFA for users, the users are still able to login to Ambari ESP cluster ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Project UPC Cablecom - Digital Roadmap\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/21560617-5db1-4347-a7d1-648fe8e39d5d/resourceGroups/dp-datalake-upch-prd-rg/providers/Microsoft.HDInsight/clusters/upch0-h8-hdi\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MFA IS not working for users ,0.387956108,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,User was able to login to Ambari with/without MFA,"""None"" was set in the inclusion tab.                       ","""None"" means, CA policy will be applied to none and everyone is excluded from the policy. In your case, the policy was MFA for all, therefore, if you set it to none, it will not apply MFA to all that is why every user was able to access cluster. And even when you removed your user from policy, you were still able to access it due to ""none"" set in the inclusions tab. As Naga explained, you have two users associated to different policies ""Office 365 policy MFA for all"" and ""Require MFA for Administrators"".  You will need to remove ""none"" from inclusion tab and set user/groups needed in each tab for ""Office 365 policy MFA for all"", so only users needed to access the cluster can do so. Whereas, MFA prompt is coming from your other policy ""Require MFA for Administrators"" with a different username. ",,,,,,,,
1.2006E+14,34:15.0,Cluster is not getting Up and Running state,"Question: What time did the problem begin?\nAnswer: {Namepii}, 4 {Namepii}, 2020, 3:00 pm IST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: At that time Azure VM allocation was going on\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: All the HDInsight cluster under our subscription is OnDemand. Today at the time of triggering the cluster from Data Factory we have seen that after cerntain point of time cluster was autometically into failed state. Tried multiple time but no luck.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - At that time Azure VM allocation was going on;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - All the HDInsight cluster under our subscription is OnDemand. Today at the time of triggering the cluster from Data Factory we have seen that after cerntain point of time cluster was autometically into failed state. Tried multiple time but no luck.;\n\n- ProblemStartTime: 06/04/2020 09:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: diageo-analytics-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3a683d84-be08-4356-bb14-3b62df1bad55/resourceGroups/diageo-analytics-prod-rg-datalake/providers/Microsoft.HDInsight/clusters/diageo-eun-analytics-prod-hdi-hd-prd02\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is not getting Up and Running state,0.124606418,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster is not getting Up and Running state,"Impact Summary: Between 07:45 and 16:57 UTC on 04 Jun 2020, a subset of customers across all Public Azure regions may have experienced deployment failures when attempting to create or delete certain service based resources via Azure Resource Manager (ARM) deployment and management service due to an underlying networking issue. While the related networking resources for the impacted services were actually being created or deleted during this time, ARM was not notified of the deployment status and hence was failing the service creation or deletion. This issue may have impacted some GET or READ action on the resources This issue was initially detected an hour after the impact start time and was identified and escalated by an underlying service experiencing end user impact. Once detected, multiple engineering teams were engaged to investigate the cause of the issue to understand what needed to be fixed. By 11:00 UTC, the appropriate networking team was engaged and began investigating. The underlying cause was identified by 13:00 UTC. We identified the appropriate fix and rolled it out to a single region to validate success. We confirmed success of the roll out and began deploying to other regions in 3 batches. At the end of each batch we validated the success of the fix. By 16:57 UTC, the fix was rolled out to all regions and mitigation was confirmed. Root Cause: A recent ARM deployment contained a configuration file that stores the URL endpoint that ARM connects to for operation status query calls. The configuration file had an incorrect endpoint for networking resources. Due to this wrong setting, the ARM status query for networking service management operations failed, which customers saw as failures when attempting to create or delete networking resources. The faulty configuration file was not caught prior to production because the update that caused the network resource failures was applied after testing was performed on a then healthy configuration file. When picking up the latest configuration file for deployment, the faulty file was assessed for production and not testing. The faulty configuration file was then manually rolled out without testing being performed with the newest configuration, breaking change.","Mitigation: We corrected the incorrect URL endpoint within the configuration file and safely re-deployed to mitigate the issue.Next Steps: We apologize for the impact to affected customers. We are continuously taking steps to improve the Microsoft Azure Platform and our processes to help ensure such incidents do not occur in the future. In this case, this includes (but is not limited to):·         Networking service will onboard to SDP (Safe Deployment Practice) endpoint configuration rollout process immediately, to ensure enough testing is done and enough time occurs between deployment batches occurs to catch any misconfigurations or changes prior to deployment.·         Networking service will immediately plug-in testing and monitoring holes to make sure we immediately identify an issue like this on the networking end as failures were only seen on the ARM end.·         Networking service will work with ARM team to streamline configuration rollout process, to guard against errors that may occur with the current manual deployment process.",190842934,,,,,,,
1.2006E+14,51:07.1,Hive ODBC Connection failing ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: ODBC connection with Qlik\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have installed ODBC driver on Qlik servers for fetching Hive Data and after 41M records it's failing with -\n\nQVX_UNEXPECTED_END_OF_DATA: SQL##f - SqlState: {Alphanumericpii}, ErrorCode: 35, ErrorMsg: [Microsoft][{Namepii}] (35) Error from server: error code: '0' error message: 'Invalid OperationHandle: OperationHandle [opType=EXECUTE_STATEMENT, {AlphanumericPII}]'.\n\nWe tried to tune ODBC parameters but it's still failing.\n\nThis has become show stopper for our project to go-live.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - ODBC connection with Qlik;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - We have installed ODBC driver on Qlik servers for fetching Hive Data and after 41M records it's failing with -\n\nQVX_UNEXPECTED_END_OF_DATA: SQL##f - SqlState: {Alphanumericpii}, ErrorCode: 35, ErrorMsg: [Microsoft][{Namepii}] (35) Error from server: error code: '0' error message: 'Invalid OperationHandle: OperationHandle [opType=EXECUTE_STATEMENT, {AlphanumericPII}]'.\n\nWe tried to tune ODBC parameters but it's still failing.\n\nThis has become show stopper for our project to go-live.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive ODBC Connection failing ,0.028146709,Root Cause : HDInsight Service\Bug\Simba Hive ODBC Driver,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,"Symptom: When run a query for more then 4.5mil records sql error occurs:QVX_UNEXPECTED_END_OF_DATA: SQL##f - SqlState: S1000, ErrorCode: 35, ErrorMsg: [Microsoft][Hardy] (35) Error from server: error code: '0' error message: 'Invalid OperationHandle: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=f7d18e77-6b8c-4546-bfde-c003433d1f5c]'.",Cause:  ODBC driver version 2.6.7 has issues handling large amount of records.,Resolution: Downgraded to version 2.1.6More Information: First tried adjusting the configurations for the driver for version 2.6.7 but these did not help.  Had to downgrade the version.  There is a patch for 2.6.7 coming but currently has not been pushed out yet.,,,,,,,,
1.2006E+14,13:45.4,Query slowness,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {Namepii} are runnimng very slow and the performance are degraded  significantly.\n\nThis is happening on 2 clusters:\n{alphanumericpii} \n{alphanumericpii}\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {Namepii} are runnimng very slow and the performance are degraded  significantly.\n\nThis is happening on 2 clusters:\n{alphanumericpii} \n{alphanumericpii};\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - {alphanumericpii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Query slowness,0.494255037,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Query slowness,Drop table involved in materialized view leaves the table in inconsistent state,Did clean the nul (SD_ID) in  the metastore is fixed the issue. Root cause is the fact that users  are allowed to issue a DROP TABLE command against a table even if there is a  materialized view using this table at the ,190943951,,,,,,,
1.2006E+14,28:31.7,Serviço indisponível,"Pergunta: A que horas começou o problema?\nResposta: qui, 4 de jun de 2020 10:00 BRT\n\nPergunta: Hora aproximado em que o problema deixou de ocorrer. {Namepii} o problema ainda estiver ocorrendo, deixe esse campo em branco\nResposta: \n\nPergunta: Foi feita alguma alteração em algum desses componentes?\nResposta: Outro, desconhecido ou não aplicável\n\nPergunta: Aumento da carga?\nResposta: Outro, desconhecido ou não aplicável\n\nPergunta: Como atenuar as ações realizadas até agora\nResposta: \n\nPergunta: Detalhes adicionais sobre o problema\nResposta: {Namepii} HDI não está disponível\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\nA que horas começou o problema? - {ALPHANUMERICPII};\nHora aproximado em que o problema deixou de ocorrer. {Namepii} o problema ainda estiver ocorrendo, deixe esse campo em branco - ;\nFoi feita alguma alteração em algum desses componentes? - Outro, desconhecido ou não aplicável;\nAumento da carga? - Outro, desconhecido ou não aplicável;\nComo atenuar as ações realizadas até agora - ;\nDetalhes adicionais sobre o problema - {Namepii} HDI não está disponível;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/04/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Azure Natura\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Plano de Suporte do Azure - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: brazilsouth\n- Location: {Namepii} South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Serviço indisponível,0.081126551,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Service unhealthy\Spark,Customer reported that their HDI cluster was unavailable.,Due to the outage mentioned in ICM#: 190842934,After the ICM was resolved. Cx reported that the HDI cluster has been restored.,190842934,,,,,,,
1.2006E+14,00:38.6,Clusters have no resources or Unexpected behaviour,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 3, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Clusters start, but Ambari RPC requests fail randomly, some spark jobs crash without reason, or spark cannot get access to SQL databases using JDBC.\n\nClusters start with nodes in unhealthy state in all subscriptions.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Clusters start, but Ambari RPC requests fail randomly, some spark jobs crash without reason, or spark cannot get access to SQL databases using JDBC.\n\nClusters start with nodes in unhealthy state in all subscriptions.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/03/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EY-CTSBP-PROD-Assurance-EY Blockchain {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/af734886-ea52-4bdb-955f-017849f4dfa9/resourceGroups/EUNPBCANETRSG02/providers/Microsoft.HDInsight/clusters/lqcae69d2c3-70d2-49c6-bd66-7bff676dc76d\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Clusters have no resources or Unexpected behaviour,0.033522626,Root Cause : HDInsight Service\Azure platform issues\Azure Service outage,Routing Azure HDInsight V5\Service unhealthy\Spark,Clusters have no resources or Unexpected behaviour,"The issue you have reported is impacting multiple customers and is a high priority. Our engineering team is already engaged, working towards a resolution. Starting at 08:45 UTC on 04 Jun 2020, a subset of customers may experience issues with resource creation for services that depend on the Azure Resource Manager (ARM) platform.",Outage resolved. ,"190,842,934,190,969,000",,,,,,,
1.2006E+14,31:56.3,PRDSUP: kpph18llapprdsupusc01 : application can connect to the cluster via ODBC. The query doesn’t complete. ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: An application can connect to the cluster via ODBC. The query doesn’t complete. The app is hung as the R process is running and never completes so the app does not proceed to the next line. \n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: An application can connect to the cluster via ODBC. The query doesn’t complete. The app is hung as the R process is running and never completes so the app does not proceed to the next line. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - An application can connect to the cluster via ODBC. The query doesn’t complete. The app is hung as the R process is running and never completes so the app does not proceed to the next line. ;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - ODBC;\nAdditional details about the issue - An application can connect to the cluster via ODBC. The query doesn’t complete. The app is hung as the R process is running and never completes so the app does not proceed to the next line. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpph18llapprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP: kpph18llapprdsupusc01 : application can connect to the cluster via ODBC. The query doesn’t complete. ,0.813561168,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,PRDSUP: kpph18llapprdsupusc01 : application can connect to the cluster via ODBC. The query doesn’t complete.,LLAP service out of tune,restarted hive services,,,,,,,,
1.20061E+14,45:45.8,Query hanging,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: More data to be processed\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: insert overwrite table patient_diagnosis_filtered_managed_ts partition (index_update)\nselect \n         regexp_replace(TT.source,'\\'','') source\n        ,regexp_replace(TT.source_type,'\\'','') source_type\n        ,regexp_replace(TT.MPI,'\\'','') MPI\n        ,regexp_replace(TT.type_id,'\\'','') type_id\n        ,regexp_replace(TT.patient_account_id,'\\'','') patient_account_id\n        ,regexp_replace(TT.code,'\\'','') code\n        ,regexp_replace(TT.provider_id,'\\'','') provider_id\n        ,regexp_replace(TT.description,'\\'','') description\n        ,regexp_replace(TT.coding_method,'\\'','') coding_method\n        ,regexp_replace(TT.diagnosis_priority,'\\'','') diagnosis_priority\n        ,regexp_replace(TT.diagnosis_timestamp,'\\'','') diagnosis_timestamp\n        ,regexp_replace(TT.event_timestamp,'\\'','') event_timestamp\n        ,regexp_replace(TT.index_update,'\\'','')  index_update\nfrom patient_diagnosis_parquet_pm TT left join manual_categories MC on TT.code = MC.diagnosis_code where MC.diagnosis_code is not null \n;\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii} - hangs at a given percentage instead of failing.  Need a way to anticipate instead of it hanging for days.  It would be far better for it to actually fail.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - More data to be processed;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - insert overwrite table patient_diagnosis_filtered_managed_ts partition (index_update)\nselect \n         regexp_replace(TT.source,'\\'','') source\n        ,regexp_replace(TT.source_type,'\\'','') source_type\n        ,regexp_replace(TT.MPI,'\\'','') MPI\n        ,regexp_replace(TT.type_id,'\\'','') type_id\n        ,regexp_replace(TT.patient_account_id,'\\'','') patient_account_id\n        ,regexp_replace(TT.code,'\\'','') code\n        ,regexp_replace(TT.provider_id,'\\'','') provider_id\n        ,regexp_replace(TT.description,'\\'','') description\n        ,regexp_replace(TT.coding_method,'\\'','') coding_method\n        ,regexp_replace(TT.diagnosis_priority,'\\'','') diagnosis_priority\n        ,regexp_replace(TT.diagnosis_timestamp,'\\'','') diagnosis_timestamp\n        ,regexp_replace(TT.event_timestamp,'\\'','') event_timestamp\n        ,regexp_replace(TT.index_update,'\\'','')  index_update\nfrom patient_diagnosis_parquet_pm TT left join manual_categories MC on TT.code = MC.diagnosis_code where MC.diagnosis_code is not null \n;;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - {alphanumericpii} - hangs at a given percentage instead of failing.  Need a way to anticipate instead of it hanging for days.  It would be far better for it to actually fail.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA Team\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/twoprocesshistorical\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Query hanging,3.305280279,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Query or Job Failure\Hive,Hive query hanging ,"Azure blob exception: Caused by: com.microsoft.azure.storage.StorageException: The block list may not contain more than 50,000 blocks.",Provided Cx with following options: Try inserting less data at one time by using conditions in the querySwitch to ADLS Gen2 storage (Best option as Gen2 does not have these limits)As well as documentation on how to properly specify a larger block size,,,,,,,,
1.20061E+14,43:24.3,Error Could not connect to metastore with the given credentials when creating cluster,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 5, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: Any customization applied\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: Error screeshot attached\n\nWhen we try to submit cluster creation using azure-sdk-for-python, we are geeting below error although the connection srtring is correct and allowed required access to Azure services \n(see attached screenshot)\nAmbari SQL Server DB.  phdhqametastoreserver/dbphdhqametastoreambari\n\nDeploymentDocument 'AmbariConfigurationValidator' failed the validation. Error: 'Cannot connect to Ambari metastore using user provided connection string\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nAny customization applied - ;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - Error screeshot attached\n\nWhen we try to submit cluster creation using azure-sdk-for-python, we are geeting below error although the connection srtring is correct and allowed required access to Azure services \n(see attached screenshot)\nAmbari SQL Server DB.  phdhqametastoreserver/dbphdhqametastoreambari\n\nDeploymentDocument 'AmbariConfigurationValidator' failed the validation. Error: 'Cannot connect to Ambari metastore using user provided connection string\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/04/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PHDH UAT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/470aa132-facc-465a-b8d7-f2b954c41062/resourceGroups/rgphdhqahdinsight/providers/Microsoft.HDInsight/clusters/phdhqahdinsight40i\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error Could not connect to metastore with the given credentials when creating cluster,0.307103375,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,cannot deploy ESP cluster with ambari DB,incorrect ambari DB was provided,provided the correct ambari DB in the code,192862369,,,,,,,
1.20061E+14,20:36.0,Failed to enable/disable auto-scale,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 5, 2020, 6:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I have 'HDInsights CLuster Operator Access' role and still I am not able enable/disable auto-scale. On edit, I am getting below error.\nError configuring autoscale on cluster\nError configuring autoscale: undefined\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I have 'HDInsights CLuster Operator Access' role and still I am not able enable/disable auto-scale. On edit, I am getting below error.\nError configuring autoscale on cluster\nError configuring autoscale: undefined;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/05/2020 12:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Prod Subscription(dws)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/019daf6c-7f28-4a87-8ea1-f46570f10024/resourceGroups/myntra_bi_hdinsight_rg/providers/Microsoft.HDInsight/clusters/processing-data-validation\n- Location: southindia\n- Location: South India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failed to enable/disable auto-scale,0.025867473,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Failed to enable/disable auto-scale,Failed to enable/disable auto-scale,Shared customer with custom RBAC role permissions that would be required to manage the enable/disable on auto-scale on HDInsight cluster.,"191,053,153,191,053,000",,,,,,,
1.20061E+14,01:26.4,Can't insert data in Hive Cluster 4,{Namepii} 4 on Hive unable to insert new data in Hive.\n\nHigh visibility from the VP level need imeediate solution.,Can't insert data in Hive Cluster 4,0.345065143,Root Cause : HDInsight Service\User Error,,Can’t insert data into the table devl02_policyconvertbasedsl.policyconvert,"During the last cluster recreation, the wrong container was attached to it.   ",The best way to resolve this is to recreate the cluster,,,,,,,,
1.20061E+14,37:37.2,NotServingRegionException while app team running their queries,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 5, 2020, 6:56 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We have seen that few regions are in transistion mode on hbase UI for table {ALPHANUMERICPII}.\n\nWhen app team is running the query it's showing below error:\n\n2020-06-05 {Alphanumericpii} o.a.h.h.c.AsyncProcess [INFO] #1, {AlphanumericPII}, {alphanumericpii} {alphanumericpii}, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region MESSAGE_ARCHIVE_2,{UNCPII} is not online on 10.2.0.74,16020,1591092483820\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We have seen that few regions are in transistion mode on hbase UI for table {ALPHANUMERICPII}.\n\nWhen app team is running the query it's showing below error:\n\n2020-06-05 {Alphanumericpii} o.a.h.h.c.AsyncProcess [INFO] #1, {AlphanumericPII}, {alphanumericpii} {alphanumericpii}, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region MESSAGE_ARCHIVE_2,{UNCPII} is not online on 10.2.0.74,16020,1591092483820\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n;\n\n- ProblemStartTime: 06/05/2020 13:26:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT PerfTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2f533aaa-6ce7-4273-ab45-2333db12ad29/resourceGroups/perf-hlt-cat-rg-01/providers/Microsoft.HDInsight/clusters/prf-maud-hlt-ussc-hbase-01\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",NotServingRegionException while app team running their queries,0.221861203,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hbase,"2020-06-05 13:24:05.951 o.a.h.h.c.AsyncProcess [INFO] #1, table=MESSAGE_ARCHIVE_2, attempt=31/35 failed=17ops, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region MESSAGE_ARCHIVE_2,\\x02pl6xx_PRD15688965362,1591078168659.afedcc36bcf3fb90afdf4bf3c1461555. is not online on 10.2.0.74,16020,1591092483820         at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:3077)         at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1015)         at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2096)         at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32393)         at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2150)         at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:112)         at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:187)         at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:167)",NotServingRegionException while app team running their queries,"Manually cleaned the lingering files fixed the issue. If it happen again, please share hbck report with us and then engage us instead of running hbck -repair command",191512118,,,,,,,
1.20061E+14,50:50.3,Cluster stuck in 'Applying Changes' mode,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We updated the Tags for HDI {Namepii} {ALPHANUMERICPII} and from then on cluster is stuck in 'Applying Changes' mode.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We updated the Tags for HDI {Namepii} {ALPHANUMERICPII} and from then on cluster is stuck in 'Applying Changes' mode.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster stuck in 'Applying Changes' mode,0.063284077,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,Cluster stuck in 'Applying Changes' mode,cluster stuck in applying change mode ,Restarted a cluster in backend,191101932,,,,,,,
1.20061E+14,57:17.4,HostName Resolution failed,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Team,\n\nWe are unable to view the Yarn logs in the Yarn UI. When we try to open the logs for any appication id, it is resulting in dns server failure and looks like it is not able to resolve the FQDN to an IP address. Please feel free to setup a call to discuss in detail. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Team,\n\nWe are unable to view the Yarn logs in the Yarn UI. When we try to open the logs for any appication id, it is resulting in dns server failure and looks like it is not able to resolve the FQDN to an IP address. Please feel free to setup a call to discuss in detail. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HostName Resolution failed,0.209671438,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Metrics are missing\Spark,HostName Resolution  failed,Because accessing yarn UI in traditional way (using port and hostname),"Recommend to  access it like  https://CLUSTERNAME.azurehdinsight.net/yarnui or https://CLUSTERNAME-int.azurehdinsight.net/yarnui or use the quick links under YARN  service for the same. You can connect to the cluster  at https://CLUSTERNAME.azurehdinsight.net. This address uses a public IP,  which may not be reachable if you have used NSGs to restrict incoming traffic  from the internet. Additionally, when you deploy the cluster in a VNet you can  access it using the private endpoint from any of the Networks inside/peered to  the VNET where HDInsight is deployed, https://CLUSTERNAME-int.azurehdinsight.net. This endpoint resolves to a  private IP inside the VNet for cluster access.",,,,,,,,
1.20061E+14,01:22.8,RM not found,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 1, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: We use airflow on VM to scale the cluster.\nBut it was looking for RM forever.\n``Looking for the active RM in [rm1, rm2].``\nERROR - Process timed out\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - We use airflow on VM to scale the cluster.\nBut it was looking for RM forever.\n``Looking for the active RM in [rm1, rm2].``\nERROR - Process timed out;\n\n- ProblemStartTime: 06/01/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-STG-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24cccmcaistage\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",RM not found,0.150974115,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,RM not found,RM not found,"Worked with customer and tried to get RMs into Active/Standby, but no luck. Engaged product group on this and they suggested to toggle off ""YARN Label"" on Ambari UI -> YARN -> Config and restart required services. Customer did the same and had successfully scaled-up the cluster. Customer confirmed that no further asks pending.",191107849,,,,,,,
1.20061E+14,09:31.5,additional storage on edge node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: Any customization applied\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I need to install and host a third-party application on the Edge Node and for that, I need to have {ALPHANUMERICPII} disk space on the Edge Node. How can I additional volume/disk to the edge node? Current available space is only {ALPHANUMERICPII} which is very tiny to install a third-party application on the edge node.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - ;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nAny customization applied - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I need to install and host a third-party application on the Edge Node and for that, I need to have {ALPHANUMERICPII} disk space on the Edge Node. How can I additional volume/disk to the edge node? Current available space is only {ALPHANUMERICPII} which is very tiny to install a third-party application on the edge node.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Unifi Field\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",additional storage on edge node,0.221626728,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,How can I add additional volume/disk to the edge node?,NA,This is not a supported scenario. The managed disk size of each node in the newly created cluster is 128 GB. This can't be changed. Please refer to below document for more information. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-supported-node-configuration ,,,,,,,,
1.20061E+14,11:45.4,Unable to access Ambari view of cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to access Ambari view of tapcfscluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to access Ambari view of tapcfscluster;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT - Tax - 01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d75945a5-535f-4626-9d68-075eedbcf430/resourceGroups/11814-OneTax-Prod-01/providers/Microsoft.HDInsight/clusters/tapcfscluster\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access Ambari view of cluster,0.442552855,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,Ambari UI not accessible.,"Unknown, cx says they were unable to access ambari but the issue is resolved.","Per previous engineer's instructions, Check what is taking so much space and clean up space on hn1;Restart ambari server on hn0;Reboot entire hn0 node if issue persists;Based on active headnode host, we might need to ssh into existing nodes and adjust that info manually.SSH onto the nodes, given from Support Engineer, within the HDInsight cluster tapcfsclusterOpen the hosts files vi /etc/hostsUpdate the host files with the headnodehost pointing to the other headnodeSave and close the fileTried reaching engineer to confirm cause and if anything else past this was done, but did not get confirmation.",,,,,,,,
1.20061E+14,49:00.7,Not able to create HDInsight cluster because quota limits,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: create HDInsight cluster \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: •Issue Definition: Not able to create HDInsight cluster because quota limits\n•Issue Details: We need increase limit for the below {NAMEPII} sizes\nStandard Ev3 ({Namepii} Europe) – {Namepii} Limit 500\n•Error {Namepii} shot or Log file to be attached or any relevant information: PFA\n•What Troubleshooting has been done so far: NA\n•Issue with technology: HDInsights\n\nSubscription ID: {guidpii}\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - create HDInsight cluster ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - •Issue Definition: Not able to create HDInsight cluster because quota limits\n•Issue Details: We need increase limit for the below {NAMEPII} sizes\nStandard Ev3 ({Namepii} Europe) – {Namepii} Limit 500\n•Error {Namepii} shot or Log file to be attached or any relevant information: PFA\n•What Troubleshooting has been done so far: NA\n•Issue with technology: HDInsights\n\nSubscription ID: {guidpii}\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Production\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to create HDInsight cluster because quota limits,30.06363737,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Symptom:120060621000707 - Not able to create HDInsight cluster because quota limits Issue:The HDInsight cluster deployment failed at 2020-06-06 12:55:23 UTC and again at 2020-06-06 14:09:24 UTC,Default HDInsight quota was not added to the subscription due to COVID-19 related capacity issues in West Europe region.,"RCA Information:The Capacity team needed to increase the HDInsight quota. Generally, this would have been added automatically without a need to request a quota increase per the documentation: https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#data-factory-limits  However, due to COVID-19 capacity issues in the West Europe region, the default HDInsight quota was not allocated to subscription: 8fb798c1-69db-4225-a9b3-3987a99f9299. The quota increase request was made on 06/06/2020 17:51 and completed by 06/06/2020 18:20.  After that, the HDInsight cluster was successfully deployed.","191,200,599,191,978,000",,,,,,,
1.20061E+14,39:36.0,unable to scaleup tapcfs cluster,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 6, 2020, 7:30 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No Change\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We are unable to scaleup tapcfs cluster. \nerror: Failed to scale the HDInsight cluster tapcfscluster.The cluster has {Alphanumericpii} please retry your scale request.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No Change;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We are unable to scaleup tapcfs cluster. \nerror: Failed to scale the HDInsight cluster tapcfscluster.The cluster has {Alphanumericpii} please retry your scale request.;\n\n- ProblemStartTime: 06/06/2020 14:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT - Tax - 01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d75945a5-535f-4626-9d68-075eedbcf430/resourceGroups/11814-OneTax-Prod-01/providers/Microsoft.HDInsight/clusters/tapcfscluster\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to scaleup tapcfs cluster,0.13141176,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,We see the scale up fails with the message “Unable to connect to cluster management endpoint to perform scaling operation. Please verify network security rules are not blocking external access to the cluster and that cluster manager (Ambari) UI can be successfully accessed.” But this is a standard deployment with no VNET so there is no way for an NSG to cause issues.,Seems to be a transient issue with the gateway nodes of the cluster,PG rebooted gateway nodes and customer has been able to successfully scale since.,191209837,,,,,,,
1.20061E+14,04:29.8,unable to add new edge node,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 5, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: unable to add new edge node to the cluster\n\nhttps://management.azure.com/subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl/applications/devairflow-en-1?api-version=2015-03-01-preview\n\nerror doesn't provide any specific details.\nAzureResourceCreation operation didn't succeed for adding application {ApplicationName: {alphanumericpii}, ApplicationId: 57747}. Operation status: Failed\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - Other, don't know or not applicable;\nDoes the user account work with other Azure services? - Other, don't know or not applicable;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - unable to add new edge node to the cluster\n\nhttps://management.azure.com/subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl/applications/devairflow-en-1?api-version=2015-03-01-preview\n\nerror doesn't provide any specific details.\nAzureResourceCreation operation didn't succeed for adding application {ApplicationName: {alphanumericpii}, ApplicationId: 57747}. Operation status: Failed\n;\n\n- ProblemStartTime: 06/05/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to add new edge node,0.88977067,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,unable to add new edge node,"The edgenode deployment failed with a policy violation -- the hdinsight cluster needs two public IP addresses along with 1 public IP address per edgenode. The template deployment failed because of policy violation. Please see details for more information.\"",\""Details\"":[{\""Code\"":\""RequestDisallowedByPolicy\"",\""Message\"":\""Resource 'publicIpgateway-4b458b27c1e8428783d8847dbcc6aebc' was disallowed by policy. Policy identifiers: '[{\\\""policyAssignment\\\"":{\\\""name\\\"":\\\""Not allowed resource types\\\"",\\\""id\\\"":\\\""/providers/Microsoft.Management/managementGroups/fabb61b8-3afe-4e75-b934-a47f782b8cd7/providers/Microsoft.Authorization/policyAssignments/c7c08af1cdeb4139ae4de683\\\""},\\\""policyDefinition\\\"":{\\\""name\\\"":\\\""Not allowed resource types\\\"",\\\""id\\\"":\\\""/providers/Microsoft.Management/managementGroups/fabb61b8-3afe-4e75-b934-a47f782b8cd7/providers/Microsoft.Authorization/policyDefinitions/f6e470f3-a275-4896-9da2-981914ef4c05\\\""}} ",As a mitigation you can remove the policy and retry deployment and add it back once done.  Referance Doc: https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/hdinsight-troubleshoot-cluster-creation-fails#resource-policy-restrictions,,,,,,,,
1.20061E+14,44:51.3,scriptaction,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 6, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: unable to add new edge nodes. provisioning is failing with Conflict. no further details are provided. tried this or different cluster as well and opened another ticket (ref {Phonenumberpii})\n\n    'resourceId': '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourcegroups/RG-RTL-RxPerso-Dev/providers/Microsoft.HDInsight/clusters/rxp03-dev-hdi-rtl/applications/test2new-edgenode',\n    'status': {\n        'value': 'Failed',\n        'localizedValue': 'Failed'\n    },\n    'subStatus': {\n        'value': '',\n        'localizedValue': ''\n    },\n    'submissionTimestamp': '{ALPHANUMERICPII}',\n    'subscriptionId': '{guidpii}',\n    'tenantId': '{guidpii}',\n    'properties': {\n        'statusCode': 'Conflict',\n        'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceDeploymentFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\n        'category': 'Administrative'\n    },\n    'relatedEvents': []\n}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - unable to add new edge nodes. provisioning is failing with Conflict. no further details are provided. tried this or different cluster as well and opened another ticket (ref {Phonenumberpii})\n\n    'resourceId': '/subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourcegroups/RG-RTL-RxPerso-Dev/providers/Microsoft.HDInsight/clusters/rxp03-dev-hdi-rtl/applications/test2new-edgenode',\n    'status': {\n        'value': 'Failed',\n        'localizedValue': 'Failed'\n    },\n    'subStatus': {\n        'value': '',\n        'localizedValue': ''\n    },\n    'submissionTimestamp': '{ALPHANUMERICPII}',\n    'subscriptionId': '{guidpii}',\n    'tenantId': '{guidpii}',\n    'properties': {\n        'statusCode': 'Conflict',\n        'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceDeploymentFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\n        'category': 'Administrative'\n    },\n    'relatedEvents': []\n}\n;\n\n- ProblemStartTime: 06/06/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RxPerso-Dev/providers/Microsoft.HDInsight/clusters/rxp03-dev-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",scriptaction,0.320031095,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,unable to add new edge node,The edgenode deployment failed with a policy violation -- the hdinsight cluster needs two public IP addresses along with 1 public IP address per edgenode. The template deployment failed because of policy violation. Please see details for more ,As a mitigation you can remove the policy and retry deployment and add it back once done.  Referance Doc: https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/hdinsight-troubleshoot-cluster-creation-fails#resource-policy-restrictions,,,,,,,,
1.20061E+14,39:43.2,Spark Pipelines are failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: Spark piplines are failing to submit job to Spark cluster.\nWhen we restarted server from ssh, was showing 'unable to bind port' error. Please check attached error screenshot.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - NA;\nAdditional details about the issue - Spark piplines are failing to submit job to Spark cluster.\nWhen we restarted server from ssh, was showing 'unable to bind port' error. Please check attached error screenshot.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BAT PaaS Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d421e7ee-e2bc-4ca8-8db5-6cd8370e1c1a/resourceGroups/RG-PP-NE-PetraAnalytics-prod-01/providers/Microsoft.HDInsight/clusters/bathdi-pp-ne-petra-spark-prod-02\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Pipelines are failing,0.022242887,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Spark,"Customer was experencing multiple spark jobs  triggered from ADF not working (timed out) over night.From ADF, and together with IcM team, we checked the trace logs for some of the timed out run ids, but the logs were inconclusive, as it seems it was expected for the jobs to be timed out after 1h.",The communication between livy and ADF was broken,Restart Livy server,191394110,,,,,,,
1.20061E+14,37:05.2,Issue with Hive while Storing Streaming Data,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 2, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: I have a Kafka Streaming Consumer job which stores the data in Hive table. The issue is that sometimes the job fails due to Hive and has to be restarted again. This is happening with all the streaming consumer jobs which are trying to access Hive. Not able to trace the reason\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I have a Kafka Streaming Consumer job which stores the data in Hive table. The issue is that sometimes the job fails due to Hive and has to be restarted again. This is happening with all the streaming consumer jobs which are trying to access Hive. Not able to trace the reason. \nHiveMetaStoreClient: Trying to connect to metastore with URI thrift://hn1-phsp02.domainservices.ncr.com:9083\n\n\nWARN HiveClientImpl: HiveClient got thrift exception, destroying client and retrying\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - I have a Kafka Streaming Consumer job which stores the data in Hive table. The issue is that sometimes the job fails due to Hive and has to be restarted again. This is happening with all the streaming consumer jobs which are trying to access Hive. Not able to trace the reason;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I have a Kafka Streaming Consumer job which stores the data in Hive table. The issue is that sometimes the job fails due to Hive and has to be restarted again. This is happening with all the streaming consumer jobs which are trying to access Hive. Not able to trace the reason. \nHiveMetaStoreClient: Trying to connect to metastore with URI thrift://hn1-phsp02.domainservices.ncr.com:9083\n\n\nWARN HiveClientImpl: HiveClient got thrift exception, destroying client and retrying;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/02/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/04af94d4-74f4-4642-b571-5b48a42b979f/resourceGroups/ITS-APPOPS-EDL-PROD-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/PHSP02ADLSPARK\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Issue with Hive while Storing Streaming Data,1.196491228,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,Issue with Hive while Storing Streaming Data,the DTU of the Azure SQL Server (Metastore DB) reached 100%,Increasing the DTU in the Azure SQL DB(metastore) ,,,,,,,,
1.20061E+14,37:45.4,YARN logs between 6/1~6/5 missing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: N/A\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - N/A;\nAdditional details about the issue - N/A;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-EUR-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a43beb5c-af15-4c6a-ab5e-c4ba0fbeee47/resourceGroups/o365ipdieur01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdieur01-sp-ne01\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",YARN logs between 6/1~6/5 missing,23.30743798,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unexpected result\Spark,Missing YARN logs in YARN UI,Unknown,"YARN logs retention period is 7 days for this cluster.Not all the application was accessible via YARN UI because of the limitation in the YARN UI, and it replaces the oldest one to new ones.Advised customer to find the YARN logs via ssh to head node if it is not available in the YARN UI.",,,,,,,,
1.20061E+14,58:25.1,Cluster creation failed,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 8, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: The cluster creation consistently fails around 8 minutes after the creation request is submitted\n\nAt this stage, we don't see any Network Interface or Sub-Deployment created\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - The cluster creation consistently fails around 8 minutes after the creation request is submitted\n\nAt this stage, we don't see any Network Interface or Sub-Deployment created;\n\n- ProblemStartTime: 06/07/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/77734520-d076-4cc8-9a7f-4ec365d0a655/resourceGroups/central-DEV-Central-Spark-Automation-HDI/providers/Microsoft.HDInsight/clusters/sSxP8XQYFz-CentralSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster creation failed,0.254130565,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Cluster creation failed,It occurred due to lack of connection between our services and AAD DS instance when creating OU container.,The issue was resolved and customer should be unblocked by now. It is a known problem and the fix will be introduced eventually.  Current workaround was to reboot both master and replica DCs.,191453787,,,,,,,
1.20061E+14,01:20.5,[Azure Government] The resource is supposed to be delete automatically,"[Azure Government] Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Never worked\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Data Factory Activity\n\nQuestion: Additional details about the issue\nAnswer: The expectation was to get the hd insights  deleted automatically but it is stuck.\nmore details can be provided by point of contact of the ticket\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Never worked;\nHow was the CRUD request submitted? - Azure Data Factory Activity;\nAdditional details about the issue - The expectation was to get the hd insights  deleted automatically but it is stuck.\nmore details can be provided by point of contact of the ticket;\n\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Azure Government Enterprise Puerto {Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/92f9d316-c230-4ced-81f7-c854b88d41d2/resourceGroups/integration-Puerto-{Namepii}-Test/providers/Microsoft.HDInsight/clusters/o51af144e-9c4f-40f0-9c5f-db40ad02e465\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] The resource is supposed to be delete automatically,0.121267749,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Delete HDInsight cluster, the HDI on demand cluster deployed by ADF activity is not getting deleted after its life cycle,Bug ,Manually delete cluster or use standard HDI cluster,,,,,,,,
1.20061E+14,49:18.1,no active RM on cluster,"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 7, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} does not active RM and is not scaling up. Service is out and our production scoring is blocked for today. :(\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} does not active RM and is not scaling up. Service is out and our production scoring is blocked for today. :(;\n\n- ProblemStartTime: 06/07/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-PROD-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24customeraiprod\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",no active RM on cluster,0.0461102,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Hadoop,120060821007094 no active RM on cluster HDInsight Service,Cluster was scaled down to 1 worker node which left one unreplicated block in HDFS,We ran the following to check and fix the HDFS replication error:hdfs fsck hdfs://mycluster/hdfs fsck hdfs://mycluster/ -delete,"191,465,896,191,465,000,000,000,000",,,,,,,
1.20061E+14,09:54.7,Hive Insert Failure - Memory Heap issue ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 8, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: insert overwrite table {AlphanumericPII} partition(PART_DATE,PART_TNAME,PART_SYM)\nselect --a.*,\nx_toptag,\nx_gaotag,\nx_gptag,\nx_depth,\nx_lostamp,\nx_route,\nx_exchtag,\nx_sreg,\nx_dreg,\nx_reg,\nx_state,\nx_sym,\nx_transactionkey,\nhdr_msg_src,\nhdr_recv_tsmp,\nhdr_desk_id,\nexecprc,\ndreg,\nclitag,\n{alphanumericpii},\ngptag,\ngaotag,\n{alphanumericpii},\nacct,\naccflat,\naostamp,\naotag,\nsreg,\natype,\ncbrk,\ncxlstate,\ndesk,\ndestuser,\ndup_oaotag,\nexchtag,\nfaftag,\n{alphanumericpii},\nloc,\nmktheld,\noaotag,\noatsrpt,\nopinst,\nosize,\nostamp,\nouser,\n{alphanumericpii},\npinst,\nptag,\nqdone,\nqopen,\nside,\nqty,\nsym,\ntif,\ntname,\ntnum,\nutext,\nxstamp,\nexec_stamp,\naftag,\nstate,\nclient,\nfaotag,\nopnclo,\nputcall,\nprodtype,\nstl,\naon,\nmatdate,\nsprice,\nfuser,\nterms,\nfdesk,\nexch,\nstamp,\nodesk,\ntradedate,\ngaftag,\ncstamp,\nupd,\ndloc,\nappl,\nscurr,\nsrvid,\nbarcon,\nruletype,\nwave,\nswacct,\nbcurr,\nestamp,\ntactic,\ncross_tmp,\ncuser,\nforigin,\ngtag,\n{alphanumericpii},\nstext,\ncacct,\nsol,\ncomm,\navgprc,\ndiscr,\ndeliv,\nlshares,\nltext,\nxacct,\nltflag,\nlocal_cstamp,\nttrade,\ncompress_flag,\ninstid,\ninsttype,\nundid,\nvwaptag,\nebrk,\nbrassrpt,\nftradeid,\nxftag,\nbstate,\nppinst,\npsize,\nbosys,\ndaj,\notradeid,\nisoind,\nexceptcode,\noptoutflag,\nbid,\nask,\nexecid,\n{alphanumericpii},\nstopprc,\nroutetype,\nbrseqnum,\nsorid,\nextrigger,\nroutetext,\ngfaftag,\nordertype,\ninvestid,\ngwaveid,\nggtag,\nioi,\nfacilsize,\nclordid,\nclrinst,\noetype,\nssexemptcode,\nauttrade,\ntxstamp,\nxtzoffset,\nundclient,\nnbbobid,\nnbboask,\naconf,\nsubwave,\nstoptime,\nhsize,\nappseqno,\nentity,\nlastmarket,\ndatype,\noatsmodifier,\nfillcondition,\natsordertype,\nnbbotime,\nexecutionnbbotime,\nquotesize,\nquoteprice,\nsrvcname,\nunsolicitedout,\nexchangeordertag,\nadjusttktprice,\ngatewayid,\nworkingprice,\nminacceptableqty,\npeginstructions,\nosi_symbol,\ntransactionkey,\nindicator,\nplflag,\nfdid,\nhandlinginstructions,\nmpid,\nrundate,\nsource,\naceflag,\n20200501 as PART_AS_OF_DT,\nupper(a.tname) as PART_TNAME,\n{alphanumericpii}) as PART_SYM\nfrom {alphanumericpii} a\nINFO  : Query ID = {alphanumericpii}\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Insert query from the beeline command fails with memorry issues which requires further investegation to understand the root cause. \n\nAttached the following logs for reference: \na) Beeline command Log \nb) {Namepii} logs \nc) Yarn Application log \nd) syslogs \n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - insert overwrite table {AlphanumericPII} partition(PART_DATE,PART_TNAME,PART_SYM)\nselect --a.*,\nx_toptag,\nx_gaotag,\nx_gptag,\nx_depth,\nx_lostamp,\nx_route,\nx_exchtag,\nx_sreg,\nx_dreg,\nx_reg,\nx_state,\nx_sym,\nx_transactionkey,\nhdr_msg_src,\nhdr_recv_tsmp,\nhdr_desk_id,\nexecprc,\ndreg,\nclitag,\n{alphanumericpii},\ngptag,\ngaotag,\n{alphanumericpii},\nacct,\naccflat,\naostamp,\naotag,\nsreg,\natype,\ncbrk,\ncxlstate,\ndesk,\ndestuser,\ndup_oaotag,\nexchtag,\nfaftag,\n{alphanumericpii},\nloc,\nmktheld,\noaotag,\noatsrpt,\nopinst,\nosize,\nostamp,\nouser,\n{alphanumericpii},\npinst,\nptag,\nqdone,\nqopen,\nside,\nqty,\nsym,\ntif,\ntname,\ntnum,\nutext,\nxstamp,\nexec_stamp,\naftag,\nstate,\nclient,\nfaotag,\nopnclo,\nputcall,\nprodtype,\nstl,\naon,\nmatdate,\nsprice,\nfuser,\nterms,\nfdesk,\nexch,\nstamp,\nodesk,\ntradedate,\ngaftag,\ncstamp,\nupd,\ndloc,\nappl,\nscurr,\nsrvid,\nbarcon,\nruletype,\nwave,\nswacct,\nbcurr,\nestamp,\ntactic,\ncross_tmp,\ncuser,\nforigin,\ngtag,\n{alphanumericpii},\nstext,\ncacct,\nsol,\ncomm,\navgprc,\ndiscr,\ndeliv,\nlshares,\nltext,\nxacct,\nltflag,\nlocal_cstamp,\nttrade,\ncompress_flag,\ninstid,\ninsttype,\nundid,\nvwaptag,\nebrk,\nbrassrpt,\nftradeid,\nxftag,\nbstate,\nppinst,\npsize,\nbosys,\ndaj,\notradeid,\nisoind,\nexceptcode,\noptoutflag,\nbid,\nask,\nexecid,\n{alphanumericpii},\nstopprc,\nroutetype,\nbrseqnum,\nsorid,\nextrigger,\nroutetext,\ngfaftag,\nordertype,\ninvestid,\ngwaveid,\nggtag,\nioi,\nfacilsize,\nclordid,\nclrinst,\noetype,\nssexemptcode,\nauttrade,\ntxstamp,\nxtzoffset,\nundclient,\nnbbobid,\nnbboask,\naconf,\nsubwave,\nstoptime,\nhsize,\nappseqno,\nentity,\nlastmarket,\ndatype,\noatsmodifier,\nfillcondition,\natsordertype,\nnbbotime,\nexecutionnbbotime,\nquotesize,\nquoteprice,\nsrvcname,\nunsolicitedout,\nexchangeordertag,\nadjusttktprice,\ngatewayid,\nworkingprice,\nminacceptableqty,\npeginstructions,\nosi_symbol,\ntransactionkey,\nindicator,\nplflag,\nfdid,\nhandlinginstructions,\nmpid,\nrundate,\nsource,\naceflag,\n20200501 as PART_AS_OF_DT,\nupper(a.tname) as PART_TNAME,\n{alphanumericpii}) as PART_SYM\nfrom {alphanumericpii} a\nINFO  : Query ID = {alphanumericpii}\n;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Beeline;\nAdditional details about the issue - Insert query from the beeline command fails with memorry issues which requires further investegation to understand the root cause. \n\nAttached the following logs for reference: \na) Beeline command Log \nb) {Namepii} logs \nc) Yarn Application log \nd) syslogs \n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/08/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_DEV\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/gm_cloudreg_qa-workload-{namepii}/providers/Microsoft.HDInsight/clusters/lyy2yg-oatsext-20200608-creg-qa-hdi\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Insert Failure - Memory Heap issue ,0.021913404,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Hive Insert Failure - Memory Heap issue,"The underlying RCA for the failures is ultimately to due insufficient memory for both the GC limit reached error and large GC time in the application. The mentioned sizing guide and memory tuning previously mentioned are the usual suspects of where this should resolve the error. However, given what we have tried is not effective, this points that the query itself is not optimal and causes severe memory pressure on the daemons. The cast, from_unixtime, unix_timestamp, substring, upper operators can each potentially cause an edge in the Tez Dag so there's good amount of upfront shuffle that occurs during mapper phase. One plan is to incrementally transform atn20200501.atn_tree_reg_view one by one so that you will not have to use any operators in your final query to produce the result you want.","About the substring partitioning piece. My various testing and investigations of substring showed that its functionality is working as designed, and it doesn’t appear that anything is wrong with it. In our investigation, we have tried to focus on understanding the underlying error and the mitigation step is supposed to be increasing the memory settings. Even with that step, we could still see there is a memory issue, in that “GC overhead limit reached” is designed to fail the query quickly so user can investigate it. There is an option to disable overhead limit checking, but that will just lead to Java heap OOM. The focus then, we tried to pivot and formulate a new execution plan that will work. Reason why I asked about column key cardinality is because the total number of partitions created might actually be too much for Hive to handle even after increasing the memory settings. You can actually calculate this theoretical number where (cardinality column key1) x (cardinality column key2) x (cardinality column key3). Based on the information given, two of the columns (which are dates) come from an infinite set, which is not ideal. Even adding a third partition will increase the number of partitions by at least 1 order. For a simplified example, if column1 and column2 have 365 degrees, and column3 26, that would translate to 365 x 365 x 26 = 3.4 million partitions. Having too many partitions can also slowdown the metadata operations during query compilation and also in general slowdown the system due to few housekeeping background tasks in HMS referring to partitions metadata. Our recommendation is to partition the data in high level (using a finite set) but use bucketing or clustering options to speed up the query performance on such partitioned tables.",191853351,,,,,,,
1.20061E+14,54:58.4,Error while unzip and copying data using hadoop command,"Eariler issue reoccurred - Please refer to the support ticket - {Phonenumberpii} for all the details.\nResolution to add '-D {alphanumericpii}' is not helping to resolve this issue anymore.\nError: \n{AlphanumericPII}$ put: java.io.IOException\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\nCaused by: com.microsoft.azure.storage.StorageException: The block list may not contain more than 50,000 blocks.\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       at {AlphanumericPII})\n       ... 15 more\n\nProblem start date and time\n{Namepii}, {Namepii} 1, 2020, 12:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/01/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Business Intelligence\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error while unzip and copying data using hadoop command,23.82747243,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\hdfs commands do not work\WASB in cluster with Enterprise Security Package,rror while unzip and copying data using hadoop command, fs.azure.write.request.size. too small,"In your browser, go to the Ambari Web UI for your cluster. The URL is https://CLUSTERNAME.azurehdinsight.net, where CLUSTERNAME is the name of your cluster. When prompted, enter the admin name and password for the cluster.From the left side of the screen, select HDFS, and then select the Configs tab.In the Filter... field, enter fs.azure.write.request.size.Change the value from 262144 (256 KB) to the new value. For example, 4194304 (4 MB).",,,,,,,,
1.20061E+14,47:12.8,Scaling up failed,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer:   'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: InternalServerError; ErrorDescription: Encountered failure(s) scaling cluster to 5 nodes. Scaling operation partially succeeded with a final node count of 3. Scaling error code: InternalServerError. Scaling error message: Failed to setup hosts during scale up.{Uncpii}\n        'category': 'Administrative'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue -   'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: InternalServerError; ErrorDescription: Encountered failure(s) scaling cluster to 5 nodes. Scaling operation partially succeeded with a final node count of 3. Scaling error code: InternalServerError. Scaling error message: Failed to setup hosts during scale up.{Uncpii}\n        'category': 'Administrative';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Scaling up failed,0.799447078,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,120060824010500 - Scaling up Failed,There was an issue with Ambari on cluster ahd649dj,Cluster ahd649dj was successfully scaled up. Cluster ahd650dj had an issue with Hive queries which was resolved by removing the property tez.queue.name,191677816,,,,,,,
1.20061E+14,48:54.1,Yarn query failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: {Namepii}:livy\nName:extract.MEOCExtract\nApplication Type:SPARK\nApplication {AlphanumericPII}\nApplication {Alphanumericpii} (Higher Integer value indicates higher priority)\nYarnApplicationState:FAILED\n{Namepii}:default\nFinalStatus Reported by AM:FAILED\nStarted:{Namepii} {Namepii} 09 08:20:02 +0000 2020\n{Alphanumericpii}, {Alphanumericpii}\nTracking URL:History\nLog Aggregation Status:SUCCEEDED\nApplication Timeout (Remaining Time):Unlimited\nDiagnostics:\nApplication {alphanumericpii}\n\nQuestion: Additional details about the issue\nAnswer: {Namepii}:livy\nName:extract.MEOCExtract\nApplication Type:SPARK\nApplication {AlphanumericPII}\nApplication {Alphanumericpii} (Higher Integer value indicates higher priority)\nYarnApplicationState:FAILED\n{Namepii}:default\nFinalStatus Reported by AM:FAILED\nStarted:{Namepii} {Namepii} 09 08:20:02 +0000 2020\n{Alphanumericpii}, {Alphanumericpii}\nTracking URL:History\nLog Aggregation Status:SUCCEEDED\nApplication Timeout (Remaining Time):Unlimited\nDiagnostics:\nApplication {alphanumericpii} failed 1 times (global limit =5; local limit is =1) due to AM Container for {alphanumericpii} exited with exitCode: 13\nFailing this attempt.Diagnostics: [2020-06-09 {Alphanumericpii} from container-launch.\nContainer {namepii}: {alphanumericpii}\nExit code: 13\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - {Namepii}:livy\nName:extract.MEOCExtract\nApplication Type:SPARK\nApplication {AlphanumericPII}\nApplication {Alphanumericpii} (Higher Integer value indicates higher priority)\nYarnApplicationState:FAILED\n{Namepii}:default\nFinalStatus Reported by AM:FAILED\nStarted:{Namepii} {Namepii} 09 08:20:02 +0000 2020\n{Alphanumericpii}, {Alphanumericpii}\nTracking URL:History\nLog Aggregation Status:SUCCEEDED\nApplication Timeout (Remaining Time):Unlimited\nDiagnostics:\nApplication {alphanumericpii};\nAdditional details about the issue - {Namepii}:livy\nName:extract.MEOCExtract\nApplication Type:SPARK\nApplication {AlphanumericPII}\nApplication {Alphanumericpii} (Higher Integer value indicates higher priority)\nYarnApplicationState:FAILED\n{Namepii}:default\nFinalStatus Reported by AM:FAILED\nStarted:{Namepii} {Namepii} 09 08:20:02 +0000 2020\n{Alphanumericpii}, {Alphanumericpii}\nTracking URL:History\nLog Aggregation Status:SUCCEEDED\nApplication Timeout (Remaining Time):Unlimited\nDiagnostics:\nApplication {alphanumericpii} failed 1 times (global limit =5; local limit is =1) due to AM Container for {alphanumericpii} exited with exitCode: 13\nFailing this attempt.Diagnostics: [2020-06-09 {Alphanumericpii} from container-launch.\nContainer {namepii}: {alphanumericpii}\nExit code: 13;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-cat-workload-{namepii}/providers/Microsoft.HDInsight/clusters/fm26nx-cros-20200608-cat-prod-hdi\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Yarn query failing,1.508632995,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,Yarn query failing,Yarn query failing,"Root Cause: The issue has been root caused to a load balancer agent rollout which triggered an existing race condition in a networking driver on the storage nodes. When this issue is triggered, the storage node will stop accepting any new service endpoint connections. However, the node still continued to serve other storage traffic and the overall connectivity to the node was healthy. As a result of this, the fabric considered the node to be healthy and were not taken out of rotation. Since only a small percentage of traffic was affected and retries succeeded, our health checks also did not flag the issue since it was below our configured threshold.Mitigation: Initial mitigation efforts was manual recovery of identified unhealthy nodes. Subsequently, once the impacting agent rollout was identified, we paused the deployment to prevent any further impact. As nodes were being manually recovered, we established an automated node recovery fix to expedite the recovery process. Following the complete roll back of the impacting deployment and all unhealthy nodes were recovered, this incident was officially mitigated.","191,565,958,191,566,000,000,000,000,000,000,000",,,,,,,
1.20061E+14,41:53.5,Hiveserver2Interactive process is not stable,"Question: What time did the problem begin?\nAnswer: {Namepii}, Apr 16, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: A warning occurs on Hive during about 8 minutes before to disappear.\nDuring this period, the connection to Hive is interrupted and make fail the jobs which are currenrly deploying .\nI am using a interactive Hive {Namepii} linked with a Spark {Namepii}.\nThis warning appears several time a day. About one or two times each two hours.\nIt is not the first time I noticed this problem, I had this trouble on {AlphanumericPII} and also when I used a single Spark {Namepii}.\nWhat can be the root issue of the port connection interruption (port 10001) ?\nThanks for support\n\nThe warning is described as below :\n\nConnection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - A warning occurs on Hive during about 8 minutes before to disappear.\nDuring this period, the connection to Hive is interrupted and make fail the jobs which are currenrly deploying .\nI am using a interactive Hive {Namepii} linked with a Spark {Namepii}.\nThis warning appears several time a day. About one or two times each two hours.\nIt is not the first time I noticed this problem, I had this trouble on {AlphanumericPII} and also when I used a single Spark {Namepii}.\nWhat can be the root issue of the port connection interruption (port 10001) ?\nThanks for support\n\nThe warning is described as below :\n\nConnection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):;\n\n- ProblemStartTime: 04/16/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hiveserver2Interactive process is not stable,0.050364933,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,"Connection failed on host hn0-dsjd4l.azure.mvtdevdesjardins.com:10001 (Traceback (most recent call last):   File ""/var/lib/ambari-agent/cache/stacks/HDP/3.0/services/HIVE/package/alerts/alert_hive_interactive_thrift_port.py"",line 210, in execute     ldap_password=ldap_password)   File ""/usr/lib/ambari-agent/lib/resource_management/libraries/functions/hive_check.py"",line 84, in check_thrift_port_sasl     timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE,   File ""/usr/lib/ambari-agent/lib/resource_management/core/base.py"",line 166, in __init__     self.env.run()   File ""/usr/lib/ambari-agent/lib/resource_management/core/environment.py"",line 160, in run     self.run_action(resource, action)   File ""/usr/lib/ambari-agent/lib/resource_management/core/environment.py"",line 124, in run_action     provider_action()   File ""/usr/lib/ambari-agent/lib/resource_management/core/providers/system.py"",line 263, in action_run     returns=self.resource.returns)   File ""/usr/lib/ambari-agent/lib/resource_management/core/shell.py"",line 72, in inner     result = function(command, **kwargs)   File ""/usr/lib/ambari-agent/lib/resource_management/core/shell.py"",line 102, in checked_call     tries=tries, try_sleep=try_sleep, timeout_kill_strategy=timeout_kill_strategy, returns=returns)   File ""/usr/lib/ambari-agent/lib/resource_management/core/shell.py"",line 150, in _call_wrapper     result = _call(command, **kwargs_copy)   File ""/usr/lib/ambari-agent/lib/resource_management/core/shell.py"",line 308, in _call     raise ExecuteTimeoutException(err_msg) ExecuteTimeoutException: Execution of 'ambari-sudo.sh su ambari-qa -l -s /bin/bash -c 'export  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/bin/:/usr/bin/:/usr/lib/hive/bin/:/usr/sbin/ ;beeline -n hive -u '""'""'jdbc:hive2://hn0-dsjd4l.azure.mvtdevdesjardins.com:10001/;transportMode=http;httpPath=cliservice;principal=hive/_HOST@AZURE.MVTDEVDESJARDINS.COM'""'""'  -e '""'""';'""'""' 2>&1 | awk '""'""'{print}'""'""' | grep -i -e '""'""'Connected to:'""'""' -e '""'""'Transaction isolation:'""'""''' was killed due timeout after 60 seconds )","This issue happens when we have multiple jobs running via. yarn on the cluster taking up most of the yarn resources. It results in high yarn usage (>90%) which restricts new hive connections to be made. Hence, we see Connection Refused error.","Check the TSG: https://msdata.visualstudio.com/HDInsight/_wiki/wikis/HDInsight.wiki/8889/Hive_Server_Connection_Refused Increase the number of allowed connections using the confighive.server2.thrift.max.worker.threadsllap.shuffle.connection-keep-alive.timeout, set it from 60 to 120 secondshive.heapsize change it from 1024 to 4096 MBCheck with Customer if yarn usage can be lowered by reducing the number of long-running jobs at a time. Else, scale up the number of worker nodes to handle the load.",,,,,,,,
1.20061E+14,47:35.6,Transaction Aborted Error - Even after cleanup - lockException,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: ERROR : FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted)\norg.apache.hadoop.hive.ql.lockmgr.LockException: Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\nCaused by: TxnAbortedException(message:Transaction {alphanumericpii} already aborted)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result$commit_txn_resultStandardScheme.read(ThriftHiveMetastore.java)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result$commit_txn_resultStandardScheme.read(ThriftHiveMetastore.java)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result.read(ThriftHiveMetastore.java)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        ... 18 more\n\nError: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted) ({alphanumericpii})\n\n\nQuestion: How was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: Hbase issue\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - ;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ERROR : FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted)\norg.apache.hadoop.hive.ql.lockmgr.LockException: Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\nCaused by: TxnAbortedException(message:Transaction {alphanumericpii} already aborted)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result$commit_txn_resultStandardScheme.read(ThriftHiveMetastore.java)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result$commit_txn_resultStandardScheme.read(ThriftHiveMetastore.java)\n        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$commit_txn_result.read(ThriftHiveMetastore.java)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII} Source)\n        at {AlphanumericPII})\n        ... 18 more\n\nError: Error while processing statement: FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.lockmgr.LockException(Transaction manager has aborted the transaction {alphanumericpii}.  Reason: Transaction {alphanumericpii} already aborted) ({alphanumericpii})\n;\nHow was the HBase job submitted? - HBase shell;\nAdditional details about the issue - Hbase issue;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq041hbasefdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Transaction Aborted Error - Even after cleanup - lockException,3.892527763,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hbase,Transaction Aborted Error - Even after cleanup - lockException,Transaction Aborted Error - Even after cleanup - lockException,"Worked with customer and found GC pauses in metastore logs. Customer had change ""hive.fetch.task.conversion"" to none, and reduce hive server2 heapsize to increase hive metastore heapsize. Customer confirmed to close the case.",191647568,,,,,,,
1.20061E+14,51:58.9,Using .jar in Jupyter Notebooks,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We are using {alphanumericpii}' {Alphanumericpii} ADLS as primary storage for our '{alphanumericpii}' HDInsight 3.6 cluster. \n\nWe have adl://sigihdieastus2.azuredatalakestore.net/etl/jars/spark-avro_2.11-3.2.0.jar in our data lake. How can we leverage this JAR file in our Jupyter Notebook PySpark code?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nAdditional details about the issue - We are using {alphanumericpii}' {Alphanumericpii} ADLS as primary storage for our '{alphanumericpii}' HDInsight 3.6 cluster. \n\nWe have adl://sigihdieastus2.azuredatalakestore.net/etl/jars/spark-avro_2.11-3.2.0.jar in our data lake. How can we leverage this JAR file in our Jupyter Notebook PySpark code?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Using .jar in Jupyter Notebooks,0.108913561,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\Notebooks,120060924008825 - Using .jar in Jupyter Notebooks,The jar files are not accessible when stored in the Storage account.,"To leverage the jar in Python code, try changing the following:CLASSPATH:/usr/hdp/current/spark2-client/jarIf the above solution does not work after testing, customer will reopen the case.",,,,,,,,
1.20061E+14,28:37.4,Unable to SSH on HN0,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are unable to SSH on headnode 0. Please reboot it from backend and confirm us ASAP.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are unable to SSH on headnode 0. Please reboot it from backend and confirm us ASAP.;\n\n- ProblemStartTime: 06/09/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to SSH on HN0,0.020191809,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Unable to SSH on HN0,hn0 connection failure,JIT Access Reboot on hn0 ,,,,,,,,
1.20061E+14,23:19.3,"hdinsight script action fails, unable to find uri location, but the associated managed identity has blob owner on the storage account","Trying to use a Script Action with HDInsight cluster.  Have associated a managed identity with the cluster and the identity has been assigned Storage Data Blob Owner.\n\nHere's the error message:\n\nFailed to submit script action: '- Custom'\nErrorCode: InvalidScriptLocation; ErrorDescription: Failed to validate script action at URI https://valleyofthewind.blob.core.windows.net/common/test-script-action.sh. Exception message: Script URI cannot be retrieved correctly. HTTP Status code: NotFound.\n\nProblem start date and time\n{Namepii}, {Namepii} 8, 2020, 12:00 AM CDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/08/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Engineering Sandbox\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: centralus\n- ResourceUri: /subscriptions/200cdc10-c664-4977-adb3-edf02fb85d6c/resourceGroups/hdinsight-spark-poc/providers/Microsoft.Storage/storageAccounts/valleyofthewind\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","hdinsight script action fails, unable to find uri location, but the associated managed identity has blob owner on the storage account",1.033711809,Root Cause : HDInsight Service\Bug\HDInsight,Routing ADLS Gen2 Storage\Authentication and Authorization\Issues using Access Control Lists (ACLs),HD Insight fails to execute script action from a script file in blob storage,HDI was not using the AD credentials that were provided in the setup that are needed to access private blobs,A few alternatives have been discussed. - Using a SAS token appended to the URI of the script to authorize the access- Making the blobs in the container publicly accessible,,,,,,,,
1.20061E+14,37:54.4,just says resource in error state,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 2:00 PM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: {\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'code\\': \\'Conflict\\',\\r\\n  \\'message\\': \\'We found an existing cluster in our records with name '{alphanumericpii}' in Error state. Please try again after deleting this existing cluster.\\'\\r{uncpii}\n    }\n  ]\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - {\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'code\\': \\'Conflict\\',\\r\\n  \\'message\\': \\'We found an existing cluster in our records with name '{alphanumericpii}' in Error state. Please try again after deleting this existing cluster.\\'\\r{uncpii}\n    }\n  ]\n};\n\n- ProblemStartTime: 06/09/2020 19:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/65758bd8-d410-4614-8fb0-5b5c9d70c9ab/resourceGroups/ssp-lct-cld-sbx-01/providers/Microsoft.HDInsight/clusters/kaf-ssp-lct-cld-sbx-01\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",just says resource in error state,0.315782559,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,just says resource in error state,"add some interval time between delete and re-create steps, that give Azure to delete the previous resource fully.","found some story behind the deployment failure. 1, We checked ARM internal logs, found your cluster failed with a httpcode 409, which means you tried to put ARM request with same parameters again even there was a failed same cluster existed.2, We also saw a delete request but it seems came before creation cluster <Here is our recommendation>Make sure your delete request is totally successful, for example you can send Get request to delete again, if return code is 404, it means source is not existed you can go on to create same cluster again. Because you are using automation process, better see how to embed the logic into the process.",191687572,,,,,,,
1.20061E+14,18:08.1,fd sandbox - kps106llapfdsbwus201 - Cluster not coming up,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM PDT\n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: New cluster was created for standby. {Namepii} has multiple issues. Could not login to cluster with service accounts, Unable to use cluster \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - New cluster was created for standby. {Namepii} has multiple issues. Could not login to cluster with service accounts, Unable to use cluster ;\n\n- ProblemStartTime: 06/10/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-rg-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps106llapfdsbwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",fd sandbox - kps106llapfdsbwus201 - Cluster not coming up,22.40722105,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Could not login to cluster with service accounts,",It seems this is likely related to LDAP admin sync issues that are being addressed in Workitem 782178 (Internal number just for reference).The work item does the following:We start ldap sync using a cron job* Runs on headnodes at 17th minutes* Waits for the machine to be up for 60 minutes* Runs on alternative hours on hn0 and hn1This is guaranteed not to complete during cluster creation. RP waiting for this is meaningless. We will push the task of marking the domain user as ambari admin in the cron job itself.,The resolution was to add the admin to the domain user manually.,195831790,,,,,,,
1.20061E+14,35:57.9,Getting error in hive meta store log,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: The command I tried to execute:\nALTER TABLE prodoperationaldb.invoice_line_fact PARTITION (country_code='{NAMEPII}',invoice_year='2020',year='2020',month='6') COMPACT 'MAJOR';\n“\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: I tried executing a compaction, but we get this error in hive meta store log:\nWARN [{Alphanumericpii}] compactor.Initiator: Will not initiate compaction for prodoperationaldb.invoice_line_fact.country_code={NAMEPII}/invoice_year=2020/year=2020/month=6 since last hive.compactor.initiator.failed.compacts.threshold attempts to compact it failed.\n \n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - The command I tried to execute:\nALTER TABLE prodoperationaldb.invoice_line_fact PARTITION (country_code='{NAMEPII}',invoice_year='2020',year='2020',month='6') COMPACT 'MAJOR';\n“\n;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - I tried executing a compaction, but we get this error in hive meta store log:\nWARN [{Alphanumericpii}] compactor.Initiator: Will not initiate compaction for prodoperationaldb.invoice_line_fact.country_code={NAMEPII}/invoice_year=2020/year=2020/month=6 since last hive.compactor.initiator.failed.compacts.threshold attempts to compact it failed.\n \n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BAT PaaS Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d421e7ee-e2bc-4ca8-8db5-6cd8370e1c1a/resourceGroups/RG-PP-NE-PetraAnalytics-prod-01/providers/Microsoft.HDInsight/clusters/bathdi-pd-{namepii}-petra-sparkhive-v4-prod-01\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting error in hive meta store log,0.315348432,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,User wasn't authorized to submits jobs,Compact jobs which ran with hive user doesn’t have permissions to ingest the data into the directory. ,Change the user and hive compactor properties; set hive.compactor.history.retention.succeeded=5; set hive.compactor.initiator.failed.compacts.threshold=4,,,,,,,,
1.20061E+14,18:09.2,Yarn - Application logs not showing in Ambari. Getting HTTP error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Getting Error 'HTTP Error 502.3 - Bad Gateway' when trying to view Application logs in Yarn. Attached file has the error log.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Getting Error 'HTTP Error 502.3 - Bad Gateway' when trying to view Application logs in Yarn. Attached file has the error log.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Hadoop Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fa0c299b-5b6f-4eae-b45b-dfaa177d967b/resourceGroups/hdicluster-prod-rg/providers/Microsoft.HDInsight/clusters/azcu-hdi\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Yarn - Application logs not showing in Ambari. Getting HTTP error,0.020796765,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Yarn - Application logs not showing in Ambari. Getting HTTP error,"Based on conversation with CX, they restarted metastore DB in ESP cluster and not able to access Yarn AppID Log with error message - 502.3 bad gateway",Restarted head node in Ambari Host UI on CX end,,,,,,,,
1.20061E+14,28:24.8,Headnode is down,Headnode of cluster rblivprocessingcluster is down.\n\nSubscription: REBUS_PRODUCTION_INSIGHTS\nSubscription ID: {guidpii}\nResource Group: {ALPHANUMERICPII}\n{Namepii} Name: rblivprocessingcluster\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: REBUS_PRE-PRODUCTION\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Headnode is down,20.81100953,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Headnode down ,"The mounting of some external SMB share and running some custom init scripts that should not be on the headnode.  Instead they should use an edge node to run custom workloads.The mouned SMB/CIFS share looks to be unstable and that could cause long delays when been accessed, especially during boot time.  Also the user's init script looks to contain some errors too.All these are not valid and supported usage scenarios. ",Unknown,"191,827,246,191,854,000",,,,,,,
1.20061E+14,05:47.7,Cluster is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network),"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 11, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: {Namepii} is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network)\nError: Could not establish connection to \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network)\nError: Could not establish connection to \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - {Namepii} is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network)\nError: Could not establish connection to ;\nAdditional details about the issue - {Namepii} is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network)\nError: Could not establish connection to ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/10/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-psdemandforecast-prod-001/providers/Microsoft.HDInsight/clusters/hdihddemandforecastpsprod\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is good to access internally from Ambari. But connection fails when try to connect external (outside HDInsight network),0.991750854,Root Cause : HDInsight Service\Azure platform issues\Networking issue,Routing Azure HDInsight V5\Ambari UI is not loading,120061024009957 Intermittent connection issues to the Hive service from outside of the Virtual Network,  The      active headnode was showing as hn1 but all of the services were not      running on headnode 1  Ambari      was throwing bind exceptions which was causing high CPU on the headnode 1,"  Rebooted      headnode 0 to failover the active services to headnode 1. Headnode 0 had      some issues coming back up due to a change in the resolv.conf file.      Customer updated the resolve.conf to fix that issue.  We also      found that the bind exceptions were caused by 2 Ambari Server processes      running on headnode 1  Killed      all of the Ambari Server processes on headnode 1 and then ran the      following to restart the Ambari Server service:sudo service ambari-server start  After      that, the CPU issue returned to normal on headnode 1  Also      provided customer the information to purge the Ambari DB if they see the      dashboard is loading slowly:CLUSTERNAME=<clustername>sudo service ambari-server stopsudo ambari-server db-purge-history --cluster-name=$CLUSTERNAME --from-date=$(date +%Y-%m-%d -d ""15 day ago"")sudo service ambari-server start",,,,,,,,
1.20061E+14,09:18.3,Different issues regarding connection to SparkHistory,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: A few users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does kinit for some or all users work from the Head node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster admin account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local admin and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hello,\n\nI've selected 'Ambari' in the dropdownlist to create the ticket but the issue is related to SparkHistory.\n\n1. I try to connect to SparkHistory using this url : https://dsjd4sparkbi-int.azurehdinsight.net/sparkhistory/\n2. I have added the username from AD in the folowing properties in {Alphanumericpii} service : \n - spark.admin.acls\n- spark.history.ui.admin.acls\n- spark.acls.enable : true\n- spark.history.ui.acls.enable : true\n3.I have two different scnearios depending of the user when I try to connect :\n - A user that is member of many groups in AD will have the following error message : Bad Message 431 : reason : Request Header Fields Too Large.\nI already have this problem for hive service, to fix it I have added the property : {alphanumericpii} = 64000\nand {alphanumericpii}.\nI'm not sure of what I have to add in order to fix it for SparkHistory\n- The secod scenario is that the user hasn't a big Header Field, but hasn't authorization, the error message is the following one : \nHTTP ERROR 403\nProblem accessing /{alphanumericpii}/. Reason:\nUser is not authorized to access this page.\n\nSo to summarize I have two different behavior that I would like to fix in order to give access to some users to SparkHistory interface.\n\nThanks for your help!\nBest regqrds,\n{Namepii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - A few users;\nDoes the user account work with other Azure services? - Other, don't know or not applicable;\nDoes kinit for some or all users work from the Head node? - ;\nDoes authentication fail even for the cluster admin account? - ;\nHave you logged in to Ambari as local admin and verified the users have been synced? - ;\nAdditional details about the issue - Hello,\n\nI've selected 'Ambari' in the dropdownlist to create the ticket but the issue is related to SparkHistory.\n\n1. I try to connect to SparkHistory using this url : https://dsjd4sparkbi-int.azurehdinsight.net/sparkhistory/\n2. I have added the username from AD in the folowing properties in {Alphanumericpii} service : \n - spark.admin.acls\n- spark.history.ui.admin.acls\n- spark.acls.enable : true\n- spark.history.ui.acls.enable : true\n3.I have two different scnearios depending of the user when I try to connect :\n - A user that is member of many groups in AD will have the following error message : Bad Message 431 : reason : Request Header Fields Too Large.\nI already have this problem for hive service, to fix it I have added the property : {alphanumericpii} = 64000\nand {alphanumericpii}.\nI'm not sure of what I have to add in order to fix it for SparkHistory\n- The secod scenario is that the user hasn't a big Header Field, but hasn't authorization, the error message is the following one : \nHTTP ERROR 403\nProblem accessing /{alphanumericpii}/. Reason:\nUser is not authorized to access this page.\n\nSo to summarize I have two different behavior that I would like to fix in order to give access to some users to SparkHistory interface.\n\nThanks for your help!\nBest regqrds,\n{Namepii};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4sparkbi\n- Location: canadaeast\n- Location: Canada East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Different issues regarding connection to SparkHistory,2.125898799,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package," A user that is member of many groups in AD will have the following error message : Bad Message 431 : reason : Request Header Fields Too Large. I already have this problem for hive service, to fix it I have added the property : hive.server2.thrift.http.request.header.size = 64000 and hive.server2.thrift.http.response.header.size=64000. I'm not sure of what I have to add in order to fix it for SparkHistory - The secod scenario is that the user hasn't a big Header Field, but hasn't authorization, the error message is the following one :  HTTP ERROR 403 Problem accessing /history/application_1591273077058_0001/1/jobs/. Reason: User is not authorized to access this page."," A user that is member of many groups in AD will have the following error message : Bad Message 431 : reason : Request Header Fields Too Large. I already have this problem for hive service, to fix it I have added the property : hive.server2.thrift.http.request.header.size = 64000 and hive.server2.thrift.http.response.header.size=64000. I'm not sure of what I have to add in order to fix it for SparkHistory - The secod scenario is that the user hasn't a big Header Field, but hasn't authorization, the error message is the following one :  HTTP ERROR 403 Problem accessing /history/application_1591273077058_0001/1/jobs/. Reason: User is not authorized to access this page.","Recommended to update following  parameter to get rid off the header size issue - Ambari->Spark-> Configs  -> Custom spark2-defaults ->  spark.ui.requestHeaderSize=16k and as stated, unauthorized issue is  mitigated after sometime.",,,,,,,,
1.20061E+14,42:11.6,Unable to sync kafka topics between worker logs,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 9, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM CDT\n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: 2020-06-10 21:19:20 +0000 [error]: #0 unexpected error error_class=NameError error='uninitialized constant Kafka::Consumer::Concurrent'\n  2020-06-10 21:19:20 +0000 [error]: #0 suppressed same stacktrace\n2020-06-10 21:19:20 +0000 [info]: Worker 0 finished unexpectedly with status 1\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - 2020-06-10 21:19:20 +0000 [error]: #0 unexpected error error_class=NameError error='uninitialized constant Kafka::Consumer::Concurrent'\n  2020-06-10 21:19:20 +0000 [error]: #0 suppressed same stacktrace\n2020-06-10 21:19:20 +0000 [info]: Worker 0 finished unexpectedly with status 1;\n\n- ProblemStartTime: 06/09/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: frontline-development\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d4391f98-8b7c-4a66-8d87-36c19b53d347/resourceGroups/dev-uswest2-alpha-kafka-rg/providers/Microsoft.HDInsight/clusters/dev-uswest2-alpha-kafka\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to sync kafka topics between worker logs,0.074483646,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Unexpected result\Kafka,Unable to sync kafka topics between worker logs,Issue to plugin incompatibility in fluentd. ,Resolved the issues by fixing the fluentd to kafka plugin,,,,,,,,
1.20061E+14,11:03.9,Getting an exception while trying to submit a pigscript to the HDInsight cluster,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Pig\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: While submitting a pig script to the HDInsight cluster from a powershell script \n\nThe call Get-AzureRmHDInsightJobOutput shows an exception. Upon looking into this further by inserting logs, the exception is occurring outside of the code in the PigScript.\n\n6/11/2020 12:02:03 AM  PyngLightLog Wait for the Pig job to complete ...\nGet-AzureRmHDInsightJobOutput : The input is not a valid {Alphanumericpii} string as it contains a non-base 64 character, more than \ntwo padding characters, or an illegal character among the padding characters. \nAt C:{Uncpii}\BigData{UNCPII}\PigScripts{UNCPII}:77 {alphanumericpii}\n+     Get-AzureRmHDInsightJobOutput -ClusterName $clusterName -DisplayOutputType S ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Get-AzureRmHDInsightJobOutput], FormatException\n    + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.GetAzureHDInsightJobOutputCommand\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Pig;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - While submitting a pig script to the HDInsight cluster from a powershell script \n\nThe call Get-AzureRmHDInsightJobOutput shows an exception. Upon looking into this further by inserting logs, the exception is occurring outside of the code in the PigScript.\n\n6/11/2020 12:02:03 AM  PyngLightLog Wait for the Pig job to complete ...\nGet-AzureRmHDInsightJobOutput : The input is not a valid {Alphanumericpii} string as it contains a non-base 64 character, more than \ntwo padding characters, or an illegal character among the padding characters. \nAt C:{Uncpii}\BigData{UNCPII}\PigScripts{UNCPII}:77 {alphanumericpii}\n+     Get-AzureRmHDInsightJobOutput -ClusterName $clusterName -DisplayOutputType S ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Get-AzureRmHDInsightJobOutput], FormatException\n    + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.GetAzureHDInsightJobOutputCommand;\n\n- ProblemStartTime: 06/10/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MyCrestron\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2eeb021e-10c1-45b0-a749-382ab69f33fc/resourceGroups/CrestronDelphiHD/providers/Microsoft.HDInsight/clusters/CrestronDelphiHD20200611\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting an exception while trying to submit a pigscript to the HDInsight cluster,0.108565895,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie",Getting an exception while trying to submit a pigscript to the HDInsight cluster,Cx was using AzureRM cmdlets,Cx updated to Az cmdlets ,,,,,,,,
1.20061E+14,41:37.1,[Azure Government] Unable to create Edge Node with ARM deployment script ,"[Azure Government] Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Installation error details:\n\nAzureResourceCreation operation didn't succeed for adding application {ApplicationName: edgenode, ApplicationId: 3}. Operation status: Failed\n\nPlease investigate the error details and produce a solution.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Installation error details:\n\nAzureResourceCreation operation didn't succeed for adding application {ApplicationName: edgenode, ApplicationId: 3}. Operation status: Failed\n\nPlease investigate the error details and produce a solution.;\n\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6278af53-06ca-42f2-8373-a4707088297b/resourceGroups/o365ipdiusg02-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdiusg02-sp-ua01\n- Location: usgovarizona\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Unable to create Edge Node with ARM deployment script ,0.127128233,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Internal error message from log entry,Unsupported VM size for edge node,Provided cx list of supported VM sizes per internal error message and cx confirmed they were able to deploy.,,,,,,,,
1.20061E+14,15:20.5,Can't authenticate Ambari database while provisioning HDI,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 11, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: When creating a HDI cluster, I chose to create a custom ambario database by creating an empty sql db, which has all the configurations done - firewall settings, allow azure services/resources to access. I can access the empty sql db from query editor successfully. But in HDInsight provisioning blade, when I try to authenticate against the database, it's stuck at validation phase and never stops spinning. Yesterday when I did the same authentication, it actually gave error. See attached email thread.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - When creating a HDI cluster, I chose to create a custom ambario database by creating an empty sql db, which has all the configurations done - firewall settings, allow azure services/resources to access. I can access the empty sql db from query editor successfully. But in HDInsight provisioning blade, when I try to authenticate against the database, it's stuck at validation phase and never stops spinning. Yesterday when I did the same authentication, it actually gave error. See attached email thread.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/11/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't authenticate Ambari database while provisioning HDI,0.142830298,Root Cause : HDInsight Service\Bug\HDInsight SDK,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Can't authenticate Ambari database while provisioning HDI,Validation Issue from the portal Team. It's a known issue and there has been a work item and Product Group is working on priority.,Ignore the Error message and proceed further to create the cluster and it will be provisioned successfully.,,,,,,,,
1.20061E+14,21:14.9,Access to the cluster sometimes fails with 'Gateway failure' including in job submission,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 4, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Sometimes when connecting to cluster you recieve gateway failure. Similar issue occured about 1 month ago and was resolved with SR #{Phonenumberpii}. It has now re-occured\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Sometimes when connecting to cluster you recieve gateway failure. Similar issue occured about 1 month ago and was resolved with SR #{Phonenumberpii}. It has now re-occured;\n\n- ProblemStartTime: 06/04/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AIP-UsageMaster-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/29766025-47e9-4f55-959f-5811071f46f3/resourceGroups/UsageProd/providers/Microsoft.HDInsight/clusters/usagemasterhdiprod\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Access to the cluster sometimes fails with 'Gateway failure' including in job submission,0.969191017,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Access to the cluster sometimes fails with 'Gateway failure' including in job submission.,Gateway nodes seem to keep losing their connection to Zookeeper. From the logs this has been ongoing and happens to both gateway nodes. This results in intermittent 502 errors when interacting with the cluster.,"Gateway nodes seem to keep losing their connection to Zookeeper. From the logs this has been ongoing and happens to both gateway nodes. This results in intermittent 502 errors when interacting with the cluster.Logrotate behavior on Zookeeper nodes causing very high IO wait, changed following lines in zookeeper-log4j configuration using ambari and then restart affected components. this will remove .out file logging and start emitting logs that would be rotated without compression.log4j.rootLogger=INFO, CONSOLE, ETW, FilterLog to log4j.rootLogger=INFO, ROLLINGFILE, ETW, FilterLoglog4j.appender.ROLLINGFILE.Threshold=DEBUG to log4j.appender.ROLLINGFILE.Threshold=INFOlog4j.appender.ROLLINGFILE.File=zookeeper.log to log4j.appender.ROLLINGFILE.File=/var/log/zookeeper/zookeeper.logZookeeper issues are fixed now.",192163298,,,,,,,
1.20061E+14,20:55.1,ORC file and AzureBlobFileSystem API issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: Beeline string\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: intermittent issues on a migrated table wtih export and import.\n\nIntermittent issues.\n\nThe query 30 % of time fails wtih the  '{ALPHANUMERICPII} ERROR [ORC_GET_SPLITS #3] io.AcidUtils: Failed to get files with ID; using regular API: {Namepii} supported for DFS; got class org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem\n'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - Beeline string;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - intermittent issues on a migrated table wtih export and import.\n\nIntermittent issues.\n\nThe query 30 % of time fails wtih the  '{ALPHANUMERICPII} ERROR [ORC_GET_SPLITS #3] io.AcidUtils: Failed to get files with ID; using regular API: {Namepii} supported for DFS; got class org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem\n';\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpp100llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ORC file and AzureBlobFileSystem API issue,37.09729052,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Beeline,Failed to get files with ID; using regular API: Only supported for DFS; got class org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystemFailed to get files with ID; using regular API: Only supported for DFS; got class org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem,ORC file and AzureBlobFileSystem API issue,"We did check with PG on this, have seen this before and it don't has a big effectFailed to get files with ID; using regular API: Only supported for DFS; got class org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystemFailed to get files with ID; using regular API: Only supported for DFS; got class org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem",189253326,,,,,,,
1.20061E+14,10:03.3,Worker node wn-12 is dead and cannot recover,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 10, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: When I tried to ssh into {alphanumericpii}, I got the following error from console:\n\n{alphanumericpii}:~$ ssh {Ipaddresspii}\nuser-9112b83b@10.3.0.43's password:\nWarning: your password will expire in 8 days\n-bash: /etc/bash.bashrc: Input/output error\n-bash: /{alphanumericpii}: Input/output error\nConnection to {Ipaddresspii} closed.\n\nQuestion: Additional details about the issue\nAnswer: Cannot ssh into {alphanumericpii} worker node. It is shown heartbeat lost in ambari and cannot be recovered. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - When I tried to ssh into {alphanumericpii}, I got the following error from console:\n\n{alphanumericpii}:~$ ssh {Ipaddresspii}\nuser-9112b83b@10.3.0.43's password:\nWarning: your password will expire in 8 days\n-bash: /etc/bash.bashrc: Input/output error\n-bash: /{alphanumericpii}: Input/output error\nConnection to {Ipaddresspii} closed.;\nAdditional details about the issue - Cannot ssh into {alphanumericpii} worker node. It is shown heartbeat lost in ambari and cannot be recovered. ;\n\n- ProblemStartTime: 06/10/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Customer 360 PROD DXT Central US EUAP\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/35485224-05b1-4f87-9d5c-bff9795de399/resourceGroups/tip-eus2ep-01-rg/providers/Microsoft.HDInsight/clusters/tipeus2ep01hdi\n- Location: {alphanumericpii}\n- Location: East US 2 Euap\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Worker node wn-12 is dead and cannot recover,0.140899524,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Worker node wn-12 is dead and cannot recover.,NA,We have rebooted workernode Wn-12. customer able to access the node.,,,,,,,,
1.20061E+14,35:48.5,Zeppelin Thrift server connection issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Intermittent thrift server connenction issues when the user is running the queries through {Namepii} notebook.\n\nThe connenction is works through otther UI tools.\n\nThe  issue is resolved once the JDBC interpreter is restarted.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nAdditional details about the issue - Intermittent thrift server connenction issues when the user is running the queries through {Namepii} notebook.\n\nThe connenction is works through otther UI tools.\n\nThe  issue is resolved once the JDBC interpreter is restarted.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps84llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zeppelin Thrift server connection issue,7.205132976,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Client tool issue\Notebooks,Zeppelin Thrift server connection issue,Zeppelin Thrift server connection issue,Issue didn't reoccur and please open a new one by referring this case when it occur again,,,,,,,,
1.20061E+14,40:55.3,We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05e2piphdidm05\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.,27.5362008,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.,We are not able access the cluster with domain user credientials in all environments and also not able to change the passwords.,"Product group was engaged on this and they were able to push fixes for few clusters and for other clusters, product group requested to drop and recreate the clusters as deploying fix is not a feasible solution. Also, helped customer with other issues on different clusters.","192,075,705,192,096,000,000,000,000",,,,,,,
1.20061E+14,23:33.6,The credentials provided for the MicrosoftAzureConsumptionInsights source are invalid.(Source at 7306177.),"Question: Problem start time\nAnswer: Sun, {Namepii} 7, 2020, 12:00 AM EDT\n\nQuestion: Subscription ID\nAnswer: \n\nQuestion: Email ID accessing the data\nAnswer: {emailpii}@loblaw.ca\n\nQuestion: Additional details\nAnswer: The credentials provided for the MicrosoftAzureConsumptionInsights source are invalid. Please update the credentials through a refresh or in the Data Source Settings dialog to continue. (Source at 7306177.)\n\n\nI got latest auth key, but still the same issue. Is there some change that happened that blocks use of Azure Consumption insight? \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Billing:\nProblem start time - {ALPHANUMERICPII};\nSubscription ID - ;\nEmail ID accessing the data - {emailpii}@loblaw.ca;\nAdditional details - The credentials provided for the MicrosoftAzureConsumptionInsights source are invalid. Please update the credentials through a refresh or in the Data Source Settings dialog to continue. (Source at 7306177.)\n\n\nI got latest auth key, but still the same issue. Is there some change that happened that blocks use of Azure Consumption insight? ;\n\n- ProblemStartTime: 06/07/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LCL_Loblaw_DV\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_BILLING\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",The credentials provided for the MicrosoftAzureConsumptionInsights source are invalid.(Source at 7306177.),18.26304908,Root Cause : HDInsight Service\User Error,Routing Azure Billing V5\Billing API\Download consumption data by using billing API,credentials provided for the MicrosoftAzureConsumptionInsights source are invalid,Invalid key,recreate key ,192878148,,,,,,,
1.20061E+14,29:27.0,issue in Bpudlit4itprod HDI Cluster.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: In {Alphanumericpii} cluster sshuser for both headnodes has expired and we are unable to change it\ncluster is not working since the disk is full, We need to clear the logs and make space quickly for the hive to work.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - In {Alphanumericpii} cluster sshuser for both headnodes has expired and we are unable to change it\ncluster is not working since the disk is full, We need to clear the logs and make space quickly for the hive to work.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/bpudlit4itprod\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",issue in Bpudlit4itprod HDI Cluster.,0.273924055,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,issue in Bpudlit4itprod HDI Cluster.,Disk Space issue on the node. ,Restarted node. restarting usually clears up the /tmp files cleaning up some space for the script action to run. I would suggest cleaning up the logs that are taking up the space.  You can inspect the folders that are taking a lot of space by running.  du -h --max-depth=1 / | sort -h  if the /var/log directories(hiveserver2 etc) are getting filled up – you can archive the logs and push them to a storage account.  Here is a doc that talks about how you can manage disk space for hive logs. https://docs.microsoft.com/en-us/azure/hdinsight/hadoop/troubleshoot-disk-space,"192,107,843,192,113,000,000,000,000",,,,,,,
1.20061E+14,09:20.6,Similar to this case 120030224003288 [CSAT Impacting],"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select * from {alphanumericpii} where uhidat = '20200605'\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: We faced same issue before and it was resolved after restarting the HDI Gateway. Attached old email conversation.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select * from {alphanumericpii} where uhidat = '20200605';\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Beeline;\nAdditional details about the issue - We faced same issue before and it was resolved after restarting the HDI Gateway. Attached old email conversation.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/cmidevllapdj\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Similar to this case 120030224003288 [CSAT Impacting],0.02868462,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,"Queries was taking to much time to retrieve data.On a HDI 4.0 and ADL Gen2 as a primary Storage account, client was taking to much to get the result from simple queries","The issue was that query was executed almost immediately but the retrieving process was taking so long.As part of a bigger change on the client side, the move from HDI3.6 Gen1 to a HDI4.0 Gen2. The data was in Parquet format (ORC is recommended for LLAP clusters ) the metastore for Gen2 had to many references to Gen1, for which was taken long time to find the right (table) and right range.",Bumped up GW timeoutCleaning up references to gen1Removed ADL tables from gen2 cluster metastoreForwarded doc https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-optimize-hive-query,"192,785,594,193,012,000",,,,,,,
1.20061E+14,54:57.2,unable to retreive size for large streaming  HDFS directories ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: Yes\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer:  hdfs dfs  -ls -R abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/\n\n\n{alphanumericpii}$ hdfs dfs -du -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup/\n\n\n\n\nhdfs dfs -du -s -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup\n\nQuestion: Additional details about the issue\nAnswer: hdfs dfs -du -s -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup\n\nWe are unabel to get the size and the screen keeps loading as the data is huge. What ths is most effecient way to get the size of such huge hdfs directories \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - Yes;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - ;\nMitigating actions taken so far -  hdfs dfs  -ls -R abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/\n\n\n{alphanumericpii}$ hdfs dfs -du -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup/\n\n\n\n\nhdfs dfs -du -s -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup;\nAdditional details about the issue - hdfs dfs -du -s -h abfss://serviceslob@adlprodadls2storage.dfs.core.windows.net/regulated/stg/dcs/public/dcs_json_data/adl_ingest_channel=soup\n\nWe are unabel to get the size and the screen keeps loading as the data is huge. What ths is most effecient way to get the size of such huge hdfs directories ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/04af94d4-74f4-4642-b571-5b48a42b979f/resourceGroups/ITS-APPOPS-EDL-PROD-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/PHSP02ADLSPARK\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to retreive size for large streaming  HDFS directories ,32.23152551,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",unable to retreive size for large streaming HDFS directories,Issue: unable to retreive size for large streaming HDFS directories,"Resolution: Below code could accomdate this request and please launch it in spark-shell. Output will be written to console and it's in KB, object CalSize{import org.apache.hadoop.fs.{FileSystem, Path} import sys.process._   def fsystemcal( ) : Unit = {     val accum1 = sc.accumulator(""0"".toDouble)      val fs = FileSystem.get(spark.sparkContext.hadoopConfiguration)      val t=fs.listStatus(new Path(s""wasb://sparkpcr-2020-08-08t14-11-19-172z@pcreastusstg.blob.core.windows.net/"")).filter(_.isDir).map(_.getPath)      sc.parallelize(t).map(_.toString).foreach(a=> { val res= Seq(""hdfs"",""dfs"",""-du"",a).!! if (res.length.toDouble > 0) {  val lv:Double=(res.split("" "")(0).toDouble/1024)  println(a)  println(lv)  accum1+=lv }})println(accum1.value)}} CalSize.fsystemcalFYI, sshuser@hn0-aj-ksp:~$ spark-shell --num-executors 30 --executor-cores 5SPARK_MAJOR_VERSION is set to 2, using Spark2Setting default log level to ""WARN"".To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).Spark context Web UI available at http://hn0-aj-ksp.hdinsightcss.com:4040Spark context available as 'sc' (master = yarn, app id = application_1596913699427_0004).Spark session available as 'spark'.Welcome to      ____              __     / __/__  ___ _____/ /__    _\ \/ _ \/ _ `/ __/  '_/   /___/ .__/\_,_/_/ /_/\_\   version 2.4.4.3.1.6.2-2      /_/ Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_262)Type in expressions to have them evaluated.Type :help for more information. scala> object CalSize{     | import org.apache.hadoop.fs.{FileSystem, Path}     |     | import sys.process._     |     |    def fsystemcal( ) : Unit = {     |     |      val accum1 = sc.accumulator(""0"".toDouble)     |     |       val fs = FileSystem.get(spark.sparkContext.hadoopConfiguration)     |     |       val t=fs.listStatus(new Path(s""wasb://sparkpcr-2020-08-08t14-11-19-172z@pcreastusstg.blob.core.windows.net/"")).filter(_.isDir).map(_.getPath)     |     |       sc.parallelize(t).map(_.toString).foreach(a=> {     |     |  val res= Seq(""hdfs"",""dfs"",""-du"",a).!!     |     |  if (res.length.toDouble > 0)     |     |  {     |     |   val lv:Double=(res.split("" "")(0).toDouble/1024)     |     |   println(a)     |     |   println(lv)     |     |   accum1+=lv     |     |  }     |     | })     |     | println(accum1.value)     |     | }     | }warning: there were three deprecation warnings; re-run with -deprecation for detailsdefined object CalSize scala> CalSize.fsystemcal1369729.5771484375",195565777,,,,,,,
1.20061E+14,08:46.1,Unable to add Script Action to Cluster via Powershell,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I did not know how to classify this issue. However, we are unable to create new script actions on our HDinsight clusters. We receive the following error which does not tell us much.\n\nSubmit-AzHDInsightScriptAction : Long running operation failed with status 'Failed'. Additional Info:'ErrorCode: ScriptExecutionFailed; ErrorDescription:\nExecution of the following scripts failed :removeALFE'\nAt {alphanumericpii} {alphanumericpii}\n+ Submit-AzHDInsightScriptAction -ClusterName '{alphanumericpii} ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Submit-AzHDInsightScriptAction], CloudException\n    + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.SubmitAzureHDInsightScriptActionCommand\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Other, don't know or not applicable;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - I did not know how to classify this issue. However, we are unable to create new script actions on our HDinsight clusters. We receive the following error which does not tell us much.\n\nSubmit-AzHDInsightScriptAction : Long running operation failed with status 'Failed'. Additional Info:'ErrorCode: ScriptExecutionFailed; ErrorDescription:\nExecution of the following scripts failed :removeALFE'\nAt {alphanumericpii} {alphanumericpii}\n+ Submit-AzHDInsightScriptAction -ClusterName '{alphanumericpii} ...\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Submit-AzHDInsightScriptAction], CloudException\n    + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.SubmitAzureHDInsightScriptActionCommand\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsApsRG/providers/Microsoft.HDInsight/clusters/cas-hdi-ml-spark23-aps\n- Location: australiaeast\n- Location: {Namepii} East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to add Script Action to Cluster via Powershell,0.106283132,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie","We are seeing an increased occurrence of the internal Hive Metastore going down in our main cluster. This week alone it happened 6 times.When it happens, the cluster is unusable and all jobs don't run. So far only a cluster restart fixes the problem.","By default we are saving each and every script action results which are executed on the cluster in the below folderThe storage logs are available at \STORAGE_ACCOUNT_NAME\DEFAULT_CONTAINER_NAME\custom-scriptaction-logs\CLUSTER_NAME\DATE.Under this directory, the logs are organized separately for headnode, worker node, and zookeeper node. See the following examples:Headnode: <ACTIVE-HEADNODE-NAME>.cloudapp.netWorker node: <ACTIVE-WORKERNODE-NAME>.cloudapp.netZookeeper node: <ACTIVE-ZOOKEEPERNODE-NAME>.cloudapp.netPlease go through below documentation https://docs.microsoft.com/en-us/azure/hdinsight/troubleshoot-script-action#default-storage-account","By default we are saving each and every script action results which are executed on the cluster in the below folderThe storage logs are available at \STORAGE_ACCOUNT_NAME\DEFAULT_CONTAINER_NAME\custom-scriptaction-logs\CLUSTER_NAME\DATE.Under this directory, the logs are organized separately for headnode, worker node, and zookeeper node. See the following examples:Headnode: <ACTIVE-HEADNODE-NAME>.cloudapp.netWorker node: <ACTIVE-WORKERNODE-NAME>.cloudapp.netZookeeper node: <ACTIVE-ZOOKEEPERNODE-NAME>.cloudapp.netPlease go through below documentation https://docs.microsoft.com/en-us/azure/hdinsight/troubleshoot-script-action#default-storage-account",,,,,,,,
1.20061E+14,53:15.1,Unable to push messages to Kafka topic,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: 1.  Unable to producing data in topics from ssh on domain joined clusters\n\n2. Syntax for topic creation options on domain joined clusters\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - 1.  Unable to producing data in topics from ssh on domain joined clusters\n\n2. Syntax for topic creation options on domain joined clusters;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/39e7994b-e4a5-46b0-91b2-90d46dab7af7/resourceGroups/mtcosmuse2sephptkafkarg/providers/Microsoft.HDInsight/clusters/thdisvk1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to push messages to Kafka topic,6.210774127,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Kafka,Unable to push messages to Kafka topic.,NA,"To create topic, you need to use pre-built jar and run command like this: java -jar -Djava.security.auth.login.config=/usr/hdp/current/kafka-broker/config/kafka_client_jaas.conf kafka-producer-consumer.jar create salesevents $KAFKABROKERS But if you want to use console prompt to enter your desired messages to that salesevents topic, you can use console-producer and consumer command which I listed below export KAFKA_OPTS=""-Djava.security.auth.login.config=/usr/hdp/current/kafka-broker/conf/kafka_client_jaas.conf""export KAFKABROKERS=""<specified broker>""Produce:/usr/hdp/current/kafka-broker/bin/kafka-console-producer.sh --topic salesevents --broker-list $KAFKABROKERS --security-protocol SASL_PLAINTEXTConsume:/usr/hdp/current/kafka-broker/bin/kafka-console-consumer.sh --topic salesevents --from-beginning --bootstrap-server $KAFKABROKERS --security-protocol SASL_PLAINTEXT Note: Creating Topics must be done by JAVA API code. That is the only way that works in ESP clusters.",192902870,,,,,,,
1.20061E+14,48:31.7,seeing alerts on cluster head node dashaboard ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: {Namepii} issued from Control M, the data load seems to be stuck at somepoint and after verifying the headnode cluster, we see a alert on the hosts for hn0 (attached)\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} issued from Control M, the data load seems to be stuck at somepoint and after verifying the headnode cluster, we see a alert on the hosts for hn0 (attached)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - {Namepii} issued from Control M, the data load seems to be stuck at somepoint and after verifying the headnode cluster, we see a alert on the hosts for hn0 (attached);\nAdditional details about the issue - {Namepii} issued from Control M, the data load seems to be stuck at somepoint and after verifying the headnode cluster, we see a alert on the hosts for hn0 (attached);\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-cat-workload-rg/providers/Microsoft.HDInsight/clusters/aho0by-metlloader-20200612-cat-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",seeing alerts on cluster head node dashaboard ,2.658278951,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,seeing alerts on cluster head node dashaboard,By design,"The components that are turned off and put in maintanance mode as they are configured for high availability. Components such as Timeline server, History server and Livy as shown in the screenshots are available on both the headnodes and are active on any one of the headnode at a given point of time. This is by design. Attached is a doc that talks more about it. reference doc: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-high-availability-components#architecture",,,,,,,,
1.20061E+14,37:48.9,Cluster provisioning state failed,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 13, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'InvalidDocumentErrorCode\\',\\r\\n \\'message\\': \\'DeploymentDocument 'HiveConfigurationValidator' failed the validation. Error: 'The Hive Metastore schema version 1.2.0 in database {alphanumericpii} is incompatible with cluster version 4.0.1000.1.2004292122'\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'InvalidDocumentErrorCode\\',\\r\\n \\'message\\': \\'DeploymentDocument 'HiveConfigurationValidator' failed the validation. Error: 'The Hive Metastore schema version 1.2.0 in database {alphanumericpii} is incompatible with cluster version 4.0.1000.1.2004292122'\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]};\n\n- ProblemStartTime: 06/13/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d3fb275c-411c-4124-b21d-154eeba679d4/resourceGroups/CloudLake-Analytics-DEV/providers/Microsoft.HDInsight/clusters/anahdispark01datahubdv01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster provisioning state failed,0.991992394,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster deployment failure with metastore schema error,Hive metastore schema 1 .2not supported in 4.0,Upgrade metastore schema to 2,,,,,,,,
1.20061E+14,58:47.8,Hive Export operations are  failing with Distscp error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n\n\nQuestion: Interactive query explain plan if available\nAnswer: Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n{ALPHANUMERICPII} ERROR [{Alphanumericpii}] dump.PartitionExport: failed\n\n\n\nQuestion: How was the interactive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n{ALPHANUMERICPII} ERROR [{Alphanumericpii}] dump.PartitionExport: failed\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n;\nInteractive query explain plan if available - Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n{ALPHANUMERICPII} ERROR [{Alphanumericpii}] dump.PartitionExport: failed\n\n;\nHow was the interactive query submitted? - Beeline;\nAdditional details about the issue - Hive export operations are failing with below errors:\n\n1. Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.ExportTask. Distcp operation failed. ({AlphanumericPII})\n\n2. ERROR [{alphanumericpii}] tools.DistCp: XAttrs not supported on at least one file system: org.apache.hadoop.tools.CopyListing$XAttrsNotSupportedException: XAttrs not supported for file system: abfss://\n{ALPHANUMERICPII} ERROR [{Alphanumericpii}] dump.PartitionExport: failed\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq044sparkespfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Export operations are  failing with Distscp error,4.269203129,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Interactive Query,Hive Export operations are failing with Distscp error,"EXPORT command was failing on partitioned table as ABFS doesn’t support “preserve XAttrs” when create directories in the export path. By default, Hive uses -pbx -update options to run distcp command to copy data files. Here, -pbx tries to preserve block size and XAttrs.",I recommended KP to change this option by “set distcp.options.pb=;” in beeline before running EXPORT command and hence it starts working.,192554880,,,,,,,
1.20062E+14,42:54.2,Unable execute script action,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: iotdevcluster\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: unable to execute script action\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - iotdevcluster;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - unable to execute script action;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: L&T Construction - Digital\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralindia\n- Location: Central India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable execute script action,0.553516654,Root Cause : HDInsight Service\Lack of documentation,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,The script was failing with object not found message due to Az.HDInsight module being missing from automation workspace,The HDInsight documentation to deploy an HDInsight cluster via an Azure Automation runbook is outdatedAz.HDInsight module not installed in Azure automation runspace,Updated the sample script to work with Az cmdlets from an Azure Automation runbook,,,,,,,,
1.20062E+14,58:56.7,HIVE query console hanging,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 11, 2020, 10:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarting HIVE service\n\nQuestion: Additional details about the issue\nAnswer: We deploy our {alphanumericpii} HDInsight cluster every weekday, and starting 6/11, our HIVE service starts hanging when trying to access the HIVE query console (HIVE view 2.0). Specifically when we're trying to execute the attached query, it freezes. Even after the query is stopped and then any other query is triggered, it continues to freeze.\n\nRestarting the HIVE service seems to be a temporary fix. Please help us identify the root cause of this problematic behavior, and help us fix it. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarting HIVE service;\nAdditional details about the issue - We deploy our {alphanumericpii} HDInsight cluster every weekday, and starting 6/11, our HIVE service starts hanging when trying to access the HIVE query console (HIVE view 2.0). Specifically when we're trying to execute the attached query, it freezes. Even after the query is stopped and then any other query is triggered, it continues to freeze.\n\nRestarting the HIVE service seems to be a temporary fix. Please help us identify the root cause of this problematic behavior, and help us fix it. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/11/2020 14:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.HDInsight/clusters/sigi03spark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HIVE query console hanging,23.17046603,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,HIVE query console hanging,Cx requested closure and stated that they no longer need support on this issue,Cx requested closure and stated that they no longer need support on this issue,,,,,,,,
1.20062E+14,56:50.2,TLS 1.2 enforcement,"Regarding the news of TLS 1.2 enforcement on HDInsight (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-release-notes-archive#transport-layer-security-tls-12-enforcement), please assist us with identifing if our connection methods to HDInsight already use TLS 1.2 by default. We use standard (non-domain-jointed) HDInsight {alphanumericpii} clusters, specifically SPARK, R (Machine Learning), and Interactive Query cluster types. \n\n-- ADF to HDInsight: Do {Namepii} {Namepii} API calls to HTTPS://sigi03spark.azurehdinsight.net using port 443 use TLS 1.2 by default?\n\n-- HDInsight PySpark to {Alphanumericpii} ADLS: does the adl:// address use TLS 1.2 by default?\n\n-- HDInsight PySpark to azure sql via JDBC: Is it TLS 1.2 by default?\n\n-- Azure Storage Explorer client to {Alphanumericpii} ADLS: Which version(s) of the Storage Explorer client uses TLS 1.2 by default?\n\n-- JDBC/ODBC: Do our on-premise application calls to HDInsight HIVE use TLS 1.2 by default? We are using the 'Cloudera ODBC Driver for {Namepii} Hive' Driver, version 2.6.4.1004 on a Windows Server 2016 VM.\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",TLS 1.2 enforcement,0.384129088,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\ODBC or JDBC,"Questions regarding TLS 1.2:- ADF to HDInsight: Do Apache Livy API calls to HTTPS://sigi03spark.azurehdinsight.net using port 443 use TLS 1.2 by default?- HDInsight PySpark to Gen1 ADLS: does the adl:// address use TLS 1.2 by default?- HDInsight PySpark to Azure SQL via JDBC: Is it TLS 1.2 by default?- Azure Storage Explorer client to Gen1 ADLS: Which version(s) of the Storage Explorer client uses TLS 1.2 by default?- JDBC/ODBC: Do our on-premise application calls to HDInsight HIVE use TLS 1.2 by default? We are using the 'Cloudera ODBC Driver for Apache Hive' Driver, version 2.6.4.1004 on a Windows Server 2016 VM.","Questions regarding TLS 1.2:- ADF to HDInsight: Do Apache Livy API calls to HTTPS://sigi03spark.azurehdinsight.net using port 443 use TLS 1.2 by default?- HDInsight PySpark to Gen1 ADLS: does the adl:// address use TLS 1.2 by default?- HDInsight PySpark to Azure SQL via JDBC: Is it TLS 1.2 by default?- Azure Storage Explorer client to Gen1 ADLS: Which version(s) of the Storage Explorer client uses TLS 1.2 by default?- JDBC/ODBC: Do our on-premise application calls to HDInsight HIVE use TLS 1.2 by default? We are using the 'Cloudera ODBC Driver for Apache Hive' Driver, version 2.6.4.1004 on a Windows Server 2016 VM.","In HDInsight, TLS termination happens at the HDI Gateway. If you use the https://<clustername>.azurehdinsight.net URL to connect to the cluster, then TLS is used. If the cluster gets created with 1.2 as the minimum, then 1.2 is enforced (Gateway cannot be negotiated down).- ADF to HDInsight: Do Apache Livy API calls to HTTPS://sigi03spark.azurehdinsight.net using port 443 use TLS 1.2 by default?Yes, There shouldn't be any changes needed as we use net462 where TLS 1.2 is enabled by default. Port 443 = To answer this, we need to know what linked service our customer is using. If it’s Spark or Hive Linked Service, it should be 443 by default as below. https://docs.microsoft.com/en-us/azure/data-factory/connector-spark#linked-service-propertieshttps://docs.microsoft.com/en-us/azure/data-factory/connector-hive- HDInsight PySpark to Gen1 ADLS: does the adl:// address use TLS 1.2 by default?Yes. Data Lake Storage Gen1 protects your data throughout its life cycle. For data in transit, Data Lake Storage Gen1 uses the industry-standard Transport Layer Security (TLS 1.2) protocol to secure data over the network. https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-security-overview#data-protection- HDInsight PySpark to Azure SQL via JDBC: Is it TLS 1.2 by default?The clients need to be configured accordingly.- Azure Storage Explorer client to Gen1 ADLS: Which version(s) of the Storage Explorer client uses TLS 1.2 by default?The latest version of Azure Storage Explorer client supports TLS 1.2 by default. Confirmed with Fiddler. https://azure.microsoft.com/en-us/features/storage-explorer/- JDBC/ODBC: Do our on-premise application calls to HDInsight HIVE use TLS 1.2 by default? We are using the 'Cloudera ODBC Driver for Apache Hive' Driver, version 2.6.4.1004 on a Windows Server 2016 VM.The clients need to be configured accordingly.",,,,,,,,
1.20062E+14,31:57.3,Filesystem is in read-only mode,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 15, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: PaaS Edge Node issue\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - PaaS Edge Node issue;\n\n- ProblemStartTime: 06/14/2020 22:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3798d569-fc09-47bc-8afb-6cf9e834f80a/resourceGroups/hdi-{namepii}-stage01-sbxdev/providers/Microsoft.HDInsight/clusters/dev-hdi-stage01\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Filesystem is in read-only mode,1.338364179,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish, Symptom:Edgenode was not coming up,Cause:Ambari lost connection to faulty edgenode,Resolution:Deleted the faulty edgenode and redeployed.  Removed edgenode from ambari.Delete componentscurl -u user:'pw' -H 'X-Requested-By: ambari' -X DELETE http://<hn1FQDN>:8080/api/v1/clusters/<clustername>/hosts/<edgenodeFQDN>/host_componentsDelete hostcurl -u user:'pw' -H 'X-Requested-By: ambari' -X DELETE http://<hn1FQDN>:8080/api/v1/clusters/<clustername>/hosts/<edgenodeFQDN> Used powershell to remove edgenode from portal.,192551622,,,,,,,
1.20062E+14,08:45.9,Token doesnt exists in token manager,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 13, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, {Namepii} 13, 2020, 10:00 AM CDT\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Other, don't know or not applicable\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: Token doesn't exists in token manager\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Logged in to Ambari with batch account user {namepii} and password.\n\nQuestion: Additional details about the issue\nAnswer: 2020-06-13 {Alphanumericpii} INFO {namepii}.microsoft.azure.datalake.store.security.AdlWebHdfsMethods: Total time taken by getAccessToken() operation: 1 ms.\n2020-06-13 {Alphanumericpii} ERROR org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager: No node in path [/{AlphanumericPII}]\n2020-06-13 {Alphanumericpii} ERROR {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider: UserProvider#getValue() failed:\norg.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 632137 for hive) can't be found in cache\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.checkToken(AbstractDelegationTokenSecretManager.java:410)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.retrievePassword(AbstractDelegationTokenSecretManager.java:422)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.verifyToken(AbstractDelegationTokenSecretManager.java:448)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGIFromToken({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGI({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.{namepii}.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:203)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - Other, don't know or not applicable;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - Token doesn't exists in token manager;\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - Logged in to Ambari with batch account user {namepii} and password.;\nAdditional details about the issue - 2020-06-13 {Alphanumericpii} INFO {namepii}.microsoft.azure.datalake.store.security.AdlWebHdfsMethods: Total time taken by getAccessToken() operation: 1 ms.\n2020-06-13 {Alphanumericpii} ERROR org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager: No node in path [/{AlphanumericPII}]\n2020-06-13 {Alphanumericpii} ERROR {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider: UserProvider#getValue() failed:\norg.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 632137 for hive) can't be found in cache\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.checkToken(AbstractDelegationTokenSecretManager.java:410)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.retrievePassword(AbstractDelegationTokenSecretManager.java:422)\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.verifyToken(AbstractDelegationTokenSecretManager.java:448)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGIFromToken({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGI({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.microsoft.azure.datalake.store.security.resources.UserProvider.getValue({Namepii} Source)\n        at {namepii}.{namepii}.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:203)\n        at {namepii}.{namepii}.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at {namepii}.{namepii}.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at {namepii}.{namepii}.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at {namepii}.{namepii}.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n;\n\n- ProblemStartTime: 06/13/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Token doesnt exists in token manager,35.42750101,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",Customer mention :  znode that stores the credential cache has found to be missing.Error org.apache.hadoop.security.token.SecretManager$InvalidToken: token (ADLS delegation token 632137 for hive) can't be found in cacheat org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.checkToken(AbstractDelegationTokenSecretManager.java:410)at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.retrievePassword(AbstractDelegationTokenSecretManager.java:422)at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.verifyToken(AbstractDelegationTokenSecretManager.java:448)at com.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGIFromToken(Unknown Source)at com.microsoft.azure.datalake.store.security.common.AuthenticationHelper.getUGI(Unknown Source)at com.microsoft.azure.datalake.store.security.resources.UserProvider.getValue(Unknown Source)at com.microsoft.azure.datalake.store.security.resources.UserProvider.getValue(Unknown Source)at com.sun.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:203)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)at com.microsoft.azure.datalake.store.security.filters.AuthFilter.doFilter(Unknown Source)at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1426)at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)at org.mortbay.jetty.Server.handle(Server.java:326)at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582),"As this cluster image is old, this version of cluster had a known bug in credential_server_stagedrestart.py that it was reporting the status as failed. This has caused the RP repeatedly trying to run the same script. This version of the script will also restart credential service from every host that it runs on. This is the reason multiple cred service restarts were occurring in a matter of 2-3 minutes. While this was addressed in the newer version of the clusters, this particular cluster image continued to face this issue.","A fixed version of the script credential_server_stagedrestart.py was applied in both head nodes. Along with this, a fix to “update manifest” script to restart credential service only from head nodes. This will be useful for older clusters that still don't have the credential_server_stagedrestart.py fix to restart only from lowest order headnote.","194,701,083,196,986,000",,,,,,,
1.20062E+14,57:04.0,Woker Node Down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: wn43-pstss1.rirave5oqsounk2e44evd0rjyg.cx.internal.cloudapp.net\n\nPlease reboot {ALPHANUMERICPII} from the backend asap.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - wn43-pstss1.rirave5oqsounk2e44evd0rjyg.cx.internal.cloudapp.net\n\nPlease reboot {ALPHANUMERICPII} from the backend asap.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: COSMOS-{Namepii} Customer Data Platform-Trade Secrets-PRD-MG\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/52dc256d-7baa-4317-a01b-1448ce2d4953/resourceGroups/mpcosmuse2sephtspipelinesparkerg/providers/Microsoft.HDInsight/clusters/pstss1\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Woker Node Down,0.036666555,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,wn43 was down,"Upon reboot wn43 was back up, monitored for more than 24 hours, no issues",Reboot wn43,192535803,,,,,,,
1.20062E+14,08:52.3,.,.,.,49.0362347,Root Cause : HDInsight Service\User Error,,.,.,NA not a valid request,,,,,,,,
1.20062E+14,37:18.2,Unable to access Ambari UI from MSFTVPN connected devices. ,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Network\n\nQuestion: Detail of the changes\nAnswer: Deleted and created cluster on Vnet. \nVirtual network\n{alphanumericpii}\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to access Ambari UI from device connected to MSFTVPN. But it works from microsft corp network connected machines. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Network;\nDetail of the changes - Deleted and created cluster on Vnet. \nVirtual network\n{alphanumericpii};\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Unable to access Ambari UI from device connected to MSFTVPN. But it works from microsft corp network connected machines. ;\n\n- ProblemStartTime: 06/08/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a04d1510-3444-42bc-9ce1-41b3c9a9c558/resourceGroups/cat-operational-dl-rg-01/providers/Microsoft.HDInsight/clusters/cat-operational-dl-hdinsight-01\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to access Ambari UI from MSFTVPN connected devices. ,0.926374926,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to access Ambari UI from MSFTVPN connected devices,Due to WFH scenario unable to connect to cluster using MSFTVPN.,Possible way of resolution on the WFH scenario.The quickest and best workaround is to use the SAW machines to access the HDI cluster. Another way is you must manually update the NSG to include 443 inbound access for your IP’s.Update from the Networking team- MSITIP team is taking care of the IP range and allocation of the MSFTVPN. I will suggest contacting them if they have any solution to access the cluster from MSFTVPN. Or what set of IP range need to set in NSG or else.,,,,,,,,
1.20062E+14,46:04.5,hive connectivity to hdinsight cluster is random,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: NA\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Hive query if applicable\nAnswer: hive connectivity to hdinsight cluster is random \n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: hive connectivity to hdinsight cluster is random \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - NA;\nIncrease in load? - Other, don't know or not applicable;\nHive query if applicable - hive connectivity to hdinsight cluster is random ;\nDoes the same query work through Beeline from the Headnode? - Other, don't know or not applicable;\nAdditional details about the issue - hive connectivity to hdinsight cluster is random ;\n\n- ProblemStartTime: 06/15/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-psdemandforecast-prod-001/providers/Microsoft.HDInsight/clusters/hdihddemandforecastpsprod\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hive connectivity to hdinsight cluster is random,0.069913501,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\Hive View,Unsupported Cluster HDI 3.5,Unsupported Cluster HDI 3.5,Unsupported Cluster HDI 3.5,,,,,,,,
1.20062E+14,01:33.4,Job started crashing without jar changes,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 15, 2020, 1:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: Not applicable\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We have a cron job starting every X minutes, worked fine for a couple days and this working. \nIt started crashing at 1 pm today. \n\nEvery health checks on HDInsight Ambari are OK. \n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - Not applicable;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We have a cron job starting every X minutes, worked fine for a couple days and this working. \nIt started crashing at 1 pm today. \n\nEvery health checks on HDInsight Ambari are OK. \n\n;\n\n- ProblemStartTime: 06/15/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7afd8a0e-516f-4623-894d-022e4e8e4c71/resourceGroups/central_feeder-PROD-rtg20prd-Automation-HDI/providers/Microsoft.HDInsight/clusters/dlfAsSfTTn-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Job started crashing without jar changes,0.108154561,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Job started crashing without jar changes,We noticed “java.lang.OutOfMemoryError: GC overhead limit exceeded” error on the hiveserver2-interactive logs which indicates that there was not enough memory provided for hive interactive service. Your JDBC URL was explicitly using hive interactive instead of Hiveserver2 and we noticed that the LLAP application died at the same time your applications started crashing.  ,The jobs started running fine after a service restart. However you can change the jdbc connection string to use HS2 and monitor the heap moving forward.,,,,,,,,
1.20062E+14,05:02.5,Can't create cluster (error 500 conflict),"Question: What time did the problem begin?\nAnswer: Sun, {Namepii} 14, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: One of your engineer restarted the AAD ; it was not able to register new machines. \n\nThis issue is apparently known. \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: error 500 conflict after 10 min\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - One of your engineer restarted the AAD ; it was not able to register new machines. \n\nThis issue is apparently known. ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - error 500 conflict after 10 min;\n\n- ProblemStartTime: 06/14/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't create cluster (error 500 conflict),0.828223046,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"2020-06-15 20:36:54.7228768 westeurope 7afd8a0e-516f-4623-894d-022e4e8e4c71 zcfoyscgwl-projectspark 26214cab1dd94e508d1ecca958fddaf9 Error 3.6.1000.67.2004291541 1 SPARK [{""ErrorCode"":""InternalError"",""ErrorDescription"":""An unexpected error occurred""}] {""LocationHeaderValue"":""https://management.azure.com/subscriptions/6c690792-2d1a-44b4-9326-c3e886c64719/providers/Microsoft.AAD/locations/northeurope/operationResults/69580b16-7f00-4087-8697-cd1df00a2c20?api-version=2017-06-01&operationResultResponseType=Location"",""RetryAfter"":""00:00:10"",""HttpStatusCode"":500,""Data"":"""",""ErrorInfo"":{""error"":{""code"":""InternalError"",""message"":""An unexpected error occurred""}}}",Can't create cluster (error 500 conflict),"Rebooted DC associated with it to get pass the issue and can track the RCA under 120060824006304, as agreed.",191453787,,,,,,,
1.20062E+14,25:12.6,Subscription got disabled due to non usage,"Hi - I opened up my subscription on Apr 6 2020 with $200 credit for 2 months. I could not make much progress on building application for last 2 months. However, I was offered to receive an extra 30 days of extension on {Namepii} 4 to explore Azure. I had an impression that my subscription will remain alive till Jul 6 2020 considering 2 months plus one additional month of subscription. But the subscription has been made disabled. Today I upgraded my account for 12 months of free service with a support plan associated to it but my subscription is still showing disabled. Pls enable my subscription purchased with {EmailPII}@outlook.com",Subscription got disabled due to non usage,0.810722297,Root Cause : HDInsight Service\User Subscription issues,Routing Azure Portal Help V4\Issues Signing In to the Azure Portal\Azure Global (portal.azure.com),Subscription got disabled due to non usage,"Hi - I opened up my subscription on Apr 6 2020 with $200 credit for 2 months. I could not make much progress on building application for last 2 months. However, I was offered to receive an extra 30 days of extension on May 4 to explore Azure. I had an impression that my subscription will remain alive till Jul 6 2020 considering 2 months plus one additional month of subscription. But the subscription has been made disabled. Today I upgraded my account for 12 months of free service with a support plan associated to it but my subscription is still showing disabled. Pls enable my subscription purchased with Rudra_atanu@outlook.com",Resolution ========== Remote session with cx. Cx reported issue with subscription and that was resolved with billing. Reported issue is with HDInsight deployment and not APP insights. Advised cx I was from Azure Monitor support and not HDInsights Services. Had cx redeploy HDinsights again to observe behavior. Install was successful. Ok to close case. ,,,,,,,,
1.20062E+14,18:14.9,Regionservers were rebooted with out a notice,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 15, 2020, 12:45 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 15, 2020, 1:20 PM PDT\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 5 region servers in prod and Stage were rebooted with out a notification to customers. Was there any outage or known maintenance on HDI cluster from you end?\n\nProd {Namepii}: {alphanumericpii}\nNodes rebooted: {alphanumericpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - 5 region servers in prod and Stage were rebooted with out a notification to customers. Was there any outage or known maintenance on HDI cluster from you end?\n\nProd {Namepii}: {alphanumericpii}\nNodes rebooted: {alphanumericpii}\n;\n\n- ProblemStartTime: 06/15/2020 19:45:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search PRD ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/112d7591-4d06-4945-8323-c9ef2f70158a/resourceGroups/adobeidx-prod-hbase/providers/Microsoft.HDInsight/clusters/adobesearchhbaseprodva7\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Regionservers were rebooted with out a notice,0.657351013,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Service unhealthy\Hbase," 5 region servers in prod and Stage were rebooted with out a notification to customers. Was there any outage or known maintenance on HDI cluster from you end?  Prod Cluster: adobesearchhbaseprodva7 Nodes rebooted: wn6,wn2,wn7 ","Incident Start Date and Time6/15/2020 7:42:00 PM (UTC)Date and Time Service was Restored6/15/2020 8:32:00 PM (UTC)Problem DescriptionStarting on 15th June 2020 between 19:42 and 20:32 UTC, a subset of customers using Storage, or Azure services with Storage dependencies, in US East2 region may have experienced service availability issues.Detailed Root CauseOn a single storage scale unit, a new feature was enabled regarding configuration deployment. A bug in this new feature resulted in the configuration onthe front-end roles to enter a bad state. This resulted in availability impact to virtual machines as virtual machines became unable to communicate withtheir backing virtual hard disks hosted in storage.What are we doing it to avoid this from happening in the future?We sincerely apologize for the impact to affected customers. We are continuously taking steps to improve the Microsoft Azure Platform and ourprocesses to help ensure such incidents do not occur in the future. This includes (but is not limited to):Short-Term We are actively rolling out the fix to the new feature for configuration deployment across all production – FixedLonger-Term We are looking into improving validation process to ensure catching such issues early before impacting our customers. – ADO - 2288 We are looking at additional software improvements to further improve handling of this scenario to not cause availability impact to ourcustomers. ","Incident Start Date and Time6/15/2020 7:42:00 PM (UTC)Date and Time Service was Restored6/15/2020 8:32:00 PM (UTC)Problem DescriptionStarting on 15th June 2020 between 19:42 and 20:32 UTC, a subset of customers using Storage, or Azure services with Storage dependencies, in US East2 region may have experienced service availability issues.Detailed Root CauseOn a single storage scale unit, a new feature was enabled regarding configuration deployment. A bug in this new feature resulted in the configuration onthe front-end roles to enter a bad state. This resulted in availability impact to virtual machines as virtual machines became unable to communicate withtheir backing virtual hard disks hosted in storage.What are we doing it to avoid this from happening in the future?We sincerely apologize for the impact to affected customers. We are continuously taking steps to improve the Microsoft Azure Platform and ourprocesses to help ensure such incidents do not occur in the future. This includes (but is not limited to):Short-Term We are actively rolling out the fix to the new feature for configuration deployment across all production – FixedLonger-Term We are looking into improving validation process to ensure catching such issues early before impacting our customers. – ADO - 2288 We are looking at additional software improvements to further improve handling of this scenario to not cause availability impact to ourcustomers. ",192692438,,,,,,,
1.20062E+14,37:22.6,Cannot scale cluster,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 13, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The cluster has not been able to scale up since {Namepii} 13\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The cluster has not been able to scale up since {Namepii} 13;\n\n- ProblemStartTime: 06/13/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-PROD-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24customeraiprod\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot scale cluster,0.851556074,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,"Unable to scale cluster and may see below exception and alos Zombie hosts in Ambari,2020-06-21 14:16:00.0000000 WARN resourcemanager DFSInputStream.java 777 DFS Read org.apache.hadoop.hdfs.BlockMissingException Could not obtain block: BP-768983909-10.8.1.133-1583269809076:blk_1073950945_212685 file=/yarn/node-labels/nodelabel.mirror org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-768983909-10.8.1.133-1583269809076:blk_1073950945_212685 file=/yarn/node-labels/nodelabel.mirror",Cannot scale cluster  ,"We did see zombie hosts in Ambari and clean those using below script from Active ambari-server,wget https://healingscriptssa.blob.core.windows.net/clusterpatches/ambari_clean_zombienodes.sh  -O ambari_clean_zombienodes.shchmod a+x ambari_clean_zombienodes.sh./ambari_clean_zombienodes.sh If you are having trouble again, please try to check the RM status and both are in Standby state, please use below commands,You can check - $ hdfs fsck hdfs://mycluster/If it says some files are under replica, or there’re missing blocks in hdfs. You can run - $ hdfs fsck hdfs://mycluster/ -delete to forcefully clean up the hdfs. After this you should be able to get rid of the standby RM issue.",193931101,,,,,,,
1.20062E+14,45:05.7,Livy for Spark2 Server went down in middle of process,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} for {Alphanumericpii} Server went down in middle of jobs runing, so we are not able to see spark job status as its they are in submitted or running state.\n\nOn hn1 other 2 services are also in down state. Please check and suggest.\n\nTimeline Service {Alphanumericpii} \nHistory Server\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} for {Alphanumericpii} Server went down in middle of jobs runing, so we are not able to see spark job status as its they are in submitted or running state.\n\nOn hn1 other 2 services are also in down state. Please check and suggest.\n\nTimeline Service {Alphanumericpii} \nHistory Server;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-workload-rg/providers/Microsoft.HDInsight/clusters/ziir95-eod-cros-20200615-creg-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Livy for Spark2 Server went down in middle of process,13.73535058,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Problem description: Credit Suisse has been experiencing issues with sporadic active head node failover (once during the lifespan of HDI cluster) due to which you were unable to submit new jobs and query the status of already submitted jobs since they were hardcoded to head node which is now Standby head node post the failover. ,"Root Cause: The root cause behind this issues has been identified as problem in log rotate policy recently implemented to fixes logging for multiple HDI Cluster components such as hdinsight-zookeeper, master-failover-controller and slave-failover-controller etc causing loss of Zookeeper Quorum leading to active head node failover. Since Credit Suisse using an older HDI image, so this problem has been visible sporadically across almost all the HDI clusters in CloudReg data pipeline. The log rotate policy was being applied once during the lifespan of the HDI Cluster hence you observed the pattern where head node failover occurs once during the lifespan of HDI Cluster. Mitigation: A fix to prevent the restart for hdinsight-failovercontroller and hdinsight-zookeeper as part of logrotate-policy has been deployed. This will ensure the Zookeeper quorum stays healthy thus avoiding unexpected failover of active head node. Recommendation: Credit Suisse should take advantage of the built in HA capabilities of the HDI service to ensure CloudReg workload submission should be transparent to head node failover (The head nodes could failover as designed). The service offers multiple ways to stay access Livy endpoints without having to hard code to a particular head node. Most of our customers submit jobs against either the main gateway endpoint, or against the internal endpoint or they check for active head node before accessing the same. As suggested earlier, you can monitor/test livy submission/querying for submitted jobs like below curl -k --user ""admin:password"" -v -X GET ""https://<spark_cluster_name>-int.azurehdinsight.net/livy/batches""More examples, refer to: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-livy-rest-interface","Root Cause: The root cause behind this issues has been identified as problem in log rotate policy recently implemented to fixes logging for multiple HDI Cluster components such as hdinsight-zookeeper, master-failover-controller and slave-failover-controller etc causing loss of Zookeeper Quorum leading to active head node failover. Since Credit Suisse using an older HDI image, so this problem has been visible sporadically across almost all the HDI clusters in CloudReg data pipeline. The log rotate policy was being applied once during the lifespan of the HDI Cluster hence you observed the pattern where head node failover occurs once during the lifespan of HDI Cluster. Mitigation: A fix to prevent the restart for hdinsight-failovercontroller and hdinsight-zookeeper as part of logrotate-policy has been deployed. This will ensure the Zookeeper quorum stays healthy thus avoiding unexpected failover of active head node. Recommendation: Credit Suisse should take advantage of the built in HA capabilities of the HDI service to ensure CloudReg workload submission should be transparent to head node failover (The head nodes could failover as designed). The service offers multiple ways to stay access Livy endpoints without having to hard code to a particular head node. Most of our customers submit jobs against either the main gateway endpoint, or against the internal endpoint or they check for active head node before accessing the same. As suggested earlier, you can monitor/test livy submission/querying for submitted jobs like below curl -k --user ""admin:password"" -v -X GET ""https://<spark_cluster_name>-int.azurehdinsight.net/livy/batches""More examples, refer to: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-livy-rest-interface","192,610,614,192,610,000,000,000,000,000,000,000",,,,,,,
1.20062E+14,37:47.7,Not able to bind the same storage account to the newly created cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to bind the same storage account to the newly created cluster\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to bind the same storage account to the newly created cluster\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: QA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c1edc178-6f74-42c6-bb36-6d014d69de84/resourceGroups/Mosaic-APAC-QA-Primary/providers/Microsoft.HDInsight/clusters/omeaqitdpqaapac01\n- Location: eastasia\n- Location: East {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to bind the same storage account to the newly created cluster,0.172503805,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Schema upgrade script failed to import com.microsoft.storage.BlobService,Default python installation had been customized on hn0,Ran metastore schema upgrade from a node where the python installation had not be customized,,,,,,,,
1.20062E+14,15:02.5,Unable to setup Azure Monitor,"Hi {Namepii},\n\nWe are unable to setup Azure Monitor for QA1-{Namepii}-HDISpark-{Namepii} and Dev-{Namepii}-HDISpark-{Namepii}. I have attached the error screenshot. Kindly look into this issue and resolve it ASAP.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67d09f1b-6137-4556-bd69-c4aaef477c44/resourceGroups/QA1-{Namepii}-HDISpark/providers/Microsoft.HDInsight/clusters/QA1-{Namepii}-HDISpark-{Namepii}\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to setup Azure Monitor,0.162158966,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Issue with Diagnostics or Metrics on Azure Portal\Azure Log Analytics Integration,Unable to setup Azure Monitor,By design ,"Dev Cluster:""Hn0 is now in a good state, I noticed that the VM agent was unresponsive and restarted it.Can you please enable the azure monitor on the “dev-loyalty-hdispark-cluster” and let me know how it goes.QA cluster: regarding the management IPs, I verified the NSG and it looks good apart from the recursive resolver IP 168.63.129.16 on port 53 which needs to be added. With that said, I was talking about the User Defined Route configured on this subnet --> az-usw-emjuqa1-udr-01. This UDR does not have the Management IPs on it. I was still not able to access the QA cluster, once you add the IPs try and install Az Monitor on this cluster ",,,,,,,,
1.20062E+14,57:55.3,Validation Failed,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 8:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: i have deployed HD Insights many times and it is always a challenge - this time it says 'Validation failed...' but I see no fields left to fill out.  There is a quota problem too I believe as I can only select 3 nodes when the request is for 8. They are requesting large VMs.  See attached screenshot of error.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - i have deployed HD Insights many times and it is always a challenge - this time it says 'Validation failed...' but I see no fields left to fill out.  There is a quota problem too I believe as I can only select 3 nodes when the request is for 8. They are requesting large VMs.  See attached screenshot of error.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/16/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d30b56e-2e25-41c5-8434-a7661a5700e5/resourceGroups/dsi_centralus_prod_rg01/providers/Microsoft.HDInsight/clusters/dsi-centralus-prod-hdi01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Validation Failed,0.961720549,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,120061624002105  - Cluster Validation failed,There was not sufficient quota,"Customer decided to use the E series VM for the moment, but will follow up regarding the DSv2 if needed in the future.",,,,,,,,
1.20062E+14,58:59.3,Not able to see Lenses.io as an application to add,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 5, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes that we are aware of\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The cluster was created successfully and working fine. We would like to add Lenses.io as an application to provide visibility to the cluster. We were able to do this in our other subscription 2 weeks ago - for some reason, it stopped showing up as an application.\nNavigation\ncluster /application / add/ search for lenses\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes that we are aware of;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The cluster was created successfully and working fine. We would like to add Lenses.io as an application to provide visibility to the cluster. We were able to do this in our other subscription 2 weeks ago - for some reason, it stopped showing up as an application.\nNavigation\ncluster /application / add/ search for lenses;\n\n- ProblemStartTime: 06/05/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} NonProd Services\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/84749ad6-8508-4851-97ae-f8055ddef370/resourceGroups/unt-sni-hdinsight/providers/Microsoft.HDInsight/clusters/unt-sni-hdinsightcluster1\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to see Lenses.io as an application to add,0.077669759,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Not able to see Lenses.io as an application to add,Lenses.io support confirmed that there is an issue with Azure Marketplace migration,There is a migration issue between Lenses.io and the Azure Marketplace. Lenses.io is currently working with the Azure Marketplace PG to address this issue. ,,,,,,,,
1.20062E+14,41:30.3,enable ssl ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: we would like some guidance on enabling SSL for producing and consuming to/from Kafka for some consumers and producers but for some we would like to keep it Plain text.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - we would like some guidance on enabling SSL for producing and consuming to/from Kafka for some consumers and producers but for some we would like to keep it Plain text.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02lak01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",enable ssl ,0.117183589,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Kafka,need help in setting up Kafka SSL,enable ssl,Provided and helped in setting up kafka ssl using following link - https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-ssl-encryption-authentication,194182906,,,,,,,
1.20062E+14,45:09.5,cluster fuera de linea,"Pregunta: ¿A qué hora comenzó {namepii} problema?\nRespuesta: lun., 15 {namepii}. 2020 15:00 {ALPHANUMERICPII}\n\nPregunta: {Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco.\nRespuesta: \n\nPregunta: ¿{Namepii} {namepii} realizado cambios en cualquiera {namepii} estos componentes?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: ¿{Namepii} aumentado {namepii} carga?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: Acciones {namepii} mitigación realizadas hasta ahora\nRespuesta: Debido a que varios nodos quedaron fuera {namepii} linea, se trato {namepii} escalar {namepii} cluster sin exito.\n\n{Namepii} cluster esta fuera {namepii} linea.\n\nPregunta: Detalles adicionales acerca del problema\nRespuesta: cluster sin servicio\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\n¿A qué hora comenzó {namepii} problema? - {ALPHANUMERICPII};\n{Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco. - ;\n¿{Namepii} {namepii} realizado cambios en cualquiera {namepii} estos componentes? - Otro, no lo sé o no {namepii} aplicable;\n¿{Namepii} aumentado {namepii} carga? - Otro, no lo sé o no {namepii} aplicable;\nAcciones {namepii} mitigación realizadas hasta ahora - Debido a que varios nodos quedaron fuera {namepii} linea, se trato {namepii} escalar {namepii} cluster sin exito.\n\n{Namepii} cluster esta fuera {namepii} linea.;\nDetalles adicionales acerca del problema - cluster sin servicio;\n\n- ProblemStartTime: 06/15/2020 20:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Plan {namepii} soporte técnico {namepii} Azure - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/678db644-8433-4ce4-96d7-c3d616140a2c/resourceGroups/GRPBigData/providers/Microsoft.HDInsight/clusters/satrackbigdata\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",cluster fuera de linea,0.441765278,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Hbase,Cluster scale up failed.,NA,We found that cluster scale-up failed with the error: Timed out waiting for hosts to register with Ambari server.Below are the host names that failed to register with ambari: wn42-satrac wn43-satrac wn44-satrac wn45-satracAs we do not see any logs for the hosts which failed to register with ambari. We are not able to provide detailed RCA on this. ,192883802,,,,,,,
1.20062E+14,03:44.3,"Ambari-Server restarted unexpectedly, server can't bind to port 42700","Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 8:17 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I was alerted to the problem by getting ambari alerts for missing ambari agent heartbeats on all nodes in the environment. I looked in the ambari-server logs on hn0, and noticed that the ambari-server restarted unexpectedly at 14:17 UTC. There are a number of errors in the ambari-server logs.  The ambari-server service status has the error of:\n\n{Namepii} 16 14:17:33 {alphanumericpii} {alphanumericpii}]:  MdsLogger.py [4355] - hdinsight_common.MdsLogger - ERROR - Failed to bind to port 42700\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I was alerted to the problem by getting ambari alerts for missing ambari agent heartbeats on all nodes in the environment. I looked in the ambari-server logs on hn0, and noticed that the ambari-server restarted unexpectedly at 14:17 UTC. There are a number of errors in the ambari-server logs.  The ambari-server service status has the error of:\n\n{Namepii} 16 14:17:33 {alphanumericpii} {alphanumericpii}]:  MdsLogger.py [4355] - hdinsight_common.MdsLogger - ERROR - Failed to bind to port 42700\n;\n\n- ProblemStartTime: 06/16/2020 14:17:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Base $1200 Annual Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/85b49761-8f6b-45d2-b452-c42625590aee/resourceGroups/WhitingPetroSCADA/providers/Microsoft.HDInsight/clusters/whitingpetroscadahdicls\n- Location: westcentralus\n- Location: West Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Ambari-Server restarted unexpectedly, server can't bind to port 42700",0.227600453,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,"Ambari-Server restarted unexpectedly, ERROR - Failed to bind to port 42700",SSH to the cluster on hn0 but the active headnode was hn1 reason active status showing fail on the command “sudo service ambari-server status”,"SSH to the active headnode and perform the status command. Note : AmbariServer on your HDInsight cluster is currently not working. If you have stopped this service on your side, you can ignore this.Recommended Steps  Use Azure      Resource Health: view detailed information about the current      and past health status of your Azure resource, whitingpetroscadahdicls, as      well as recommended actions that you can take for specific availability      issues.  Create a      Resource Health alert: the alert will notify      you and your team the next time there is an issue with your Azure services      that affects you. Configure alerts for resource health events.",,,,,,,,
1.20062E+14,13:53.1,Heartbeat isuses and Hosts information missing in Ambari ui,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Heartbeat issues\nHosts information missing\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Heartbeat issues\nHosts information missing;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpp100llapprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Heartbeat isuses and Hosts information missing in Ambari ui,0.256248877,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Interactive Query,Ambari-server stale PID persit,Heartbeat isuses and Hosts information missing in Ambari ui,"We do see hung ambari-server PID on HN0 is caused the issue and after killing the lingering/hung PID, it started wokring fine.",,,,,,,,
1.20062E+14,35:57.2,OneForOneBlockFetcher:138  - Failed while starting block fetches,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: Applcation ID: {alphanumericpii}\n\nError log:\n\n2020-06-16 17:17:52 ERROR OneForOneBlockFetcher:138  - Failed while starting block fetches\njava.io.IOException: Connection from wn32-o365ip.wlegp5devo2uhcwz0040ftpzvc.px.internal.cloudapp.net/10.0.0.40:35607 closed\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n2020-06-16 17:19:57 ERROR RetryingBlockFetcher:143  - Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\njava.io.IOException: Connecting to wn32-o365ip.wlegp5devo2uhcwz0040ftpzvc.px.internal.cloudapp.net/10.0.0.40:35607 timed out (120000 ms)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - N/A;\nAdditional details about the issue - Applcation ID: {alphanumericpii}\n\nError log:\n\n2020-06-16 17:17:52 ERROR OneForOneBlockFetcher:138  - Failed while starting block fetches\njava.io.IOException: Connection from wn32-o365ip.wlegp5devo2uhcwz0040ftpzvc.px.internal.cloudapp.net/10.0.0.40:35607 closed\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n2020-06-16 17:19:57 ERROR RetryingBlockFetcher:143  - Exception while beginning fetch of 1 outstanding blocks (after 1 retries)\njava.io.IOException: Connecting to wn32-o365ip.wlegp5devo2uhcwz0040ftpzvc.px.internal.cloudapp.net/10.0.0.40:35607 timed out (120000 ms)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII});\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-AUS-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6c921e7f-817d-472f-a87a-696e45988c45/resourceGroups/o365ipdiaus01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdiaus01-sp-ae01\n- Location: australiaeast\n- Location: {Namepii} East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",OneForOneBlockFetcher:138  - Failed while starting block fetches,0.985113196,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Spark,OneForOneBlockFetcher:138 - Failed while starting block fetches,app failed with connectivity issues for which NM was turned off.,Went on a call with lucas.yang and @Roukna Sengupta  and walked through the logs. Only one app failed with connectivity issues for which NM was turned off. Other failures are due to eventhub timeouts. They will be handling this with eventhubs.,192927490,,,,,,,
1.20062E+14,36:13.9,Repeated Errors connecting to SQL,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 9:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: I have attached the spark configuration details in excel format.\n\nQuestion: Additional details about the issue\nAnswer: We have been receiving errors about this app: AppPool-CiEvtApp, connect to SQL.  These are the stack traces we are seeing:\n\n1) Log File: AppPool-CiEvtApp_.log Start Line Number: 73350\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n\n--------------\n\n2) Log File: AppPool-CiEvtApp_.log Start Line Number: 86028\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n*******  CI Monitor Alert End *******@channel\n1:22\n[APS] CI Monitor\n******* /home/sshuser/logs/AppPool-CiEvtApp_.log Alert Start *******\nLog File: AppPool-CiEvtApp_.log Start Line Number: 86079\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - I have attached the spark configuration details in excel format.;\nAdditional details about the issue - We have been receiving errors about this app: AppPool-CiEvtApp, connect to SQL.  These are the stack traces we are seeing:\n\n1) Log File: AppPool-CiEvtApp_.log Start Line Number: 73350\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n\n--------------\n\n2) Log File: AppPool-CiEvtApp_.log Start Line Number: 86028\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n*******  CI Monitor Alert End *******@channel\n1:22\n[APS] CI Monitor\n******* /home/sshuser/logs/AppPool-CiEvtApp_.log Alert Start *******\nLog File: AppPool-CiEvtApp_.log Start Line Number: 86079\nError Detail:\n ERROR org.apache.spark.sql.execution.streaming.StreamingQueryListenerBus: Listener {alphanumericpii} threw an exception\ncom.microsoft.sqlserver.jdbc.SQLServerException: The driver could not establish a secure connection to SQL Server by using Secure Sockets Layer (SSL) encryption. Error: 'Read timed out {AlphanumericPII}'.\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)\n    at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Read timed out {AlphanumericPII}\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/16/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsApsRG/providers/Microsoft.HDInsight/clusters/cas-spark23-etl-hdi-aps\n- Location: australiaeast\n- Location: {Namepii} East\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Repeated Errors connecting to SQL,0.074596003,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,Repeated Errors connecting to SQL,intermittent -- issue happens on wn11 only as per the customer,workaround -- restart appAsked for tcp dump on wn11 when the issue happens.,,,,,,,,
1.20062E+14,41:25.5,Kafka brokers stopped ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 2 out of 8 kafka brokers are down. It showed the disk space getting out of space, so change the following settings, with no affect\n\nlog.retention.hours\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - 2 out of 8 kafka brokers are down. It showed the disk space getting out of space, so change the following settings, with no affect\n\nlog.retention.hours\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Lumada Manufacturing Insights - Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kafka brokers stopped ,0.191394232,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Kafka brokers stopped,Disk space issue due to one of the heavy partition from topic . Partition itself occupies 500GB  space on kafka disk. This is a clear case of hot spotting since all other partitions are not growing as fast as this partition. ,Removed the logs on the disks to get some free space and restarted the brokers.After setting the log retention to 2days disks cleared out the old logs and relieved the disks.We have reduced the retention from 4 days to 2 days.Also suggested customer the below two options:Option 1: Scale out the cluster and re-balance all the partitions across multiple disks.Option 2: Create a cluster with bigger sku and more no. of disks attached.,,,,,,,,
1.20062E+14,27:53.2,Cannot diagnose script failure because Ambari UI is not loading,"I am trying to research why a script is failing on the HDI cluster. I cannot connect to the cluster to do so. \n\nProblem start date and time\n{Namepii}, {Namepii} 16, 2020, 9:00 AM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/16/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data & Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67cd1994-a844-433b-bc69-82430f893851/resourceGroups/czr-prod-eus-dnamdw-rg/providers/Microsoft.HDInsight/clusters/HDIShelfScoringMKTProd\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot diagnose script failure because Ambari UI is not loading,15.04254348,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Ambari UI is not loading,Cannot diagnose script failure because Ambari UI is not loading.,NA,As customer trying to run a map reduce and map reduce libraries are not compatible with the r versions installed. It's not supported by us as the r versions installed are not compatible.,,,,,,,,
1.20062E+14,06:11.7,Unable to connect from HDInsight,"Question: Approximate start time of the most recent occurrence\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 PM EDT\n\nQuestion: Session ID\nAnswer: {Muidpii}\n\nQuestion: Details\nAnswer: Created SQL DB to be used for Ambari database with HDInsight Hadoop cluster. While attempting to create the cluster, on the storage page...selected the SQL server/DB created for this. Entered credentials and test connection failed. Unable to proceed with cluster creation.\n\nSimilar to existing incident number {Phonenumberpii}\n\nQuestion: Select the troubleshooting steps you have performed:\nAnswer: Don't Know\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for SQL Database:\nApproximate start time of the most recent occurrence - {ALPHANUMERICPII};\nSession ID - {Muidpii};\nDetails - Created SQL DB to be used for Ambari database with HDInsight Hadoop cluster. While attempting to create the cluster, on the storage page...selected the SQL server/DB created for this. Entered credentials and test connection failed. Unable to proceed with cluster creation.\n\nSimilar to existing incident number {Phonenumberpii};\nSelect the troubleshooting steps you have performed: - Don't Know;\n\n- ProblemStartTime: 06/16/2020 16:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DemoSubscription\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: eastus\n- ResourceUri: /subscriptions/7ea32f54-3e55-46c8-8950-a09270b2d7db/resourceGroups/scenario4-rg/providers/Microsoft.Sql/servers/severn-logging-sqlserver/databases/severn-logging-sqldb\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect from HDInsight,0.129945538,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure SQL Database V4\Portal and Client Tools\Azure Portal,Can't authenticate Ambari database while provisioning HDI,Ignore the Error message and proceed further to create the cluster and would be able to provision successfully.,Known Issue and there is a work item as mentioned below.https://msdata.visualstudio.com/HDInsight/_workitems/edit/763804,,,,,,,,
1.20062E+14,22:10.5,zookeeper node down,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Zookeeper node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Connection failed: [Errno 111] Connection refused to zk1-tipeus.ar3d0attn2oe1e4y5jeixzw2cc.cbnx.internal.cloudapp.net:2181\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Zookeeper node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Connection failed: [Errno 111] Connection refused to zk1-tipeus.ar3d0attn2oe1e4y5jeixzw2cc.cbnx.internal.cloudapp.net:2181;\n\n- ProblemStartTime: 06/15/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Customer 360 PROD DXT Central US EUAP\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/35485224-05b1-4f87-9d5c-bff9795de399/resourceGroups/tip-eus2ep-01-rg/providers/Microsoft.HDInsight/clusters/tipeus2ep01hdi\n- Location: {alphanumericpii}\n- Location: East US 2 Euap\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",zookeeper node down,0.09280708,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,zookeeper node down and No metric data observed ,Not Identified,Rebooted on hns and zk nodes,,,,,,,,
1.20062E+14,42:00.4,Head Node Connection Failure Issue,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe have been  facing connection issues with headnode on our new Domain join cluster in prudction hence the enviroment is not stable. \n\nWe wanted to understand the why we getting this aelrt and how to avoid these .\n\nAlert ERROR  screen shot attached.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi {Namepii},\n\nWe have been  facing connection issues with headnode on our new Domain join cluster in prudction hence the enviroment is not stable. \n\nWe wanted to understand the why we getting this aelrt and how to avoid these .\n\nAlert ERROR  screen shot attached.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/16/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Prod_DR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cca3be6-ea39-4394-9aab-242213bd98e5/resourceGroups/enterprise-prd/providers/Microsoft.HDInsight/clusters/cmiprodllapdj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head Node Connection Failure Issue,0.287947107,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Failed to connect to hn0-cmipro.addscummins.com port 30070: Connection refused 000).,"The alter came up after a scale up process failed, showing the followed error:Connection failed to http://hn0-cmipro.addscummins.com:30070 (Execution of 'curl --location-trusted -k --negotiate -u : -b /var/lib/ambari-agent/tmp/cookies/d0d5782e-8459-46bc-a98f-647f1f235e12 -c /var/lib/ambari-agent/tmp/cookies/d0d5782e-8459-46bc-a98f-647f1f235e12 -w '%{http_code}' http://hn0-cmipro.addscummins.com:30070 --connect-timeout 5 --max-time 7 -o /dev/null 1>/tmp/tmpAHHWFu 2>/tmp/tmpmHUMsV' returned 7.   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                  Dload  Upload   Total   Spent    Left  Speed  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to hn0-cmipro.addscummins.com port 30070: Connection refused 000).",Check the process running on port 30070$ netstat -an | grep 30070 | grep LIST Kill the processReconnect using the ssh session ,,,,,,,,
1.20062E+14,41:46.8,Notification alerts for Long running jobs,"Need Notification alerts for long running jobs (More than 3 hours) in ESP HDInsight clusters \n\nProblem start date and time\nWed, {Namepii} 17, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/16/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Free Trial\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: RHC\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Service Health\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Notification alerts for Long running jobs,0.161842967,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,N/A,Feature Request,custom script log analytics workspace,,,,,,,,
1.20062E+14,30:32.6,Jobs failure,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 17, 2020, 6:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar -D mapreduce.job.queuename=rdl\\\ncore -input adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/external/file/rxconnect/RXC_PATIENT_ADDRES\\\n{ALPHANUMERICPII} -output 'adl://prodrxperso.azuredatalakestore.net/user/$USER/count_prod/RXC_PATIENT_A\\\nDDRESS' -mapper ''wc -l'' -reducer $''awk \\'{a+=\\\\$0}END{print a}{Uncpii}\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: 20/06/17 11:31:36 INFO mapreduce.{Namepii}: {Namepii} {alphanumericpii} failed with state FAILED due to: {Namepii} {alphanumericpii}\\\n{Alphanumericpii} failed 5 times due to Error launching {alphanumericpii}. Got exception: java.io.IOException: Failed on\\\nlocal exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: '{alphanumericpii}'; destina\\\ntion host is: '{alphanumericpii}; \n    at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:785)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPB\\\n{AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Couldn't set up IO streams\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    ... 16 more\nCaused by: java.lang.NoClassDefFoundError: {PUIDPII}\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at java.security.AccessController.doPrivileged(Native Method)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    ... 19 more\n. Failing the application.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar -D mapreduce.job.queuename=rdl\\\ncore -input adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/external/file/rxconnect/RXC_PATIENT_ADDRES\\\n{ALPHANUMERICPII} -output 'adl://prodrxperso.azuredatalakestore.net/user/$USER/count_prod/RXC_PATIENT_A\\\nDDRESS' -mapper ''wc -l'' -reducer $''awk \\'{a+=\\\\$0}END{print a}{Uncpii}\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Beeline;\nAdditional details about the issue - 20/06/17 11:31:36 INFO mapreduce.{Namepii}: {Namepii} {alphanumericpii} failed with state FAILED due to: {Namepii} {alphanumericpii}\\\n{Alphanumericpii} failed 5 times due to Error launching {alphanumericpii}. Got exception: java.io.IOException: Failed on\\\nlocal exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: '{alphanumericpii}'; destina\\\ntion host is: '{alphanumericpii}; \n    at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:785)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPB\\\n{AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII} Source)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\nCaused by: java.io.IOException: Couldn't set up IO streams\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    ... 16 more\nCaused by: java.lang.NoClassDefFoundError: {PUIDPII}\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at java.security.AccessController.doPrivileged(Native Method)\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    at {AlphanumericPII})\n    ... 19 more\n. Failing the application.;\n\n- ProblemStartTime: 06/17/2020 11:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jobs failure,0.101579275,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Jobs failure,Jobs failure,"Worked with product group on this and confirmed to customer that ""discard"" option on mount is the root cause of the issue. This ""discard"" option on the file /etc/fstab - since the storage of the OS disk used on the virtual machine doesn't actually supports the TRIM operation ( the disk storage is not SSD but HDD instead ) and forcing the disk to perform these operations on the EXT4 root file system. This discard option is added by us. Produce group have added a disk check on restart which can auto-heal this RO issue now (which was run as a patch when hn0 was rebooted). This patch was applied across clusters/subscriptions and will be in place for future provisionings aswell.",192878526,,,,,,,
1.20062E+14,24:34.5,failed to connect to the cluster to submit jobs,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Network\n\nQuestion: Detail of the changes\nAnswer: unable to submit jobs from the head node 0\n\n{AlphanumericPII}$ curl -k --user '71112109' -X POST -H 'Content-Type:application/json' -H 'X-Requested-By: user' --data '@Ingest_bluecoat.txt' https://p02-las-as.azurehdinsight.net/livy/batches\nEnter host password for user '71112109':\ncurl: (7) Failed to connect to p02-las-as.azurehdinsight.net port 443: Connection timed out\n\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We already have an NSG rule to allow HDInsight service\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Network;\nDetail of the changes - unable to submit jobs from the head node 0\n\n{AlphanumericPII}$ curl -k --user '71112109' -X POST -H 'Content-Type:application/json' -H 'X-Requested-By: user' --data '@Ingest_bluecoat.txt' https://p02-las-as.azurehdinsight.net/livy/batches\nEnter host password for user '71112109':\ncurl: (7) Failed to connect to p02-las-as.azurehdinsight.net port 443: Connection timed out\n;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We already have an NSG rule to allow HDInsight service;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-rg/providers/Microsoft.HDInsight/clusters/p02spark-as-p02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",failed to connect to the cluster to submit jobs,0.026672628,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,failed to connect to the cluster to submit jobs,By design,"Where is the curl command being passed from? -->Is this a VM/client machine within or is connected the Vnet where HDinsight cluster is deployed? if yes --> you would have to use the '-int' endpoint to hit the internal loadbalancer instead of passing via the public internet, this endpoint wiull resolve to a private IP in the clusters Vnet. The internal endpoint would look like : https://p02-las-as-int.azurehdinsight.net/livy/batchesIf the client is located outside the Vnet then you would have to whitelist the client's Public IP to be able to connect to the cluster. ",,,,,,,,
1.20062E+14,07:22.5,Query Performance issue.,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 11, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 17, 2020, 12:00 AM CDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Will share interactive query\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Hive query takke more time than usual to execute. Already shraed details with {Namepii} Thapa. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Will share interactive query;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Ambari Hive view;\nAdditional details about the issue - Hive query takke more time than usual to execute. Already shraed details with {Namepii} Thapa. ;\n\n- ProblemStartTime: 06/11/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {Xuidpii}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e56a92fa-5993-43a3-95e9-244023388b90/resourceGroups/PROD-HDINSIGHTS-GROUP/providers/Microsoft.HDInsight/clusters/prodhdiiq\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Query Performance issue.,4.185017456,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Interactive Query,Cluster performance degradation.,hdfs out of diskzk quoram ,https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-failshttps://docs.microsoft.com/en-us/archive/blogs/bigdatasupport/hdfs-gets-full-in-azure-hdinsight-with-many-hive-temporary-files,,,,,,,,
1.20062E+14,53:16.8,Yarn portal not working. Cluster in weird state,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 17, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I enabled schedule based auto scale yesterday. Today I tried to disable auto scale and scale up my cluster. Now the cluster is in weird state, I am not able to open yarn portal. We are not able to run our batch jobs. Please help.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I enabled schedule based auto scale yesterday. Today I tried to disable auto scale and scale up my cluster. Now the cluster is in weird state, I am not able to open yarn portal. We are not able to run our batch jobs. Please help.;\n\n- ProblemStartTime: 06/17/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Teams-RecGen_StreamProcessing-PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/95fcc4dc-c3b2-463c-9a36-471714d13ad4/resourceGroups/batchcluster/providers/Microsoft.HDInsight/clusters/BatchNEUCluster\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Yarn portal not working. Cluster in weird state,1.105754827,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,Yarn portal not working. Cluster in weird state,Both the head nodes were in maintenance mode and Resource Manager was in standy mode on both the nodes.,"One of the blocks were corrupted in HDFS.After removing the corrupted block and restarting the Resource Manager could bring up the RM up and running.Hence YARN UI is accessible after that.Also, Ambari DB is throttled.Hence recommendation is to create a custom Ambari DB to S1 to S2 tier for better performance.",,,,,,,,
1.20062E+14,20:18.4,Cluster is in 'Updating Error' state,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 17, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I tried to disable auto scale. Now this the cluster is in this weird error state. I am not able to open Ambari or yarn portal.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I tried to disable auto scale. Now this the cluster is in this weird error state. I am not able to open Ambari or yarn portal.;\n\n- ProblemStartTime: 06/17/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Teams-RecGen_StreamProcessing-PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/95fcc4dc-c3b2-463c-9a36-471714d13ad4/resourceGroups/batchcluster/providers/Microsoft.HDInsight/clusters/BatchcusCluster\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is in 'Updating Error' state,9.043224918,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,Cluster is in 'Updating Error' state.,NA,"While you have disabled autoscale, From our backend logs, we see that an exception occured while submiting script actions to Ambari.Upon further troubleshooting, we see that cluster manifest haven't got updated. Since the cluster manifest did not get updated, we failed the workflow and cluster is in ERROR state.It looks like it failed at the networking layer. As we do not have the complete network stack trace we couldn't provide RCA at this momemt.Workitem created on this issue.https://msdata.visualstudio.com/HDInsight/_workitems/edit/799045",,,,,,,,
1.20062E+14,28:08.0,"Getting an 'internal error' every time I try to deploy this cluster. I have tried deleting the cluster and redeploying it, with no luck.","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Error code\nAzureResourceCreationFailedErrorCode\nError message\nInternal server error occurred while processing the request. Please retry the request or contact support.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Intune EDP Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1af8aa9c-4f0a-4327-9e42-60389744f4af/resourceGroups/ntn-prd-usw2-rg-spark/providers/Microsoft.HDInsight/clusters/ntn-prd-usw2-spark-gdpr\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Getting an 'internal error' every time I try to deploy this cluster. I have tried deleting the cluster and redeploying it, with no luck.",0.911342354,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Service unhealthy\Spark,"Getting an 'internal error' every time I try to deploy this cluster. I have tried deleting the cluster and redeploying it, with no luck.",Reached deployment limit. ,"Recommended steps:Check for the cluster location and the number of nodes for the existing cluster. Try to create a new cluster in a different location. If it not possible to change the location, try to check the limit and increase the quota.After increasing  the quota, try to re-create a new cluster with more worker nodes and it should work successfully. ",,,,,,,,
1.20062E+14,46:19.4,creation faild at cluser container step,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 18, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: The issue is known and is related to ticket {Phonenumberpii}, ADDS bug.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: 'statusMessage': '{{uncpii}\':{\\'code\\':\\'ResourceNotFound\\',\\'message\\':{Uncpii} Resource '{AlphanumericPII}' under resource group '{AlphanumericPII}' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix{Uncpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - The issue is known and is related to ticket {Phonenumberpii}, ADDS bug.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - 'statusMessage': '{{uncpii}\':{\\'code\\':\\'ResourceNotFound\\',\\'message\\':{Uncpii} Resource '{AlphanumericPII}' under resource group '{AlphanumericPII}' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix{Uncpii}\n\n- ProblemStartTime: 06/17/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/210caf07-d474-4d04-9c42-02bdc9d29b3d/resourceGroups/central-PROD-pep-spark-112-V2-V1-Automation-HDI/providers/Microsoft.HDInsight/clusters/W4P7jhKabr-CentralSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",creation faild at cluser container step,0.217854356,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,creation faild at cluser container step,known bug https://portal.microsofticm.com/imp/v3/incidents/details/191453787/home,restarted again and now it works....permanant fix is set for Monday hotfix ,"191,453,787,193,123,000",,,,,,,
1.20062E+14,37:02.6,The autoscaling didnt finish and it is stuck in there,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 16, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: None\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The autoscaling was working fine, schedule based, but the day before yesterdat it didnt finish and it has been stuck in an 'oin going operation' since then\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - None;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The autoscaling was working fine, schedule based, but the day before yesterdat it didnt finish and it has been stuck in an 'oin going operation' since then;\n\n- ProblemStartTime: 06/16/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZRINFRAESTRUCTURA\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3f8d5f46-3a0e-4bc6-9e32-3e4774c514aa/resourceGroups/AZRDATALAKE/providers/Microsoft.HDInsight/clusters/v360devhdpc2\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",The autoscaling didnt finish and it is stuck in there,4.264738718,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,The autoscaling didnt finish and it is stuck in there,cluster was stuck in Error status,PG out back in Running state ,193029660,,,,,,,
1.20062E+14,46:19.7,Queries are not completing. Zookeper service down.,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 17, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select campaign_id , count (*)\nfrom materalization_stage.eloqua_segment_detail_as \nwhere campaign_id in ('{ALPHANUMERICPII}', '{ALPHANUMERICPII}', '{ALPHANUMERICPII}', '{ALPHANUMERICPII}')\ngroup by campaign_id\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Issue started from two qlik servers:\n{Ipaddresspii} -  {ALPHANUMERICPII}\n{Ipaddresspii}  -  {ALPHANUMERICPII}\n\nAfter that, we noticed that we'd get the same error accessing Hive from {Namepii} or Beeline (errors and query attached).\n\nWe also notices an health issue with zookeeper.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select campaign_id , count (*)\nfrom materalization_stage.eloqua_segment_detail_as \nwhere campaign_id in ('{ALPHANUMERICPII}', '{ALPHANUMERICPII}', '{ALPHANUMERICPII}', '{ALPHANUMERICPII}')\ngroup by campaign_id\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Issue started from two qlik servers:\n{Ipaddresspii} -  {ALPHANUMERICPII}\n{Ipaddresspii}  -  {ALPHANUMERICPII}\n\nAfter that, we noticed that we'd get the same error accessing Hive from {Namepii} or Beeline (errors and query attached).\n\nWe also notices an health issue with zookeeper.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/16/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: FCAITA-EMEA-PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/590fa16d-e37a-43d4-900c-60256027e70e/resourceGroups/rsg-EM03859P000/providers/Microsoft.HDInsight/clusters/hdinsight03859\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Queries are not completing. Zookeper service down.,0.30486421,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Query or Job Failure\Hive,Ambari website down/unresponsive.  Qlik ODBC servers unable to make connections to cluster's Thrift endoint.  Zookeeper unhealthy and unable to form a quorum,Increase in resident set size of the Journal Node process running on each of the ZK nodes caused kswapd0 to utilize more than 90 percent system CPU time trying to free memory,Rebooted all of the cluster nodes,193013791,,,,,,,
1.20062E+14,12:49.4,Name nodes unreachable while on autoscale,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Name nodes for the cluster went down. \nWe restarted the hdfs services, name nodes were up and then went down again after health check.\n\nQuestion: Increase in load?\nAnswer: More data to be processed\n\nQuestion: Mitigating actions taken so far\nAnswer: Restart services for name node. Name nodes went down again.\n\nQuestion: Additional details about the issue\nAnswer: Autoscale was on. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Name nodes for the cluster went down. \nWe restarted the hdfs services, name nodes were up and then went down again after health check.;\nIncrease in load? - More data to be processed;\nMitigating actions taken so far - Restart services for name node. Name nodes went down again.;\nAdditional details about the issue - Autoscale was on. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} Prod Subscription(dws)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/019daf6c-7f28-4a87-8ea1-f46570f10024/resourceGroups/myntra_bi_hdinsight_rg/providers/Microsoft.HDInsight/clusters/utm-session-insights-prod-clickstream\n- Location: southindia\n- Location: South India\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Name nodes unreachable while on autoscale,0.13794689,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,"Name nodes for the cluster went down.  We restarted the hdfs services, name nodes were up and then went down again after health check.; Increase in load? - More data to be processed;",RM went to standby and name node went to unknow state,disabling the node label resolved the issue .,"193,025,231,193,025,000,000,000,000",,,,,,,
1.20062E+14,21:23.3,Kafka Criticial Alert Regarding Broker Node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi,\n\nFirst, you might ignore problem type/sub-type. I had to select something. I tried to select something relevant.\n\nProblem is: Kafka Ambari shows Critical alert in one of the Kafka broker node in production environment (Kafka Instance Name: {alphanumericpii}). I have attached logs/screenshots from Ambari Portal. Please treat it as an urgent issue.\n\nAlert from Ambari portal:\n\nConnection failed: 'NoneType' object has no attribute 'split' to wn2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net \n\nAnother alert triggered to support team:\n\nServices Reporting Alerts\nCRITICAL [AMBARI] \nAMBARI\nCRITICAL Ambari Agent Heartbeat \nzk2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net is not sending heartbeats \n{Namepii}: {alphanumericpii} \nHost: zk2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net \nThis notification was sent to Main DAL Support \n{Namepii} Ambari {Ipaddresspii} \n\n\n\nRegards,\nMustafiz\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi,\n\nFirst, you might ignore problem type/sub-type. I had to select something. I tried to select something relevant.\n\nProblem is: Kafka Ambari shows Critical alert in one of the Kafka broker node in production environment (Kafka Instance Name: {alphanumericpii}). I have attached logs/screenshots from Ambari Portal. Please treat it as an urgent issue.\n\nAlert from Ambari portal:\n\nConnection failed: 'NoneType' object has no attribute 'split' to wn2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net \n\nAnother alert triggered to support team:\n\nServices Reporting Alerts\nCRITICAL [AMBARI] \nAMBARI\nCRITICAL Ambari Agent Heartbeat \nzk2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net is not sending heartbeats \n{Namepii}: {alphanumericpii} \nHost: zk2-ccprd2.uf1orwxzvbgulplgnxlnslxija.ux.internal.cloudapp.net \nThis notification was sent to Main DAL Support \n{Namepii} Ambari {Ipaddresspii} \n\n\n\nRegards,\nMustafiz;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: INF PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e479944e-434c-465a-a154-32e05268f875/resourceGroups/maz-cac-prda2-dalkfk-1082-rg/providers/Microsoft.HDInsight/clusters/ccprd2mazdalkfk\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kafka Criticial Alert Regarding Broker Node,0.027103244,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Kafka Criticial Alert Regarding Broker Node,Kafka broker got an alert and connection failed on wn2,Rebooted on wn2 and zk nodes,,,,,,,,
1.20062E+14,30:45.2,Scaling Operation Over 5 Hours,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 18, 2020, 5:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I scaled out the cluster to 700 nodes on the portal since 6am today. It's been over 5 hours, no failures but still running.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I scaled out the cluster to 700 nodes on the portal since 6am today. It's been over 5 hours, no failures but still running.;\n\n- ProblemStartTime: 06/18/2020 12:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EDP Core Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d6132b1-574a-42db-a8c6-d583d892ebd2/resourceGroups/spark-p-core-rg/providers/Microsoft.HDInsight/clusters/EDPCoreSparkSharedProd\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Scaling Operation Over 5 Hours,13.03849282,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,120061821006718  - Scaling Operation Over 5 Hours,Ambari DB locked while registering the new nodes,The Product Group suggested using a custom Ambari DB and increasing the Ambari Server heap size,193055619,,,,,,,
1.20062E+14,32:31.4,Spark in yarn mode won't accept jar local arguments for files on adls,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: We have a spark job that passes local arguments to the jar. One of the local arguments is a properties file that is stored on an ADLS conainter. When the job is submitted (either via Oozie or spark-submit), it throws a file not found and it seems to be looking for the file on the local filesystem instead of adls.\n\nHere is the spark-submit:\nspark-submit --master yarn-cluster --num-executors 1 --driver-memory 5g --executor-memory 10g --verbose --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf {AlphanumericPII} --queue default --class {AlphanumericPII} abfs://chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/cfs-etl-pipeline.jar abfs://chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties false\n\nHere is the error: User class threw exception: java.io.FileNotFoundException: abfs:/chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties (No such file or directory)\n\n{Namepii} Kola is aware of this issue and was going to check internally if anyone knew about this and see if he could replicate.\n\nQuestion: Additional details about the issue\nAnswer: User class threw exception: java.io.FileNotFoundException: abfs:/chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties (No such file or directory)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Scala;\nSpark configuration details - We have a spark job that passes local arguments to the jar. One of the local arguments is a properties file that is stored on an ADLS conainter. When the job is submitted (either via Oozie or spark-submit), it throws a file not found and it seems to be looking for the file on the local filesystem instead of adls.\n\nHere is the spark-submit:\nspark-submit --master yarn-cluster --num-executors 1 --driver-memory 5g --executor-memory 10g --verbose --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf {AlphanumericPII} --queue default --class {AlphanumericPII} abfs://chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/cfs-etl-pipeline.jar abfs://chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties false\n\nHere is the error: User class threw exception: java.io.FileNotFoundException: abfs:/chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties (No such file or directory)\n\n{Namepii} Kola is aware of this issue and was going to check internally if anyone knew about this and see if he could replicate.;\nAdditional details about the issue - User class threw exception: java.io.FileNotFoundException: abfs:/chbp23adlbatch-2020-06-16t18-59-39-295z@adlcertadls2storage.dfs.core.windows.net/apollo/edl/platform/edl-migration-impetus/current/conf/db-param/d8-db-params.properties (No such file or directory);\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/chbp23adlbatch\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark in yarn mode won't accept jar local arguments for files on adls,3.132900325,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Spark in yarn mode won't accept jar local arguments for files on adls," the code it looks for parameter file based on “hdfs://”, and if it doesn’t start with that it looks on local filesystem. So they are going to fix that so it can exist on abfs://. Here was the code: def loadProperties(propertyFilePath: String): scala.collection.mutable.Map[String, String] = {    if (propertyFilePath.trim().startsWith(""hdfs://"")) {      return loadPropertiesFromHDFS(propertyFilePath, sparkSession)    }",Modify code to pull from the storage account instead of local,,,,,,,,
1.20062E+14,06:29.1,PRDSUP - kpps83sparkespprdsupwus201 - Lock on ADLS Locations,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 18, 2020, 10:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: --executor-memory 6g --num-executors 8 --executor-cores 4 --driver-memory 4g  --conf spark.yarn.submit.waitAppCompletion=false\n\n\n\nQuestion: Additional details about the issue\nAnswer: issue: \norg.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException: Operation failed: 'There is currently a lease on the resource and no lease ID was specified in the request.', 412, PUT, https://kpadlsgen2prdsupwus201.dfs.core.windows.net/adf/tenant/insightdriven/monthlyarchive/NCAL/archivejson062020?timeout=90, LeaseIdMissing, 'There is currently a lease on the resource and no lease ID was specified in the request. {AlphanumericPII} {AlphanumericPII}'\n\nLocation where \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - --executor-memory 6g --num-executors 8 --executor-cores 4 --driver-memory 4g  --conf spark.yarn.submit.waitAppCompletion=false\n\n;\nAdditional details about the issue - issue: \norg.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException: Operation failed: 'There is currently a lease on the resource and no lease ID was specified in the request.', 412, PUT, https://kpadlsgen2prdsupwus201.dfs.core.windows.net/adf/tenant/insightdriven/monthlyarchive/NCAL/archivejson062020?timeout=90, LeaseIdMissing, 'There is currently a lease on the resource and no lease ID was specified in the request. {AlphanumericPII} {AlphanumericPII}'\n\nLocation where ;\n\n- ProblemStartTime: 06/18/2020 17:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP - kpps83sparkespprdsupwus201 - Lock on ADLS Locations,0.850577706,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,PRDSUP - kpps83sparkespprdsupwus201 - Lock on ADLS Locations,PRDSUP - kpps83sparkespprdsupwus201 - Lock on ADLS Locations,Worked with ADLS Gen2 team and shared details with customer on the lease. Customer had cleared the lease and had successfully run the spark application.,,,,,,,,
1.20062E+14,16:04.2,Cannot scalue up,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 17, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: cannot scale up since June 17\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - cannot scale up since June 17;\n\n- ProblemStartTime: 06/17/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot scalue up,0.861258798,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Cannot scalue up,Cannot scalue up,"Ambari-server was found running on both the headnode, support stopped the same on passive headnode and restarted Ambari-server. Customer confirmed that he is able to scale-up the cluster now.",,,,,,,,
1.20062E+14,38:33.6,HDInsight cluster upgrade,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: dev-offprev-hdispark-cluster\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe need to upgrade our existing HDinsight clusters from Spark 2.3 (HDI 3.6) to Spark 2.4 (HDI 4.0). Kindly share the upgrade documentation to start this activity ASAP.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - dev-offprev-hdispark-cluster;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hi {Namepii},\n\nWe need to upgrade our existing HDinsight clusters from Spark 2.3 (HDI 3.6) to Spark 2.4 (HDI 4.0). Kindly share the upgrade documentation to start this activity ASAP.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight cluster upgrade,13.28337302,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Advisory,Advisory,"As a recap, currently there is not way to upgrade cluster versions.You would need to destroy the old cluster and deploy the new cluster with the new versions.",,,,,,,,
1.20062E+14,57:55.5,Zookeeper node failures on 16th and 17th June 2020,"Why did zookeper nodes stop working on {Alphanumericpii} and 17th June 2020 ?\n\nAlong with that, we have also observed critical alerts on worker nodes.\n\nProblem start date and time\n{Namepii}, {Namepii} 16, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/15/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/4b5dbbb6-c084-4bfc-af2c-7505b64958af/resourceGroups/mdsp-iots-prod/providers/Microsoft.HDInsight/clusters/mdsp-iots-prod-hbase-aks\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zookeeper node failures on 16th and 17th June 2020,0.351660478,Root Cause : HDInsight Service\Transient error / Unknown,,"Unhealthy Cluster, connection failed for Zk servers ",Zookeeper server failed to form quorum.Log file grew in headnode,https://docs.microsoft.com/en-us/azure/hdinsight/spark/zookeeper-troubleshoot-quorum-failsManually deleted the log file and patched the cluster with log rotate,193840291,,,,,,,
1.20062E+14,59:16.6,Heartbeat lost on wn29 & wn57,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe are getting heartbeat lost error in ambari UI for {alphanumericpii} & {alphanumericpii} in dev-offprev-hdispark-cluster. I have attached the error screenshots. Kindly look into it and resolve ASAP.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi {Namepii},\n\nWe are getting heartbeat lost error in ambari UI for {alphanumericpii} & {alphanumericpii} in dev-offprev-hdispark-cluster. I have attached the error screenshots. Kindly look into it and resolve ASAP.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/DEV-HDI-SPARK/providers/Microsoft.HDInsight/clusters/dev-offprev-hdispark-cluster\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Heartbeat lost on wn29 & wn57,0.147191614,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Spark,Heartbeat lost on wn29 & wn57,Heartbeat lost on wn29 & wn57,Checked on the cluster and found lot of omsagent zombie processes on the cluster. Shared suggestions with customer to disable and enable omsagent on Azure portal for HDInsight cluster. Restarted both nodes and the issue is fixed now,,,,,,,,
1.20062E+14,50:04.7,Could not retrieve cluster information from cluster,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 19, 2020, 8:30 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Password, access key, or certificate rotation\n\nQuestion: Detail of the changes\nAnswer: After changing the account password used to run oozie/spark job on the HDInsight cluster\n\nThe user : {emailpii}@sgazureprd.onmicrosoft.com \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Error from oozie : \n\nCould not retrieve cluster information from https://rtg40prod.hdi.datalakefeeder.prd.euw.gbis.sg-azure.com/api/v1/clusters. reason: {'Code':'Unauthorized','Message':'Token acquisition {AlphanumericPII}'} \n\n\nError from one cluster headnode when tring to log in with this account :\n\nsu - az-svc-rtg-hdiprd\nPassword:\nYour account has been locked. Please contact your System administrator\n\nPlease join our conf call :\n\nJoin Skype Meeting      \nTrouble Joining? Try Skype Web App\nJoin by phone\n{Phonenumberpii}# (India-Toll Free)                   English (United States) \n{Alphanumericpii}# (India-Toll Free)                               English (United States)  \nFind a local number \nConference ID: 16093862 \n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Password, access key, or certificate rotation;\nDetail of the changes - After changing the account password used to run oozie/spark job on the HDInsight cluster\n\nThe user : {emailpii}@sgazureprd.onmicrosoft.com ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Error from oozie : \n\nCould not retrieve cluster information from https://rtg40prod.hdi.datalakefeeder.prd.euw.gbis.sg-azure.com/api/v1/clusters. reason: {'Code':'Unauthorized','Message':'Token acquisition {AlphanumericPII}'} \n\n\nError from one cluster headnode when tring to log in with this account :\n\nsu - az-svc-rtg-hdiprd\nPassword:\nYour account has been locked. Please contact your System administrator\n\nPlease join our conf call :\n\nJoin Skype Meeting      \nTrouble Joining? Try Skype Web App\nJoin by phone\n{Phonenumberpii}# (India-Toll Free)                   English (United States) \n{Alphanumericpii}# (India-Toll Free)                               English (United States)  \nFind a local number \nConference ID: 16093862 \n;\n\n- ProblemStartTime: 06/19/2020 12:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7afd8a0e-516f-4623-894d-022e4e8e4c71/resourceGroups/central_feeder-PROD-rtg4019062020-Automation-HDI/providers/Microsoft.HDInsight/clusters/RnvL4sX9w3-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Could not retrieve cluster information from cluster,0.398000997,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,"Error from oozie :   Could not retrieve cluster information from https://rtg40prod.hdi.datalakefeeder.prd.euw.gbis.sg-azure.com/api/v1/clusters. reason: {'Code':'Unauthorized','Message':'Token acquisition failed','CorrelationId':'818c61969d614b249b4e7d4c8c5bf431','ResponseTimestamp':'2020-06-19T13:23:27.2116386Z'} ",Could not retrieve cluster information from cluster,"Below are issues worked on and fixed,Found this issue was with a zombie job that was using the old password. Killing old job and then it started working fineAuthentication error issue is fixed, once after updating the service end point policy.Hive Interactive issue is fixed once after the restart.",,,,,,,,
1.20062E+14,40:08.8,indisponibilidad del cluster por un lapso de tiempo,"Pregunta: ¿A qué hora comenzó {namepii} problema?\nRespuesta: vie., 19 {namepii}. 2020 7:30 {ALPHANUMERICPII}\n\nPregunta: {Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco.\nRespuesta: vie., 19 {namepii}. 2020 8:00 {ALPHANUMERICPII}\n\nPregunta: ¿Es un problema nuevo o ha sucedido antes?\nRespuesta: Problema nuevo, funcionaba antes\n\nPregunta: ¿{Namepii} ha hecho algún cambio?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: ¿{Namepii} aumentado {namepii} carga?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: Identificador {namepii} {namepii} aplicación {namepii} YARN para {namepii} trabajo {namepii} HBase, si se conoce\nRespuesta: \n\nPregunta: {Namepii} {namepii} HBase\nRespuesta: \n\nPregunta: ¿Cómo se envió {namepii} trabajo {namepii} HBase?\nRespuesta: {Namepii} {namepii} HBase\n\nPregunta: Detalles adicionales acerca del problema\nRespuesta: no tengo un diagnostico\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\n¿A qué hora comenzó {namepii} problema? - {ALPHANUMERICPII};\n{Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco. - {ALPHANUMERICPII};\n¿Es un problema nuevo o ha sucedido antes? - Problema nuevo, funcionaba antes;\n¿{Namepii} ha hecho algún cambio? - Otro, no lo sé o no {namepii} aplicable;\n¿{Namepii} aumentado {namepii} carga? - Otro, no lo sé o no {namepii} aplicable;\nIdentificador {namepii} {namepii} aplicación {namepii} YARN para {namepii} trabajo {namepii} HBase, si se conoce - ;\n{Namepii} {namepii} HBase - ;\n¿Cómo se envió {namepii} trabajo {namepii} HBase? - {Namepii} {namepii} HBase;\nDetalles adicionales acerca del problema - no tengo un diagnostico;\n\n- ProblemStartTime: 06/19/2020 12:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Plan {namepii} soporte técnico {namepii} Azure - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/678db644-8433-4ce4-96d7-c3d616140a2c/resourceGroups/GRPBigData/providers/Microsoft.HDInsight/clusters/bigdatasatrack02\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",indisponibilidad del cluster por un lapso de tiempo,7.308116012,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hbase,indisponibilidad del cluster por un lapso de tiempo,Due to scaling operation,"Customer's cluster was down for a period of time. On Friday June 19th from 7:30 AM to 8:30 AM . This was due to the scaling operation performed on the 19th, the worker nodes were automatically rebooted. Suggested customer to not to scale down below 3 nodes in the future and this would lead to the cluster not responding appropriately. ",,,,,,,,
1.20062E+14,14:04.1,AmbariClusterCreationFailedErrorCode,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: An error occurred during the ARM deployment of the cluster. Please help resolve.\n5:38:10 PM - Resource Microsoft.HDInsight/clusters 'hiveclusterprodsouthcentralus' failed with message '{\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'AmbariClusterCreationFailedErrorCode',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}'\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - An error occurred during the ARM deployment of the cluster. Please help resolve.\n5:38:10 PM - Resource Microsoft.HDInsight/clusters 'hiveclusterprodsouthcentralus' failed with message '{\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'AmbariClusterCreationFailedErrorCode',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Payouts PayoutJournal Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb075b87-16bb-42c1-9e6a-1338cc47f6e2/resourceGroups/payoutjournal_prod_southcentralus_spark/providers/Microsoft.HDInsight/clusters/hiveclusterprodsouthcentralus\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",AmbariClusterCreationFailedErrorCode,4.178736732,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,AmbariClusterCreationFailedErrorCode.,NA, Identified issue with config. Hive interactive service did not start due to misconfiguration. ,,,,,,,,
1.20062E+14,40:37.5,"Since 9am EST, a keberos error, and not accessible to the jobs anymore. ","Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 19, 2020, 9:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 2020-06-19 {Alphanumericpii} | main                 |  WARN |                            {AlphanumericPII}  | NEGOTIATE authentication error: Invalid name provided (Mechanism level: KrbException: Cannot locate default realm) \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - ;\nAdditional details about the issue - 2020-06-19 {Alphanumericpii} | main                 |  WARN |                            {AlphanumericPII}  | NEGOTIATE authentication error: Invalid name provided (Mechanism level: KrbException: Cannot locate default realm) ;\n\n- ProblemStartTime: 06/19/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2953b2cf-932d-4b39-a68b-9c02bbd7c3c7/resourceGroups/eqd-ctr-cat-1-PROD-catappprd01cluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/FpV9HoVHRS-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Since 9am EST, a keberos error, and not accessible to the jobs anymore. ",0.029774591,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,2020-06-19 15:26:35.528 | main                 |  WARN |                            org.apache.http.impl.auth.HttpAuthenticator:203  | NEGOTIATE authentication error: Invalid name provided (Mechanism level: KrbException: Cannot locate default realm) ;,"Since 9am EST, a keberos error, and not accessible to the jobs anymore","This issue is fixed, once after updating the service end point policy",,,,,,,,
1.20062E+14,53:36.1,Cluster is not scaling and more than 20 node Managers are not live,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The Node Mangers are not live and the cluster is also not scaling up.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The Node Mangers are not live and the cluster is also not scaling up.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SDO - Big Data Program\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/23c0c9e6-02a0-43fa-b7b7-71dca8da4585/resourceGroups/RG-Prod-{Namepii}-DDP/providers/Microsoft.HDInsight/clusters/hdisprod-ddp\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster is not scaling and more than 20 node Managers are not live,0.120959376,Root Cause : HDInsight Service\Azure platform issues\Windows Azure SQL Database issue,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,"Cluster in error state, observing several node managers down after scaling the cluster up, Ambari DB ASC graph shows db is exhausted.","This customer was having a few issues, the core issue was that the node managers on new nodes would go down when scaling up. They intermittently would hit an update error state as well, this is resolved by PG but is not the core issue they are reporting. Seems the cause for the node managers going down may have been due to their Ambari DB needing to be scaled. It is also unclear if creating a separate ATS database would help this issue as well.Issue:Cluster Scaled up but only 7 out of 15 node manager are alive. Findings:During troubleshooting we found that the Ambari Db has exhausted and it is unable to handle the scaling operation.The scale down and scale up through RP was still affected by the ambari db issue. But, the autoscale could decommission nodes as it was less taxing on ambari than a scale activity. This destabilized the cluster. We had to manually recommission nodes to get back the required capacity. Recommendations:By scaling up ambari db sku, we should be able to avoid this issue.Long term fix is to recreate the cluster with a custom ambari db and enabling autoscale.  Additional Information Requested:Q. What does Ambari DB holdsAmbari stores all the information needed to managed the state and configuration of your cluster. Information concerning the Ambari users and the configuration of Ambari Views are two other items you will see. You can find the database DDLs on the Ambari server host in the /var/lib/ambari-server/resources directory. The table names in the schema are informatively named and if you do a quick grep on ""CREATE TABLE"" you can get a quick grasp on the type of data stored by Ambari.Check the ambari database properties in /etc/ambari-server/conf/ambari.propertiesThe Ambari DB also hold the ATS Tables along with Ambari Tables Q. How to use separate DB for ATSMove ATS DB to a custom SQL serverPlease note that the existing jobs will be affected when you move the ATS db over to a new instancePlease ensure that the SQL DB is provisioned, with a good enough SKUYou can change the SKU as you goPlease ensure that the network access policies (NSGs) are consistent with the HDInsight recommendations for a custom ambari databasePlease run the following script on the active headnodehttps://hdiconfigactions.blob.core.windows.net/hadoopcorepatchingscripts/update_ats_db.sh (update the script and pass the required arguments)",Gave cx recommendations to scale the Ambari DB and potentially separating the ATS database as well.,193349510,,,,,,,
1.20062E+14,01:42.1,HDI Kafka worker node hostnames not resolvable,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 20, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: changed the configs in the Kafka Broker to stop using the FQDN and start using the IP addresses\n\nQuestion: Additional details about the issue\nAnswer: Server is currently unable to connect to HDI kafka worker nodes when attempting to ssh from AKS cluster. \n\nErrors received when connecting to Kafka worker node 3 and worker node 1 via ssh from AKS cluster ({Alphanumericpii}) :\n•Can't resolve address: wn3-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net:9092 java.nio.channels.UnresolvedAddressException\n•Could not resolve hostname wn1-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net: nodename nor servname provided, or not known\n\nSource/Destination next hop details:\nSource: {alphanumericpii} ({Ipaddresspii}) - ILB-AM-EastUS-SS-PaloAlto-EastWest ({Ipaddresspii}) -Destination: wn3-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net ({Ipaddresspii})\nSource: {alphanumericpii} ({Ipaddresspii}) - ILB-AM-EastUS-SS-PaloAlto-EastWest ({Ipaddresspii}) - Destination wn1-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net ({Ipaddresspii})\n\nThe issue is currently affecting production environment as external users are still using the FQDN to access the broker.\n\nWe are looking for assistance in troubleshooting why FQDN has stopped working.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - changed the configs in the Kafka Broker to stop using the FQDN and start using the IP addresses;\nAdditional details about the issue - Server is currently unable to connect to HDI kafka worker nodes when attempting to ssh from AKS cluster. \n\nErrors received when connecting to Kafka worker node 3 and worker node 1 via ssh from AKS cluster ({Alphanumericpii}) :\n•Can't resolve address: wn3-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net:9092 java.nio.channels.UnresolvedAddressException\n•Could not resolve hostname wn1-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net: nodename nor servname provided, or not known\n\nSource/Destination next hop details:\nSource: {alphanumericpii} ({Ipaddresspii}) - ILB-AM-EastUS-SS-PaloAlto-EastWest ({Ipaddresspii}) -Destination: wn3-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net ({Ipaddresspii})\nSource: {alphanumericpii} ({Ipaddresspii}) - ILB-AM-EastUS-SS-PaloAlto-EastWest ({Ipaddresspii}) - Destination wn1-hdikez.ll2jzjxw5hwenp4v1b1wdyootg.bx.internal.cloudapp.net ({Ipaddresspii})\n\nThe issue is currently affecting production environment as external users are still using the FQDN to access the broker.\n\nWe are looking for assistance in troubleshooting why FQDN has stopped working.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/20/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: ELC-AM-PROD-PAAS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f57996ce-6cfe-400a-a311-f797fd8484d8/resourceGroups/RG-AM-EastUS-Prod-CDPNA/providers/Microsoft.HDInsight/clusters/hdikezprod-am-eastus-cdpna\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI Kafka worker node hostnames not resolvable,1.745172371,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Service unhealthy\Kafka,The names of the workers where kafka brokers were hosted were not able to be resolved by customer's custom DNS server,DNSSEC validation.  PFE who RCA'd issue indicated this issue had been seen in the past on customer's forwarding servers,Issue self-mitigated,,,,,,,,
1.20062E+14,12:43.4,Hbase :RetriesExhaustedWithDetailsException; CDC is failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: java.io.IOException: {Namepii} to wn151-kpp091.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.208.215:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: \norg.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 7 actions: Operation Timeout: 7 times, servers with issues: {alphanumericpii}\n\nQuestion: {Namepii} was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: java.io.IOException: {Namepii} to wn151-kpp091.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.208.215:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: \norg.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 7 actions: Operation Timeout: 7 times, servers with issues: {alphanumericpii}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - java.io.IOException: {Namepii} to wn151-kpp091.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.208.215:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: \norg.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 7 actions: Operation Timeout: 7 times, servers with issues: {alphanumericpii};\n{Namepii} was the HBase job submitted? - HBase shell;\nAdditional details about the issue - java.io.IOException: {Namepii} to wn151-kpp091.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.208.215:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: \norg.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 7 actions: Operation Timeout: 7 times, servers with issues: {alphanumericpii};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpp091hbaseprodwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hbase :RetriesExhaustedWithDetailsException; CDC is failing,18.1870091,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hbase,Hbase :RetriesExhaustedWithDetailsException; CDC is failing,Hbase :RetriesExhaustedWithDetailsException; CDC is failing,"We do see multiple exceptions in the logs and copied few below,regionserver Slf4JLogger.java 2020-06-16 02:55:27.6041600 LEAK: ByteBuf.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.(responseTooSlow): {""call"":""Multi(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MultiRequest)"",""starttimems"":XXXX,""responsesize"":103,""method"":""Multi"",""param"":""region=XXXXXX:XXXX,NW_XXXXX,1590915493882.XXXXX., for 14 action(s) and 1st row key=NW_XXXX"",""processingtimems"":10018,""client"":""XXXXXX:55332"",""queuetimems"":0,""class"":""HRegionServer""}Slow sync cost: 46656 ms, current pipeline: [][1] - Every RPC will have a time out of 60 sec. Some of the client end logs says clearly that this time out is happening and it will retry. On the server side, once this call is over, we will see that the client already given up with this call. So we will cancel it with out sending any response. We use Netty at the RPC layer for reading req bytes into and sending response.  Netty uses Byte buffers from its pool for these.    In all paths we are supposed to call Netty ByteBuf.release() after usage of this Buffer . But when cancel call connection, we were missing this call.  (https://issues.apache.org/jira/browse/HBASE-22963). Our PG is cheking on this and see we can backport this or not.[2] and [3] - If your writes are critical, we would recommend to use HDInsight HBase Accelerated Writes and see more info here - https://azure.microsoft.com/en-us/updates/hdinsight-hbase-accelerated-writes-is-now-generally-available/#:~:text=The%20accelerated%20writes%20feature%20in,of%20standard%20Azure%20page%20blobs.",193917102,,,,,,,
1.20062E+14,42:35.2,Cluster not scaling,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} not scaling with the following error:\n\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':\\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: TooManyDeploymentsInResourceGroup; ErrorDescription: Please delete some deployments in the resource group '{alphanumericpii}' and subscription '{guidpii}'. Current number of deployments: '800', Additional number of deployments required: '8', Limit of deployments per resource group: '800'. For more information, please visit https://go.microsoft.com/fwlink/?linkid=859626 or contact support.\\\n\nCan you please clear all deployments older than 5 days?\n\nWe've never had to do this before. Has something changed recently?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - {Namepii} not scaling with the following error:\n\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':\\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'InternalServerError\\',\\'message\\':{UNCPII}: TooManyDeploymentsInResourceGroup; ErrorDescription: Please delete some deployments in the resource group '{alphanumericpii}' and subscription '{guidpii}'. Current number of deployments: '800', Additional number of deployments required: '8', Limit of deployments per resource group: '800'. For more information, please visit https://go.microsoft.com/fwlink/?linkid=859626 or contact support.\\\n\nCan you please clear all deployments older than 5 days?\n\nWe've never had to do this before. Has something changed recently?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-rg-ingest1/providers/Microsoft.HDInsight/clusters/eds5prd-ingest-cluster\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster not scaling,0.085484315,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Error message from portal clearly states it's an issue with the resource group deployment history.,Customer's deployment history reached the hard maximum of 800 for their resource group.,Advised cx to delete old deployments from their resource group deployment history and provided documentation on new feature that cleans up old deployments automatically.,,,,,,,,
1.20062E+14,49:45.5,HDInsight 4.0 & Juptyer,"Regarding this article (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-version-release#how-to-upgrade-to-hdinsight-40) on HDInsight 4.0, Azure Data {Namepii} Storage {Alphanumericpii} can't save Jupyter notebooks in a SPARK cluster.\n\nIf {Alphanumericpii} ADLS is not supported by HDInsight 4.0, and {Alphanumericpii} ADLS cannot store Jupyter notebooks, what are all of the alternatives we have to store Jupyter Notebooks for our SPARK clusters?\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight 4.0 & Juptyer,0.237506267,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Client tool issue\Notebooks,HDInsight 4.0 & Jupyter.,NA,Jupyter notebooks are saved locally to the headnodes and you have to manually back it up to storage account. Please ssh into cluster and use below commands : hdfs dfs -ls /HdiNotebooks à everything in this directory is visible to Jupyter from the home pagehdfs dfs –copyToLocal /HdiNotebooks à Download the contents of the HdiNotebooks folderhadoop fs -cp /HdiNotebooks/sample.ipynb abfs://sample@testadlsgen2account.dfs.core.windows.net/sample/   àcopy sample.ipynb to storage account Document reference: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-jupyter-notebook-kernels#where-are-the-notebooks-stored,,,,,,,,
1.20062E+14,41:03.5,Unable to Connect to Worker Node,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 22, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Log files filled up all of the disk space on wn2. When trying to ssh to the cluster, the password is expired, but I cannot change it due to the lack of disk space (Error: Authentication token manipulation error) and the connection closes. The directory that needs to be cleared is ~/nifi-1.8.0/logs.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Log files filled up all of the disk space on wn2. When trying to ssh to the cluster, the password is expired, but I cannot change it due to the lack of disk space (Error: Authentication token manipulation error) and the connection closes. The directory that needs to be cleared is ~/nifi-1.8.0/logs.;\n\n- ProblemStartTime: 06/22/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: TBRAYS Azure Main\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2cb8b0ef-55e9-4297-91a4-6710f8b7888d/resourceGroups/tbr-bops-hdinsightCluster01/providers/Microsoft.HDInsight/clusters/tbr-bops-hdinsightCluster01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to Connect to Worker Node,0.045306179,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Unable to Connect to Worker Node,No disc space and connection failure,rebooted on wn2 and wn1,,,,,,,,
1.20062E+14,35:29.4,prod : kp02hbaseadfhdiprodusc01 : Not able to reach wn11,"{Alphanumericpii} not able to connect ,{Ipaddresspii}\n\n \n\n\nProblem start date and time\n{Namepii}, {Namepii} 22, 2020, 2:00 PM PDT\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/22/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kp02hbaseadfhdiprodusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prod : kp02hbaseadfhdiprodusc01 : Not able to reach wn11,0.019011567,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,prod : kp02hbaseadfhdiprodusc01 : Not able to reach wn11,Vm agent unresponsive. ,Restarted from ACIS,193601630,,,,,,,
1.20062E+14,12:28.2,Alert for Kafka Broker - Connection failed: 'NoneType' object has no attribute 'split',"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 22, 2020, 6:38 PM GMT-3\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} Broker presents error:\nConnection failed: 'NoneType' object has no attribute 'split' to wn0-wishli.ccbvhlumfjpuvoqcxs4si35qjh.nx.internal.cloudapp.net:9092\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} Broker presents error:\nConnection failed: 'NoneType' object has no attribute 'split' to wn0-wishli.ccbvhlumfjpuvoqcxs4si35qjh.nx.internal.cloudapp.net:9092\n;\n\n- ProblemStartTime: 06/22/2020 21:38:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Sponsorship(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/30a25c0e-1b63-4aa3-9240-834cf5725970/resourceGroups/freedom-front/providers/Microsoft.HDInsight/clusters/wishlistprdfreedom\n- Location: brazilsouth\n- Location: {Namepii} South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Alert for Kafka Broker - Connection failed: 'NoneType' object has no attribute 'split',0.033828472,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Kafka,Alert for Kafka Broker - Connection failed: 'NoneType' object has no attribute 'split',Ambari alert on Kafka broker and Ambari Metrics collector.,"I have noticed the alert on Ambari Metrics collector process. I would like to request to perform the below resolution steps.Recommended Steps for Ambari Metrics Collector  Login into the Ambari portal  Set AMS to maintenance  Stop AMS from Ambari  Identify the following from the AMS Configs screen:     hbase.rootdir (Default value is file:///mnt/data/ambari-metrics-collector/hbase)   hbase.tmp.dir(Default value is /var/lib/ambari-metrics-collector/hbase-tmp)    SSH into headnode0. as superuser  Remove the AMS zookeeper data by backing      up and removing the contents of 'hbase.tmp.dir'/zookeeper  Remove any Phoenix spool files      from 'hbase.tmp.dir'/phoenix-spool folder  Note: It is worthwhile to skip this      step and first restarting AMS to see if the issue is resolved. If AMS is      still failing to come up, try this step: AMS data would be stored in hbase.rootdir identified above. Use      regular OS commands to backup and remove the files: # tar czf      /mnt/backupof-ambari-metrics-collector-hbase-$(date +%Y%m%d-%H%M%S).tar.gz      /mnt/data/ambari-metrics-collector/hbase  Restart AMS using Ambari Recommended Steps for alert on the Kafka Broker Process Perform restart of Ambari agent. Restart Ambari agent on wn0           1. ssh into cluster and ssh into wn12. check status of Ambari agent$sudo systemctl status ambari-agent3. stop Ambari agent and check the status$sudo systemctl stop ambari-agent$sudo systemctl status ambari-agent 4. check if there are zoombie processes$ps -ef | grep -v java | grep ambari-agentif there are other then ""grep"" process running, kill them all. 5. start Ambari agent and check the status$sudo systemctl start ambari-agent$sudo systemctl status ambari-agent 6. Check Ambari UI if there are new alerts.",,,,,,,,
1.20062E+14,40:26.1,wn8 not responding after reboot,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 23, 2020, 8:00 AM CDT\n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: When looking in Ambari this morning, wn8 had lost its heartbeat.  When I logged onto the system there was a lot of input/output errors and most commands were failing.  I did a sudo reboot on it and its not coming back up.  Need some assistance to get it back up.\n\nLast login: Fri {Namepii} 19 21:27:02 2020 from {Ipaddresspii}\n-bash: /etc/bash_completion.d/apport_completion: Input/output error\n-bash: /etc/bash_completion.d/cloud-init: Input/output error\n-bash: /etc/bash_completion.d/cryptdisks: Input/output error\n-bash: /etc/bash_completion.d/git-prompt: Input/output error\n-bash: /etc/bash_completion.d/grub: Input/output error\n-bash: /etc/bash_completion.d/insserv: Input/output error\n/usr/bin/lesspipe: line 28: /usr/bin/basename: Input/output error\n/usr/bin/lesspipe: line 295: [: =: unary operator expected\n-bash: /etc/bash_completion.d/apport_completion: Input/output error\n-bash: /etc/bash_completion.d/cloud-init: Input/output error\n-bash: /etc/bash_completion.d/cryptdisks: Input/output error\n-bash: /etc/bash_completion.d/git-prompt: Input/output error\n-bash: /etc/bash_completion.d/grub: Input/output error\n-bash: /etc/bash_completion.d/insserv: Input/output error\nehiadmin@wn8-x1ncsp:~$ uptime\n-bash: /usr/bin/uptime: Input/output error\nehiadmin@wn8-x1ncsp:~$ sudo reboot\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - When looking in Ambari this morning, wn8 had lost its heartbeat.  When I logged onto the system there was a lot of input/output errors and most commands were failing.  I did a sudo reboot on it and its not coming back up.  Need some assistance to get it back up.\n\nLast login: Fri {Namepii} 19 21:27:02 2020 from {Ipaddresspii}\n-bash: /etc/bash_completion.d/apport_completion: Input/output error\n-bash: /etc/bash_completion.d/cloud-init: Input/output error\n-bash: /etc/bash_completion.d/cryptdisks: Input/output error\n-bash: /etc/bash_completion.d/git-prompt: Input/output error\n-bash: /etc/bash_completion.d/grub: Input/output error\n-bash: /etc/bash_completion.d/insserv: Input/output error\n/usr/bin/lesspipe: line 28: /usr/bin/basename: Input/output error\n/usr/bin/lesspipe: line 295: [: =: unary operator expected\n-bash: /etc/bash_completion.d/apport_completion: Input/output error\n-bash: /etc/bash_completion.d/cloud-init: Input/output error\n-bash: /etc/bash_completion.d/cryptdisks: Input/output error\n-bash: /etc/bash_completion.d/git-prompt: Input/output error\n-bash: /etc/bash_completion.d/grub: Input/output error\n-bash: /etc/bash_completion.d/insserv: Input/output error\nehiadmin@wn8-x1ncsp:~$ uptime\n-bash: /usr/bin/uptime: Input/output error\nehiadmin@wn8-x1ncsp:~$ sudo reboot\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: 9885 - Decision Support Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/816a4b01-2bf2-44ce-9e31-b1fec9095726/resourceGroups/DS3_DEVResourceGroup_Central/providers/Microsoft.HDInsight/clusters/x1ncsparkstrm01\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",wn8 not responding after reboot,0.984084108,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Unable to access wn8,Wn8 not responding,rebooted wn8 from backend.,193705119,,,,,,,
1.20062E+14,42:45.6,Problems with the service 'mdsd',"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: {Namepii} node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have observed an issue in one of the headnodes which has caused the hadoop services to fall down. These services did not have space left in the device. The mdsd was taking more than {ALPHANUMERICPII} space and a lot of times the same error being stored in the logs (I'm attaching the error in the case). {Namepii} is it possible this amount is generated with these errors?\n\nThanks\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - {Namepii} node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We have observed an issue in one of the headnodes which has caused the hadoop services to fall down. These services did not have space left in the device. The mdsd was taking more than {ALPHANUMERICPII} space and a lot of times the same error being stored in the logs (I'm attaching the error in the case). {Namepii} is it possible this amount is generated with these errors?\n\nThanks;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/22/2020 22:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} OMEGA Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72644eaf-2d9b-4fa3-abf8-d511c6368cd5/resourceGroups/hcbae2p01rsgcdl001/providers/Microsoft.HDInsight/clusters/hcbae2p01hdicdlsping001\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Problems with the service 'mdsd',0.022249909,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Problems with the service 'mdsd',Problems with the service 'mdsd',Worked with customer and engaged product group on this. Product group advised to whitelist set of IP Addresses to fix mdsd errors. Customer is not happy to do that. Shared with customer that mdsd service logs are required for troubleshooting any issues related to the customer and poses risk to support assisting issues related to cluster. Customer agreed to the same and stopped mdsd service and confirmed to close the case.,194017881,,,,,,,
1.20062E+14,07:09.1,"Hi Team, we have observed one of the data node is missing hearbeat since 33 mins ago as displayed..","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have observed heartbeat lost on the worker node:\nHostname:\nwn228-entspa.rkzxzos33neexlrsld0v3rt5me.gx.internal.cloudapp.net\nIP {Alphanumericpii}\nThis was reported 33 mins ago, all other wn are running fine.\nThis is a production issue, so please look at it asap.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We have observed heartbeat lost on the worker node:\nHostname:\nwn228-entspa.rkzxzos33neexlrsld0v3rt5me.gx.internal.cloudapp.net\nIP {Alphanumericpii}\nThis was reported 33 mins ago, all other wn are running fine.\nThis is a production issue, so please look at it asap.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-gdaenthadoop-cus-01-{namepii}/providers/Microsoft.HDInsight/clusters/entsparkpepgda\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Hi Team, we have observed one of the data node is missing hearbeat since 33 mins ago as displayed..",0.077973433,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,"Hi Team, we have observed one of the data node is missing hearbeat since 33 mins ago as displayed..","Hi Team, we have observed one of the data node is missing hearbeat since 33 mins ago as displayed..",Worked with customer and deployed logrotate policy below and minimized logging of zookeeper process to reduce pressure on zookeeper process.wget https://hdiconfigactions.blob.core.windows.net/hadoopcorepatchingscripts/logrotate-policy.sh$ chmod +777 logrotate-policy.sh$ ./logrotate-policy.shFound high load on zookeeper node 6 due to IO pressure and engaged product group on this and product group installed iotop on the node and zookeeper process has been stable now on the cluster from almost 20 days. Customer confirmed to close the case.,195508939,,,,,,,
1.20062E+14,10:20.4,Hbase :Data load and container allocation issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hbase :Data load and container allocation issues\n\nContainer killed on request. Exit code is 143 [2020-06-23 {Alphanumericpii} exited with a non-zero exit code 143.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hbase :Data load and container allocation issues\n\nContainer killed on request. Exit code is 143 [2020-06-23 {Alphanumericpii} exited with a non-zero exit code 143.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpp602hbaseprodwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hbase :Data load and container allocation issues,0.235920853,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hbase,Hbase :Data load and container allocation issues,Hbase :Data load and container allocation issues,"Worked with customer on this and clarified with customer that YARN would allocate resources based on yarn.scheduler.minimum-allocation-mb and/or yarn.scheduler.maximum-allocation-mb and resource allocation would be in ""multiples"" of yarn.scheduler.minimum-allocation-mb.",,,,,,,,
1.20062E+14,03:36.1,MI failing to connect to ADLSgen2 during HDInsight deployment,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 PM EDT\n\nQuestion: {Namepii} name\nAnswer: sevdev\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Hello, I am receiving an error despite the selected MI having 'Storage Blob Data Owner ' permissions on the storage account 'stresstestchgreen'\n\nDeployment correlation ID: {guidpii}\nOperation ID: /subscriptions/0df229a4-d02e-4432-aa88-814c9a04b171/resourceGroups/devcluster/providers/Microsoft.Resources/deployments/HDInsight__2020-06-23T15.54.43.167Z/operations/47CCFAAFC669DEBD\n\n{\n    'code': 'BadRequest',\n    'message': 'DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Could not validate storage account stresstestchgreen.dfs.core.windows.net. Make sure that the account details are correct. HdInsight supports only general-purpose storage accounts with standard tier. Ensure that the account is not a premium or blob only storage account. Information about various storage accounts can be found at http://go.microsoft.com/fwlink/?LinkId=808302. If the storage account has firewall enabled, the subscription that hosts the account must have Microsoft.HDInsight registered as a resource provider. Information on how to do the registration can be found at: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-register-provider-errors''\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - sevdev;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Hello, I am receiving an error despite the selected MI having 'Storage Blob Data Owner ' permissions on the storage account 'stresstestchgreen'\n\nDeployment correlation ID: {guidpii}\nOperation ID: /subscriptions/0df229a4-d02e-4432-aa88-814c9a04b171/resourceGroups/devcluster/providers/Microsoft.Resources/deployments/HDInsight__2020-06-23T15.54.43.167Z/operations/47CCFAAFC669DEBD\n\n{\n    'code': 'BadRequest',\n    'message': 'DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Could not validate storage account stresstestchgreen.dfs.core.windows.net. Make sure that the account details are correct. HdInsight supports only general-purpose storage accounts with standard tier. Ensure that the account is not a premium or blob only storage account. Information about various storage accounts can be found at http://go.microsoft.com/fwlink/?LinkId=808302. If the storage account has firewall enabled, the subscription that hosts the account must have Microsoft.HDInsight registered as a resource provider. Information on how to do the registration can be found at: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-register-provider-errors''\n};\n\n- ProblemStartTime: 06/23/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AG-SEVERN\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Developer\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Developer\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MI failing to connect to ADLSgen2 during HDInsight deployment,2.369987525,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,MI failing to connect to ADLSgen2 during HDInsight deployment HDInsight Service,Permissions were not given right.,Create a cluster with Managed Identity choosing ADLS Gen 2 as your primary storage and by not enabling the firewall.Make sure the owner permissions are givenSelect the primary storage as Azure Data Lake Storage Gen2Create a cluster with Azure Data Lake storage Gen2 using Managed Identity with the below link.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-storage-gen2#create-a-user-assigned-managed-identity,,,,,,,,
1.20062E+14,47:50.1,Clusters failing to create,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Operation name\nCreate or Update {Namepii}\nTime stamp\n{Namepii} {Namepii} 23 2020 07:30:21 {ALPHANUMERICPII} (Pacific Daylight Time)\nEvent initiated by\n{alphanumericpii}\nError code\nGatewayTimeout\nMessage\nThe gateway did not receive a response from 'Microsoft.HDInsight' within the specified time period.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Operation name\nCreate or Update {Namepii}\nTime stamp\n{Namepii} {Namepii} 23 2020 07:30:21 {ALPHANUMERICPII} (Pacific Daylight Time)\nEvent initiated by\n{alphanumericpii}\nError code\nGatewayTimeout\nMessage\nThe gateway did not receive a response from 'Microsoft.HDInsight' within the specified time period.;\n\n- ProblemStartTime: 06/23/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AFL - Integrate TEST 01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9a47f5d2-bbd1-49a0-9709-1a165ea46850/resourceGroups/idm-afltest01/providers/Microsoft.HDInsight/clusters/cd35c84e37044481c9cbba36f5757c923\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Clusters failing to create,0.074292912,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,HDInsight provisions  virtual machines associated with clusters in our ‘provisioning subscriptions’.  Each region has multiple such provisioning subscriptions. One of our  provisioning subscriptions in the region faced capacity issues due to a spike in  cluster creations. We have addressed the issue by adding additional capacity for  the affected subscription. We have also made improvements to our alerts by  fine-tuning our thresholds to catch such issues quicker.,Clusters failing to  create,It is failed due to  internal VHD provisioning subscriptions hit a quota limit and caused Cluster  creation failures. After fixing this and in the next retry it worked  fine,,,,,,,,
1.20062E+14,48:02.4,"Worker nodes frequently down for EMEA PROD, STG and China STG","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: On EMEA STG HD CLuster 2 Node are Down 'wn0' and 'wn1'.\nOn EMEA PROD  HD {Namepii} 1 node is down '{alphanumericpii}'.\nOn CHINA STG HD cluster 2 nodes are down 'wn0' and 'wn1'.\n\nRestarting the nodes is not helping. Kindly provide RCA and permanent solution.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - On EMEA STG HD CLuster 2 Node are Down 'wn0' and 'wn1'.\nOn EMEA PROD  HD {Namepii} 1 node is down '{alphanumericpii}'.\nOn CHINA STG HD cluster 2 nodes are down 'wn0' and 'wn1'.\n\nRestarting the nodes is not helping. Kindly provide RCA and permanent solution.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EMEA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/31b2ba9a-0826-4a10-ab4e-f239517ec26f/resourceGroups/Mosaic-EMEA-Prod-Primary/providers/Microsoft.HDInsight/clusters/omweeitcbmprodemea01\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Worker nodes frequently down for EMEA PROD, STG and China STG",0.150724233,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Unable to access worker nodes and Ambari showed multiple alerts,worker nodes was all down.,Restarted all worker nodes,193864032,,,,,,,
1.20062E+14,12:15.5,Nodemanager unhealthy,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 1/1 local-dirs have errors: [ /mnt/resource/hadoop/yarn/local : Directory is not writable: /mnt/resource/hadoop/yarn/local ] 1/1 log-dirs have errors: [ /mnt/resource/hadoop/yarn/log : Cannot create directory: /mnt/resource/hadoop/yarn/log ]\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - 1/1 local-dirs have errors: [ /mnt/resource/hadoop/yarn/local : Directory is not writable: /mnt/resource/hadoop/yarn/local ] 1/1 log-dirs have errors: [ /mnt/resource/hadoop/yarn/log : Cannot create directory: /mnt/resource/hadoop/yarn/log ];\n\n- ProblemStartTime: 06/23/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Nodemanager unhealthy,0.14124413,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,1/1 local-dirs have errors: [ /mnt/resource/hadoop/yarn/local : Directory is not writable: /mnt/resource/hadoop/yarn/local ] 1/1 log-dirs have errors: [ /mnt/resource/hadoop/yarn/log : Cannot create directory: /mnt/resource/hadoop/yarn/log ],Nodemanager  unhealthy,Fixing  the permission on /mnt/resource/hadoop/yarn from root:root to yarn:hadoop fixed  the issue.,,,,,,,,
1.20062E+14,33:41.8,Oozie failure with keberos authentication error,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: When trying to write to the storage, we got a keberos token error and the connection was refused\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - ;\nAdditional details about the issue - When trying to write to the storage, we got a keberos token error and the connection was refused;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/23/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2953b2cf-932d-4b39-a68b-9c02bbd7c3c7/resourceGroups/eqd-ctr-cat-1-PROD-catappprd01cluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/FpV9HoVHRS-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Oozie failure with keberos authentication error,0.008323936,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,Intermittent issue: ERROR AbstractCredentialServiceCaller: Connection refused (Connection refused),ERROR AbstractCredentialServiceCaller: Connection refused (Connection refused)Token cache issues. ,You have notified that this issue happens intermittently and is auto-resolved. We saw delegation token exceptions in the Credential service logs at the same time the job failed.  You can use the following configuration spark.hadoop.fs.hdfs.impl.disable.cache=true  à to disable token cache from the spark side. Since your Oozie job is talking to  Spark+hive  you can use the following parameter spark.yarn.security.tokens.hive.enabled=false àto let spark know that it needs to use Oozie delegation token to pass to hive instead of getting new ones,,,,,,,,
1.20062E+14,36:31.9,Hbase import are failing with multiple exceptions,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: Hbase import are failing with multiple exceptions\n\n1.org.apache.hadoop.hbase.RegionTooBusyException:\n{AlphanumericPII}: Call to wn36-kpp602.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.209.40:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call {alphanumericpii}, {AlphanumericPII}, {AlphanumericPII} on {alphanumericpii}, tracking started null, retrying {alphanumericpii}, {AlphanumericPII}\n\nQuestion: How was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: java.io.IOException: Call to wn36-kpp602.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.209.40:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call {alphanumericpii}, {AlphanumericPII}, {AlphanumericPII} on {alphanumericpii}, tracking started null, retrying {alphanumericpii}, {AlphanumericPII}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - Hbase import are failing with multiple exceptions\n\n1.org.apache.hadoop.hbase.RegionTooBusyException:\n{AlphanumericPII}: Call to wn36-kpp602.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.209.40:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call {alphanumericpii}, {AlphanumericPII}, {AlphanumericPII} on {alphanumericpii}, tracking started null, retrying {alphanumericpii}, {AlphanumericPII};\nHow was the HBase job submitted? - HBase shell;\nAdditional details about the issue - java.io.IOException: Call to wn36-kpp602.alefynhkbt3elhjl5uwldi1qkg.xx.internal.cloudapp.net/10.10.209.40:16020 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call {alphanumericpii}, {AlphanumericPII}, {AlphanumericPII} on {alphanumericpii}, tracking started null, retrying {alphanumericpii}, {AlphanumericPII};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpp602hbaseprodwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hbase import are failing with multiple exceptions,0.180892846,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hbase,Hbase import are failing with multiple exceptions,Hbase import are failing with multiple exceptions,Checked and suggested customer to pre-split the tables before the import process.,,,,,,,,
1.20062E+14,51:01.2,Resource managers stuck in standby state,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 2020-06-23 {Alphanumericpii} WARN  service.AbstractService - When stopping the service org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager : java.lang.NullPointerException\njava.lang.NullPointerException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-23 {Alphanumericpii} INFO  service.AbstractService - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\norg.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\nQuestion: Additional details about the issue\nAnswer: 2020-06-23 {Alphanumericpii} WARN  service.AbstractService - When stopping the service org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager : java.lang.NullPointerException\njava.lang.NullPointerException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-23 {Alphanumericpii} INFO  service.AbstractService - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\norg.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 2020-06-23 {Alphanumericpii} WARN  service.AbstractService - When stopping the service org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager : java.lang.NullPointerException\njava.lang.NullPointerException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-23 {Alphanumericpii} INFO  service.AbstractService - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\norg.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n;\nAdditional details about the issue - 2020-06-23 {Alphanumericpii} WARN  service.AbstractService - When stopping the service org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager : java.lang.NullPointerException\njava.lang.NullPointerException\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-23 {Alphanumericpii} INFO  service.AbstractService - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\norg.apache.hadoop.service.ServiceStateException: com.google.protobuf.InvalidProtocolBufferException: Could not obtain block: {AlphanumericPII} file=/yarn/node-labels/nodelabel.mirror\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n;\n\n- ProblemStartTime: 06/23/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b8d79299-dbc4-42b6-b557-01b3a7cf0605/resourceGroups/RG-RTL-RxPerso-Prod/providers/Microsoft.HDInsight/clusters/rxp04-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Resource managers stuck in standby state,6.784244889,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Resource managers stuck in standby state, yarn node label issue being addressed in task 671999,delete corrupt file /yarn/node-labels/nodelabel.mirrorTurn odd Node label,,,,,,,,
1.20062E+14,00:10.3,Oozie job cannot find Kerberos ticket,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Oozie\n\nQuestion: YARN Application ID for the job if known\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We recently moved Oozie code to Azure. Now that we are using HDInsight, we have changed all the properties (JDBC string, usernames, etc.), but we are seeing that it cannot find a Kerberos ticket. We have a ticket when submitting the job, and the keytab exists at the same location on all worker nodes. We don't understand why this is happening, but the code was working on our on-prem HDP 2.6.5 cluster.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Oozie;\nYARN Application ID for the job if known - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - We recently moved Oozie code to Azure. Now that we are using HDInsight, we have changed all the properties (JDBC string, usernames, etc.), but we are seeing that it cannot find a Kerberos ticket. We have a ticket when submitting the job, and the keytab exists at the same location on all worker nodes. We don't understand why this is happening, but the code was working on our on-prem HDP 2.6.5 cluster.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/chbp25adlbatch\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Oozie job cannot find Kerberos ticket,27.25332975,Root Cause : HDInsight Service\Bug\Other,"Routing Azure HDInsight V5\Query or Job Failure\MapReduce, Pig, Sqoop or Oozie",Oozie job cannot find Kerberos ticket,"As a summary, there is a know Claudera issue and they have instructed us to rename the keytab and to use this new name with the --keytab argument as a workaround. The Claudera work item that deals with this issue is  https://issues.apache.org/jira/browse/OOZIE-3586", rename the keytab and to use this new name with the --keytab argument as a workaround.,194810150,,,,,,,
1.20062E+14,52:45.6,Spark jobs are failing ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: regular jobs\n\nQuestion: Additional details about the issue\nAnswer: when multiple jobs are triggered \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - regular jobs;\nAdditional details about the issue - when multiple jobs are triggered ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BAT PaaS Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d421e7ee-e2bc-4ca8-8db5-6cd8370e1c1a/resourceGroups/RG-PP-NE-PetraAnalytics-prod-01/providers/Microsoft.HDInsight/clusters/bathdi-pp-{namepii}-petra-spark-prod-02\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark jobs are failing ,5.373407284,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Job not getting submitted to hdinsight from ADF,Cx submitting too many jobs than the cluster can handlehttps://supportability.visualstudio.com/AzureHDinsight/_wiki/wikis/AzureHDinsight/292369/adf-livy-spark,Increase worker nodes or reduce the no of jobs submitted,193908314,,,,,,,
1.20062E+14,27:33.0,Hive Serveice Frequent Outage,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 23, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, {Namepii} 24, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi {Namepii},\n\nWe have been facing very often LLAP Hive going  outage due the service is moving to Maintenance mode automatically hence many users and downstream jobs were impacting.\n\nPlease look into it and help us what is causing issues here.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi {Namepii},\n\nWe have been facing very often LLAP Hive going  outage due the service is moving to Maintenance mode automatically hence many users and downstream jobs were impacting.\n\nPlease look into it and help us what is causing issues here.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/23/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Prod_DR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cca3be6-ea39-4394-9aab-242213bd98e5/resourceGroups/enterprise-prd/providers/Microsoft.HDInsight/clusters/llapprd01djenterpriseprd\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Serveice Frequent Outage,0.34732693,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Hive service frequent outage,zookeeper snapshots causing performance issues on Hive service,Cleared the Zookeeper snapshots and restarted the zookeeper services. Set autopurge.snapRetainCount to a value of 3 in Ambari and restart the zookeeper servers from Ambari. By default these value is set to 30 Hive service connection issue is caused when there is any performance issues with the jobs that are running/when there is high load and that may cause Hive server unavailable for sometime. In this scenario we suggest to increase the HiveServer2Interactive heap size.,,,,,,,,
1.20062E+14,06:14.0,prod - kpp608sparkprodwus201 - cluster created with wrong zookeeper sku,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is created with wrong SKU - Default zookeeper SKU 2(2) cores instead of SKU passed.as parameter. This issue repeating for unsecure spark cluster. Works on other cluster types\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - {Namepii} is created with wrong SKU - Default zookeeper SKU 2(2) cores instead of SKU passed.as parameter. This issue repeating for unsecure spark cluster. Works on other cluster types;\n\n- ProblemStartTime: 06/24/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpp608sparkprodwus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prod - kpp608sparkprodwus201 - cluster created with wrong zookeeper sku,0.056759164,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other, HDInsight for Spark cluster type does not support any SKU other than Standard_a2_v2 ,prod - kpp608sparkprodwus201 - cluster created with wrong zookeeper sku," HDInsight for Spark cluster type does not support any SKU other than Standard_a2_v2 for Zookeeper hosts. In the portal also, you do not see the way to edit it. Hence from the template when it is submitted, the value given Standard_D5_V2 is overriden by default settings for ZK hosts.",193915138,,,,,,,
1.20062E+14,32:57.8,Prem | Azure HDInsight Service | Getting an error when accessing a cluster node from the HDInsight console.,Getting an error when accessing a cluster node from the HDInsight console.,Prem | Azure HDInsight Service | Getting an error when accessing a cluster node from the HDInsight console.,0.048161626,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,,Customer got 502 error when attempting to log into Ambari using the -int endpoint for the cluster,Ambari Server unhealthy.  Jumpbox had local IP and NSG did not have entry for NAT'd address,Customer was unable to login to headnodes so we rebooted cluster to get Ambari restarted,,,,,,,,
1.20062E+14,23:02.4,False alert of dead region,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Ignore the false alert. \nCreate a graph in the ambri which gives regional server availability over time.\n\nQuestion: Additional details about the issue\nAnswer: Query: \nmetrics_hmaster_CL\n| where masterActiveTime_d &gt; 0\n| summarize live = max(numRegionServers_d), dead = max(numDeadRegionServers_d) by ClusterName_s, HostName_s\n\n{Namepii} : https://portal.azure.com#@348a1296-55b6-466e-a7af-4ad1a1b79713/blade/Microsoft_Azure_Monitoring_Logs/LogsBlade/source/Alerts.EmailLinks/scope/%7B%22resources%22%3A%5B%7B%22resourceId%22%3A%22%2Fsubscriptions%2F231ce626-a41d-4bb2-9bec-51ab394e76a6%2FresourceGroups%2Fdemand-impact-prod%2Fproviders%2FMicrosoft.OperationalInsights%2Fworkspaces%2Fprod-demandimpact-hbase-loganalytics%22%7D%5D%7D/q/eJzLTS0pykwujs%2FITSwuSS2Kd%2FZR4KpRKM9ILUpVgAg5JpdklqWGZOamxqco2CkYgOSLS3NzE4syq1IVcoByCrZApRUaeaW5Qanpmfl5walFZalFxfEpmjoKKamJKQh5FyAPXY1CUqWCc04pyCq%2FRKAlxToKHvnFJRA2AA%3D%3D/prettify/1/timespan/2020-06-24T19%3a24%3a24.0000000Z%2f2020-06-24T19%3a54%3a24.0000000Z\n\nThe above query was not returning any result and from 06/24 it started returning the results.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Ignore the false alert. \nCreate a graph in the ambri which gives regional server availability over time.;\nAdditional details about the issue - Query: \nmetrics_hmaster_CL\n| where masterActiveTime_d &gt; 0\n| summarize live = max(numRegionServers_d), dead = max(numDeadRegionServers_d) by ClusterName_s, HostName_s\n\n{Namepii} : https://portal.azure.com#@348a1296-55b6-466e-a7af-4ad1a1b79713/blade/Microsoft_Azure_Monitoring_Logs/LogsBlade/source/Alerts.EmailLinks/scope/%7B%22resources%22%3A%5B%7B%22resourceId%22%3A%22%2Fsubscriptions%2F231ce626-a41d-4bb2-9bec-51ab394e76a6%2FresourceGroups%2Fdemand-impact-prod%2Fproviders%2FMicrosoft.OperationalInsights%2Fworkspaces%2Fprod-demandimpact-hbase-loganalytics%22%7D%5D%7D/q/eJzLTS0pykwujs%2FITSwuSS2Kd%2FZR4KpRKM9ILUpVgAg5JpdklqWGZOamxqco2CkYgOSLS3NzE4syq1IVcoByCrZApRUaeaW5Qanpmfl5walFZalFxfEpmjoKKamJKQh5FyAPXY1CUqWCc04pyCq%2FRKAlxToKHvnFJRA2AA%3D%3D/prettify/1/timespan/2020-06-24T19%3a24%3a24.0000000Z%2f2020-06-24T19%3a54%3a24.0000000Z\n\nThe above query was not returning any result and from 06/24 it started returning the results.;\n\n- ProblemStartTime: 06/24/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/demand-impact-prod/providers/Microsoft.HDInsight/clusters/prodih-azwus-prod-demandimpact-hdihbase001\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",False alert of dead region,0.658351298,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Hbase,False alert of dead region,Alert was set to fire if there are any results at all. ,"alert is working as designed.modified the logic so the alert will fire when expectedalso walked through logic of creating a second alert to monitor the table in questionif the data stops flowing in the future, the second alert would fire to let them know ",,,,,,,,
1.20062E+14,28:52.2,Not able to choose HEAD NODE as A2m V2 instance,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name if available\nAnswer: moesif-spark-dev\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: Any customization applied\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We are trying to create Spark 2.2 HD insight cluster in WEST US2. In the process to select type of instance for HEAD node, there is no option to select A2m V2 Node size. {Namepii} option we see is D and M. However for selecting WORKER node, we do see option of A2m Instance\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name if available - moesif-spark-dev;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nAny customization applied - ;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We are trying to create Spark 2.2 HD insight cluster in WEST US2. In the process to select type of instance for HEAD node, there is no option to select A2m V2 Node size. {Namepii} option we see is D and M. However for selecting WORKER node, we do see option of A2m Instance;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Web\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/01739aa8-1629-495e-a1e1-12f86fe84b71/resourceGroups/spark-dev/providers/Microsoft.HDInsight/clusters/moesif-spark-dev\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to choose HEAD NODE as A2m V2 instance,0.864963233,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with other customization,Not able to choose HEAD NODE as A2m V2 instance,Deprecation of VM's.,"I could discuss with Product Group about the A2M_V2 virtual machine availability. They have deprecated the support for A2M_v2 and other SKUs with only 2 cores starting from April 6, 2020. A minimum 4-core VM is required for Head Node to ensure the high availability and reliability of HDInsight clusters. Starting from April 6 2020, customers can only choose 4-core or above VM as Head Node for the new HDInsight clusters. Existing clusters will continue to run as expected. They are rolling out these changes region wise and shortly all regions will be deprecated of support for A2M_V2 and hence the unavailability in WESTUS 2 as well.",194695236,,,,,,,
1.20063E+14,26:37.6,Azure Portal: Zookeeper info is not available for  Spark  ( ESP & NON ESP)  clusters .,"Azure Portal: Zookeeper info is not available for  Spark  ( ESP & NON ESP)  clusters  on the portal.\n\nThe Zookeeper info is avaialable on the portal for the Hbase ,spark,LLAP clusters.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Azure Portal: Zookeeper info is not available for  Spark  ( ESP & NON ESP)  clusters .,0.680351772,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,Azure Portal: Zookeeper info is not available for Spark ( ESP & NON ESP) clusters .,Azure Portal: Zookeeper info is not available for Spark ( ESP & NON ESP) clusters .,Checked with PG and they confirmed that changing zookeeper SKU’s for Spark cluster is not supported and Taylor (PG) confirmed that his recommendation to change zookeeper SKU is only for LLAP clusters,,,,,,,,
1.20063E+14,57:33.2,The query is being automatically killed with an Exception in Prod dm04 cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: error -\n{AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-25 {Alphanumericpii} [ERROR] [{alphanumericpii}] |webapp.Dispatcher|: error handling URI: /{AlphanumericPII}\njava.lang.IllegalStateException: No view rendered for 200\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: Exception when the query ran -\n{AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-25 {Alphanumericpii} [ERROR] [{alphanumericpii}] |webapp.Dispatcher|: error handling URI: /{AlphanumericPII}\njava.lang.IllegalStateException: No view rendered for 200\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - error -\n{AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-25 {Alphanumericpii} [ERROR] [{alphanumericpii}] |webapp.Dispatcher|: error handling URI: /{AlphanumericPII}\njava.lang.IllegalStateException: No view rendered for 200\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - Exception when the query ran -\n{AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n2020-06-25 {Alphanumericpii} [ERROR] [{alphanumericpii}] |webapp.Dispatcher|: error handling URI: /{AlphanumericPII}\njava.lang.IllegalStateException: No view rendered for 200\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n;\n\n- ProblemStartTime: 06/24/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Production 01 (S05)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a6c3b779-1b87-4257-9b7a-5017a0b61aca/resourceGroups/RS05UE2PInformationPlatform-RG01/providers/Microsoft.HDInsight/clusters/rs05u2piphdidm04\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",The query is being automatically killed with an Exception in Prod dm04 cluster,4.409847433,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,The query is being automatically killed with an Exception in Prod dm04 cluster,Turns out the cluster has a Vnet with UDR configured to send all traffic via their internal firewall/Network appliance that is unable to handle large requests and all the clusters are competing here causing a bottleneck. ,Networking configuration rectified at the customer side,"194,069,434,194,247,000",,,,,,,
1.20063E+14,23:56.1,HDInsight firewall rules,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: We are not observing any problems creating our HDInsight clusters. There was no Support Case option for HDInsight networking. We are writing firewall rules for our new Azure subscription. We understand the HDInsight cluster is comprised of multiple nodes, so we are asking the following questions because we want to avoid writing firewall rules for the entire HDInsight subnet.\n\n- Is there a single static IP address of the HDInsight cluster that we can write firewall rules for?\n- Are IP addresses of HDInsight cluster nodes static? Meaning, if we create an HDInsight cluster in a particular subnet, delete the cluster and recreate it with the same name, will the IP addresses of the headnodes, workernodes, zookeeper nodes, etc. stay the same as it's previous deployment?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - We are not observing any problems creating our HDInsight clusters. There was no Support Case option for HDInsight networking. We are writing firewall rules for our new Azure subscription. We understand the HDInsight cluster is comprised of multiple nodes, so we are asking the following questions because we want to avoid writing firewall rules for the entire HDInsight subnet.\n\n- Is there a single static IP address of the HDInsight cluster that we can write firewall rules for?\n- Are IP addresses of HDInsight cluster nodes static? Meaning, if we create an HDInsight cluster in a particular subnet, delete the cluster and recreate it with the same name, will the IP addresses of the headnodes, workernodes, zookeeper nodes, etc. stay the same as it's previous deployment?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight firewall rules,0.222927266,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,HDInsight firewall rules,NA,"HDInsight firewall rules Recommendations:Is there a single static IP address of the HDInsight cluster that we can write firewall rules for?There is no single static IP address of the HDInsight cluster.There are several dependencies that require inbound traffic. The inbound management traffic can't be sent through a firewall device. The source addresses for this traffic are known and are published here. You can also create Network Security Group (NSG) rules with this information to secure inbound traffic to the clusters.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresseshttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-service-tagsIf you are trying to configure outbound network traffic for Azure HDInsight clusters using Azure Firewall, Please refer to below document https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-restrict-outbound-trafficAre IP addresses of HDInsight cluster nodes static? Meaning, if we create an HDInsight cluster in a particular subnet, delete the cluster and recreate it with the same name, will the IP addresses of the headnodes, workernodes, zookeeper nodes, etc. stay the same as it's previous deployment?No the Ipaddresses of the headnode,worker nodes, zookeeper nodes etc change for every deployment.",,,,,,,,
1.20063E+14,40:48.1,HDI serviuce pathing and updating,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi Azure Support, this is a General question on Azure HDI services.\nWe have miltiple HDIs in production, running Spark, Kafka, etc.\n\nCan you tell us what is the {Namepii} version patching stategy for HDI services, when are pathes applied, when is kernel pathches applies and nodes rebooted and when or who is a version of the HDI and Kafka updated?\n\nRegards,\n{Namepii} Petrov\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hi Azure Support, this is a General question on Azure HDI services.\nWe have miltiple HDIs in production, running Spark, Kafka, etc.\n\nCan you tell us what is the {Namepii} version patching stategy for HDI services, when are pathes applied, when is kernel pathches applies and nodes rebooted and when or who is a version of the HDI and Kafka updated?\n\nRegards,\n{Namepii} Petrov;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Citrix Analytics Production 1 (AUT RnD) (Env Prod) (Production)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0acc51a8-3378-4cdd-9b83-adf7e6042e9d/resourceGroups/CitrixAnalyticsRG/providers/Microsoft.HDInsight/clusters/etl-a-cas-hdi-spark\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI serviuce pathing and updating,0.011746958,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,HDI service pathing and updating,HDI service pathing and updating,"Provided below links for the same,HDI cluster to a newer version - https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-upgrade-clusterSpark - https://docs.microsoft.com/en-us/azure/hdinsight/spark/migrate-versionsKafka  - https://docs.microsoft.com/en-us/azure/hdinsight/kafka/migrate-versions",,,,,,,,
1.20063E+14,19:40.0,There is a service 360 action item that needs the cluster's gateway VMs to explicitly disable SSLv2 and SSLv3,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 22, 2020, 12:00 AM MST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Simply wish to know if there is a way to login into the gateway VMs and run a powershelll script that will explicitly disable {AlphanumericPII} and {AlphanumericPII} on the VMs.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Simply wish to know if there is a way to login into the gateway VMs and run a powershelll script that will explicitly disable {AlphanumericPII} and {AlphanumericPII} on the VMs.;\n\n- ProblemStartTime: 06/22/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Customer 360 PROD DXT Central US EUAP\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/35485224-05b1-4f87-9d5c-bff9795de399/resourceGroups/dxt-wus-01-rg/providers/Microsoft.HDInsight/clusters/dxtwus01hdi\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",There is a service 360 action item that needs the cluster's gateway VMs to explicitly disable SSLv2 and SSLv3,1.096342993,Root Cause : HDInsight Service\Secure Gateway issues,Routing Azure HDInsight V5\Alerts firing on Services\Spark,There is a service 360 action item that needs the cluster's gateway VMs to explicitly disable SSLv2 and SSLv3 ,N/A,"It is not possible to access the gateway nodes. You could opt only TLS 1.2 for all connections through the public and to support this, a new property minSupportedTls version can be specified during the cluster creation. Data on the disks are encrypted by Microsoft-managed keys by default. So, you can Bring Your Own key (BYOK) for disk encryption and manage it by using Azure key vault.Make sure you HDInsight is registered as a Managed Identity with Azure Key Vault and add the encryption during cluster creation. Also, could refer to https://docs.microsoft.com/en-us/azure/hdinsight/disk-encryption ",,,,,,,,
1.20063E+14,42:10.2,Kafka stopped after a perf test,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 4:30 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: {Namepii} data to be processed\n\nQuestion: Mitigating actions taken so far\nAnswer: No actions\n\nQuestion: Additional details about the issue\nAnswer: Yesterday I was running some load test scripts on my service.\nFor some background, my service consists of multiple kafka producers and a few consumer groups. The producers produce some messages into some topics and the consumer groups read from those messages and periodically checkpoint. I was {namepii} how fast I could consume / produce.\nAt some point during my test the kafka client started to see request timeout errors. I stopped the test soon after, but the timeout errors continued.\nI then restarted my service and the timeouts still occurred. It's been almost a full day since I initially ran the test but trying to consume messages from kafka continues to fail with timeouts.\nFor all intensive purposes the kafka cluster is basically unavailable.\n\nI ssh'd into the head node and have been trying some commands to see what's happening. I created a topic, produced some messages, and attempted to consume them. Consuming them fails with a timeout. I attached the console output from my test.\n\nPlease advise on what to do about this. Thanks.\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - {Namepii} data to be processed;\nMitigating actions taken so far - No actions;\nAdditional details about the issue - Yesterday I was running some load test scripts on my service.\nFor some background, my service consists of multiple kafka producers and a few consumer groups. The producers produce some messages into some topics and the consumer groups read from those messages and periodically checkpoint. I was {namepii} how fast I could consume / produce.\nAt some point during my test the kafka client started to see request timeout errors. I stopped the test soon after, but the timeout errors continued.\nI then restarted my service and the timeouts still occurred. It's been almost a full day since I initially ran the test but trying to consume messages from kafka continues to fail with timeouts.\nFor all intensive purposes the kafka cluster is basically unavailable.\n\nI ssh'd into the head node and have been trying some commands to see what's happening. I created a topic, produced some messages, and attempted to consume them. Consuming them fails with a timeout. I attached the console output from my test.\n\nPlease advise on what to do about this. Thanks.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/24/2020 23:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PushChannel - eDog\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/38225a1f-df96-45a1-8994-b34c43eaca79/resourceGroups/eDog.westus2.MicroserviceDeployment/providers/Microsoft.HDInsight/clusters/wus21-pushfd-k\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kafka stopped after a perf test,28.14988217,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Service unhealthy\Kafka,Kafka stopped after a perf test,Kafka cluster had a deadlock issue and therefore customer could not perform consume/ produce operations on the data.,A deadlock patch was applied to customer's cluster since its a known issue.,,,,,,,,
1.20063E+14,29:04.6,S360 error which was due to TLS is not 1.2 for current cluster,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 10:30 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: When created this HDInsight cluster, TLS was not selected and it's not 1.2. Due to recent announcement, TLS is required to be 1.2. We want to know if there is a solution to enable TLS for this existing cluster since this cluster is in production and set up in a safe environment (vNET) already.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - When created this HDInsight cluster, TLS was not selected and it's not 1.2. Due to recent announcement, TLS is required to be 1.2. We want to know if there is a solution to enable TLS for this existing cluster since this cluster is in production and set up in a safe environment (vNET) already.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/24/2020 17:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DD Autobots Production\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9b4ca723-4224-409a-9442-d015a570635c/resourceGroups/autobotsprod/providers/Microsoft.HDInsight/clusters/autobotsvnet\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",S360 error which was due to TLS is not 1.2 for current cluster,0.138441619,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,S360 error which was due to TLS is not 1.2 for current cluster,"Due to recent announcement, TLS is required to be 1.2",Update from PG:Cluster TLS version is needed to set during provisioning. There is no option to change it post creation. Please re-create the cluster with TLS 1.2.,194087489,,,,,,,
1.20063E+14,22:16.0,"After deleting inbound NAT rules , backend pools become invisible and throwing 404 errors","Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 25, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Due to security incident, security team advised to remove port 22 and 23 from head node load balancer, after then we see backend pools been disappeared and throwing 404 errors.\n\nSecurity team is trying to fix this issue for them to analyse the backend pool for any compromise. \n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: How was the interactive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Due to security incident, security team advised to remove port 22 and 23 from head node load balancer, after then we see backend pools been disappeared and throwing 404 errors.\n\nSecurity team is trying to fix this issue for them to analyse the backend pool for any compromise. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Due to security incident, security team advised to remove port 22 and 23 from head node load balancer, after then we see backend pools been disappeared and throwing 404 errors.\n\nSecurity team is trying to fix this issue for them to analyse the backend pool for any compromise. ;\nInteractive query explain plan if available - ;\nHow was the interactive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Due to security incident, security team advised to remove port 22 and 23 from head node load balancer, after then we see backend pools been disappeared and throwing 404 errors.\n\nSecurity team is trying to fix this issue for them to analyse the backend pool for any compromise. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/24/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/USEQFSOFINRSG02/providers/Microsoft.HDInsight/clusters/USEQFSOFINHDI03\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","After deleting inbound NAT rules , backend pools become invisible and throwing 404 errors",6.465995614,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Interactive Query,"After deleting inbound NAT rules , backend pools become invisible and throwing 404 errors","After deleting inbound NAT rules , backend pools become invisible and throwing 404 errors",Worked with customer and had helped identify the NSG blocking the communication. Customer had fixed the NSG rule to connect to headnodes.,194645710,,,,,,,
1.20063E+14,08:38.6,Kafka client is not able to access kafka cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Error processing append operation on partition {AlphanumericPII} \nrg.apache.kafka.common.errors.NotEnoughReplicasException: The size of the current ISR {Alphanumericpii}) is insufficient to satisfy the min.isr requirement of 2 for partition {AlphanumericPII}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Error processing append operation on partition {AlphanumericPII} \nrg.apache.kafka.common.errors.NotEnoughReplicasException: The size of the current ISR {Alphanumericpii}) is insufficient to satisfy the min.isr requirement of 2 for partition {AlphanumericPII};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII} (HighSec)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/084971f5-dda5-4b57-9062-2e9289a1962e/resourceGroups/strpl-paas-dev-rgp-001/providers/Microsoft.HDInsight/clusters/kafka-strpl-dev-001\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kafka client is not able to access kafka cluster,0.328986124,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Kafka,Kafka client is not able to access kafka cluster,Kafka client is not able to access kafka cluster,Worked with product group on this and they suggested to run below script on the cluster – $wget https://hdiconfigactions.blob.core.windows.net/hadoopcorepatchingscripts/logrotate-policy.sh$ chmod +777 logrotate-policy.sh$ ./logrotate-policy.sh,194139604,,,,,,,
1.20063E+14,31:45.2,Unable to connect to Hive Service. Service is down,"Question: What time did the problem begin?\nAnswer: ‎6‎/‎22‎/‎2020‎ ‎12‎:‎00‎:‎00‎ ‎AM\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: Please refer MS Case number {Phonenumberpii} \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Could not establish connection to jdbc:hive2://cmidevllapdj-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2: Required field 'serverProtocolVersion' is unset! \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - Please refer MS Case number {Phonenumberpii} ;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Could not establish connection to jdbc:hive2://cmidevllapdj-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2: Required field 'serverProtocolVersion' is unset! ;\n\n- ProblemStartTime: 06/22/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/cmidevllapdj\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect to Hive Service. Service is down,0.102775157,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Unable to connect to HS2I running on hn1. ,"Customer and Support installed HS2I on hn1 while troubleshooting a different issue.  Subsequently, customer was unable to connect to HS2I service running on hn1","Not supported.  HS2I is not highly available on any current shipped version of HDInsight.  As such, all incoming thrift traffic on Interactive Hive clusters is routed to hn0 by the HDI gateway",,,,,,,,
1.20063E+14,18:54.0,HBase traces in the logs and service not enabled,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: First, we have no problems with any existing HBase service but as it's related to it and there is no other category which matches for the service, I opened it here. \n\nWe would like to understand why there are logs related to the HBase Master in the cluster headnodes, when we have no HBase service installed in the cluster. Why is it so? (Attached the file with the line we observed in one of the clusters).\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - First, we have no problems with any existing HBase service but as it's related to it and there is no other category which matches for the service, I opened it here. \n\nWe would like to understand why there are logs related to the HBase Master in the cluster headnodes, when we have no HBase service installed in the cluster. Why is it so? (Attached the file with the line we observed in one of the clusters).;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/25/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cb42b9e9-66f5-4b34-8ae9-92aa9fbe3cc3/resourceGroups/hcbae2d01rsgdtl001/providers/Microsoft.HDInsight/clusters/hcbae9c01hdicdlspapp001\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HBase traces in the logs and service not enabled,1.185856424,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hbase,HBase traces in the logs and service not enabled,HBase traces in the logs and service not enabled,"Metrics Collector (Ambari Metrics service) is built using Hadoop technologies such as Apache HBase(and etc) and which is the reason, you see HBase naming when looking at AMS related logs/configurations.",,,,,,,,
1.20063E+14,13:36.1,Connection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 10:36 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: We are seeing following error from HDFS and YARN Web UIs:\nConnection failed to http://wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30075 ('NoneType' object has no attribute 'split')\n-------------------\nSeeing the following error from the failing node:\nConnection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None;\nAdditional details about the issue - We are seeing following error from HDFS and YARN Web UIs:\nConnection failed to http://wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30075 ('NoneType' object has no attribute 'split')\n-------------------\nSeeing the following error from the failing node:\nConnection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010;\n\n- ProblemStartTime: 06/26/2020 17:36:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Demand-Forecast-Prod/providers/Microsoft.HDInsight/clusters/prddfh-azwus-prd-demandforecast-hdihbase001\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Connection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010,0.164442949,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hbase,Connection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010,Connection failed: 'NoneType' object has no attribute 'split' to wn3-prddfh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30010,"Restart of ambari-agent service on wn3 mitigated the issue. As discussed, if it happen again please refer this case details.","193,201,295,194,186,000,000,000,000",,,,,,,
1.20063E+14,29:10.4,Provision edge node admin account for debugging,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Head node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Need elevated access for security troubleshooting purposes\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Head node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Need elevated access for security troubleshooting purposes;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/371211a1-ad00-47d9-bcbd-3f302dfcc9b9/resourceGroups/USEQFSOFINRSG02/providers/Microsoft.HDInsight/clusters/USEQFSOFINHDI03\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Provision edge node admin account for debugging,0.019266503,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Need elevated access for security troubleshooting purposes,Provision edge node admin account for debugging,"Recommended to  switch user to root and try.  For  protections from DDoS attacks, can leverage Azure Security Center and  please go through the following link once - https://docs.microsoft.com/en-us/azure/hdinsight/security-baseline#14-deny-communications-with-known-malicious-ip-addresses",,,,,,,,
1.20063E+14,51:57.7,Deployment failed (Code: Internal Error),"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Restart AADDS service on your end\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Hello, \n\n{Namepii} deployment fails within 10 min with an Internal Error.\n\nThis issue happened for two weeks. We had multiple discussion with Microsoft Teams until they discovered a bug in AADDS. \n\nMicrosoft Teams delivered a patch on monday supposed to fix this issue. \n\nIt seems the patch did not fix the issue. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Restart AADDS service on your end;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Hello, \n\n{Namepii} deployment fails within 10 min with an Internal Error.\n\nThis issue happened for two weeks. We had multiple discussion with Microsoft Teams until they discovered a bug in AADDS. \n\nMicrosoft Teams delivered a patch on monday supposed to fix this issue. \n\nIt seems the patch did not fix the issue. ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7afd8a0e-516f-4623-894d-022e4e8e4c71/resourceGroups/central_feeder-PROD-nes20200626bv2t1cluster-{Namepii}-HDI/providers/Microsoft.HDInsight/clusters/hYCU0IWame-ProjectSpark\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Deployment failed (Code: Internal Error),4.17641522,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,Deployment failed (Code: Internal Error),Deployment failed (Code: Internal Error),"Resolution: Fix is available for West Europe and North Europe and it went on 07/09/2020. Due to inconvenience caused to you, we provided a hotfix and that hotfix ended up being broken it seems. There was no new root cause and it's the same as earlier.",191453787,,,,,,,
1.20063E+14,06:02.4,Oozie job failed at final stage because of Kerberos authentication problem,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 7:33 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Occurred serveral times at the final stage of oozie job. Login failure due to Kerberos authentication issue. And the job failed. Please see the attached log. \nThis happened sporadically. Please indicate whether there is a solution or workaround to avoid this issue.\n\nPlease contact {Namepii} Torjman \nEmail: {emailpii}@sgcib.com \nPhone: {Phonenumberpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - ;\nAdditional details about the issue - Occurred serveral times at the final stage of oozie job. Login failure due to Kerberos authentication issue. And the job failed. Please see the attached log. \nThis happened sporadically. Please indicate whether there is a solution or workaround to avoid this issue.\n\nPlease contact {Namepii} Torjman \nEmail: {emailpii}@sgcib.com \nPhone: {Phonenumberpii};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/24/2020 23:33:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2953b2cf-932d-4b39-a68b-9c02bbd7c3c7/resourceGroups/eqd-ctr-cat-1-PROD-catappprd01cluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/FpV9HoVHRS-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Oozie job failed at final stage because of Kerberos authentication problem,0.022807938,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,Oozie job failed at final stage because of Kerberos authentication problem,Oozie job failed at final stage because of Kerberos authentication problem,"Worked with customer and based on the logs shared by customer, it seems connectivity to the realm (in krb5.conf) had timedout and based on application runtime, it could have failed (timedout) in <=2 min. There are no other logs with regards to communication with KDC.Suggested customer to enable krb5 debugging to understand better on the failure -  --conf ""spark.driver.extraJavaOptions=-Dsun.security.krb5.debug=true -Dsun.security.jgss.debug=true -Dsun.security.spnego.debug=true"" --conf ""spark.executor.extraJavaOptions=-Dsun.security.krb5.debug=true -Dsun.security.jgss.debug=true -Dsun.security.spnego.debug=true"" Customer told that he did not see the issue again and advised to close the case.",,,,,,,,
1.20063E+14,33:11.9,Seeing heartbeat errors for spark cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: No action taken.\n\nQuestion: Additional details about the issue\nAnswer: Seeing following alerts in spark cluster:\n\n\n        There are 14 stale alerts from 14 host(s):\nwn106-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn107-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn108-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn109-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn110-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn111-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn112-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn114-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn115-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn116-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn117-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn118-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn120-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn122-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)]\n      \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - No action taken.;\nAdditional details about the issue - Seeing following alerts in spark cluster:\n\n\n        There are 14 stale alerts from 14 host(s):\nwn106-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn107-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn108-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn109-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn110-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn111-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn112-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn114-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn115-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn116-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn117-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn118-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn120-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)],\nwn122-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net\n  [Ambari Agent Heartbeat (46d 9h 23m)]\n      ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Demand-Forecast-Prod/providers/Microsoft.HDInsight/clusters/prddfs-azwus-spark\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Seeing heartbeat errors for spark cluster,4.121343544,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Spark,"        There are 14 stale alerts from 14 host(s): wn106-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn107-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn108-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn109-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn110-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn111-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn112-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn114-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn115-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn116-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn117-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn118-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn120-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)], wn122-prddfs.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net   [Ambari Agent Heartbeat (46d 9h 23m)]       ; ", Seeing  heartbeat errors for spark cluster,"To cleanup alerts for old hosts present in Ambari, do the following:Stop the Ambari server.For the decommissioned host which is still appearing in alerts tab, run the following commands: delete from alert_current where history_id in (select alert_id from alert_history where host_name in ('hostname'));  delete from alert_history where host_name in ('hostname');Start the Ambari Server. ",,,,,,,,
1.20063E+14,45:54.3,Unable to scale the cluster,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 1:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: We have scaled down cluster last week. \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We have two cluster in wcus. This one and cfvstreamingwcus. I have been trying to scale out both the clusters since morning, but it's not working. I have tried incremental increase by as low as 10 instances. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - We have scaled down cluster last week. ;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We have two cluster in wcus. This one and cfvstreamingwcus. I have been trying to scale out both the clusters since morning, but it's not working. I have tried incremental increase by as low as 10 instances. ;\n\n- ProblemStartTime: 06/26/2020 20:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Teams-RecGen_StreamProcessing-PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/95fcc4dc-c3b2-463c-9a36-471714d13ad4/resourceGroups/nrtstreamingwcus/providers/Microsoft.HDInsight/clusters/callrecordstreamingwcus\n- Location: westcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to scale the cluster,18.79050551,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to scale the cluster.,NA,"We see that cluster scale up failed due to Timed out waiting for Ambari to update node labelsBoth the clusters Callrecordstreamingwcus, cfvstreamingwcus are deleted and there are no logs flowing from the cluster to analyse the issue.",194813418,,,,,,,
1.20063E+14,12:22.5,High memory and CPU usage ,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 9:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Submit command thorugh LivySubmit LogicApp, \nNow scaled up 25 nodes\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} CPU and Memory usage, some batch requires lot of time to be completed and queue increment\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Submit command thorugh LivySubmit LogicApp, \nNow scaled up 25 nodes;\nAdditional details about the issue - {Namepii} CPU and Memory usage, some batch requires lot of time to be completed and queue increment;\n\n- ProblemStartTime: 06/26/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: GBS_IoTPlatform\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/50456edb-757e-4cbc-94bb-44bf85acc96e/resourceGroups/prodgen-SPARK/providers/Microsoft.HDInsight/clusters/prodgensparkhdi\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",High memory and CPU usage ,16.70401023,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,performance issue ,"get call to jar files resulting in 404, causing storage performance issues",cx moved to a new cluster and  storage,,,,,,,,
1.20063E+14,50:52.5,Not able to fetch logs from Tez_View,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 29, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: How was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Issue Details: \n\nNot able to fetch logs from Tez_View. When we browse the Tez Ui it keeps on loading and doesn’t come up with any records. This used to work fine earlier.\nGetting the below errors when it tries to fetch data.\nAdapter operation failed » 500: Failed to fetch results by the proxy from url: http://headnodehost:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=11&_=1593095292088&user.name=sysadmin. Internal Error.. Connection refused (Connection refused)\nNote: No changes has been in config side with related to Tez\n\n{Namepii} : Bpapiobs\nURL : https://bpapiobs-int.azurehdinsight.net/\n{Alphanumericpii} IP : {Alphanumericpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\nHow was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Issue Details: \n\nNot able to fetch logs from Tez_View. When we browse the Tez Ui it keeps on loading and doesn’t come up with any records. This used to work fine earlier.\nGetting the below errors when it tries to fetch data.\nAdapter operation failed » 500: Failed to fetch results by the proxy from url: http://headnodehost:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=11&_=1593095292088&user.name=sysadmin. Internal Error.. Connection refused (Connection refused)\nNote: No changes has been in config side with related to Tez\n\n{Namepii} : Bpapiobs\nURL : https://bpapiobs-int.azurehdinsight.net/\n{Alphanumericpii} IP : {Alphanumericpii}\n;\n\n- ProblemStartTime: 06/28/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/bpapiobs\n- Location: northeurope\n- Location: North Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to fetch logs from Tez_View,1.510850773,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hbase,Not able to fetch logs from Tez_View,Not able to fetch logs from Tez_View,Checked and engaged product group on this and they confirmed that this was due to Ambari DB hitting DTU due to ATS usage and shared steps with customer to move ATS workload into its own Azure SQL DB.,194670443,,,,,,,
1.20063E+14,23:00.5,Spark Hive warehouse connector error ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Spark Hive warehouse connector error \n\nWe have followed below set up process but we are getting error \n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector#hive-warehouse-connector-setup\n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector-zeppelin\n\n{Namepii} note book\n```%{alphanumericpii}\n\nimport {namepii}.hortonworks.hwc.HiveWarehouseSession\nimport {namepii}.hortonworks.hwc.HiveWarehouseSession._\nimport org.apache.spark.sql.SaveMode\n\n// # Initialize the hive context\nval hive = HiveWarehouseSession.session(spark).build()\n\nhive.setDatabase('default')\nval {namepii} = hive.executeQuery('select * from hivesampletable')\n{namepii}.show()```\n\nError\njava.lang.RuntimeException: java.lang.NullPointerException\n  at {namepii}.hortonworks.spark.sql.hive.llap.HiveWarehouseDataSourceReader.planBatchInputPartitions(HiveWarehouseDataSourceReader.java:170)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements$$anonfun$org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering$1.apply(EnsureRequirements.scala:149)\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements$$anonfun$org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering$1.apply(EnsureRequirements.scala:148)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.foreach({Namepii}.scala:392)\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.map({Namepii}.scala:296)\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements.org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering(EnsureRequirements.scala:148)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.foldLeft({Namepii}.scala:84)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  ... 72 elided\nCaused by: java.lang.NullPointerException\n  at {namepii}.hortonworks.spark.sql.hive.llap.HiveWarehouseDataSourceReader.planBatchInputPartitions(HiveWarehouseDataSourceReader.java:159)\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nAdditional details about the issue - Spark Hive warehouse connector error \n\nWe have followed below set up process but we are getting error \n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector#hive-warehouse-connector-setup\n\nhttps://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-hive-warehouse-connector-zeppelin\n\n{Namepii} note book\n```%{alphanumericpii}\n\nimport {namepii}.hortonworks.hwc.HiveWarehouseSession\nimport {namepii}.hortonworks.hwc.HiveWarehouseSession._\nimport org.apache.spark.sql.SaveMode\n\n// # Initialize the hive context\nval hive = HiveWarehouseSession.session(spark).build()\n\nhive.setDatabase('default')\nval {namepii} = hive.executeQuery('select * from hivesampletable')\n{namepii}.show()```\n\nError\njava.lang.RuntimeException: java.lang.NullPointerException\n  at {namepii}.hortonworks.spark.sql.hive.llap.HiveWarehouseDataSourceReader.planBatchInputPartitions(HiveWarehouseDataSourceReader.java:170)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements$$anonfun$org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering$1.apply(EnsureRequirements.scala:149)\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements$$anonfun$org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering$1.apply(EnsureRequirements.scala:148)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.foreach({Namepii}.scala:392)\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.map({Namepii}.scala:296)\n  at org.apache.spark.sql.execution.exchange.EnsureRequirements.org$apache$spark$sql$execution$exchange$EnsureRequirements$$ensureDistributionAndOrdering(EnsureRequirements.scala:148)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at scala.collection.immutable.{Namepii}.foldLeft({Namepii}.scala:84)\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  at {AlphanumericPII})\n  ... 72 elided\nCaused by: java.lang.NullPointerException\n  at {namepii}.hortonworks.spark.sql.hive.llap.HiveWarehouseDataSourceReader.planBatchInputPartitions(HiveWarehouseDataSourceReader.java:159)\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PHDH UAT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/470aa132-facc-465a-b8d7-f2b954c41062/resourceGroups/rgphdhqahdinsight/providers/Microsoft.HDInsight/clusters/p2044qahdinsight40\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Hive warehouse connector error ,1.532875672,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Client tool issue\Notebooks,NullPointerException when running a Hive query via the HWC executeQuery() method,Regression in HWC,Subscription was pinned to build prior to regression being introduced,195406667,,,,,,,
1.20063E+14,41:57.7,Error fetching data from ADLS gen1,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 8:00 PM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: insert overwrite table rpc_stg.dim_store_dw_mf select{uncpii}\nmf.county_t\\\nax_id,{uncpii}\ndw.st_dea_nbr,{uncpii}\ncast(dw.st_ncpdp_id as string) as st_ncpdp_id,{uncpii}\ndw.st_\\\n\nlicense_nbr,{uncpii}\nmf.area,{uncpii}\nmf.rx_store,{uncpii}\nmf.active_date_yyyymmdd,{uncpii}\\nmf.store_name,{uncpii}\nmf.date_closed_yyyymmdd,{uncpii}\ndw.st_cvs_store_y_n,{uncpii}\nmf.\\\nno_of_entrances,{uncpii}\ncast (mf.front_store_rank/front_store_rank_sign as string) as frnt_rnk_nbr,{uncpii}\nmf.r\\\nevamp_date,{uncpii}\nmf.rx_store as rx_store1,{uncpii} as str_open_dt,{uncpii}\nmf.relocat_to_store,{uncpii}\\nil_square_feet,{uncpii}\nmf.store_rpt_designation as store_rpt_designation1,{uncpii}\ndw.st_vsat_y_n,\\\n\\ndw.st_sr_citzen_y_n_eff_date,\\ndw.st_sr_citzen_disc_ind,\\ndw.st_sr_citzen_percent,\\ndw.st_create_date,\\nmf.acquisition_code,\\nmf.\\\nclass,{uncpii}\n'tot_rnk_nbr' as tot_rnk_nbr,{uncpii} as reloc_dt,{uncpii} as acq_dsc,{uncpii}\n'' as timezone_dsc,{uncpii}\\n'' as mc_str_nbr,{uncpii} as hr24_ind,{uncpii} as store_typ_cd,{uncpii} as store_typ_dsc,{uncpii} as facility_typ_cd,{uncpii} as facility_typ_dsc,{uncpii}\\nst_pharm_name,{uncpii}\ndw.st_mail_address,{uncpii}\ndw.st_mail_state,{uncpii}\ndw.st_phone_nb\\\nr,{uncpii}\ndw.st_county_code,{uncpii}\ndw.st_city,{uncpii}\ndw.st_zip,{uncpii}\ndw.st_next_ndc_cmpd_n\\\nbr,{uncpii}\ndw.st_next_cust_nbr,{uncpii}\ndw.st_next_phys_order_nbr,{uncpii}\ndw.st_p\\\nrice_awp,{uncpii}\ndw.st_price_mac_or_eac,{uncpii}\ndw.st_use_acquis_price_y_n,{uncpii}\\nug_database_code as string) as st_drug_database_code,{uncpii} as string) as st_price_baseline,{uncpii}\\n_default as string) as st_price_default,{uncpii} as string) as st_fee_sched_cmpd_default,{uncpii}\\nice_variance as string) as st_price_variance,{uncpii} as string) as st_price_to_use,{uncpii}\\n3 as string) as st_max_days_rx_class3,{uncpii} as string) as st_max_days_rx_class4,{uncpii}\\n{alphanumericpii} as string) as st_max_days_rx_class5,{uncpii} as string) as st_max_refills_class3,{uncpii}\\n{alphanumericpii} as string) as st_max_refills_class4,{uncpii} as string) as st_max_refills_class5,{uncpii}\\nnior_u_and_c_age_limit as string) as st_senior_u_and_c_age_limit,{uncpii} as string) as st_infant_u_an\\\nd_c_age_limit,{uncpii} as string) as st_tcc_resp_scan_delay_secs,{uncpii} as rx_ind,{uncpii} as drive_thru,\\n'\\\n' as photo_lab,{uncpii} as remodl_dt,{uncpii} as beauty_advr_ind,{uncpii} as wic_ind,{uncpii} as phone_nbr,{uncpii} as fax_nbr,{uncpii} as rx_phone_nbr,\\n'\\\n' as rx_fax_nbr,{uncpii} as iso_state_cd,{uncpii}\nmf.rx_area,{uncpii}\ndw.st_division_nbr,{uncpii} as div_cd,{uncpii} as div_name,\\\\\nn'' as mgr_name,{uncpii}\n'' as dstr_mgr_fnme,{uncpii} as dstr_mgr_lnme,{uncpii} as dstr_mgr_phone_nbr,{uncpii} as dstr_mgr_email,{uncpii} as\\\n rx_region_nbr,{uncpii} as regn_mgr_fnme,{uncpii} as regn_mgr_lnme,{uncpii} as regn_mgr_phone_nbr,{uncpii} as regn_mgr_email,{uncpii} as latitude,\\n'' \\\nas longitude,{uncpii} as geo_mkt_cd,{uncpii} as geo_mkt_dsc,{uncpii} as ad_rgn_cd,{uncpii} as ad_rgn_dsc,{uncpii} as area_mgr_fnme,{uncpii} as area_mgr_lnm\\\ne,{uncpii}\nmf.state_code,{uncpii}\nmf.numeric_state_code,{uncpii}\nmf.st_id_tax_pre\\\nf,{uncpii}\nmf.city_tax_ind,{uncpii}\nmf.date_rx_opened_yyyymmdd,{uncpii}\nmf.dat\\\ne_deal_died_yyyymmdd,{uncpii}\nmf.date_pay_opened_yyyymmdd,{uncpii}\nmf.old_rx_region,{uncpii}\\nploy_no,{uncpii}\nmf.inv_svc_agt,{uncpii}\nmf.consol_store_rp_flg,{uncpii}\n'' as publish_name,{uncpii} as \\\nstr_close_dt,{uncpii} as plan_scan_dt,{uncpii} as merch_start_dt,{uncpii} as legal_name,{uncpii} as ein,{uncpii} as staterx_nbr,{uncpii} as ncpdp_id,{uncpii} a\\\ns npi_nbr,{uncpii} as stat_cd,{uncpii} as stat_dsc,{uncpii} as stat_begin_dt,{uncpii} as opco_cd,{uncpii} as opco_dsc,{uncpii} as bus_segment,{uncpii} as fs_dc\\\n_cd,{uncpii} as fs_dc_name,{uncpii} as fs_del_freq,{uncpii} as rx_dc_cd,{uncpii} as rx_dc_name,{uncpii} as rx_del_freq,{uncpii} as rx_open_dt,{uncpii} as rx_cl\\\nose_dt,{uncpii} as sis_str_nbr,{uncpii} as bus_need_dsc,{uncpii} as rlp_mgr_fnme,{uncpii} as rlp_mgr_lnme,{uncpii} as rlp_mgr_phone_nbr,{uncpii} as rlp_mgr\\\n_mobile_nbr,{uncpii} as rlp_mgr_email,{uncpii} as dea_exp_dt,{uncpii} as staterx_exp_dt,{uncpii} as data_line_tst_dt,{uncpii} as str_cross_tz_diff,\\n''\\\n as store_in_store,{uncpii} as sis_external_number,{uncpii} as mg_agent_id,{uncpii} as mg_agent_seq,{uncpii} as quad_scan_option,{uncpii} as optical_ce\\\nnter,{uncpii} as hearing_center,{uncpii} as foodstmp_ind,{uncpii} as card_vendor_name,{uncpii} as load_date{uncpii} (select * from rx_\\\nrtl_base.mfstore where mngd_load_dt In( select max(cast(mngd_load_dt as int)) from rx_rtl_base.mfstore)) mf{uncpii} left outer join{uncpii}\\nect * from rx_rtl_base.dwstore where mngd_load_dt In( select max(cast(mngd_load_dt as int)) from rx_rtl_base.dwstore))dw{uncpii} (cast(\\\nmf.store_num as int) = cast(dw.st_store_nbr as int)){uncpii} dw.st_store_nbr is {NAMEPII}'}\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Caused by: java.io.IOException: LISTSTATUS failed with error 0x83090a8d Retryable transaction error in KSM. {alphanumericpii}\n{alphanumericpii}] failed with error 0x83090a8d Retryable transaction error in KSM. {guidpii} {Alphanumericpii}\n-{ALPHANUMERICPII} {AlphanumericPII}\n\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - insert overwrite table rpc_stg.dim_store_dw_mf select{uncpii}\nmf.county_t\\\nax_id,{uncpii}\ndw.st_dea_nbr,{uncpii}\ncast(dw.st_ncpdp_id as string) as st_ncpdp_id,{uncpii}\ndw.st_\\\n\nlicense_nbr,{uncpii}\nmf.area,{uncpii}\nmf.rx_store,{uncpii}\nmf.active_date_yyyymmdd,{uncpii}\\nmf.store_name,{uncpii}\nmf.date_closed_yyyymmdd,{uncpii}\ndw.st_cvs_store_y_n,{uncpii}\nmf.\\\nno_of_entrances,{uncpii}\ncast (mf.front_store_rank/front_store_rank_sign as string) as frnt_rnk_nbr,{uncpii}\nmf.r\\\nevamp_date,{uncpii}\nmf.rx_store as rx_store1,{uncpii} as str_open_dt,{uncpii}\nmf.relocat_to_store,{uncpii}\\nil_square_feet,{uncpii}\nmf.store_rpt_designation as store_rpt_designation1,{uncpii}\ndw.st_vsat_y_n,\\\n\\ndw.st_sr_citzen_y_n_eff_date,\\ndw.st_sr_citzen_disc_ind,\\ndw.st_sr_citzen_percent,\\ndw.st_create_date,\\nmf.acquisition_code,\\nmf.\\\nclass,{uncpii}\n'tot_rnk_nbr' as tot_rnk_nbr,{uncpii} as reloc_dt,{uncpii} as acq_dsc,{uncpii}\n'' as timezone_dsc,{uncpii}\\n'' as mc_str_nbr,{uncpii} as hr24_ind,{uncpii} as store_typ_cd,{uncpii} as store_typ_dsc,{uncpii} as facility_typ_cd,{uncpii} as facility_typ_dsc,{uncpii}\\nst_pharm_name,{uncpii}\ndw.st_mail_address,{uncpii}\ndw.st_mail_state,{uncpii}\ndw.st_phone_nb\\\nr,{uncpii}\ndw.st_county_code,{uncpii}\ndw.st_city,{uncpii}\ndw.st_zip,{uncpii}\ndw.st_next_ndc_cmpd_n\\\nbr,{uncpii}\ndw.st_next_cust_nbr,{uncpii}\ndw.st_next_phys_order_nbr,{uncpii}\ndw.st_p\\\nrice_awp,{uncpii}\ndw.st_price_mac_or_eac,{uncpii}\ndw.st_use_acquis_price_y_n,{uncpii}\\nug_database_code as string) as st_drug_database_code,{uncpii} as string) as st_price_baseline,{uncpii}\\n_default as string) as st_price_default,{uncpii} as string) as st_fee_sched_cmpd_default,{uncpii}\\nice_variance as string) as st_price_variance,{uncpii} as string) as st_price_to_use,{uncpii}\\n3 as string) as st_max_days_rx_class3,{uncpii} as string) as st_max_days_rx_class4,{uncpii}\\n{alphanumericpii} as string) as st_max_days_rx_class5,{uncpii} as string) as st_max_refills_class3,{uncpii}\\n{alphanumericpii} as string) as st_max_refills_class4,{uncpii} as string) as st_max_refills_class5,{uncpii}\\nnior_u_and_c_age_limit as string) as st_senior_u_and_c_age_limit,{uncpii} as string) as st_infant_u_an\\\nd_c_age_limit,{uncpii} as string) as st_tcc_resp_scan_delay_secs,{uncpii} as rx_ind,{uncpii} as drive_thru,\\n'\\\n' as photo_lab,{uncpii} as remodl_dt,{uncpii} as beauty_advr_ind,{uncpii} as wic_ind,{uncpii} as phone_nbr,{uncpii} as fax_nbr,{uncpii} as rx_phone_nbr,\\n'\\\n' as rx_fax_nbr,{uncpii} as iso_state_cd,{uncpii}\nmf.rx_area,{uncpii}\ndw.st_division_nbr,{uncpii} as div_cd,{uncpii} as div_name,\\\\\nn'' as mgr_name,{uncpii}\n'' as dstr_mgr_fnme,{uncpii} as dstr_mgr_lnme,{uncpii} as dstr_mgr_phone_nbr,{uncpii} as dstr_mgr_email,{uncpii} as\\\n rx_region_nbr,{uncpii} as regn_mgr_fnme,{uncpii} as regn_mgr_lnme,{uncpii} as regn_mgr_phone_nbr,{uncpii} as regn_mgr_email,{uncpii} as latitude,\\n'' \\\nas longitude,{uncpii} as geo_mkt_cd,{uncpii} as geo_mkt_dsc,{uncpii} as ad_rgn_cd,{uncpii} as ad_rgn_dsc,{uncpii} as area_mgr_fnme,{uncpii} as area_mgr_lnm\\\ne,{uncpii}\nmf.state_code,{uncpii}\nmf.numeric_state_code,{uncpii}\nmf.st_id_tax_pre\\\nf,{uncpii}\nmf.city_tax_ind,{uncpii}\nmf.date_rx_opened_yyyymmdd,{uncpii}\nmf.dat\\\ne_deal_died_yyyymmdd,{uncpii}\nmf.date_pay_opened_yyyymmdd,{uncpii}\nmf.old_rx_region,{uncpii}\\nploy_no,{uncpii}\nmf.inv_svc_agt,{uncpii}\nmf.consol_store_rp_flg,{uncpii}\n'' as publish_name,{uncpii} as \\\nstr_close_dt,{uncpii} as plan_scan_dt,{uncpii} as merch_start_dt,{uncpii} as legal_name,{uncpii} as ein,{uncpii} as staterx_nbr,{uncpii} as ncpdp_id,{uncpii} a\\\ns npi_nbr,{uncpii} as stat_cd,{uncpii} as stat_dsc,{uncpii} as stat_begin_dt,{uncpii} as opco_cd,{uncpii} as opco_dsc,{uncpii} as bus_segment,{uncpii} as fs_dc\\\n_cd,{uncpii} as fs_dc_name,{uncpii} as fs_del_freq,{uncpii} as rx_dc_cd,{uncpii} as rx_dc_name,{uncpii} as rx_del_freq,{uncpii} as rx_open_dt,{uncpii} as rx_cl\\\nose_dt,{uncpii} as sis_str_nbr,{uncpii} as bus_need_dsc,{uncpii} as rlp_mgr_fnme,{uncpii} as rlp_mgr_lnme,{uncpii} as rlp_mgr_phone_nbr,{uncpii} as rlp_mgr\\\n_mobile_nbr,{uncpii} as rlp_mgr_email,{uncpii} as dea_exp_dt,{uncpii} as staterx_exp_dt,{uncpii} as data_line_tst_dt,{uncpii} as str_cross_tz_diff,\\n''\\\n as store_in_store,{uncpii} as sis_external_number,{uncpii} as mg_agent_id,{uncpii} as mg_agent_seq,{uncpii} as quad_scan_option,{uncpii} as optical_ce\\\nnter,{uncpii} as hearing_center,{uncpii} as foodstmp_ind,{uncpii} as card_vendor_name,{uncpii} as load_date{uncpii} (select * from rx_\\\nrtl_base.mfstore where mngd_load_dt In( select max(cast(mngd_load_dt as int)) from rx_rtl_base.mfstore)) mf{uncpii} left outer join{uncpii}\\nect * from rx_rtl_base.dwstore where mngd_load_dt In( select max(cast(mngd_load_dt as int)) from rx_rtl_base.dwstore))dw{uncpii} (cast(\\\nmf.store_num as int) = cast(dw.st_store_nbr as int)){uncpii} dw.st_store_nbr is {NAMEPII}'};\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Beeline;\nAdditional details about the issue - Caused by: java.io.IOException: LISTSTATUS failed with error 0x83090a8d Retryable transaction error in KSM. {alphanumericpii}\n{alphanumericpii}] failed with error 0x83090a8d Retryable transaction error in KSM. {guidpii} {Alphanumericpii}\n-{ALPHANUMERICPII} {AlphanumericPII}\n\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/27/2020 01:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error fetching data from ADLS gen1,28.19513067,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Query or Job Failure\Hive,"Issue : Error fetching data from ADLS gen1Symptom:  Error while running simple HDFS move command.ERROR : Status: FailedERROR : Vertex failed, vertexName=Map 4, vertexId=vertex_1592601459200_8651_1_02, diagnostics=[Vertex vertex_1592601459200_8651_1_0\2 [Map 4] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: mfstore initializer failed, vertex=vertex_1592601459200_8651_\1_02 [Map 4], java.lang.RuntimeException: serious problem","Root CauseADLS is made of several hundreds of partitions and one of the partitions in block manager service in Azure Data Lake storage (ADLS) had a primary failover to a secondary node.This is a normal activity in a highly available infrastructure like ADLS. But in this case the failover of this said partition went over the threshold. Usually the failover takes few seconds but, in this case, it ran into minutes. This caused the customer jobs that reads/writes data to the said partition fail. ",ADLS engineering team is reviewing the failover logic and is adding safeguards and instrumentation to avoid such incidents in the future. ,194201122,,,,,,,
1.20063E+14,30:19.9,PREM || Azure HDInsight Service || Have several cases that are all on HDInsight and want to see if there’s any common thread.,Have several cases that are all on HDInsight and want to see if there’s any common thread.,PREM || Azure HDInsight Service || Have several cases that are all on HDInsight and want to see if there’s any common thread.,1.408322775,Root Cause : HDInsight Service\By Design\Storm,,Had a call with Cheryl and went through all the processClosing this ,Had a call with Cheryl and went through all the processClosing this ,Had a call with Cheryl and went through all the processClosing this ,,,,,,,,
1.20063E+14,50:31.3,Quota request for HDInsight,we are going to continue working on HDI 3.6 Platform without upgrade for next one year.I saw in Azure site online that support will expire for HDI 3.6 on 12/31/2020. we would like to get the support until next year.Please confirm the extended support until next year.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_QUOTA\n- SupportPlanDisplayName: Premier\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Quota request for HDInsight,0.170054592,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure Quota\HDInsight,Extension of support on HDInsight 3.6 beyond Dec31 2020.,NA,We are extending the retirement and support 6 months for HDInsight 3.6 which is till June 2021 for all customers. A public documentation will be released shortly on the same.  ,,,,,,,,
1.20063E+14,51:25.7,Spark SQLContext not able to access Hive post upgrade from Spark 2.2 to Spark 2.3,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 29, 2020, 8:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: We had upgraded the HDInsight Spark {Namepii} from Spark 2.2 (HDI 3.6) to Spark 2.3 (HDI 3.6)\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: https://anahdispark01datahubqa01.azurehdinsight.net/yarnui/hn/cluster/app/application_1593171849164_0003\n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: As we are running using ADF Spark activity, we are not explicity passing any Spark configurations. However to reproduce the issue, we also ran it on Edge node using client mode and got the same error\n\nspark-submit --class com.zurichna.pada.composite.Gloss_Composite.mainCompositeStream --master yarn --deploy-mode client --num-executors 3 ./{AlphanumericPII} {alphanumericpii} zna_stg_expected_loss.stg_data_curated_zsp_cls_remap_cmps_only zna_curated_expected_loss.calendar adl://storadls01datahubqa02.azuredatalakestore.net/data/curation/expected_loss/gl/work adl://storadls01datahubqa02.azuredatalakestore.net/data/curated/expected_loss/gl/cmps_covg_lvl 202003 Y 0 0 0 0\n\nQuestion: Additional details about the issue\nAnswer: The Spark job is failing post upgrade of HDI cluster from Spark version 2.2 to Spark version 2.3\n\nWe are creating a SQLContext in Spark to access Hive tables as below:\n val sc = new SparkContext(sparkConf)\n val sqlContext = SparkSession.builder().enableHiveSupport().getOrCreate()\n {alphanumericpii} = sqlContext.sql('FROM ' + {alphanumericpii} + ' SELECT * where ' +\n      'exclusion_flag = 'N'')\n\n{alphanumericpii} is assigned Hive Table name of `{alphanumericpii}`\n\nThe spark job is failing with `{alphanumericpii}` not found error.\n\nThe same code is working fine with the older version of Spark 2.2 cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - We had upgraded the HDInsight Spark {Namepii} from Spark 2.2 (HDI 3.6) to Spark 2.3 (HDI 3.6);\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - https://anahdispark01datahubqa01.azurehdinsight.net/yarnui/hn/cluster/app/application_1593171849164_0003;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - As we are running using ADF Spark activity, we are not explicity passing any Spark configurations. However to reproduce the issue, we also ran it on Edge node using client mode and got the same error\n\nspark-submit --class com.zurichna.pada.composite.Gloss_Composite.mainCompositeStream --master yarn --deploy-mode client --num-executors 3 ./{AlphanumericPII} {alphanumericpii} zna_stg_expected_loss.stg_data_curated_zsp_cls_remap_cmps_only zna_curated_expected_loss.calendar adl://storadls01datahubqa02.azuredatalakestore.net/data/curation/expected_loss/gl/work adl://storadls01datahubqa02.azuredatalakestore.net/data/curated/expected_loss/gl/cmps_covg_lvl 202003 Y 0 0 0 0;\nAdditional details about the issue - The Spark job is failing post upgrade of HDI cluster from Spark version 2.2 to Spark version 2.3\n\nWe are creating a SQLContext in Spark to access Hive tables as below:\n val sc = new SparkContext(sparkConf)\n val sqlContext = SparkSession.builder().enableHiveSupport().getOrCreate()\n {alphanumericpii} = sqlContext.sql('FROM ' + {alphanumericpii} + ' SELECT * where ' +\n      'exclusion_flag = 'N'')\n\n{alphanumericpii} is assigned Hive Table name of `{alphanumericpii}`\n\nThe spark job is failing with `{alphanumericpii}` not found error.\n\nThe same code is working fine with the older version of Spark 2.2 cluster;\n\n- ProblemStartTime: 06/29/2020 13:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6f043c4a-d73e-4af2-b3a9-18f26aec9466/resourceGroups/CloudLake-Analytics-QA/providers/Microsoft.HDInsight/clusters/anahdispark01datahubqa01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark SQLContext not able to access Hive post upgrade from Spark 2.2 to Spark 2.3,1.220686305,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unexpected result\Spark,Spark SQLContext not able to access Hive post upgrade from Spark 2.2 to Spark 2.3.,NA,Modified spark code and it's working now.,,,,,,,,
1.20063E+14,47:42.0,Intermittent error connecting ADLS,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 28, 2020, 8:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 28, 2020, 12:00 AM CDT\n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: 20/06/28 09:24:00 ERROR secure.AbstractCredentialServiceCaller: Connection refused (Connection refused)\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Issue resolved after sometime. This kind of errors are being reported every few days recently.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - 20/06/28 09:24:00 ERROR secure.AbstractCredentialServiceCaller: Connection refused (Connection refused);\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Other, don't know or not applicable;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Issue resolved after sometime. This kind of errors are being reported every few days recently.;\n\n- ProblemStartTime: 06/28/2020 13:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Intermittent error connecting ADLS,0.144918913,Root Cause : HDInsight Service\Bug\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package",Intermittent error connecting ADLS,"Lowering the severity as we have a potential mitigationThe staged restart script had a bug and it was reporting the status as ""Failed"". This is the cause for RP repeatedly trying to run the same script.",Please update it on the running cluster sudo find / -name credential_server_stagedrestart.pybackup the original filereplace it with the new file -- provided to the cx via 120072921002211,195416389,,,,,,,
1.20063E+14,03:45.9,Worker node wn170-ahd649 is in decommissoned status,Worker node {alphanumericpii} is in decommissoned status.\n\nWe scaled down HDI cluster on Friday from 14 to 8 worker nodes. Rest of the worker nodes cleanup well from Ambari but this specific worker node is in Decommissioned status in Ambari. Please let us know how to get this cleaned.\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment Management Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Worker node wn170-ahd649 is in decommissoned status,2.795105324,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,120062924004079 - Worker node wn170-ahd649 is in decommissoned status,The services could not be stopped on wn170 during the scale down.,Tried deleting the node using the following Ambari Rest API calls:curl -u '<user>'  -H 'X-Requested-By: ambari' -X DELETE http://hn0-ahd649.azfrk.com:8080/api/v1/clusters/ahd649dj/hosts/wn170-ahd649.azfrk.com/host_componentscurl -u '<user>'  -H 'X-Requested-By: ambari' -X DELETE http://hn0-ahd649.azfrk.com8080/api/v1/clusters/ahd649dj/hosts/wn170-ahd649.azfrk.comThe API calls failed so the Product Group manually deleted the worker node from the Ambari SQL DB.,,,,,,,,
1.20063E+14,16:04.9,I am trying to host the above cluster as Premium tier cluster,"Question: What time did the problem begin?\nAnswer: Wed, {Namepii} 24, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: sentanacmg\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: update the hadoop and spark version in the configuration script \n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: we just changed the hadoop and spark version in  our old configuration script.  we are facing error :Premium cluster can only be used ESP storage account \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - sentanacmg;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - update the hadoop and spark version in the configuration script ;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - we just changed the hadoop and spark version in  our old configuration script.  we are facing error :Premium cluster can only be used ESP storage account ;\n\n- ProblemStartTime: 06/24/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMFG NonProduction\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/059ed1ab-6824-4344-9a65-a0504248340f/resourceGroups/Enterprise_Analytics/providers/Microsoft.HDInsight/clusters/sentanacmg\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I am trying to host the above cluster as Premium tier cluster,0.939318524,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Active Directory integration,I am trying to host the above cluster as Premium tier cluster,Premium Tiers are supported only in ESP clusters.,"I am trying to host the above cluster as Premium tier clusterRecommendations:As discussed in the previous call, we tried to deploy Rserver and Rstudio on an Edge node of spark ESP cluster and it did not succeed. We reached out to our product Group to check if it is by design that we don't support R ,Rstudio and Hue on ESP clusters and Product Group confirmed that ESP clusters don't support the above tools. There is an option in standard cluster where you can create an MLCLuster that has R,Rstudio in it. But these MLClusters do not support ESP and it comes with HDInsight 3.6 which is retiring on Dec 31 2020. Hence our recommendation is to stick to the Standard Cluster.",,,,,,,,
1.20063E+14,32:45.0,Cluster went into an error state after trying to scale up cluster,"Question: What time did the problem begin?\nAnswer: Sat, {Namepii} 27, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: This failed previously, and we were told to recreate our clusters with a custom Ambari DB. We recreated using that, but faced the same issue.\nOther cluster with problem: EDPCoreSparkSharedProd\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: The Ambari DB used is: edp-prd-usce-sqlserver-ambari/bchcookedclusterdb\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - This failed previously, and we were told to recreate our clusters with a custom Ambari DB. We recreated using that, but faced the same issue.\nOther cluster with problem: EDPCoreSparkSharedProd;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - The Ambari DB used is: edp-prd-usce-sqlserver-ambari/bchcookedclusterdb;\n\n- ProblemStartTime: 06/27/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EDP Core Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d6132b1-574a-42db-a8c6-d583d892ebd2/resourceGroups/spark-p-core-rg/providers/Microsoft.HDInsight/clusters/edp-prd-usce-spark-bchcooked\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster went into an error state after trying to scale up cluster,1.047627871,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Cluster went into an error state after trying to scale up cluster.,Cluster went into an error state after trying to scale up cluster.,"subscription (AzureProductSubscriptionID: 6d6132b1-574a-42db-a8c6-d583d892ebd2) on Tenant(Tenant Id: 33e01921-4d64-4f8c-a055-5bdaffd5e33d) was raised earlier with ticket number ""120061821006718"" which is still open with an ICM attached to it( 193055619). ",,,,,,,,
1.20063E+14,31:25.2,Unable to spin up HDInsight cluster using Azure Template HDInsight Service,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 29, 2020, 9:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: cxdp-cams-spark-hdinsight-cluster-prod\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: Error message is not clear enough to pin point the problem - \nHere is what it shows:\nerror:   Deployment provisioning state was not successful.\nerror:   Error information has been recorded to /home/apps/pcamscld/.azure/azure.err\nverbose: Error: Deployment provisioning state was not successful.\n    at {Alphanumericpii} (/{alphanumericpii})\n    at ___ (/{alphanumericpii})\n    at /{alphanumericpii}\n    at ___ (/{alphanumericpii})\n    at ___ (/{alphanumericpii})\n    at ___ (/{AlphanumericPII})\n    at ___ (/{alphanumericpii})\n    at __$getFailedNestedOperations (/{AlphanumericPII})\n    at ___ (/{alphanumericpii})\n    at {alphanumericpii} (/{alphanumericpii})\nerror:   group deployment create command failed\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - cxdp-cams-spark-hdinsight-cluster-prod;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - Error message is not clear enough to pin point the problem - \nHere is what it shows:\nerror:   Deployment provisioning state was not successful.\nerror:   Error information has been recorded to /home/apps/pcamscld/.azure/azure.err\nverbose: Error: Deployment provisioning state was not successful.\n    at {Alphanumericpii} (/{alphanumericpii})\n    at ___ (/{alphanumericpii})\n    at /{alphanumericpii}\n    at ___ (/{alphanumericpii})\n    at ___ (/{alphanumericpii})\n    at ___ (/{AlphanumericPII})\n    at ___ (/{alphanumericpii})\n    at __$getFailedNestedOperations (/{AlphanumericPII})\n    at ___ (/{alphanumericpii})\n    at {alphanumericpii} (/{alphanumericpii})\nerror:   group deployment create command failed;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Business Intelligence\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier Mission Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to spin up HDInsight cluster using Azure Template HDInsight Service,0.368029641,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to spin up HDInsight cluster using Azure Template HDInsight Service,Unable to spin up HDInsight cluster using Azure Template HDInsight Service,Checked in the backend and found that storage profile has wrong FQDN of storage account. Customer had fixed the same and confirmed that he can provision clusters successfully,,,,,,,,
1.20063E+14,28:53.5,HDInsight 3.6 retirement,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Power {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: We are not actively facing any problems deploying our HDInsight clusters. There is no 'HDInsight - Other' option for opening a Support Case.\n\nAs per this article (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning), HDInsight 3.6 will be retired on 12/31/2020. Can you please confirm if Microsoft support for HDInsight 3.6 can be extended past 12/31/2020? How much will this extended support cost?\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Power {Namepii};\nAdditional details about the issue - We are not actively facing any problems deploying our HDInsight clusters. There is no 'HDInsight - Other' option for opening a Support Case.\n\nAs per this article (https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning), HDInsight 3.6 will be retired on 12/31/2020. Can you please confirm if Microsoft support for HDInsight 3.6 can be extended past 12/31/2020? How much will this extended support cost?;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight 3.6 retirement,0.083778505,"Root Cause : HDInsight Service\Advisory (not for how-to) tracking advanced support for Prodirect, Premier, and Unified support",Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Support for HDInsight 3.6 expires 2021-06-30,Customer performing migration planning to migrate workloads running on HDI 3.6 to HDI 4.0.  They wanted to know if there was an extended support plan available if they were unable to migrate workloads to HDI 4.0 on or before 2021-06-30,"At this time, HDInsight Program Management indicate no extended support plan will be offered",,,,,,,,
1.20063E+14,16:41.2,hive ATS check fail,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: N/A\n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: This happened while entering the hive UI.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nHive query if applicable - N/A;\nDoes the same query work through Beeline from the Headnode? - Other, don't know or not applicable;\nAdditional details about the issue - This happened while entering the hive UI.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/30/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LCL_Loblaw_PR\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d4a34414-bde5-4f23-9d2e-7130811f344b/resourceGroups/RG-LCLPR-HDIDSS-CC/providers/Microsoft.HDInsight/clusters/dss-spark-prod\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hive ATS check fail,1.762670984,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Client tool issue\Hive View,hive ATS check fail,hive ATS check fail,"Worked with customer and found that HN0 was active headnode while ATS/HistoryServer were running HN1. On customer approval, restarted HN1 that moved services to ""active headnode"". Customer is able to load hive view successfully now.",,,,,,,,
1.20063E+14,22:19.0,We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. ,"Question: What time did the problem begin?\nAnswer: Wed, Jul 1, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Hive query if applicable\nAnswer: Issue – We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. \n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Issue – We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nHive query if applicable - Issue – We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. ;\nDoes the same query work through Beeline from the Headnode? - Other, don't know or not applicable;\nAdditional details about the issue - Issue – We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 06/30/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/rg-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi002dlqa001\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are getting ODBC connection error when connecting to HDI cluster using hive ODBC driver. Same setting are working randomly. ,6.823807993,Root Cause : HDInsight Service\Bug\Simba Hive ODBC Driver,Routing Azure HDInsight V5\Client tool issue\Hive View,Symptom: Hive ODBC connection failing to connect.,Cause:  Version 2.6.7 causing caching issue.,Resolution: Downgraded to 2.1,194830840,,,,,,,
1.2007E+14,50:35.5,error in kafka,"Question: What time did the problem begin?\nAnswer: Wed, Jul 1, 2020, 1:40 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: worker nodes restarted, problem continues\n\nQuestion: Additional details about the issue\nAnswer: a similar incident is reported yesterday {Phonenumberpii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - worker nodes restarted, problem continues;\nAdditional details about the issue - a similar incident is reported yesterday {Phonenumberpii};\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/01/2020 06:40:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: FastData\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d1567da6-65e2-47ec-be0e-532f83a954cd/resourceGroups/storage-rg/providers/Microsoft.HDInsight/clusters/pro-kafka-peru\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",error in kafka,0.453906128,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Kafka,Kafka connection issues,"discovered that the connection was set to ZK and brokers...172.30.243.16:9092,172.30.243.8:9092,172.30.243.5:9092,172.30.243.14:9092,172.30.243.15:9092,172.30.243.11:9092,172.30.243.19:9092","removed ZK left only brokers172.30.243.14:9092,172.30.243.15:9092,172.30.243.11:9092,172.30.243.19:9092... now it works fine",194776469,,,,,,,
1.2007E+14,18:19.8,Resource health is going down every day since last few days,"Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: restarts \n\nQuestion: Additional details about the issue\nAnswer: Hive metastore process going down and resource health going down\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - restarts ;\nAdditional details about the issue - Hive metastore process going down and resource health going down;\n\n- ProblemStartTime: 06/25/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: wadogo-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ec95fa5b-2bf5-4849-a3fb-ea1b5aceb03f/resourceGroups/mmp-prod-eastus-reporting/providers/Microsoft.HDInsight/clusters/mmp-hdi\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Resource health is going down every day since last few days,0.162352045,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Resource health is going down every day since last few days,Resource health is going down every day since last few days,"Worked with customer and increased hive metastore heap size, that fixed the alerts on the cluster.",,,,,,,,
1.2007E+14,39:23.2,Unable to create HDI cluster with Azure DataLake Gen2,"Question: What time did the problem begin?\nAnswer: Wed, Jul 1, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: hditest\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: We are trying to create HDI cluster and it's not showing Azure DataLake {Alphanumericpii} account while creating.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - hditest;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - We are trying to create HDI cluster and it's not showing Azure DataLake {Alphanumericpii} account while creating.;\n\n- ProblemStartTime: 06/30/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: AZURE-PTC-CUST-ANALYTICS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/26501947-30f8-46ad-8b80-555d125d0e5c/resourceGroups/Unifi_Data_Platform/providers/Microsoft.HDInsight/clusters/UDP-Hdinsight\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to create HDI cluster with Azure DataLake Gen2,0.031074627,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,Unable to create HDI cluster with Azure DataLake Gen2,No permission in subscription ID and RBAC to create an user managed ID,Add a permission into storage account and subscription ID1. CX is unable to see a existing GEN2 storage account in creating page of hadoop cluster in Azure portal - Resolved by enabling Blob public access2. Need a Managed ID to complete hadoop cluster deployment - CX will contact Admin to add/update RBAC to Contributor/Owner,,,,,,,,
1.2007E+14,12:23.7,How to connect using SSL port from Beeline to HIVE,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Connection string used\nAnswer: jdbc:hive2://ahd703-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We have a third party system coming and acecssing HIVE tables using beeline. We would like to expose beeline only with SSL port. but this command is not working. Please advice how to set it up.\njdbc:hive2://ahd703-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nConnection string used - jdbc:hive2://ahd703-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nAdditional details about the issue - We have a third party system coming and acecssing HIVE tables using beeline. We would like to expose beeline only with SSL port. but this command is not working. Please advice how to set it up.\njdbc:hive2://ahd703-int.azurehdinsight.net:443/default;transportMode=http;ssl=true;httpPath=/hive2;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} and Analytics Services\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to connect using SSL port from Beeline to HIVE,26.2740889,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Client tool issue\Beeline,How to connect using SSL port from Beeline to HIVE.,Certificate issues.,Deployed intermediate certificate [Microsoft IT TLS CA 2] to both gateways which resolved issue.,197003639,,,,,,,
1.2007E+14,11:41.5,I cannot access any of the hyperlink under 'o365ipdinam06-sp-wu01' Cluster dashboards,"Question: What time did the problem begin?\nAnswer: {Namepii}, {Namepii} 30, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: I am unable to access any of the hyperlinks under '{alphanumericpii}' {Namepii} management interfaces of HDInsight option from my Azure portal. The web browser will result in 'cannot reach this page'.\nI'm using the latest Microsft's Edge web browser on my Microsoft's issued Surface Laptop 3.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - None;\nAdditional details about the issue - I am unable to access any of the hyperlinks under '{alphanumericpii}' {Namepii} management interfaces of HDInsight option from my Azure portal. The web browser will result in 'cannot reach this page'.\nI'm using the latest Microsft's Edge web browser on my Microsoft's issued Surface Laptop 3.;\n\n- ProblemStartTime: 06/30/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-NAM-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cda42e6-a623-4800-abdf-431ef3ec65e5/resourceGroups/o365ipdinam06-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdinam06-sp-wu01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I cannot access any of the hyperlink under 'o365ipdinam06-sp-wu01' Cluster dashboards,0.054971206,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,I cannot access any of the hyperlink under cluster dashboards,NSG Validation,The issue is with NSG Rules and whitelisting the IPaddress helped in accessing the Ambari UI. ,,,,,,,,
1.2007E+14,44:02.9,Query is running really slow also not able to see all the DAGs in Tez view,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select {namepii}(*) from\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: As this is the domain join cluster,\nIm this cluster {Namepii} select * query taking lots of time and failing,\nalso in tez view we are not able to see the dags using {namepii} user.\nand some jobs are showing succeeded in RM ui while its showing in running state from tez view.\nKindly look into this \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select {namepii}(*) from;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - As this is the domain join cluster,\nIm this cluster {Namepii} select * query taking lots of time and failing,\nalso in tez view we are not able to see the dags using {namepii} user.\nand some jobs are showing succeeded in RM ui while its showing in running state from tez view.\nKindly look into this ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/72d4c1b3-fd6e-432a-b18a-89eec2c10a6b/resourceGroups/pep-idesbx-cus-01-{namepii}/providers/Microsoft.HDInsight/clusters/fritolaydjspark\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Query is running really slow also not able to see all the DAGs in Tez view,6.047975341,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,Query is running really slow also not able to see all the DAGs in Tez view,Query is running really slow also not able to see all the DAGs in Tez view,Worked with customer and customer observed that there were YARN applications pending on the queue due to resource contention. Suggested customer to monitor and scale-up the cluster as required.,,,,,,,,
1.2007E+14,12:54.2,LLAP Cluster: Scale up issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: LLAP {Namepii}: Scale up issues\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - LLAP {Namepii}: Scale up issues;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-{namepii}-cto-adfcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps108llapfdsbwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",LLAP Cluster: Scale up issues,20.86364309,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,LLAP Cluster: Scale up issues,LLAP Cluster: Scale up issues,Will track refund under 120080821000073. Please create a new case by referring this when it occur in future.,194832148,,,,,,,
1.2007E+14,33:57.3,Worker node is booting up since quite some time.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 2, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: Authorized uses only. All activity may be monitored and reported.\n'System is booting up. See {alphanumericpii})'\nConnection to wn3-sca01.cvshaadds.com closed by remote host.\nConnection to wn3-sca01.cvshaadds.com closed.\n{alphanumericpii}:~$\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None;\nAdditional details about the issue - Authorized uses only. All activity may be monitored and reported.\n'System is booting up. See {alphanumericpii})'\nConnection to wn3-sca01.cvshaadds.com closed by remote host.\nConnection to wn3-sca01.cvshaadds.com closed.\n{alphanumericpii}:~$\n;\n\n- ProblemStartTime: 07/02/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: FS Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/adcd8a66-2a06-4fe9-b54b-ce22945b477e/resourceGroups/RG-RTL-USE2-SCA-DEV/providers/Microsoft.HDInsight/clusters/sca01-dev-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Worker node is booting up since quite some time.,0.056697937,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,'System is booting up. See pam_nologin(8)' Connection to wn3-sca01.cvshaadds.com closed by remote host. Connection to wn3-sca01.cvshaadds.com closed.,Worker node is booting up since quite some time,Rebooted the WN3 host to get pass the issue. If it happen again please have SSH verbose log with us to continue work on the RCA.,194967472,,,,,,,
1.2007E+14,19:55.4,HDInsight Cluster down,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: When our clients try to connect to the HD Insight nodes using the IP of the node, they aren't able to connect. This issue started occuurring today and we were able to connect to them prior.\n\nWe also ran into issues when trying to use the cluster's hostname to connect.\n\nPlease advise.\n\n{Alphanumericpii} does NOT approve of additional charges beyond resolving the primary issue.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - When our clients try to connect to the HD Insight nodes using the IP of the node, they aren't able to connect. This issue started occuurring today and we were able to connect to them prior.\n\nWe also ran into issues when trying to use the cluster's hostname to connect.\n\nPlease advise.\n\n{Alphanumericpii} does NOT approve of additional charges beyond resolving the primary issue.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure (LuminaAnalyticscom): #1150836\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight Cluster down,0.01843284,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,HDInsight Cluster down - Kafka broker node stopped working and connection failure onto worker nodes,stopped working in metrics data collection with Kafka broker nodes connection failure on wn,Restarted hn and wn,,,,,,,,
1.2007E+14,46:29.1,Nonprod - kpq041hbasefdqawus201 - Cleanup Hbase table in transition,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 2, 2020, 11:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: NA\n\nQuestion: HBase query\nAnswer: {ALPHANUMERICPII}) table deop\n\n\nQuestion: How was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: Issue:  Hbase table ({ALPHANUMERICPII}) got corrupted while rebalancing (May while scaling down/up) and now we are not able drop it for reloading.\nEnvironment : FD QA\n{Namepii} name: https://kpq041hbasefdqawus201-int.azure\n\nTransition regions:\nNumber of requests: 28348456\nNumber of regions: 1125\nNumber of regions in transition: 45\n\nSteps tried.\n1. {Namepii} consistency check\n2. Fix not supported in {ALPHANUMERICPII}\n3. Restarted Hbase service\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the HBase job if known - NA;\nHBase query - {ALPHANUMERICPII}) table deop\n;\nHow was the HBase job submitted? - HBase shell;\nAdditional details about the issue - Issue:  Hbase table ({ALPHANUMERICPII}) got corrupted while rebalancing (May while scaling down/up) and now we are not able drop it for reloading.\nEnvironment : FD QA\n{Namepii} name: https://kpq041hbasefdqawus201-int.azure\n\nTransition regions:\nNumber of requests: 28348456\nNumber of regions: 1125\nNumber of regions in transition: 45\n\nSteps tried.\n1. {Namepii} consistency check\n2. Fix not supported in {ALPHANUMERICPII}\n3. Restarted Hbase service\n;\n\n- ProblemStartTime: 07/02/2020 18:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq041hbasefdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Nonprod - kpq041hbasefdqawus201 - Cleanup Hbase table in transition,1.868818106,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Unexpected result\Hbase,Nonprod - kpq041hbasefdqawus201 - Cleanup Hbase table in transition,Nonprod - kpq041hbasefdqawus201 - Cleanup Hbase table in transition,"Resolution: Peformed below procedure to drop the table,Removed required table from underlying storage hdfs dfs -rm -r /hbase/data/RFD_ONELINK01_T/PS_KP_GL_ATT_DBRemove from zkrmr /hbase-unsecure/table/RFD_ONELINK01_T:PS_KP_GL_ATT_DBPatched hbck and jar is uploaded to customer cluster. Then fixMeta is executedsudo -u hbase hbase hbck -fixMetaStop all the HMasters from AmbariStop all HBase servicesClick on Action > Stop HBaseMake sure nothing created here:hdfs dfs -ls /hbase/data/RFD_ONELINK01_T/PS_KP_GL_ATT_DBFrom Ambari start allAction > Start HBaseFrom HMaster UI after some time it can be seen that few regions are in opening state.Checked master proc wals. hdfs dfs -ls /hbase-wals/MasterProcWALsAnd as everything is flushed and no need of the wal replay, cleaned all those.hdfs dfs -rm  /hbase-wals/MasterProcWALs/*Restarted active HMaster and one of the standbys become active and things turned green.",194976405,,,,,,,
1.2007E+14,27:59.2,kpps80sparkprdsupwus201: gateway errror,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:  503 gateway error\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii}:  503 gateway error;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps80sparkprdsupwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",kpps80sparkprdsupwus201: gateway errror,1.047485817,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,kpps80sparkprdsupwus201: gateway errror,kpps80sparkprdsupwus201: gateway errror,Checked and found the issue was due to High DTU on Ambari database due to ATS entities on the Database. Shared solution with customer to host ATS in its own database to minimize load on Ambari database or create cluster with External Ambari database.,195103112,,,,,,,
1.2007E+14,20:00.1,Unable to read hiveserver2 config from zookeeper,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We had an issue on the 1st of July at 10pm ({Namepii} time), when trying to run an oozie job  which 1st action is to create partition for HIve , we got this error\n\n200619170348603-oozie-oozi-W] {AlphanumericPII}] Exception in addtoJobConf\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\nCaused by: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                ... 17 more\nCaused by: org.apache.zookeeper.KeeperException$AuthFailedException: KeeperErrorCode = AuthFailed for /{alphanumericpii}\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                ... 20 more\n\nRerunning several minutes fixed the problem, but this is not the first time it happens, please investigate.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We had an issue on the 1st of July at 10pm ({Namepii} time), when trying to run an oozie job  which 1st action is to create partition for HIve , we got this error\n\n200619170348603-oozie-oozi-W] {AlphanumericPII}] Exception in addtoJobConf\njava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\nCaused by: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read {AlphanumericPII} configs from ZooKeeper\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                ... 17 more\nCaused by: org.apache.zookeeper.KeeperException$AuthFailedException: KeeperErrorCode = AuthFailed for /{alphanumericpii}\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                at {AlphanumericPII})\n                ... 20 more\n\nRerunning several minutes fixed the problem, but this is not the first time it happens, please investigate.\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7afd8a0e-516f-4623-894d-022e4e8e4c71/resourceGroups/central_feeder-PROD-nes20200619PV1T4cluster-Automation-HDI/providers/Microsoft.HDInsight/clusters/GlU2bjiF6D-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to read hiveserver2 config from zookeeper,0.248227483,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,200619170348603-oozie-oozi-W] ACTION[0000500-200619170348603-oozie-oozi-W@CreateDailyRawPartitions] Exception in addtoJobConfjava.sql.SQLException: org.apache.hive.jdbc.ZooKeeperHiveClientException: Unable to read HiveServer2 configs from ZooKeeper                at org.apache.hive.jdbc.HiveConnection.&lt;init&gt;(HiveConnection.java:187)                at org.apache.hive.jdbc.HiveDriver.connect(HiveDriver.java:105)                at java.sql.DriverManager.getConnection(DriverManager.java:664)                at java.sql.DriverManager.getConnection(DriverManager.java:270)                at org.apache.oozie.action.hadoop.Hive2Credentials.addtoJobConf(Hive2Credentials.java:66)                at org.apache.oozie.action.hadoop.JavaActionExecutor.setCredentialTokens(JavaActionExecutor.java:1367),"We checked the logs and noticed that During the time of impact, we found that both HDFS and YARN Resource Manager weren't healthy. We saw the respective probes being timed out consistently. Without these components, HS2 will not work and there would be connection failures. Later, we saw Network connectivity issues  recovered and After which, services became healthy.If the issue reoccurs again let us know as soon as possible to do live troubleshooting ","We checked the logs and noticed that During the time of impact, we found that both HDFS and YARN Resource Manager weren't healthy. We saw the respective probes being timed out consistently. Without these components, HS2 will not work and there would be connection failures. Later, we saw Network connectivity issues  recovered and After which, services became healthy.If the issue reoccurs again let us know as soon as possible to do live troubleshooting ",,,,,,,,
1.20071E+14,54:10.7,Cannot delete the cluster,"Question: What time did the problem begin?\nAnswer: Sun, Jul 5, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: no but we need the redeploy because of a broken cluster\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: without this cluster we cannot provide work to data science\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - New problem, worked before;\nAny changes made? - no but we need the redeploy because of a broken cluster;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - without this cluster we cannot provide work to data science;\n\n- ProblemStartTime: 07/04/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: CSP\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Cloud Solution Provider\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6c53cca3-a4bc-49aa-b862-19f713f7b8eb/resourceGroups/hdinsight-acc-rg/providers/Microsoft.HDInsight/clusters/dshva1-hdi\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot delete the cluster,0.080535482,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to delete due to active DNS name.  Public IPs were in failed state,Public Ip was associated with active DNS,Added in a unique name to DNS at public ipPut Public IP to a healthy state and deleted all clusters that needed deleting.,"195,347,121,195,768,000",,,,,,,
1.20071E+14,06:28.2,public dns for HDInsight not working,"the azurehdinsight.net is not resolving correctly.\n\nProblem start date and time\nSun, Jul 5, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 07/04/2020 22:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: CSP\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Cloud Solution Provider\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",public dns for HDInsight not working,4.355958751,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,* Unable to delete due to active DNS name.  * Public IPs were in failed stat,Public IP was associated with active DNS,* Added in a unique name to DNS at public IP* Put Public IP to a healthy state and deleted all clusters that needed deleting.,195822266,,,,,,,
1.20071E+14,11:04.4,Cluster failing to create with error that the name is already in use,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 1:52 PM GMT+1\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: When we have had this error previously, it was caused by a DNS entry that was not deleted, causing the new creation to think the cluster name was already in use. \n\nWe are getting that same error again:\n'{Namepii} name '{alphanumericpii}' is already in use by another HDInsight cluster'. \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: The cluster is failing to start with the two errors below:\n\n'{Namepii} name '{alphanumericpii}' is already in use by another HDInsight cluster' \n\nAND\n\n'The gateway did not receive a response from 'Microsoft.HDInsight' within the specified time period'. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - When we have had this error previously, it was caused by a DNS entry that was not deleted, causing the new creation to think the cluster name was already in use. \n\nWe are getting that same error again:\n'{Namepii} name '{alphanumericpii}' is already in use by another HDInsight cluster'. ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - The cluster is failing to start with the two errors below:\n\n'{Namepii} name '{alphanumericpii}' is already in use by another HDInsight cluster' \n\nAND\n\n'The gateway did not receive a response from 'Microsoft.HDInsight' within the specified time period'. ;\n\n- ProblemStartTime: 07/06/2020 12:52:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: RL - Integrate PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster failing to create with error that the name is already in use,0.062159544,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster failing to create with error that the name is already in use,"Our PG has sent us an explanation as to what occurred yesterday during your deployment....  To explain what really happened here, I'll explain some background about how requests are processed by our service. The customer request is intercepted by ARM and forwarded to HDInsight RP. HDI RP is required to respond back to ARM within 20s with a http status, typically 'Http status 202' if request is valid. If HDI RP does not respond back within 20s to ARM, ARM considers the request to have timed out and retries on behalf of the customer. When HDI RP retrieves the redundant (retry) request from ARM, it returns back a conflict since its already processing the create request for this cluster. That conflict is what customer sees in their activity logs on the portal.  Why does HDI RP not respond back within 20s?This can happen if any validation tasks take longer than expected. We have pushed out improvements 6 months ago where all validation tasks are required to complete within 10s or we skip validation and let the cluster creation proceed anyway. We identified a bug in this which has missed a scenario - a call to retrieve storage properties is not enforced under this validation strategy and therefore can take longer than 20s if the client does not respond back or underlying service becomes unavailable. We will be investing in improvements for making sure the customer does not see this confusing conflict message even when their cluster creation is successful.",redeploy,195378598,,,,,,,
1.20071E+14,11:27.6,[Azure Government] FailedToConnectWithClusterErrorCode  - Unable to connect to cluster management endpoint,"[Azure Government] Question: What time did the problem begin?\nAnswer: Fri, {Namepii} 26, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: hdi-ugv-dna-dv\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We are deploying {namepii} Terraform template and have tried modifying the NSG to allow from all and also tried without egress control but still get the same error:\n\nError waiting for creation of HDInsight Spark {Namepii} 'hdi-ugv-dna-dv' (Resource {Namepii} 'RGP-UGV-DNA-DV'): Code='FailedToConnectWithClusterErrorCode' Message='Unable to connect to cluster management endpoint. Please retry later.'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - hdi-ugv-dna-dv;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We are deploying {namepii} Terraform template and have tried modifying the NSG to allow from all and also tried without egress control but still get the same error:\n\nError waiting for creation of HDInsight Spark {Namepii} 'hdi-ugv-dna-dv' (Resource {Namepii} 'RGP-UGV-DNA-DV'): Code='FailedToConnectWithClusterErrorCode' Message='Unable to connect to cluster management endpoint. Please retry later.';\n\n- ProblemStartTime: 06/26/2020 04:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: dev-spoke-apps\n- PUID: {Xuidpii}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d0709920-f127-4944-afda-3757f1db064b/resourceGroups/RGP-UGV-DNA-DV/providers/Microsoft.HDInsight/clusters/hdi-ugv-dna-dv\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] FailedToConnectWithClusterErrorCode  - Unable to connect to cluster management endpoint,0.261069156,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,"[{""ErrorCode"":""FailedToConnectWithClusterErrorCode"",""ErrorDescription"":""Unable to connect to cluster management endpoint. Please retry later.""}]",Misconfigured DNS server had an authoritative zone configured for database.usgovcloudapi.net that only had a single local IP address for the private link SQL DB feature. This was causing the name lookup for all other names in the database.usgovcloudapi.net to fail,Fixed the DNS configuration by removing the authoritative zone and adding an entry specific the the SQL DB private link IP,195717111,,,,,,,
1.20071E+14,52:01.1,Failed to submit Spark job - Bad gateway error,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 9:57 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: All Jobs are failing\n\nQuestion: Additional details about the issue\nAnswer: We have two prod clusters and both stopped working same time with same error.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - All Jobs are failing;\nAdditional details about the issue - We have two prod clusters and both stopped working same time with same error.;\n\n- ProblemStartTime: 07/06/2020 16:57:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSFT MSCIT {Namepii} ADL\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/892e9c08-9a45-479b-82bf-f34e7ff27da3/resourceGroups/maxscrgadls/providers/Microsoft.HDInsight/clusters/maxhdindwsparkprod\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Failed to submit Spark job - Bad gateway error,0.189593403,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Query or Job Failure\Spark,"livy folders are missing, ",Spark 2.1 is not supported anymore https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-release-notes#deprecation-of-spark-21-and-22-in-hdinsight-36-spark-cluster,Update Spark version,195388946,,,,,,,
1.20071E+14,06:51.6,AAD app registration certificate expire,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: NA\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We are using ‘datalakeprod’ to provision HDI cluster for {AlphanumericPII} storage account. The certificate is getting expire. We need your help to create a new certificate (pfx) file. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - NA;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We are using ‘datalakeprod’ to provision HDI cluster for {AlphanumericPII} storage account. The certificate is getting expire. We need your help to create a new certificate (pfx) file. ;\n\n- ProblemStartTime: 07/05/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/{namepii}-JCIDataLake-Production-0004/providers/Microsoft.HDInsight/clusters/hdi003dlprod001\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",AAD app registration certificate expire,0.152446194,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,AAD app registration certificate expire and refreash GEN1 failure,The ADLS Gen 1 certificate renewal workflow failure is due to a regression on HDI side and there was an ongoing issue where gateways fail to pick up the latest/ renewed ADLS Gen 1 certificate because the renew ADLS Gen 1 certificate workflow failing at the RestartVmGroupsStaggered stage because of an operation that's already started,Essentially trigger credential service to start using the new ADLS Gen 1 certificate for getting tokens to access the ADLS Gen 1 storage account followed by below TSG.ttps://msdata.visualstudio.com/HDInsight/_wiki/wikis/HDInsight.wiki/3665/JobFailuresDueToExpiredADLSCert-TSG,197359988,,,,,,,
1.20071E+14,47:07.5,Yarn application resources were not allocated to the jobs waiting in que ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: sh /cs/cat/ERR_RJT/scripts/shell/error_reject_extract_trigger_script.sh %%\\{UNCPII}\ERR_TRADEDATE %%ORDER_DATE_YYYYMMDD /cs/cat/ERR_RJT/cfg/error_reject_trigger_script.conf %%\\{UNCPII}\ERR_Mpid %%\\{UNCPII}\LIVYNODE_DNS CatCesExtract\n\n\nQuestion: Additional details about the issue\nAnswer: yarn application shows the job is waiting for resources and was just stuck in waiting state for almost 2 hrs, re-try also did not work.  had to create a new cluster and move on with the jobs. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - sh /cs/cat/ERR_RJT/scripts/shell/error_reject_extract_trigger_script.sh %%\\{UNCPII}\ERR_TRADEDATE %%ORDER_DATE_YYYYMMDD /cs/cat/ERR_RJT/cfg/error_reject_trigger_script.conf %%\\{UNCPII}\ERR_Mpid %%\\{UNCPII}\LIVYNODE_DNS CatCesExtract\n;\nAdditional details about the issue - yarn application shows the job is waiting for resources and was just stuck in waiting state for almost 2 hrs, re-try also did not work.  had to create a new cluster and move on with the jobs. ;\n\n- ProblemStartTime: 07/06/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-cat-workload-{namepii}/providers/Microsoft.HDInsight/clusters/obikt5-errorreject-20200706-cat-prod-hdi\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Yarn application resources were not allocated to the jobs waiting in que ,0.580734845,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,Yarn application resources were not allocated to the jobs waiting in que,Yarn application resources were not allocated to the jobs waiting in que,Worked with product group on this and confirmed that customer had provisioned the cluster while the fix was in progress. Subsequent provisionings did receive the fix as confirmed by customer.,196023764,,,,,,,
1.20071E+14,05:47.6,Error when creating a new HDI Cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: zszEEmQrWx-ProjectSpark\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes made.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: We are getting this error when creating a new cluster:\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'error\\': {{uncpii}\n \\'code\\': \\'InvalidTemplateDeployment\\',\\r\\n \\'message\\': \\'The template deployment failed because of policy violation. Please see details for more information.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'RequestDisallowedByPolicy\\',\\r\\n \\'target\\': \\'gateway-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'message\\': \\'Resource '{alphanumericpii}' was disallowed by policy. Policy identifiers: '[{\\\\{UNCPII}\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\\\{Uncpii}\\\\\'policyDefinition\\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\\\{Uncpii}\',{uncpii}\n \\'additionalInfo\\': [{uncpii}\n {{uncpii}\n \\'type\\': \\'PolicyViolation\\',\\r\\n \\'info\\': {{uncpii}\n \\'policyDefinitionDisplayName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'evaluationDetails\\': {{uncpii}\n \\'evaluatedExpressions\\': [{uncpii}\n {{uncpii}\n \\'result\\': \\'True\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'type\\',\\r\\n \\'path\\': \\'type\\',\\r\\n \\'expressionValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'targetValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'operator\\': \\'Equals\\'\\r\\n },{uncpii}\n {{uncpii}\n \\'result\\': \\'False\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'Microsoft.Network/loadBalancers/frontendIPConfigurations[*].publicIPAddress.id\\',\\r\\n \\'path\\': \\'properties.frontendIPConfigurations[*].properties.publicIPAddress.id\\',\\r\\n \\'expressionValue\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourcegroups/mlt-dar-pscdatahub-1-DEV-hdinsightpscdatahubdev3-Automation-HDI/providers/Microsoft.Network/publicIPAddresses/publicIpgateway-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'targetValue\\': \\'False\\',\\r\\n \\'operator\\': \\'Exists\\'\\r\\n }{uncpii}\n ]{uncpii}\n },{uncpii}\n \\'policyDefinitionId\\': \\'/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionEffect\\': \\'Deny\\',\\r\\n \\'policyAssignmentId\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentDisplayName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentScope\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2\\',\\r\\n \\'policyAssignmentSku\\': {{uncpii}\n \\'name\\': \\'A0\\',\\r\\n \\'tier\\': \\'Free\\'\\r\\n }{uncpii}\n }{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'},{'code':'BadRequest','message':'{{uncpii}\n \\'error\\': {{uncpii}\n \\'code\\': \\'InvalidTemplateDeployment\\',\\r\\n \\'message\\': \\'The template deployment failed because of policy violation. Please see details for more information.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'RequestDisallowedByPolicy\\',\\r\\n \\'target\\': \\'headnode-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'message\\': \\'Resource '{alphanumericpii}' was disallowed by policy. Policy identifiers: '[{\\\\{UNCPII}\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\\\{Uncpii}\\\\\'policyDefinition\\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\\\{Uncpii}\',{uncpii}\n \\'additionalInfo\\': [{uncpii}\n {{uncpii}\n \\'type\\': \\'PolicyViolation\\',\\r\\n \\'info\\': {{uncpii}\n \\'policyDefinitionDisplayName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'evaluationDetails\\': {{uncpii}\n \\'evaluatedExpressions\\': [{uncpii}\n {{uncpii}\n \\'result\\': \\'True\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'type\\',\\r\\n \\'path\\': \\'type\\',\\r\\n \\'expressionValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'targetValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'operator\\': \\'Equals\\'\\r\\n },{uncpii}\n {{uncpii}\n \\'result\\': \\'False\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'Microsoft.Network/loadBalancers/frontendIPConfigurations[*].publicIPAddress.id\\',\\r\\n \\'path\\': \\'properties.frontendIPConfigurations[*].properties.publicIPAddress.id\\',\\r\\n \\'expressionValue\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourcegroups/mlt-dar-pscdatahub-1-DEV-hdinsightpscdatahubdev3-Automation-HDI/providers/Microsoft.Network/publicIPAddresses/publicIpheadnode-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'targetValue\\': \\'False\\',\\r\\n \\'operator\\': \\'Exists\\'\\r\\n }{uncpii}\n ]{uncpii}\n },{uncpii}\n \\'policyDefinitionId\\': \\'/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionEffect\\': \\'Deny\\',\\r\\n \\'policyAssignmentId\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentDisplayName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentScope\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2\\',\\r\\n \\'policyAssignmentSku\\': {{uncpii}\n \\'name\\': \\'A0\\',\\r\\n \\'tier\\': \\'Free\\'\\r\\n }{uncpii}\n }{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\nPreviously we were getting this error:\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'UnableToEstablishConnectivityFromVirtualMachines\\',\\r\\n        \\'message\\': \\'Unable to establish connectivity from virtual machines. Please ensure that your network configuration allows outbound access from within the virtual network. For more information, please refer to: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment\\'\\r\\n      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - zszEEmQrWx-ProjectSpark;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes made.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - We are getting this error when creating a new cluster:\n\n{'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'BadRequest','message':'{{uncpii}\n \\'error\\': {{uncpii}\n \\'code\\': \\'InvalidTemplateDeployment\\',\\r\\n \\'message\\': \\'The template deployment failed because of policy violation. Please see details for more information.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'RequestDisallowedByPolicy\\',\\r\\n \\'target\\': \\'gateway-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'message\\': \\'Resource '{alphanumericpii}' was disallowed by policy. Policy identifiers: '[{\\\\{UNCPII}\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\\\{Uncpii}\\\\\'policyDefinition\\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\\\{Uncpii}\',{uncpii}\n \\'additionalInfo\\': [{uncpii}\n {{uncpii}\n \\'type\\': \\'PolicyViolation\\',\\r\\n \\'info\\': {{uncpii}\n \\'policyDefinitionDisplayName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'evaluationDetails\\': {{uncpii}\n \\'evaluatedExpressions\\': [{uncpii}\n {{uncpii}\n \\'result\\': \\'True\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'type\\',\\r\\n \\'path\\': \\'type\\',\\r\\n \\'expressionValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'targetValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'operator\\': \\'Equals\\'\\r\\n },{uncpii}\n {{uncpii}\n \\'result\\': \\'False\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'Microsoft.Network/loadBalancers/frontendIPConfigurations[*].publicIPAddress.id\\',\\r\\n \\'path\\': \\'properties.frontendIPConfigurations[*].properties.publicIPAddress.id\\',\\r\\n \\'expressionValue\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourcegroups/mlt-dar-pscdatahub-1-DEV-hdinsightpscdatahubdev3-Automation-HDI/providers/Microsoft.Network/publicIPAddresses/publicIpgateway-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'targetValue\\': \\'False\\',\\r\\n \\'operator\\': \\'Exists\\'\\r\\n }{uncpii}\n ]{uncpii}\n },{uncpii}\n \\'policyDefinitionId\\': \\'/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionEffect\\': \\'Deny\\',\\r\\n \\'policyAssignmentId\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentDisplayName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentScope\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2\\',\\r\\n \\'policyAssignmentSku\\': {{uncpii}\n \\'name\\': \\'A0\\',\\r\\n \\'tier\\': \\'Free\\'\\r\\n }{uncpii}\n }{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'},{'code':'BadRequest','message':'{{uncpii}\n \\'error\\': {{uncpii}\n \\'code\\': \\'InvalidTemplateDeployment\\',\\r\\n \\'message\\': \\'The template deployment failed because of policy violation. Please see details for more information.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'RequestDisallowedByPolicy\\',\\r\\n \\'target\\': \\'headnode-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'message\\': \\'Resource '{alphanumericpii}' was disallowed by policy. Policy identifiers: '[{\\\\{UNCPII}\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\\\{Uncpii}\\\\\'policyDefinition\\\\{Uncpii}:{\\\\\\'name\\\\{Uncpii}:\\\\{UNCPII}\\\{Uncpii}\\\\\'id\\\\{Uncpii}:\\\\{Uncpii}/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\\\{Uncpii}\',{uncpii}\n \\'additionalInfo\\': [{uncpii}\n {{uncpii}\n \\'type\\': \\'PolicyViolation\\',\\r\\n \\'info\\': {{uncpii}\n \\'policyDefinitionDisplayName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'evaluationDetails\\': {{uncpii}\n \\'evaluatedExpressions\\': [{uncpii}\n {{uncpii}\n \\'result\\': \\'True\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'type\\',\\r\\n \\'path\\': \\'type\\',\\r\\n \\'expressionValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'targetValue\\': \\'Microsoft.Network/loadBalancers\\',\\r\\n \\'operator\\': \\'Equals\\'\\r\\n },{uncpii}\n {{uncpii}\n \\'result\\': \\'False\\',\\r\\n \\'expressionKind\\': \\'Field\\',\\r\\n \\'expression\\': \\'Microsoft.Network/loadBalancers/frontendIPConfigurations[*].publicIPAddress.id\\',\\r\\n \\'path\\': \\'properties.frontendIPConfigurations[*].properties.publicIPAddress.id\\',\\r\\n \\'expressionValue\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourcegroups/mlt-dar-pscdatahub-1-DEV-hdinsightpscdatahubdev3-Automation-HDI/providers/Microsoft.Network/publicIPAddresses/publicIpheadnode-0d2b581ae55b43f0b22f097a8082d0cb\\',\\r\\n \\'targetValue\\': \\'False\\',\\r\\n \\'operator\\': \\'Exists\\'\\r\\n }{uncpii}\n ]{uncpii}\n },{uncpii}\n \\'policyDefinitionId\\': \\'/providers/Microsoft.Management/managementgroups/GBIS-ITEC-DEV/providers/Microsoft.Authorization/policyDefinitions/NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionName\\': \\'NWK-GEN-P-5-v1.3.16\\',\\r\\n \\'policyDefinitionEffect\\': \\'Deny\\',\\r\\n \\'policyAssignmentId\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/providers/Microsoft.Authorization/policyAssignments/NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentDisplayName\\': \\'NWK-GEN-P-5\\',\\r\\n \\'policyAssignmentScope\\': \\'/subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2\\',\\r\\n \\'policyAssignmentSku\\': {{uncpii}\n \\'name\\': \\'A0\\',\\r\\n \\'tier\\': \\'Free\\'\\r\\n }{uncpii}\n }{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\nPreviously we were getting this error:\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'UnableToEstablishConnectivityFromVirtualMachines\\',\\r\\n        \\'message\\': \\'Unable to establish connectivity from virtual machines. Please ensure that your network configuration allows outbound access from within the virtual network. For more information, please refer to: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment\\'\\r\\n      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/06/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourceGroups/mlt-dar-pscdatahub-1-DEV-test-Automation-HDI/providers/Microsoft.HDInsight/clusters/zszEEmQrWx-ProjectSpark\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error when creating a new HDI Cluster,0.317978701,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Error when creating a new HDI Cluster,NSG Settings,fix NSG Settings,,,,,,,,
1.20071E+14,42:07.3,HDInsight script action,"Question: Local start time of the latest occurrence\nAnswer: \n\nQuestion: Error code\nAnswer: Not listed above\n\nQuestion: Storage server Request ID\nAnswer: \n\nQuestion: Provide any additional details\nAnswer: We are triggering the below Powershell code for our HDInsight script action to fetch a script from our 'sigibdstorage' Blob container 'protegritypoc', but are getting the error in the attached screenshot. \n\nOur HDInsight service principal 'HDISigi' has 'Reader' access to the storage account, and the 'protegritypoc' container is allowing anonymous access. Can you please help us resolve this immediately?\n\n\nPowershell code:\n    #Install Protegrity 'Big Data Protector'\n    Submit-AzHDInsightScriptAction `\n        -ResourceGroupName '{AlphanumericPII}' `\n        -ClusterName protegritypoc `\n        -Name 'InstallProtegrityBigDataProtector' `\n        -{Namepii} 'https://sigibdstorageqa.blob.core.windows.net/protegritypoc/bdp_script_action.sh' `\n        -NodeTypes HeadNode,WorkerNode -PersistOnSuccess\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Storage Account Management:\nLocal start time of the latest occurrence - ;\nError code - Not listed above;\nStorage server Request ID - ;\nProvide any additional details - We are triggering the below Powershell code for our HDInsight script action to fetch a script from our 'sigibdstorage' Blob container 'protegritypoc', but are getting the error in the attached screenshot. \n\nOur HDInsight service principal 'HDISigi' has 'Reader' access to the storage account, and the 'protegritypoc' container is allowing anonymous access. Can you please help us resolve this immediately?\n\n\nPowershell code:\n    #Install Protegrity 'Big Data Protector'\n    Submit-AzHDInsightScriptAction `\n        -ResourceGroupName '{AlphanumericPII}' `\n        -ClusterName protegritypoc `\n        -Name 'InstallProtegrityBigDataProtector' `\n        -{Namepii} 'https://sigibdstorageqa.blob.core.windows.net/protegritypoc/bdp_script_action.sh' `\n        -NodeTypes HeadNode,WorkerNode -PersistOnSuccess;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: SIGI Big Data\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/a2c669eb-c5cd-4600-b074-255e95d61b86/resourceGroups/SIGI-01-EastUS2/providers/Microsoft.Storage/storageAccounts/sigibdstorageqa\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDInsight script action,0.078630581,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure Storage Management\Authentication and Authorization\Issues using Azure AD (RBAC & oAuth),"Cx received an ""InvalidScriptLocation"" error while trying to submit a custom HDI script action","The script action is failing with “Forbidden” error. Internal Error is “SASIpAuthorizationError”. The storage logs show that the request to reach the storage account is coming from IP 168.61.46.99 and this IP is not listed in the storage account firewall. This IP is part of Azure HDInsight management IPs and are documented in the below article. When the script action is submitted, we validate if the script location is accessible or not and this is happening from one of the IPs listed in the article. Even though the storage account is added as secondary account to the cluster, the script validation is done my HDInsight Resource provider and its failing. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-management-ip-addresses","The Cx added the below 4 IPs to the storage firewall and reran the script action. 168.61.49.9923.99.5.239168.61.48.131138.91.141.162Disabling the firewall (as a workaround, not as a resolution) allowed them to proceed with the HDInsight portion of their PoC. ",196386299,,,,,,,
1.20071E+14,35:08.1,Cannot access ADLS Gen 2 from this cluster using the ServicePrincipal and Cert auth,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: n/a\n\nQuestion: Additional details about the issue\nAnswer: User class threw exception: com.microsoft.azure.datalake.store.ADLException: Error getting info for file /mcommitbalanceevents/pix-balancejournal/0/2020/07/06/21/33/37.avro\nOperation GETFILESTATUS failed with exception java.net.UnknownHostException : pix-mcommitbalance-air.azuredatalakestore.net\nLast encountered exception thrown after 5 tries. [java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException]\n[ServerRequestId:null]\nat {AlphanumericPII})\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - n/a;\nAdditional details about the issue - User class threw exception: com.microsoft.azure.datalake.store.ADLException: Error getting info for file /mcommitbalanceevents/pix-balancejournal/0/2020/07/06/21/33/37.avro\nOperation GETFILESTATUS failed with exception java.net.UnknownHostException : pix-mcommitbalance-air.azuredatalakestore.net\nLast encountered exception thrown after 5 tries. [java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException,java.net.UnknownHostException]\n[ServerRequestId:null]\nat {AlphanumericPII});\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CCM Data - AIRCAPI\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/35d955bc-01e1-4276-8078-ebf05d933028/resourceGroups/AIRCAPIDevEastUS/providers/Microsoft.HDInsight/clusters/ccmaircapidevc08acq\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot access ADLS Gen 2 from this cluster using the ServicePrincipal and Cert auth,0.205739904,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,They can not access Gen2 storage account from the cluster.,"The cluster was set it up with a ADL Gen1 as a primary storage account, since Gen1 and Gen2 are not compatible they can't add a ADL Gen2 as a secondary storage account.","Move the data from Gen2 to Gen 1 using ADF -> https://docs.microsoft.com/en-us/azure/data-factory/load-azure-data-lake-storage-gen2-from-gen1 or https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-overviewClient also mention they have a code with the credentials for the Gen2 storage account, but they want to avoid using that approach since the credential are visible on the code. Another solution for this is to create a certificate and storage it on the cluster's head nodes, then when the code is executed, it can retrieve the certificate and decrypt it. This approach will take an extra effort from the software development side. ",,,,,,,,
1.20071E+14,05:11.6,Transient errors in deployment. Script actions not getting submitted. Operation State is Conflict.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 2020-07-07 {Alphanumericpii}: Remove-AzHDInsightPersistedScriptAction : Operation returned an invalid status code 'Conflict'\n2020-07-07 {Alphanumericpii}: At /{AlphanumericPII} {alphanumericpii}\n2020-07-07 {Alphanumericpii}: + Remove-AzHDInsightPersistedScriptAction -ClusterName $ClusterName ...\n2020-07-07 {Alphanumericpii}: + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n2020-07-07 {Alphanumericpii}: + CategoryInfo : CloseError: (:) [Remove-AzHDInsightPersistedScriptAction], ErrorResponseException\n2020-07-07 {Alphanumericpii}: + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.RemoveAzureHDInsightPersistedScriptActionCommand\n2020-07-07 {Alphanumericpii}:\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - 2020-07-07 {Alphanumericpii}: Remove-AzHDInsightPersistedScriptAction : Operation returned an invalid status code 'Conflict'\n2020-07-07 {Alphanumericpii}: At /{AlphanumericPII} {alphanumericpii}\n2020-07-07 {Alphanumericpii}: + Remove-AzHDInsightPersistedScriptAction -ClusterName $ClusterName ...\n2020-07-07 {Alphanumericpii}: + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n2020-07-07 {Alphanumericpii}: + CategoryInfo : CloseError: (:) [Remove-AzHDInsightPersistedScriptAction], ErrorResponseException\n2020-07-07 {Alphanumericpii}: + FullyQualifiedErrorId : Microsoft.Azure.Commands.HDInsight.RemoveAzureHDInsightPersistedScriptActionCommand\n2020-07-07 {Alphanumericpii}:;\n\n- ProblemStartTime: 07/07/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe01-sp-eu01\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Transient errors in deployment. Script actions not getting submitted. Operation State is Conflict.,0.155108587,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Transient errors in deployment. Script actions not getting submitted. Operation State is Conflict.,Running Script action parallelly conflict and the cluster changes to customizing state.,Please try to run the script action one after another.,,,,,,,,
1.20071E+14,40:31.1,Unable to connect to cluster management endpoint. Please retry later,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 7, 2020, 12:00 AM EDT\n\nQuestion: {Namepii} name\nAnswer: dynamicscraping\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToConnectWithClusterErrorCode\\',\\r\\n \\'message\\': \\'Unable to connect to cluster management endpoint. Please retry later.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - dynamicscraping;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'FailedToConnectWithClusterErrorCode\\',\\r\\n \\'message\\': \\'Unable to connect to cluster management endpoint. Please retry later.\\'\\r{uncpii} }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n;\n\n- ProblemStartTime: 07/07/2020 04:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: arrow_big_data\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a0694c48-f1cd-4f98-9977-8056c78baef6/resourceGroups/HDInsight_WUS_POC/providers/Microsoft.HDInsight/clusters/DynamicScraping\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to connect to cluster management endpoint. Please retry later,0.039906233,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Unable to connect to cluster management endpoint. Please retry later,NSG rules in place to restrict outbound connectivity. ,"Change the NSG rules , provided doc on whats the supported configuration. Firewall, NVAs etc.",,,,,,,,
1.20071E+14,13:04.0,QA: kp05hbasefdhdiqausc01: Not able to access node ,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Not able to ssh to {Ipaddresspii}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Not able to ssh to {Ipaddresspii};\n\n- ProblemStartTime: 07/07/2020 21:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kp05hbasefdhdiqausc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",QA: kp05hbasefdhdiqausc01: Not able to access node ,0.042105974,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,unable to SSH in to WN0,QA: kp05hbasefdhdiqausc01: Not able to access node,Rebooted the WN0 host to get pass the issue,,,,,,,,
1.20071E+14,59:52.9,unable to create cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer:         'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'AmbariClusterCreationFailedErrorCode\\',\\'message\\':{Uncpii} server error occurred while processing the request. Please retry the request or contact support. The following host components failed to start up: APP_TIMELINE_SERVER, HISTORYSERVER, HIVE_METASTORE, HIVE_SERVER_INTERACTIVE, {ALPHANUMERICPII}, METRICS_COLLECTOR, METRICS_GRAFANA, NAMENODE, OOZIE_SERVER, RANGER_ADMIN, RANGER_USERSYNC, RESOURCEMANAGER, {ALPHANUMERICPII}, {ALPHANUMERICPII}, WEBHCAT_SERVER, ZEPPELIN_MASTER, HIVE_SERVER.{Uncpii}\n        'eventCategory': 'Admin\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue -         'statusMessage': '{{uncpii}\':\\'Failed\\',\\'error\\':{\\'code\\':\\'ResourceOperationFailure\\',\\'message\\':{Uncpii} resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\'details\\':[{\\'code\\':\\'AmbariClusterCreationFailedErrorCode\\',\\'message\\':{Uncpii} server error occurred while processing the request. Please retry the request or contact support. The following host components failed to start up: APP_TIMELINE_SERVER, HISTORYSERVER, HIVE_METASTORE, HIVE_SERVER_INTERACTIVE, {ALPHANUMERICPII}, METRICS_COLLECTOR, METRICS_GRAFANA, NAMENODE, OOZIE_SERVER, RANGER_ADMIN, RANGER_USERSYNC, RESOURCEMANAGER, {ALPHANUMERICPII}, {ALPHANUMERICPII}, WEBHCAT_SERVER, ZEPPELIN_MASTER, HIVE_SERVER.{Uncpii}\n        'eventCategory': 'Admin;\n\n- ProblemStartTime: 07/07/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: FS Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9406c5fb-8168-43ae-8b61-57701174598f/resourceGroups/RG-RTL-SCA-PROD/providers/Microsoft.HDInsight/clusters/sca10-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to create cluster,0.016112105,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,unable to create cluster,unable to create cluster,Worked with customer and there were multiple issues with provisioning and customer had fixed them.,,,,,,,,
1.20071E+14,10:21.1,llap appication is not working since last 4 hours,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 12:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Tried to restart HIVE Server 2 interactive service\n\nQuestion: Additional details about the issue\nAnswer: Hive interactive queries are not executing since last couple of hours. We tried to restart the Hive interactive service also, but service is not restarting.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Tried to restart HIVE Server 2 interactive service;\nAdditional details about the issue - Hive interactive queries are not executing since last couple of hours. We tried to restart the Hive interactive service also, but service is not restarting.;\n\n- ProblemStartTime: 07/08/2020 06:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AVALA Aimbase Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/dbb4eb18-427d-4399-82d2-c8644c869282/resourceGroups/aimbase-data-pd-{namepii}/providers/Microsoft.HDInsight/clusters/c10-pd-{namepii}-hdi\n- Location: northcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",llap appication is not working since last 4 hours,19.26023086,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Hive jobs was not able to be executed for 4 hours,Worknodes were down causing llap daemons to not run,Restarted worker nodes,,,,,,,,
1.20071E+14,54:27.2,Version compatibility Issue with cluster,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: We have provisoned HDinsight 4.0 {alphanumericpii}) with spark stack respective to previous {alphanumericpii}). We can see hbase client version changes in current cluster. \n\nPrevious hbase client Version 2.0.2.3.1.2.7-1.\nCurrent version Version 2.1.6.3.1.6.0-77\n\nWhich is breaking our application and code. Kindly provide solution to rollback to previous version.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - NA;\nAdditional details about the issue - We have provisoned HDinsight 4.0 {alphanumericpii}) with spark stack respective to previous {alphanumericpii}). We can see hbase client version changes in current cluster. \n\nPrevious hbase client Version 2.0.2.3.1.2.7-1.\nCurrent version Version 2.1.6.3.1.6.0-77\n\nWhich is breaking our application and code. Kindly provide solution to rollback to previous version.;\n\n- ProblemStartTime: 07/07/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: be-jem-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e2f8d34a-db77-45ba-b4d8-0846445a31aa/resourceGroups/jemp-hdp-rg/providers/Microsoft.HDInsight/clusters/jemp-spark-24-hdp\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Version compatibility Issue with cluster,0.338424144,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Spark,Version compatibility Issue with cluster,This is because the versions of Guava library mismatch between spark and hbase.,"Due to tight dead line that the customer is facing, it is decided to pin spark version to HDIVersion: 4.0.1000.1.2004292122 for subscription e2f8d34a-db77-45ba-b4d8-0846445a31aa",195664275,,,,,,,
1.20071E+14,43:20.8,Unable to delete HDInsight cluster,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 11:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Wed, Jul 8, 2020, 4:00 PM GMT+2\n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: Nothing\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Tried to delete with the azure CLI too.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or it has happened before? - {Namepii} problem, worked before;\nAny changes made? - Nothing;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Tried to delete with the azure CLI too.;\n\n- ProblemStartTime: 07/08/2020 09:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: PCM-Development\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d674eb73-5f97-47b7-9477-ce4d8be4f561/resourceGroups/gsebdpdevdatglwwrsg91/providers/Microsoft.HDInsight/clusters/g8c86fbaa-86e0-432f-90af-b2f7a5d71ac6\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to delete HDInsight cluster,0.174122461,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Delete HDInsight cluster,eUnable to delete HDInsight cluster in portal or Azure CLI,An unknown bug on our end,The Product group was able to delete the cluster via ACIS actionThe Cx would like to know if their client was charged while the cluster was not accessible but could not provide the EA Enrollment ID to the billing team. Recommended that the Cx open a new support request with the billing team once they receive this information ,195809136,,,,,,,
1.20071E+14,32:40.8,Cluster identity certificate update failed,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Password, access key, or certificate rotation\n\nQuestion: Detail of the changes\nAnswer: Hi,\nWe are trying to update certfile and it is failing with below error. Could you please assist us in resolving below issue?\n\nError:\nInvoke-AzResourceAction : {'code':'InternalServerError','message':'ErrorCode: Unexpected workflow execution exception;\nErrorDescription: Unexpected workflow execution exception'}\nAt C:{Uncpii}\pvallabhan{UNCPII} - {Namepii}. {Namepii}{Uncpii}\Desktop{Uncpii}\{Namepii}{UNCPII}:81 {alphanumericpii}\n+ Invoke-AzResourceAction `\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Invoke-AzResourceAction], ErrorResponseMessageException\n    + FullyQualifiedErrorId : Microsoft.{Namepii}.Commands.ResourceManager.Cmdlets.Implementation.InvokAzureResourceAction\n   Cmdlet\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: NA\n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: NA\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Password, access key, or certificate rotation;\nDetail of the changes - Hi,\nWe are trying to update certfile and it is failing with below error. Could you please assist us in resolving below issue?\n\nError:\nInvoke-AzResourceAction : {'code':'InternalServerError','message':'ErrorCode: Unexpected workflow execution exception;\nErrorDescription: Unexpected workflow execution exception'}\nAt C:{Uncpii}\pvallabhan{UNCPII} - {Namepii}. {Namepii}{Uncpii}\Desktop{Uncpii}\{Namepii}{UNCPII}:81 {alphanumericpii}\n+ Invoke-AzResourceAction `\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : CloseError: (:) [Invoke-AzResourceAction], ErrorResponseMessageException\n    + FullyQualifiedErrorId : Microsoft.{Namepii}.Commands.ResourceManager.Cmdlets.Implementation.InvokAzureResourceAction\n   Cmdlet;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - NA;\n{Namepii} was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - NA;\n\n- ProblemStartTime: 07/08/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MRC Upper PLAT_PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b3e5a71f-cd70-411f-ace9-5e5f55287358/resourceGroups/RG_Enterprise_DataHub_prd/providers/Microsoft.HDInsight/clusters/azmrcedhhditeprd\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster identity certificate update failed,1.209747406,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Hive,Unable to run any queries and cert refresh would not refresh.,ADLS Gen 1 certificate needed to be refreshed.  Due to Regression fix for gateway customer was unable to refresh cert,ad-hoc workaround from pg.,"195,674,276,195,710,000",,,,,,,
1.20071E+14,42:21.9,cluster scaling not working as intended,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} unable to scale down. We have 200 GB space available but the cluster is not scaling down\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {Namepii} unable to scale down. We have 200 GB space available but the cluster is not scaling down;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-{namepii}/providers/Microsoft.HDInsight/clusters/p02-las-as\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",cluster scaling not working as intended,0.059167939,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,cluster scaling not working as intended,"As mentioned earlier we noticed that all the exiting nodes had AMs running on them and killing a few applications released the memory eventually decommissioning the node in a graceful manner. We now know why auto-scale was not triggered, however I will work on this in detail on my side comparing cluster resource availability and the # of nodes from a cost efficient standpoint and get back to you.Earlier we were able to determine that the autoscaling (scale down ) would not be triggered if there is an active AM container running on it, however we noticed that yarn memory was still under-utilized  and I had a conversation with the product team and they have concluded that this is by design and currently this feature is not yet supported in Yarn (ie bin packing the AM on nodes).",by design ,,,,,,,,
1.20071E+14,01:39.6,Need to migrate HDInsight Resources from one subscription to another,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I'm attempting to move my HDInsights cluster to another subscription and I was able to move the cluster but not the related resources such as NIC, VNET, Load Balancer, etc.\nExisting resource group:\nhttps://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerlogs-stage-east/overview\n\nDestination resource group:\nhttps://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/9ac620f7-71c8-45a1-9df6-30a33bf1e515/resourceGroups/yammerlogs-stage-east/overview\n\nWhen I attempt to move any NIC I get an error:\n'message':'Move for resource /subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerlogs-stage-east/providers/Microsoft.Network/networkInterfaces/nic-zookeepernode-3-2db2fd5fe5c94ccdb5210d684b59720d is not supported since it references resource /subscriptions/154e7f2c-cb78-4897-a817-ebe3396388fd/resourceGroups/rg0-2db2fd5fe5c94ccdb5210d684b59720dresourcegroup/providers/Microsoft.Compute/virtualMachines/zookeepernode-0-vm-3 in a different subscription {guidpii}.'}\n\nI need to do this for 4 additional HDInsight clusters so understanding how to address the problem myself would be best.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - I'm attempting to move my HDInsights cluster to another subscription and I was able to move the cluster but not the related resources such as NIC, VNET, Load Balancer, etc.\nExisting resource group:\nhttps://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerlogs-stage-east/overview\n\nDestination resource group:\nhttps://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/9ac620f7-71c8-45a1-9df6-30a33bf1e515/resourceGroups/yammerlogs-stage-east/overview\n\nWhen I attempt to move any NIC I get an error:\n'message':'Move for resource /subscriptions/f01565aa-2d94-41fb-a38f-5d158b3096c1/resourceGroups/yammerlogs-stage-east/providers/Microsoft.Network/networkInterfaces/nic-zookeepernode-3-2db2fd5fe5c94ccdb5210d684b59720d is not supported since it references resource /subscriptions/154e7f2c-cb78-4897-a817-ebe3396388fd/resourceGroups/rg0-2db2fd5fe5c94ccdb5210d684b59720dresourcegroup/providers/Microsoft.Compute/virtualMachines/zookeepernode-0-vm-3 in a different subscription {guidpii}.'}\n\nI need to do this for 4 additional HDInsight clusters so understanding how to address the problem myself would be best.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Yammer Log Aggregation\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9ac620f7-71c8-45a1-9df6-30a33bf1e515/resourceGroups/yammerlogs-stage-east/providers/Microsoft.HDInsight/clusters/yammerlogs-stage-east-d13\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to migrate HDInsight Resources from one subscription to another,0.908152904,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Need to migrate HDInsight Resources from one subscription to another,NA,"Moving resources from one subscription to other is currently not supported as the VM's, NIC's are still be in the provisioning subscription as these are provisioned internally when the cluster is created is created.Hence the recommendation is to recreate the clusters in another subscription.",,,,,,,,
1.20071E+14,10:05.6,Websocket connection issues through zeppelin,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: {Namepii}: Websocket connection issues\n\nQuestion: Interactive query explain plan if available\nAnswer: {Namepii}: Websocket connection issues\n\nQuestion: How was the interactive query submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: Websocket connection issues\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - {Namepii}: Websocket connection issues;\nInteractive query explain plan if available - {Namepii}: Websocket connection issues;\nHow was the interactive query submitted? - {Namepii};\nAdditional details about the issue - Websocket connection issues;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-rg-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq101llapfdqawus201\n- Location: {alphanumericpii}\n- Location: West US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Websocket connection issues through zeppelin,8.246520717,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Java heap space exceptions in the log,Websocket  connection issues through zeppelin,"Recommended to increase the increase the  memory for Zeppelin web ui and test it. Basically, the more people that connect  to zeppelin, the more memory and resources it will use. By default the memory is  1GB and if there is memory to spare on the HN0 machine where it runs,  I would  increase it to 4 GB of RAM. From Ambari | Zeppelin | Advanced  | zeppelin_env_content sectionzeppelin.jdbc.concurrent.max_connection=10  is it specific to notebook or Zeppelin service?  ==> This is specific to  notebookWhat happen when we change  zeppelin.jdbc.concurrent.use= false  ==> If we set it to false, we cannot  run concurrent queries",,,,,,,,
1.20071E+14,57:34.3,PRDSUP - kp50kafkaadfhdiprdsupusc01 - Unhealthy zookeeper node,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 5:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Zookeeper node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Could not take action as node is not responsive\n\nQuestion: Additional details about the issue\nAnswer: Zookeeper node zk4-kp50ka.i3pqnysmw2jufmkmo3tuf15qcb.gx.internal.cloudapp.net not responsive .\n\nTried logging in and fails. Reset password fails on node both manually and via Script action. \n\nNeed immediete resolution on replacement node or bring back node \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Zookeeper node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Could not take action as node is not responsive;\nAdditional details about the issue - Zookeeper node zk4-kp50ka.i3pqnysmw2jufmkmo3tuf15qcb.gx.internal.cloudapp.net not responsive .\n\nTried logging in and fails. Reset password fails on node both manually and via Script action. \n\nNeed immediete resolution on replacement node or bring back node ;\n\n- ProblemStartTime: 07/08/2020 00:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-rg-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kp50kafkaadfhdiprdsupusc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",PRDSUP - kp50kafkaadfhdiprdsupusc01 - Unhealthy zookeeper node,0.697449783,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,PRDSUP - kp50kafkaadfhdiprdsupusc01 - Unhealthy zookeeper node,PRDSUP - kp50kafkaadfhdiprdsupusc01 - Unhealthy zookeeper node,"As discussed, we have worked with product group on this and able to redeploy the zookeeper node. As confirmed, fix (to avoid zookeeper running into RO file system during reboot) was pushed, since your zookeeper was down during that time, I had shared script to run on the zookeeper node.","195,769,023,195,814,000",,,,,,,
1.20071E+14,30:38.4,S020 Data storage error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: select count(*) from {alphanumericpii}\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: seems like most queries are failing\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - select count(*) from {alphanumericpii};\nHive query explain plan if available - ;\nHow was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - seems like most queries are failing;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA Team\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/twoprocesshistorical\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",S020 Data storage error,0.301152735,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Cx received S020 Data storage error while trying to execute a hive query from Ambari Hive view,"source of issue related to our code not being able to read a password from ""keystore"".          java.lang.RuntimeException: Can't read db password from keystore. Please, check master key was set correctly. java.lang.RuntimeException: Can't read db password from keystore. Please, check master key was set correctly.",Restarting the Ambari Server process,196006589,,,,,,,
1.20071E+14,30:05.6,Error rescaling cluster Failed to scale the HDInsight cluster twoprocesshistorical.,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Error rescaling cluster\nFailed to scale the HDInsight cluster twoprocesshistorical. The cluster has 4 nodes. Please retry your scale request.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Error rescaling cluster\nFailed to scale the HDInsight cluster twoprocesshistorical. The cluster has 4 nodes. Please retry your scale request.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA Team\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/twoprocesshistorical\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error rescaling cluster Failed to scale the HDInsight cluster twoprocesshistorical.,0.059460859,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Symptom: When scaling up this action fails,Cause:  Ambari was not responding as expected,Resolution: Restarted Ambari and scale was successful. ,196006589,,,,,,,
1.20071E+14,15:29.4,setfacl: Fatal internal error. java.lang.UnsupportedOperationException: Secure doesn't support setAcl,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} to give 'hive' user rwx permission to an HDFS directory '/user/unifi/unifi_output'. getfacl works whereas setfacl fails with the below error.\n\nI did configure ACLs on HDFS by adding property dfs.namenode.acls.enabled=true in Ambari under hdfs custom hdfs-site\n\n(unifi_virtualenv) {alphanumericpii}:~$ hdfs dfs -setfacl -R -m user:hive:rwx /user/unifi/unifi_output/\n-setfacl: Fatal internal error\njava.lang.UnsupportedOperationException: Secure doesn't support modifyAclEntries\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} to give 'hive' user rwx permission to an HDFS directory '/user/unifi/unifi_output'. getfacl works whereas setfacl fails with the below error.\n\nI did configure ACLs on HDFS by adding property dfs.namenode.acls.enabled=true in Ambari under hdfs custom hdfs-site\n\n(unifi_virtualenv) {alphanumericpii}:~$ hdfs dfs -setfacl -R -m user:hive:rwx /user/unifi/unifi_output/\n-setfacl: Fatal internal error\njava.lang.UnsupportedOperationException: Secure doesn't support modifyAclEntries\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Unifi {Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a0020070-6516-4e49-b8a4-dffcf772d63c/resourceGroups/{namepii}-ashok-ptc/providers/Microsoft.HDInsight/clusters/uf1hdi\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",setfacl: Fatal internal error. java.lang.UnsupportedOperationException: Secure doesn't support setAcl,0.420227139,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\hdfs commands do not work\Azure Storage in standard cluster,setfacl: Fatal internal error. java.lang.UnsupportedOperationException: Secure doesn't support setAcl,This is by design.,"WASB storage driver API's are designed in a way that it does not support ACL's.However customer found a workaround by setting below,set hive.server2.enable.doAs to True in hive-site for SQL Authorization. This eliminated the need to set ACLS explicitly.",,,,,,,,
1.20071E+14,25:56.3,ambari not responding - several health alerts,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 9, 2020, 9:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: review of the load balancer infrastructure and review of the error logs which it seems several have been listed\n\nQuestion: Additional details about the issue\nAnswer: service for hbase cluster seems to be working, just access to ambari over port 443 is not.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - review of the load balancer infrastructure and review of the error logs which it seems several have been listed;\nAdditional details about the issue - service for hbase cluster seems to be working, just access to ambari over port 443 is not.;\n\n- ProblemStartTime: 07/09/2020 14:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HCSC Azure Prod - Infrastructure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/c4b71001-3b61-4bd7-af51-df7bfc0d9f1f/resourceGroups/hcsc_ecm_prod_rg/providers/Microsoft.HDInsight/clusters/hcsc36hdiprod02\n- Location: northcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ambari not responding - several health alerts,0.149058758,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,ambari not responding - several health alerts,NSG restrictions,Edit NSG,,,,,,,,
1.20071E+14,40:34.4,dns resolution of headnode with windows box in subnet,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: the following dns does not resolve within the windows box in same subnet.\n\nhn0-azrhdi.pi5pne3npkeubcrujixdphztze.ex.internal.cloudapp.net\n\nNeed help in looking at routing.\n\nRegards,\nSK\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - the following dns does not resolve within the windows box in same subnet.\n\nhn0-azrhdi.pi5pne3npkeubcrujixdphztze.ex.internal.cloudapp.net\n\nNeed help in looking at routing.\n\nRegards,\nSK;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EA-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a122ee66-fd55-4e1b-b7b1-7677a4ab3932/resourceGroups/rg_azrbdcsdev/providers/Microsoft.HDInsight/clusters/azrhdieldev1\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",dns resolution of headnode with windows box in subnet,10.21486753,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Customer reported that their hybrid automation runbook was failing because part of their script executed an SSH connection with the cluster but this was not succeeding.,"Customer did not have their DNS/network configured correctly, this was not due to HDInsight",Cx worked with networking to figure out the issue and resolve the issue with their custom DNS,,,,,,,,
1.20071E+14,14:47.5,Unable to reach repository,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: [10:27 PM] {Namepii} {Namepii}\n    \nspark-shell --packages com.hortonworks.shc:shc-core:1.1.0.3.1.2.2-1 --repositories http://repo.hortonworks.com/content/groups/public/\n\n\nQuestion: Additional details about the issue\nAnswer: http://repo.hortonworks.com/content/groups/public/ is unreachable for each environment. If there have any changes form cloudera and hortonworks, Please share those changes.\n\nOur all jobs are stopped due to repo and dependancy not reachable.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - [10:27 PM] {Namepii} {Namepii}\n    \nspark-shell --packages com.hortonworks.shc:shc-core:1.1.0.3.1.2.2-1 --repositories http://repo.hortonworks.com/content/groups/public/\n;\nAdditional details about the issue - http://repo.hortonworks.com/content/groups/public/ is unreachable for each environment. If there have any changes form cloudera and hortonworks, Please share those changes.\n\nOur all jobs are stopped due to repo and dependancy not reachable.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: be-jem-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e2f8d34a-db77-45ba-b4d8-0846445a31aa/resourceGroups/jemp-hdp-rg/providers/Microsoft.HDInsight/clusters/jemp-24-spark-hdp\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to reach repository,0.229114912,Root Cause : HDInsight Service\Scenario not supported,Routing Azure HDInsight V5\Unexpected result\Spark,All jobs are stopped due to repo and dependancy not reachable.,http://repo.hortonworks.com/content/groups/public repo was unreachable,Wait for the hortonworks site to recoverAlternative 1:Set up alternatives offered by other repositories that have the libraries for shc.  https://github.com/hortonworks-spark/shchttps://mvnrepository.com/artifact/com.hortonworks/shc-core Alternative 2:Set up a local mirror to the hortonworks repository. https://docs.cloudera.com/HDPDocuments/Ambari-2.7.5.0/bk_ambari-installation/content/getting_started_setting_up_a_local_repository.htmlhttps://community.cloudera.com/t5/Support-Questions/Setting-up-a-local-repository-to-mirror-multiple-HDP/m-p/159835 ,,,,,,,,
1.20071E+14,02:56.0,LSv2 series VMs are not an option for hadoop clusters,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM EDT\n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Received an error that Invalid {NAMEPII} {alphanumericpii}\n\nI would like to create a hadoop cluster that uses local storage and {alphanumericpii} is the only series that meets the storage density requirement of {ALPHANUMERICPII} usable disk with under 3000 nodes.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Received an error that Invalid {NAMEPII} {alphanumericpii}\n\nI would like to create a hadoop cluster that uses local storage and {alphanumericpii} is the only series that meets the storage density requirement of {ALPHANUMERICPII} usable disk with under 3000 nodes.;\n\n- ProblemStartTime: 07/09/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AG-SEVERN\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: {Namepii}\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - {Namepii}\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",LSv2 series VMs are not an option for hadoop clusters,0.939560441,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,LSv2 series VMs are not an option for hadoop clusters,NA,"Product Group confirmed that HDInsight support only certain VM's(like D-series,E-series etc) and the VM's mentioned in the request are not in the supported VM list.",,,,,,,,
1.20071E+14,42:29.5,Missing hbase metrics,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 7, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We recently costed a somewhat {namepii} running ticket to resolve this issue by increasing the heap memory for the ambari-metrics-process on one of the head nodes.  This resolved the head node timeout issue we were having where the for a week or two.  Now we are facing a similar problem where no metrics are being present in the ambari UI but without the timeout issue.  I have verified the process appears to be running and not exceeding available heap on the head node.  Uncertain what next steps should be.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - We recently costed a somewhat {namepii} running ticket to resolve this issue by increasing the heap memory for the ambari-metrics-process on one of the head nodes.  This resolved the head node timeout issue we were having where the for a week or two.  Now we are facing a similar problem where no metrics are being present in the ambari UI but without the timeout issue.  I have verified the process appears to be running and not exceeding available heap on the head node.  Uncertain what next steps should be.;\n\n- ProblemStartTime: 07/07/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Allocation-Prod/providers/Microsoft.HDInsight/clusters/prdalh-azwus-prd-allocation-hdihbase001\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Missing hbase metrics,0.13431102,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Metrics are missing\Hbase,Missing hbase metrics,"Heap space issues with AMS monitor java.lang.OutOfMemoryError: Java heap space07:27:11,100 ERROR [676187048@qtp-1005245720-15] log:87 - Error for /ws/v1/timeline/metricsjava.lang.OutOfMemoryError: Java heap space07:27:11,100 ERROR [1044062347@qtp-1005245720-6] log:87 - Error for /ws/v1/timeline/metricsjava.lang.OutOfMemoryError: Java heap space",Asked to increase the heap space further as suggested on 120042324004072 alsoasked to run Commands to run from hn0:/usr/hdp/current/zookeeper-client/bin/zkCli.sh -server localhost:61181rmr /ams-hbase-unsecure,,,,,,,,
1.20071E+14,58:33.9,[Azure Government] Cannot scale up cluster due to 'Cluster Size' page error,"[Azure Government] Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Cannot scale up cluster due to '{Namepii} Size' page error\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Cannot scale up cluster due to '{Namepii} Size' page error;\n\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-GCC-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ad2a8933-826d-4752-88b0-9d4f59730f0b/resourceGroups/o365ipdigcc01-rg-spark/providers/Microsoft.HDInsight/clusters/o365ipdigcc01-sp-uv01\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Cannot scale up cluster due to 'Cluster Size' page error,0.021656724,Root Cause : HDInsight Service\Azure portal related issues,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,120070924004986 - Cannot scale up cluster due to 'Cluster Size' page error HDInsight Service,There is potentially an Azure Portal issue affecting the Gov cloud.,"To rule out an issue with the browser, try clearing your browser cache and reopening the Azure Portal in Incognito or Private mode.  Try from a different browser to see if the issue is reproducible.If you still cannot access this blade without error, try scaling the cluster using PowerShell or Azure CLI until the Portal issue is resolved.PowerShell:Set-AzHDInsightClusterSize -ClusterName 'o365ipdigcc01-sp-uv01' -TargetInstanceCount <# of worker nodes needed> Azure CLI:az hdinsight resize --resource-group 'o365ipdigcc01-rg-spark' --name 'o365ipdigcc01-sp-uv01' --workernode-count <# of worker nodes needed>If the above did not solve the issue, asked customer to collect and send the browser trace so I can provide it to the Product Group for further investigation. Instructions:https://docs.microsoft.com/en-us/azure/azure-portal/capture-browser-trace",,,,,,,,
1.20071E+14,05:08.7,Hive Metastore issues,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: Getting the same error as described in this stack overflow issue:\nhttps://stackoverflow.com/questions/61339697/error-failed-error-in-acquiring-locks-error-communicating-with-the-metastore\n\nLooking to scale the default metastore with the help of support.\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the interactive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: ERROR : FAILED: Error in acquiring locks: Error communicating with the metastore\norg.apache.hadoop.hive.ql.lockmgr.LockException: Error communicating with the metastore\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.hive.ql.{Namepii}.acquireLocks({Namepii}.java:1651)\nat org.apache.hadoop.hive.ql.{Namepii}.lockAndRespond({Namepii}.java:1838)\nat org.apache.hadoop.hive.ql.{Namepii}.runInternal({Namepii}.java:2008)\nat org.apache.hadoop.hive.ql.{Namepii}.run({Namepii}.java:1752)\nat org.apache.hadoop.hive.ql.{Namepii}.run({Namepii}.java:1746)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.thrift.TApplicationException: Internal error processing lock\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.reflect.GeneratedMethodAccessor109.invoke({Namepii} Source)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.{namepii}.proxy.$Proxy38.lock({Namepii} Source)\nat {namepii}.reflect.GeneratedMethodAccessor109.invoke({Namepii} Source)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.{namepii}.proxy.$Proxy38.lock({Namepii} Source)\nat {AlphanumericPII})\n... 25 more\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - Getting the same error as described in this stack overflow issue:\nhttps://stackoverflow.com/questions/61339697/error-failed-error-in-acquiring-locks-error-communicating-with-the-metastore\n\nLooking to scale the default metastore with the help of support.;\nInteractive query explain plan if available - ;\n{Namepii} was the interactive query submitted? - ODBC;\nAdditional details about the issue - ERROR : FAILED: Error in acquiring locks: Error communicating with the metastore\norg.apache.hadoop.hive.ql.lockmgr.LockException: Error communicating with the metastore\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.hadoop.hive.ql.{Namepii}.acquireLocks({Namepii}.java:1651)\nat org.apache.hadoop.hive.ql.{Namepii}.lockAndRespond({Namepii}.java:1838)\nat org.apache.hadoop.hive.ql.{Namepii}.runInternal({Namepii}.java:2008)\nat org.apache.hadoop.hive.ql.{Namepii}.run({Namepii}.java:1752)\nat org.apache.hadoop.hive.ql.{Namepii}.run({Namepii}.java:1746)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat java.security.AccessController.doPrivileged(Native Method)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nCaused by: org.apache.thrift.TApplicationException: Internal error processing lock\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.reflect.GeneratedMethodAccessor109.invoke({Namepii} Source)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.{namepii}.proxy.$Proxy38.lock({Namepii} Source)\nat {namepii}.reflect.GeneratedMethodAccessor109.invoke({Namepii} Source)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {namepii}.{namepii}.proxy.$Proxy38.lock({Namepii} Source)\nat {AlphanumericPII})\n... 25 more;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Payouts PayoutJournal Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb075b87-16bb-42c1-9e6a-1338cc47f6e2/resourceGroups/payoutjournal_prod_southcentralus_spark/providers/Microsoft.HDInsight/clusters/hiveclusterprodsouthcentralus\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Metastore issues,0.05915829,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,Hive queries involving tables having multiple partitions (> ~250) sometime fail,"In Hive metastore, each partition involved in the hive query requires at most 8 parameters to acquire a lock as shown below.struct LockComponent {    1: required LockType type,    2: required LockLevel level,    3: required string dbname,    4: optional string tablename,    5: optional string partitionname,    6: optional DataOperationType operationType = DataOperationType.UNSET,    7: optional bool isTransactional = false,    8: optional bool isDynamicPartitionWrite = false}For instance, look at the following constructor method which has 7 parameters.LockComponent(type:SHARED_READ, level:PARTITION, dbname:prod, tablename:product, partitionname:databaseid=102, operationType:SELECT, isTransactional:true)If the hive query contains tables having more than ~250 partitions cumulatively, the threshold limit of 2100 parameters is reached on the SQL server side. Hence, we see the below error.SQLServerException: The incoming request has too many parameters. The server supports a maximum of 2100 parameters. Reduce the number of parameters and resend the request.In SQL Server, we use a batch size of 1000 rows by default. Here, each row signifies a partition. If we work with more than 250 partitions in one query (suppose 500), the batch size would try to contain corresponding rows for all the 500 partitions which would require to at most 4000 parameters to acquire the locks. This easily exceeds the threshold of 2100 parameters.",Added following configs in Custom hive-site section of Hive configs via. Ambarihive.direct.sql.max.elements.values.clause=100hive.direct.sql.max.elements.in.clause=100TSG Link:https://msdata.visualstudio.com/HDInsight/_wiki/wikis/HDInsight.wiki/9534/Hive_Inability_To_Acquire_Locks,,,,,,,,
1.20071E+14,00:02.7,Shop Site data processor spark job running for long,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: How was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Team,\n\nWe have a spark job'Shopsite-data-processor' on a regurlar day it is finished in less than 4 hours, but today it is taking more than 7 hrs. So we need your help what excatly it is taking time.\n\nQuestion: Additional details about the issue\nAnswer: Attaching the error screenshots. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\nHow was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Team,\n\nWe have a spark job'Shopsite-data-processor' on a regurlar day it is finished in less than 4 hours, but today it is taking more than 7 hrs. So we need your help what excatly it is taking time.;\nAdditional details about the issue - Attaching the error screenshots. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-Prod-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/135d2085-e95f-4550-b69c-4b5ec0c17f9a/resourceGroups/Prod-{Namepii}-HDISpark/providers/Microsoft.HDInsight/clusters/Prod-{Namepii}-HDISpark2-3-2-{Namepii}-3-6\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Shop Site data processor spark job running for long,0.40960993,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark," After  increase in the executor size to 4GB, no longer see any OutOfDirectMemoryError  exceptions. The issue is related to customer's business logic. They added a new  dataset to their script and left joining that with existing dataset. This is  causing the performance issue and making their pipeline run from 2 hours to 9+  hours",Shop Site data  processor spark job running for long," After  increase in the executor size to 4GB, no longer see any OutOfDirectMemoryError  exceptions. The issue is related to customer's business logic. They added a new  dataset to their script and left joining that with existing dataset. This is  causing the performance issue and making their pipeline run from 2 hours to 9+  hours",195873683,,,,,,,
1.20071E+14,14:51.2,"Scaling up to 500 nodes failed, leaving us with 488. Then 4 nodes have died.","Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 12:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: We recreated our cluster with a custom Ambari DB sot hat we could scale up to 500. That didn't work, as we could only get to 488, and then, some nodes started dying, leaving us with 484 now.\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Our DB load appears to be ok while scaling up. Our head nodes sku = {ALPHANUMERICPII}.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - We recreated our cluster with a custom Ambari DB sot hat we could scale up to 500. That didn't work, as we could only get to 488, and then, some nodes started dying, leaving us with 484 now.;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Our DB load appears to be ok while scaling up. Our head nodes sku = {ALPHANUMERICPII}.;\n\n- ProblemStartTime: 07/06/2020 19:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EDP {Namepii} Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d6132b1-574a-42db-a8c6-d583d892ebd2/resourceGroups/spark-p-core-{namepii}/providers/Microsoft.HDInsight/clusters/edp-prd-usce-spark-bchshared\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Scaling up to 500 nodes failed, leaving us with 488. Then 4 nodes have died.",0.083446914,Root Cause : HDInsight Service\Azure platform issues\Compute,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,"Scaling up to 500 nodes failed, leaving us with 488. Then 4 nodes have died",Capacity issue on central US region ,"Capacity issue got resolved and due to security policy not able to SSH to the cluster, PG team has deleted this unhealthy worker nodes from the backend using ACIS action""wn12-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn260-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn379-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn419-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn430-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn660-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net"",     ""wn89-edp-pr.43p2p5iw21ee1hmrydojxvy2cf.gx.internal.cloudapp.net""","197,514,808,198,414,000",,,,,,,
1.20071E+14,52:30.8,Gateway-related errors have caused some spark jobs to not be submitted,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: We have had to manually retrigger our jobs. We have alerts in place, and the jobs (orchestrated by ADF) have retries.\n\nQuestion: Additional details about the issue\nAnswer: Our ADF pipelines fails to deploy our jobs, giving a 'Bad Gateway' error. The {Namepii} metrics show some 4xx and 5xx http responses that align with our hourly jobs start times.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - We have had to manually retrigger our jobs. We have alerts in place, and the jobs (orchestrated by ADF) have retries.;\nAdditional details about the issue - Our ADF pipelines fails to deploy our jobs, giving a 'Bad Gateway' error. The {Namepii} metrics show some 4xx and 5xx http responses that align with our hourly jobs start times.;\n\n- ProblemStartTime: 07/08/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EDP {Namepii} Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d6132b1-574a-42db-a8c6-d583d892ebd2/resourceGroups/spark-p-core-{namepii}/providers/Microsoft.HDInsight/clusters/edp-prd-usce-spark-bchcooked\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Gateway-related errors have caused some spark jobs to not be submitted,0.209597305,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,Gateway-related errors have caused some spark jobs to not be submitted,Seems to be a transient error,"After a week, the customer was no longer experiencing the gateway errors",,,,,,,,
1.20071E+14,35:17.5,Seeing alerts on hdfs name node last checkin,"Question: What time did the problem begin?\nAnswer: Wed, Jul 8, 2020, 1:00 PM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: We have tried several name node restarts, articles found say to put in safemode first and save then restart name node and failover controller. Does not appear that the safemode and save is working with hdfs commands and the restarts are not clearing up the alert.\nWondering if we could get some help on steps to resolve this alert.\n\nQuestion: Additional details about the issue\nAnswer: HDFShn0-d3ncsp.gjmbfqtgdwberocxrnqnl2m5cf.ex.internal.cloudapp.net\nCRIT for about an hour 6\n{Namepii} Checkpoint: [47 hours, 12 minutes, 25811 transactions]\nHDFShn1-d3ncsp.gjmbfqtgdwberocxrnqnl2m5cf.ex.internal.cloudapp.net\nCRIT for 5 hours {Namepii} Checkpoint: [47 hours, 13 minutes, 25810 transactions]\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - We have tried several name node restarts, articles found say to put in safemode first and save then restart name node and failover controller. Does not appear that the safemode and save is working with hdfs commands and the restarts are not clearing up the alert.\nWondering if we could get some help on steps to resolve this alert.;\nAdditional details about the issue - HDFShn0-d3ncsp.gjmbfqtgdwberocxrnqnl2m5cf.ex.internal.cloudapp.net\nCRIT for about an hour 6\n{Namepii} Checkpoint: [47 hours, 12 minutes, 25811 transactions]\nHDFShn1-d3ncsp.gjmbfqtgdwberocxrnqnl2m5cf.ex.internal.cloudapp.net\nCRIT for 5 hours {Namepii} Checkpoint: [47 hours, 13 minutes, 25810 transactions];\n\n- ProblemStartTime: 07/08/2020 18:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: 9885 - Decision Support Test\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/816a4b01-2bf2-44ce-9e31-b1fec9095726/resourceGroups/DS3_DEVResourceGroup_Central/providers/Microsoft.HDInsight/clusters/d3ncsparkstrm02\n- Location: northcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Seeing alerts on hdfs name node last checkin,0.068524052,Root Cause : HDInsight Service\Configuration\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Seeing alerts on hdfs name node last checkin,dfs.namenode.checkpoint.delay,Config change in dfs.namenode.checkpoint.delay = 1 hour instead of 6 hours,,,,,,,,
1.20071E+14,00:02.4,error Deploying ML Service on HD Insight,"Question: What time did the problem begin?\nAnswer: Fri, Jul 10, 2020, 1:55 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: N/A\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: NO\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: HDI Version 3.6 isn ot supported for clusterType 'MLSERVICES' and componenetVersion 'default'. (Code:BadRequest)\n\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'HDI Version'3.6' is not supported for clusterType 'MLSERVICES' and componentVersion 'default'.\\'\\r{uncpii}\n    }\n  ]\n}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - N/A;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - NO;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - HDI Version 3.6 isn ot supported for clusterType 'MLSERVICES' and componenetVersion 'default'. (Code:BadRequest)\n\n{\n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'BadRequest',\n      'message': '{{uncpii}\n  \\'code\\': \\'BadRequest\\',\\r\\n  \\'message\\': \\'HDI Version'3.6' is not supported for clusterType 'MLSERVICES' and componentVersion 'default'.\\'\\r{uncpii}\n    }\n  ]\n};\n\n- ProblemStartTime: 07/10/2020 08:55:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Visual Studio Enterprise: BizSpark\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: RHC\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Service Health\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",error Deploying ML Service on HD Insight,3.92353696,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,120071021001708 - Error Deploying ML Service on HDInsight ServiceValidation Error:HDI Version'3.6' is not supported for clusterType 'mlservices' and componentVersion 'default'.,The Product Group has identified this issue as a bug in the validation code and filed an internal work item to repair it:https://msdata.visualstudio.com/HDInsight/_workitems/edit/813893,"Until the bug fix is deployed, the Product Group suggests using PowerShell to deploy the cluster because it should hit this bug less frequently.Customer has decided to use Databricks for the ML workflow instead.",196034740,,,,,,,
1.20071E+14,23:53.8,Cluster creaetino fails with remainingCores is too small even if I have enough ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: gh-fastly-spark-{namepii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: When trying to create cluster I'm getting Message='{\\'status\\':400,\\'message\\':{UNCPII} is too small{Uncpii}\n\n{Namepii} I'm asking only for 32 cores and have 100+ available\n\n\nThat error is different from standard error about cores that should look like '{Namepii} SubscriptionId '' does not have cores left to create resource ''. Required: 60, Available: 8.'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - gh-fastly-spark-{namepii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - When trying to create cluster I'm getting Message='{\\'status\\':400,\\'message\\':{UNCPII} is too small{Uncpii}\n\n{Namepii} I'm asking only for 32 cores and have 100+ available\n\n\nThat error is different from standard error about cores that should look like '{Namepii} SubscriptionId '' does not have cores left to create resource ''. Required: 60, Available: 8.';\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GitHub - NonProd - {Namepii} Platform - GitHub {Namepii} Warehouse\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster creaetino fails with remainingCores is too small even if I have enough ,10.07722488,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster creation fails with remaining Cores is too small even if I have enough,A bug was causing the discrepancy were internal DB was set to less core and the portal was showing the different Quota limit.,"Re-creating the cluster or need to increase the core limit in internal DB.Note: There was a known issue with the “remaining Cores is too small” A bug was causing the discrepancy were internal DB was set to less core and the portal was showing the different Quota limit.Also, I have noticed that recreated cluster gh-metastore-spark-test took 34 minutes.Accepted                     2020-07-14 18:47:13Running                       2020-07-14 19:21:38",,,,,,,,
1.20071E+14,53:45.7,Jobs not running on the cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I am not able to open YARN UI to even see if the jobs are progressing. The jobs are submitted through ADF and they are timing out continuously.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I am not able to open YARN UI to even see if the jobs are progressing. The jobs are submitted through ADF and they are timing out continuously.;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: Cloud Cost Management - Modern(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: RHC\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Service Health\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/61fe56f2-85b8-4bcf-9d89-15b8e0c73ce1/resourceGroups/ACIEastUSProd/providers/Microsoft.HDInsight/clusters/closedperiodc11\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jobs not running on the cluster,0.069135805,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Spark,"Checking Ambari UI, both RM's showed in standby.",Both resource managers were in standby mode,"Found that hn1 was the active head node running Ambari and forced hn1's resource manager to active. After this, the RM UI was accessible and cx confirmed jobs are running fine now.",,,,,,,,
1.20071E+14,32:20.9,ADLS Certificate Update failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are updating the ADLS certificate, it fails with the following error:\n\n\\'code\\':\\'InternalServerError\\',\\'message\\':\\'ErrorCode: Unexpected workflow execution exception; ErrorDescription: Unexpected workflow execution exception\\\n\nWe are using the code mentioned here: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-store#refresh-the-hdinsight-certificate-for-data-lake-storage-gen1-access\n\nIt has worked in the past.\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are updating the ADLS certificate, it fails with the following error:\n\n\\'code\\':\\'InternalServerError\\',\\'message\\':\\'ErrorCode: Unexpected workflow execution exception; ErrorDescription: Unexpected workflow execution exception\\\n\nWe are using the code mentioned here: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-store#refresh-the-hdinsight-certificate-for-data-lake-storage-gen1-access\n\nIt has worked in the past.\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-{namepii}-ingest1/providers/Microsoft.HDInsight/clusters/eds5prd-ingest-cluster\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADLS Certificate Update failing,14.04964228,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hive,ADLS Certificate Update failing,Platform issue with a hotfix scheduled to be released for each Region,Updated ADLS ceritficate manually ,"196,131,016,196,137,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.20071E+14,27:10.5,Unable to change Cluster Size,"Question: What time did the problem begin?\nAnswer: Sat, Jul 11, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: When attempting to change the nuber of cluster nodes from 4 to 12 it does not allow the option to save because of the following error 'Ongoing operation on cluster, please wait for '{alphanumericpii}' to return to 'Running' status to scale.'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - When attempting to change the nuber of cluster nodes from 4 to 12 it does not allow the option to save because of the following error 'Ongoing operation on cluster, please wait for '{alphanumericpii}' to return to 'Running' status to scale.';\n\n- ProblemStartTime: 07/11/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6d30b56e-2e25-41c5-8434-a7661a5700e5/resourceGroups/dsi_centralus_prod_rg01/providers/Microsoft.HDInsight/clusters/dsi-cus-prod-hdi02\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to change Cluster Size,1.948165737,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to change Cluster Size,Unhealthy cluster state due to UnknownHostException possibly caused by cached information.   ,PG suggested re-creating cluster was more viable than bringing unhealthy cluster back up.,196178495,,,,,,,
1.20071E+14,35:30.1,High inserts in HBase ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: {Namepii} was the HBase job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hi\n\n{Namepii} had a Production incident at the moment which caused messages delays.  Our applications use Azure HDI (HBase and {Namepii}) as their DB and messaging systems. we have tried to restart our aplliocations  and also restarted services on Hbase worker nodes, but still didn't help. \n\nwe noticed that there were much more inserts operation happening at the moment. please see attached screenshot for details.\n\nCan you help us find out why there are so many inserts operation at the moment? \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\n{Namepii} was the HBase job submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hi\n\n{Namepii} had a Production incident at the moment which caused messages delays.  Our applications use Azure HDI (HBase and {Namepii}) as their DB and messaging systems. we have tried to restart our aplliocations  and also restarted services on Hbase worker nodes, but still didn't help. \n\nwe noticed that there were much more inserts operation happening at the moment. please see attached screenshot for details.\n\nCan you help us find out why there are so many inserts operation at the moment? ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Fleetboard_Kosmos_Prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d3427c25-23ff-4bff-8e7d-5a812ce87299/resourceGroups/f-we-prod-agw-{namepii}/providers/Microsoft.HDInsight/clusters/hdi4-f-we-prod-agw-hbase\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",High inserts in HBase ,2.334223567,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hbase,Symptom: Hbase showing high writes/ingestion.,Cause:  Kafka Cluster brokers seemed to be down during this time causing a backup of data and offsets to be off.,Resolution: Brought back up the brokers,,,,,,,,
1.20071E+14,04:56.2,services fail to start on hn1 and cluster creation fails,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: sca16-prod-hdi-rtl.azurehdinsight.net\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: - \nInternal server error occurred while processing the request. Please retry the request or contact support. The following host components failed to start up: HIVE_METASTORE, HIVE_SERVER, {ALPHANUMERICPII}, WEBHCAT_SERVER.\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - sca16-prod-hdi-rtl.azurehdinsight.net;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - - \nInternal server error occurred while processing the request. Please retry the request or contact support. The following host components failed to start up: HIVE_METASTORE, HIVE_SERVER, {ALPHANUMERICPII}, WEBHCAT_SERVER.\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: FS Data Analytics Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9406c5fb-8168-43ae-8b61-57701174598f/resourceGroups/RG-RTL-SCA-PROD/providers/Microsoft.HDInsight/clusters/sca16-prod-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",services fail to start on hn1 and cluster creation fails,1.076629708,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,services fail to start on hn1 and cluster creation fails,The RCA is as follows...configure_ambari_server.py is used configure ambari server security during the cluster setup. It was intended to run only once during cluster setup. But during scale operations also hdinsight agent is triggered and it is executed multiple time (actually when startup agent triggers the hdinsight agent)There is currently an internal task to fix the issue (TASK 816476) but it will take some time until the fix is tested and deployed.,Restarting the ambari server,,,,,,,,
1.20071E+14,25:57.3,"repo.hortonworks suddenly unloaded some of the JAR versions used in our application.  storm, phoenix and  hbase jars","Question: What time did the problem begin?\nAnswer: Fri, Jul 10, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the {Namepii} job if known\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: from friday morning IST 2020-07-10 some of the jars suddenly unloaded from \n'https://repo.hortonworks.com/content/repositories/releases' \nour application teams refers some of the JAR versions and uses in topology below listed: \nphoenix-core-4.7.0.2.6.5.3006-29.jar, \nstorm-hbase-1.1.0.2.6.5.3006-29.jar, \nstorm-core-1.1.0.2.6.5.3003-25.jar \ncausing breaking in their application. Request assistance on it.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the {Namepii} job if known - ;\nAdditional details about the issue - from friday morning IST 2020-07-10 some of the jars suddenly unloaded from \n'https://repo.hortonworks.com/content/repositories/releases' \nour application teams refers some of the JAR versions and uses in topology below listed: \nphoenix-core-4.7.0.2.6.5.3006-29.jar, \nstorm-hbase-1.1.0.2.6.5.3006-29.jar, \nstorm-core-1.1.0.2.6.5.3003-25.jar \ncausing breaking in their application. Request assistance on it.;\n\n- ProblemStartTime: 07/09/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tech Enabled Solutions EXT Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7fe693d5-2d30-4322-99a9-d83c97c0eba6/resourceGroups/prd-hlt-cat-{namepii}-01/providers/Microsoft.HDInsight/clusters/prd-hlt-mh-ussc-cat-storm-02\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","repo.hortonworks suddenly unloaded some of the JAR versions used in our application.  storm, phoenix and  hbase jars",4.283689193,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Query or Job Failure\Storm,"repo.hortonworks suddenly unloaded some of the JAR versions used in our application. storm, phoenix and hbase jars",Files missing due to HWX issue,contacted HWX and they restored the files,196364449,,,,,,,
1.20071E+14,11:48.5,"Error when accessing Amabari Metrics - Server UI, the whole cluster is not avaible","Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM EDT\n\nQuestion: Is issue intermittent?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: The {Namepii} is accessible after some time.\n\nQuestion: Additional details about the issue\nAnswer: In Amabari, I try to access Amabari {Namepii}, when I click on Grafana from Quick Links.  There is a new tab opened and when I enter the non-fed user to access, the credential doesn't work and the whole cluster is unavailable. With the error message:\n{'Code':'Unauthorized','Message':'Credentials were {AlphanumericPII}'}\n\nAfter some time, I am able to log in again in the cluster or I can use incognito mode to open a new session. \n\nIs the credentials for Grafana different from the cluster?\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs issue intermittent? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - The {Namepii} is accessible after some time.;\nAdditional details about the issue - In Amabari, I try to access Amabari {Namepii}, when I click on Grafana from Quick Links.  There is a new tab opened and when I enter the non-fed user to access, the credential doesn't work and the whole cluster is unavailable. With the error message:\n{'Code':'Unauthorized','Message':'Credentials were {AlphanumericPII}'}\n\nAfter some time, I am able to log in again in the cluster or I can use incognito mode to open a new session. \n\nIs the credentials for Grafana different from the cluster?;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/09/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourceGroups/mlt-dar-pscdatahub-1-DEV-arc10-{Namepii}-HDI/providers/Microsoft.HDInsight/clusters/BaYV0fyPN6-ProjectSpark\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Error when accessing Amabari Metrics - Server UI, the whole cluster is not avaible",0.091093894,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,"Error when accessing Amabari Metrics - Server UI, the whole cluster is not avaible","Currently, in Azure HDInsight, Grafana is supported with the Spark, HBase, Kafka and Interactive Query cluster types. It is not supported for clusters with Enterprise Security Pack enabled.",known limitation,,,,,,,,
1.20071E+14,53:28.4,Ambari UI is not opening 502 error,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 1:50 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: Yes\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: restarted ambar server and agent\n\nQuestion: Additional details about the issue\nAnswer: 502 - Web server received an invalid response while acting as a gateway or proxy server.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - Yes;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - restarted ambar server and agent;\nAdditional details about the issue - 502 - Web server received an invalid response while acting as a gateway or proxy server.;\n\n- ProblemStartTime: 07/13/2020 17:50:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari UI is not opening 502 error,0.023571264,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,502 error while accessing ambari UI,Ambari server running on both headnodes,Restart ambari server via script,,,,,,,,
1.20071E+14,29:38.8,Getting a bunch of heartbeat alert,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 11:20 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Getting a bunch of heartbeat alert:\n\nDescription: Ambari HDInsight cluser alert notification received with these attributes [definitionName: ambari_server_agent_heartbeat, definitionLabel: Ambari Agent Heartbeat, serviceName: AMBARI, alertState: CRITICAL, alertText: zk0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net is not sending heartbeats, alertTimestamp: {Phonenumberpii}, hostname: zk0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net]\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Getting a bunch of heartbeat alert:\n\nDescription: Ambari HDInsight cluser alert notification received with these attributes [definitionName: ambari_server_agent_heartbeat, definitionLabel: Ambari Agent Heartbeat, serviceName: AMBARI, alertState: CRITICAL, alertText: zk0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net is not sending heartbeats, alertTimestamp: {Phonenumberpii}, hostname: zk0-helx2.0h4fsfuzj43expwy0ax1reqxwa.dx.internal.cloudapp.net]\n;\n\n- ProblemStartTime: 07/13/2020 18:20:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a548e950-33a3-489b-94b3-29b5ad6030bc/resourceGroups/helx-prod-dataingest-wds-hdi-westus-{namepii}/providers/Microsoft.HDInsight/clusters/helx2-prod-dataingest-wds-hdi-westus-hdik\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting a bunch of heartbeat alert,0.005361376,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Kafka,Getting a bunch of heartbeat alert,"We noticed that there was a failover of ambari-server process from hn0 to hn1 at around 17:59 UTC a few minutes before the alerts were fired and I have verified that it triggers a short alert regarding the heartbeats when there is a ambari-server failover. Failover for a process from one node to another can happen because of multiple reasons and is expected to happen in a graceful manner.   Here is the documentation that talks in detail about it.https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-high-availability-components#the-failover-process We noticed that the headnodes have been running for 600+ days without a restart, and the load on these machines is at around 8 on an average a good old restart might help free up the stress on these machines.","failover process, by design ","196,393,159,196,393,000",,,,,,,
1.20071E+14,46:25.4,Keep deleteing forever,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 12:00 PM GMT+2\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Keep deleteing forever\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Keep deleteing forever;\n\n- ProblemStartTime: 07/13/2020 10:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bd5f9e65-833e-447c-9e5b-fb8d5270388d/resourceGroups/GSD-NCS-PROD-MLTO-np-core-rg/providers/Microsoft.HDInsight/clusters/hdprestogsdncsprodmltonpcorerg\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Keep deleteing forever,0.031951719,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Delete HDInsight cluster,Keep deleteing forever,Resolved by error correction on the customer side,Resolved by error correction on the customer side,,,,,,,,
1.20071E+14,49:09.9,Keep deleteing forever,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 12:00 PM GMT+2\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Keep deleteing forever\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Keep deleteing forever;\n\n- ProblemStartTime: 07/13/2020 10:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bd5f9e65-833e-447c-9e5b-fb8d5270388d/resourceGroups/DHUB_GPL-PROD-DI/providers/Microsoft.HDInsight/clusters/hdscede09dhubgplproddi\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Keep deleteing forever,0.071516826,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Delete HDInsight cluster,Keep deleteing forever,deleting error,Error correction on CX end,,,,,,,,
1.20071E+14,50:07.4,Keep deleteing forever,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 12:00 PM GMT+2\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Keep deleteing forever\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Other, don't know or not applicable;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Keep deleteing forever;\n\n- ProblemStartTime: 07/13/2020 10:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bd5f9e65-833e-447c-9e5b-fb8d5270388d/resourceGroups/GSD-NCS-PROD-MLTO-np-core-rg/providers/Microsoft.HDInsight/clusters/hdsparkgsdncsprodmltonpcorerg\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Keep deleteing forever,0.076117846,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Delete HDInsight cluster,Keep deleteing forever,Deleting error,error correction on CX end,,,,,,,,
1.20071E+14,41:08.1,QA: kp05hbasefdhdiqausc01: Not able to run the queries,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the HBase job if known\nAnswer: \n\nQuestion: HBase query\nAnswer: \n\nQuestion: {Namepii} was the HBase job submitted?\nAnswer: HBase shell\n\nQuestion: Additional details about the issue\nAnswer: QA: {alphanumericpii}: Not able to run the queries\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made? - ;\nIncrease in load? - ;\nYARN Application ID for the HBase job if known - ;\nHBase query - ;\n{Namepii} was the HBase job submitted? - HBase shell;\nAdditional details about the issue - QA: {alphanumericpii}: Not able to run the queries;\n\n- ProblemStartTime: 07/13/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-{namepii}-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kp05hbasefdhdiqausc01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",QA: kp05hbasefdhdiqausc01: Not able to run the queries,8.715334656,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Query or Job Failure\Hbase,QA: kp05hbasefdhdiqausc01: Not able to run the queries,  On      analyzing figured out that the tabledescriptor (.tabledesc) was missing in      /hbase/data/hbase/namepsace. ,  We      copied .tabledesc from a good cluster. And followed following steps  Stop      HBase     Rmr      /hbase-unsecure/region-in-transition  hadoop      fs -mv /hbase/MasterProcWALs /tmp/bkpMasterProc  hadoop      fs -mv /hbase/WALs /tmp/bkpWALs  Start      HBase,196570283,,,,,,,
1.20071E+14,27:26.5,Pin the HDI 4 spark clusters to 3.1.2.7-1 ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Currently {Namepii} are pointing to 3.1.6.0-77.\nPin the HDI 4 spark clusters to 3.1.2.7-1 \n\nQuestion: Additional details about the issue\nAnswer: Currently {Namepii} are pointing to 3.1.6.0-77.\n\nPin the HDI 4 spark clusters to 3.1.2.7-1 \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - Currently {Namepii} are pointing to 3.1.6.0-77.\nPin the HDI 4 spark clusters to 3.1.2.7-1 ;\nAdditional details about the issue - Currently {Namepii} are pointing to 3.1.6.0-77.\n\nPin the HDI 4 spark clusters to 3.1.2.7-1 ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_DEV\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/gm_cloudreg_qa-cat-csqa-rg/providers/Microsoft.HDInsight/clusters/ncg5j5-fbco-202020714-cat-qa-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Pin the HDI 4 spark clusters to 3.1.2.7-1 ,0.355618924,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,ePin the HDI 4 spark clusters to 3.1.2.7-1,ePin the HDI 4 spark clusters to 3.1.2.7-1,Worked with product group and executed pinning request.,"196,486,968,196,548,000",,,,,,,
1.20071E+14,39:55.3,Hive service is down. restart operation unresponsive.,"Hive {Namepii} were unresponsive. Tried restarting Hive services. But the process got hunged. Please help to recover hive services.\n\nProblem start date and time\n{Namepii}, Jul 14, 2020, 4:30 PM GMT+5:30\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/14/2020 11:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CMI_Dev_Stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7cdd2240-016b-4b98-b5c1-53d351618a75/resourceGroups/enterprise-dev/providers/Microsoft.HDInsight/clusters/llapdjenterprisedev\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive service is down. restart operation unresponsive.,0.073387582,Root Cause : HDInsight Service\Bug\Hadoop - HDP,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,HS2I failed to start,"Leader election failed for ResourceManager due to an NPE, and there was no ""active"" RM.","Restarted the RM on hn0, and this allowed the RM on hn1 to assume the ""active"" role.  Restarting HS2I then succeeded",,,,,,,,
1.20071E+14,13:30.1,We are unable to connect to one of our spark server,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 13, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are not able to connect to one of our spark server. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are not able to connect to one of our spark server. ;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/13/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: US_AUDIT_PREPROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d7ac9c0b-155b-42a8-9d7d-87e883f82d5d/resourceGroups/App-Cortex-AME-LRN-RG/providers/Microsoft.HDInsight/clusters/cortexaapslrnspark\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We are unable to connect to one of our spark server,0.097464323,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,We are unable to connect to one of our spark server,We are unable to connect to one of our spark server,Worked with customer and engaged product group on this. Product group had checked and informed that this particular edgenode was created earlier in Nov 2019 and later dropped. But it seems the vhd associated with the edgenode wasnt deleted that is causing the edgenode fail to start now. Product group suggested to delete the edgenode and recreate again. Customer told that they would look into this later and agreed to archive the case now.,196563890,,,,,,,
1.20071E+14,28:44.2,"topology_script.py is built on Python2 and python2 reached EOL on Jan 1, 2020","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: The rack awareness script /etc/hadoop/conf/topology_script.py is built on {Alphanumericpii} and as you know Python is already on End of Life Support as of {Namepii} 1, 2020.\nWe run application on edge node which are build on {Alphanumericpii} and the application fails with errors listed below.\n\nWhen is Microsoft planning to rebuild the topology script to {Alphanumericpii} or better change it a shell script?\n\nERROR 1:\nWARN [20/07/14 {Alphanumericpii}] [{alphanumericpii}] org.apache.hadoop.net.ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py {Ipaddresspii}\nExitCodeException {AlphanumericPII}:   File '/etc/hadoop/conf/topology_script.py', line 63\n    print rack\n          ^\nSyntaxError: Missing parentheses in call to 'print'. Did you mean print(rack)?\n\n\n\nERROR 2:\nWARN [20/06/22 {Alphanumericpii}] [{alphanumericpii}] org.apache.hadoop.net.ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py {Ipaddresspii}\nExitCodeException {AlphanumericPII}: Traceback (most recent call last):\nFile '/etc/hadoop/conf/topology_script.py', line 21, in module\nfrom string import join\nImportError: cannot import name 'join' from 'string' (/usr/local/lib/python3.8/string.py)\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Other, don't know or not applicable;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - The rack awareness script /etc/hadoop/conf/topology_script.py is built on {Alphanumericpii} and as you know Python is already on End of Life Support as of {Namepii} 1, 2020.\nWe run application on edge node which are build on {Alphanumericpii} and the application fails with errors listed below.\n\nWhen is Microsoft planning to rebuild the topology script to {Alphanumericpii} or better change it a shell script?\n\nERROR 1:\nWARN [20/07/14 {Alphanumericpii}] [{alphanumericpii}] org.apache.hadoop.net.ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py {Ipaddresspii}\nExitCodeException {AlphanumericPII}:   File '/etc/hadoop/conf/topology_script.py', line 63\n    print rack\n          ^\nSyntaxError: Missing parentheses in call to 'print'. Did you mean print(rack)?\n\n\n\nERROR 2:\nWARN [20/06/22 {Alphanumericpii}] [{alphanumericpii}] org.apache.hadoop.net.ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py {Ipaddresspii}\nExitCodeException {AlphanumericPII}: Traceback (most recent call last):\nFile '/etc/hadoop/conf/topology_script.py', line 21, in module\nfrom string import join\nImportError: cannot import name 'join' from 'string' (/usr/local/lib/python3.8/string.py);\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Unifi Field\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","topology_script.py is built on Python2 and python2 reached EOL on Jan 1, 2020",0.094360683,Root Cause : HDInsight Service\By Design\Hadoop - HDP,"Routing Azure HDInsight V5\Unexpected result\MapReduce, Pig, Sqoop or Oozie","topology_script.py is built on Python2 and python2 reached EOL on Jan 1, 2020Cx runs application on edge node which are built on Python3 and the application fails with errors","Issue is by design. There are lot of dependencies on python 2.7 (both Hadoop components and WA agent and stuff). We cannot move the Hadoop system to a higher version of python.  The version of /etc/hadoop/conf/topology_script.py is related and will not be changed only for python3 per current distribution. In the future, our product teams will consider your request based on the whole roadmap of the development.",Install python virtual machines to allow side by side existence of multiple python versions.Use anaconda for all of your python3 apps and do not change the cluster scripts.,,,,,,,,
1.20071E+14,33:45.0,Request Body too large error with the Spark errors,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: 413 error\n\nQuestion: Additional details about the issue\nAnswer: 413 error\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - 413 error;\nAdditional details about the issue - 413 error;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prod-01/providers/Microsoft.HDInsight/clusters/kpp090sparkprodwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Request Body too large error with the Spark errors,9.94429437,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,"""The uncommitted block count cannot exceed the maximum limit of 100,000 blocks.Request Body too large error with the Spark errors","Spark event log file is probably hitting the file length limit for WASB.In Spark 2.3, each Spark app generates one Spark event log file. The Spark event log file for a Spark streaming app continues to grow while the app is running. Today a file on WASB has a 50000 block limit, and the default block size is 4 MB. So in the default configuration, the max file size is 195 GB. However, Azure Storage has increased the max block size to 100 MB, which effectively brought the single file limit to 4.75 TB","There are three solutions available for this error:  Increase the block size to up to 100 MB. In Ambari UI,      modify HDFS configuration      property fs.azure.write.request.size (or create it      in Custom core-site section). Set the property to a larger      value, for example: 33554432. Save the updated configuration and restart      affected components.  Periodically stop and resubmit the spark-streaming job.  Use HDFS to store Spark event logs. Using HDFS for      storage may result in loss of Spark event data during cluster scaling or      Azure upgrades.     Make changes       to spark.eventlog.dir and spark.history.fs.logDirectory via       Ambari UI:  Copyspark.eventlog.dir = hdfs://mycluster/hdp/spark2-eventsspark.history.fs.logDirectory = ""hdfs://mycluster/hdp/spark2-events""     Create directories on HDFS:  Copyhadoop fs -mkdir -p hdfs://mycluster/hdp/spark2-eventshadoop fs -chown -R spark:hadoop hdfs://mycluster/hdphadoop fs -chmod -R 777 hdfs://mycluster/hdp/spark2-eventshadoop fs -chmod -R o+t hdfs://mycluster/hdp/spark2-events     Restart all affected services via Ambari UI.   Please follow the link below for more in details, https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-troubleshoot-event-log-requestbodytoolarge",,,,,,,,
1.20071E+14,48:57.4,Can't delete cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 14, 2020, 1:38 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: by opening a case and the Product Group had to do something to kill it. See case {Phonenumberpii}. Still waiting on RCA.\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: My co-worker is using azure java sdk.\n{alphanumericpii}\nazure-mgmt-hdinsight\nversion: {alphanumericpii}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Not new, happened before;\nPrevious solution if applicable - by opening a case and the Product Group had to do something to kill it. See case {Phonenumberpii}. Still waiting on RCA.;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - My co-worker is using azure java sdk.\n{alphanumericpii}\nazure-mgmt-hdinsight\nversion: {alphanumericpii}\n;\n\n- ProblemStartTime: 07/14/2020 08:38:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: aerserv-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9ef27971-25ed-4df5-9b7e-46cb50431641/resourceGroups/aerserv-prod-eastus-rg/providers/Microsoft.HDInsight/clusters/daily-adurlsreport-cluster-20200713\n- Location: eastus\n- Location: East US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't delete cluster,0.059127198,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Delete HDInsight cluster,Can't delete cluster,"Suspect : regarding the RCA of why the cluster is getting stuck in operational state, suspect the old sdk has something to do here: Customer is using java  hdi mgmt SDK to create clusters and the version is : 1.0.0-beta-1 which is very old –> asked them to upgrade to the latest stable release ie 1.3.3 Refer to https://portal.microsofticm.com/imp/v3/incidents/details/194997652/home for RCA",PG deleted the cluster from the backend,196550429,,,,,,,
1.20071E+14,47:33.6,Not able to create cluster with express route ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {namepii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to create HD insight cluster with express route vnet. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {namepii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to create HD insight cluster with express route vnet. ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EnS-{Namepii}-DL-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a04d1510-3444-42bc-9ce1-41b3c9a9c558/resourceGroups/cat-operational-dl-{namepii}-01/providers/Microsoft.HDInsight/clusters/cat-operational-dl-hdinsight-01\n- Location: westcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to create cluster with express route ,0.235224647,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Not able to create cluster with express route,Not able to access the cluster using MSFT VPN ,"After given ask from the HDI team, express route team denied that HDI cluster will not able to deploy through express route. Update from express Route team: I am not familiar with having HD insight cluster in express route nor am I aware of it being tested as a POC",198268049,,,,,,,
1.20071E+14,54:24.3,Unable to launch cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: edema\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes have been made\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'UnableToEstablishConnectivityFromVirtualMachines\\',\\r\\n \\'message\\': \\'Unable to establish connectivity from virtual machines. Please ensure that your network configuration allows outbound access from within the virtual network. For more information, please refer to: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment\\'\\r\\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]}\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - edema;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - No changes have been made;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - {'code':'DeploymentFailed','message':'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.','details':[{'code':'Conflict','message':'{{uncpii}\n \\'status\\': \\'Failed\\',\\r\\n \\'error\\': {{uncpii}\n \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii} \\'details\\': [{uncpii}\n {{uncpii}\n \\'code\\': \\'UnableToEstablishConnectivityFromVirtualMachines\\',\\r\\n \\'message\\': \\'Unable to establish connectivity from virtual machines. Please ensure that your network configuration allows outbound access from within the virtual network. For more information, please refer to: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-plan-virtual-network-deployment\\'\\r\\n }{uncpii}\n ]{uncpii}\n }{uncpii}\n}'}]};\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Azure Cloud Platform\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to launch cluster,0.070459654,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to launch cluster,DNS setting change made on CX side,corrected the DNS setting internally by CX and they were able to deploy a Hadoop cluster  ,,,,,,,,
1.20072E+14,17:17.6,Error creating the cluster,"Question: What time did the problem begin?\nAnswer: Wed, Jul 15, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Error creating the cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Error creating the cluster;\n\n- ProblemStartTime: 07/15/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/RG-RTL-RefTemp-Dev/providers/Microsoft.HDInsight/clusters/reftemp01-dev-hdi-rtl\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error creating the cluster,0.012029832,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Error creating the cluster,Error creating the cluster,Worked with customer and found that the issue was due to connectivity to ranger database. Customer had fixed and completed provisioning.,,,,,,,,
1.20072E+14,43:38.4,Head node issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: 2020-07-15 {Alphanumericpii} - ERROR [{AlphanumericPII}] - com.infa.products.ldm.deployment.exceptions.DeploymentFailureException: [{AlphanumericPII}] Service operation [INIT_SERVICE_Hadoop_Resource_Manager] failed for service [Hadoop_Resource_Manager] because of following error: [java.util.concurrent.ExecutionException: com.infa.products.ldm.deployment.exceptions.DeploymentFailureException: [{AlphanumericPII}] {Namepii} Service validations failed with error [com.infa.products.ldm.deployment.exceptions.ValidationFailureException: [{AlphanumericPII}] Connecting to hdfs namenode has failed due to the following error : [org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: The account being accessed does not support http.]].]\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - 2020-07-15 {Alphanumericpii} - ERROR [{AlphanumericPII}] - com.infa.products.ldm.deployment.exceptions.DeploymentFailureException: [{AlphanumericPII}] Service operation [INIT_SERVICE_Hadoop_Resource_Manager] failed for service [Hadoop_Resource_Manager] because of following error: [java.util.concurrent.ExecutionException: com.infa.products.ldm.deployment.exceptions.DeploymentFailureException: [{AlphanumericPII}] {Namepii} Service validations failed with error [com.infa.products.ldm.deployment.exceptions.ValidationFailureException: [{AlphanumericPII}] Connecting to hdfs namenode has failed due to the following error : [org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: The account being accessed does not support http.]].];\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Core Data {Alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e2b0e829-5210-40ae-b73f-20805aa01351/resourceGroups/bnlwe-da01-p-80219-rg/providers/Microsoft.HDInsight/clusters/p-80219-bnlwe-da01-unilevercom-hdi-02\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Head node issue,0.005736628,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Hadoop,[org.apache.hadoop.fs.azure.AzureException: com.microsoft.azure.storage.StorageException: The account being accessed does not support http.]].],the issue was with changing the configuration of default storage account connected to the cluster to use secure transfer to be enabled and we were able to verify that by looking at the Activity logs as well.,We were able to switch it back and rerun the jobs successfully,,,,,,,,
1.20072E+14,00:32.3,Spark2 History Server UI - Out of Memory,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 6, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 6, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: We've increased the config Spark {Namepii} in \nAdvanced {alphanumericpii} from 1GB to 2GB then to 4GB but the issue still persists.\n\nUrl: https://arc10.hdi.pscdatahub.dev.euw.gbis.sg-azure.com//sparkhistory/history/application_1593723985536_0250/1/jobs/\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We've increased the config Spark {Namepii} in \nAdvanced {alphanumericpii} from 1GB to 2GB then to 4GB but the issue still persists.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - We've increased the config Spark {Namepii} in \nAdvanced {alphanumericpii} from 1GB to 2GB then to 4GB but the issue still persists.\n\nUrl: https://arc10.hdi.pscdatahub.dev.euw.gbis.sg-azure.com//sparkhistory/history/application_1593723985536_0250/1/jobs/;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - We've increased the config Spark {Namepii} in \nAdvanced {alphanumericpii} from 1GB to 2GB then to 4GB but the issue still persists.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/06/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourceGroups/mlt-dar-pscdatahub-1-DEV-arc10-{Namepii}-HDI/providers/Microsoft.HDInsight/clusters/BaYV0fyPN6-ProjectSpark\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark2 History Server UI - Out of Memory,0.081385962,Root Cause : HDInsight Service\Bug\Spark,Routing Azure HDInsight V5\Service unhealthy\Spark,"This issue is often caused by a lack of resources when opening large spark-event  files. The Spark heap size is set to 1 GB by default, but large Spark event  files may require more than this.",You receive the following  error when opening events in Spark History server: scala.MatchError:  java.lang.OutOfMemoryError: Java heap space (of class  java.lang.OutOfMemoryError),"We have created a work item for this and donot have an ETA for the  fix yet. But would recommend you to follow the workaround as showed below. Yes,  we recommend to update to Spark heap size as  per the needs (4GB and more) for large spark event files to  access through Spark History UI.You can do this from within the Ambari browser UI by selecting the  Spark2/Config/Advanced spark2-env section. Add the following property to change  the Spark History Server memory from 1g to 4g:  export SPARK_DAEMON_MEMORY=4g and  then make  sure to restart all affected services from Ambari.",,,,,,,,
1.20072E+14,36:03.8,Cannot access cluster management interface,"Question: What time did the problem begin?\nAnswer: Wed, Jul 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Added Microsoft's VPN IP address to {alphanumericpii} network security group, issue pertains\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} time this issue happened, {Namepii} {Namepii} helped me resolved it by guiding me to adding my IP address of Microsoft's VPN to network security group. After moving to a different apartment, the issue arose again (I suspect due to the change in my local home network?). This time adding the IP address to network security group doesn't fixed it.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Added Microsoft's VPN IP address to {alphanumericpii} network security group, issue pertains;\nAdditional details about the issue - {Namepii} time this issue happened, {Namepii} {Namepii} helped me resolved it by guiding me to adding my IP address of Microsoft's VPN to network security group. After moving to a different apartment, the issue arose again (I suspect due to the change in my local home network?). This time adding the IP address to network security group doesn't fixed it.;\n\n- ProblemStartTime: 07/15/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-NAM-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cda42e6-a623-4800-abdf-431ef3ec65e5/resourceGroups/o365ipdinam06-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdinam06-sp-wu01\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot access cluster management interface,0.058231689,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Ambari UI is not loading,Not able to access Ambari UI,NSG blocking the access,Added the Client IP in the NSG and now Ambari UI is accessible,,,,,,,,
1.20072E+14,55:00.5,504 Gateway Time-out” error. ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: Issue Description:\n\nWhile running query in domain joined cluster from hive view users are facing “504 Gateway Time-out” error. \nHowever the same queries are able to execute from command line (ODBC & JDBC), the queries are able to execute from hive view if the limit is set to low values.\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - ODBC;\nAdditional details about the issue - Issue Description:\n\nWhile running query in domain joined cluster from hive view users are facing “504 Gateway Time-out” error. \nHowever the same queries are able to execute from command line (ODBC & JDBC), the queries are able to execute from hive view if the limit is set to low values.\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/bpudlupsprod\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",504 Gateway Time-out” error. ,1.806001083,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,e504 Gateway Time-out” error.,e504 Gateway Time-out” error.,Worked with customer and customer had run “set hive.fetch.task.conversion=none” and able to run problematic query as well successfully on hive view.,,,,,,,,
1.20072E+14,29:20.6,Cluster taking over 2 hours to get to running status,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: Running with spark 2.3 and cluster is not coming up to a runnning status after 2 hours\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - Running with spark 2.3 and cluster is not coming up to a runnning status after 2 hours;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Production Classic\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster taking over 2 hours to get to running status,0.793337838,Root Cause : HDInsight Service\Azure platform issues\Azure VM Resource issues,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Cluster in Operational State,2 worker nodes failed to come up due to transient issues,The customer is able to delete the cluster,196738865,,,,,,,
1.20072E+14,42:15.9,prdsup - kpp109sparkespprdsupwus201 - edge node deployment failre,"Question: What time did the problem begin?\nAnswer: Wed, Jul 15, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Edge node deployments failing twice \n\nQuestion: Additional details about the issue\nAnswer: Edge node deployments failing twice \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Edge node deployments failing twice ;\nAdditional details about the issue - Edge node deployments failing twice ;\n\n- ProblemStartTime: 07/15/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpp109sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",prdsup - kpp109sparkespprdsupwus201 - edge node deployment failre,0.051112672,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,kpp109sparkespprdsupwus201 - edge node deployment failre,kpp109sparkespprdsupwus201 - edge node deployment failre,"Customer was able to provision the edgenode after restarting Ambari-server. To avoid this (restart of Ambari-server), product group had deploy fix for the actual issue and confirmed that subsequent provisionings of HDInsight clusters would receive the fix.",196008068,,,,,,,
1.20072E+14,49:42.4,[Azure Government] Our spark jobs are not being submitted to the cluster. They are stuck in the ADF pipeline where they should be deployed to HDI.,"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 14, 2020, 5:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: How was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: The issue is in when ADF is submitting jobs to the cluster. There are four jobs that have failed since yesterday due to timeoutes that occur since the jobs are not being submitted. \n\nIntially when I logged into YARN, I saw that the submitted jobs were in this 'NEW_SAVING' state under STATUS in the descrption bar. This is no longer there. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\nHow was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - N/A;\nAdditional details about the issue - The issue is in when ADF is submitting jobs to the cluster. There are four jobs that have failed since yesterday due to timeoutes that occur since the jobs are not being submitted. \n\nIntially when I logged into YARN, I saw that the submitted jobs were in this 'NEW_SAVING' state under STATUS in the descrption bar. This is no longer there. ;\n\n- ProblemStartTime: 07/15/2020 00:00:00\n- Cloud: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PROD – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - ProDirect\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-de-core-rg/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchProd\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Our spark jobs are not being submitted to the cluster. They are stuck in the ADF pipeline where they should be deployed to HDI.,0.028247301,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,120071524005741 - Our spark jobs are not being submitted to the cluster. They are stuck in the ADF pipeline where they should be deployed to HDI.,The YARN service was not working properly.,The customer restarted the YARN services and the jobs starting running again.,,,,,,,,
1.20072E+14,06:02.3,I cannot connect remotely to this cluster through PowerBI or a Jupyter notebook,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Does Ambari login work?\nAnswer: Yes\n\nQuestion: Connection string being used\nAnswer: https://ubproddmshdinsight.azurehdinsight.net\n\nQuestion: Does Beeline work from within the cluster using zookeeper connection string copied from Ambari?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: From PowerBI I get this error: \nDetails: 'ODBC: ERROR [{ALPHANUMERICPII}] [Microsoft][DSI] An error occurred while attempting to retrieve the error message for key 'TEHTTPClientDetailedException' with message parameters ['Bad Status: Unrecognized response with no error message header. Status code: '] and component ID 200: Message not found in file 'C:{Uncpii} Files{Uncpii} Spark ODBC Driver{UNCPII}\en-US{UNCPII}\n\nAnd from jupyter notebook I get an authentication failed error. \n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nDoes Ambari login work? - Yes;\nConnection string being used - https://ubproddmshdinsight.azurehdinsight.net;\nDoes Beeline work from within the cluster using zookeeper connection string copied from Ambari? - Other, don't know or not applicable;\nAdditional details about the issue - From PowerBI I get this error: \nDetails: 'ODBC: ERROR [{ALPHANUMERICPII}] [Microsoft][DSI] An error occurred while attempting to retrieve the error message for key 'TEHTTPClientDetailedException' with message parameters ['Bad Status: Unrecognized response with no error message header. Status code: '] and component ID 200: Message not found in file 'C:{Uncpii} Files{Uncpii} Spark ODBC Driver{UNCPII}\en-US{UNCPII}\n\nAnd from jupyter notebook I get an authentication failed error. ;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HC-Dragon-DMO-Prod-US\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9ef102be-8e69-43a4-b2bb-63ec3670b7d2/resourceGroups/UBprodDMSResearch/providers/Microsoft.HDInsight/clusters/ubproddmshdinsight\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I cannot connect remotely to this cluster through PowerBI or a Jupyter notebook,0.079787851,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Authentication failure\ODBC or JDBC connecting to standard cluster,I cannot connect remotely to this cluster through PowerBI or a Jupyter notebook,I cannot connect remotely to this cluster through PowerBI or a Jupyter notebook,Worked with customer and clarified to customer that Hadoop cluster comes with spark client and he would need to create spark cluster to be able to submit spark jobs remotely.,,,,,,,,
1.20072E+14,12:20.9,Unable to add an EDGE node,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to add EDGE node via ARM template\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - Unable to add EDGE node via ARM template;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: MMDE LIVE CSP\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: CSP\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Cloud Solution Provider\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: westeurope\n- Location: West Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to add an EDGE node,0.14075319,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Unexpected result\Kafka,Symptom: When trying to add an edgenode failure to point to artifact location,Cause:  Microsoft public doc the deploy button has a bug when pointing to the artifact,Resolution: Created a custom template deployment and pointed to a different artifact.,,,,,,,,
1.20072E+14,35:38.4,Cluster in Applying changes state for a long period of time,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: None\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Server is in starting state for more than an hour. I see lot of errors in Ambari console. \n\nGenerally server starts in 30 mins. Yesterday it worked fine, no changes were made. I need help in investigation. I am even not able to delete the file and launch it again.\n\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - None;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Server is in starting state for more than an hour. I see lot of errors in Ambari console. \n\nGenerally server starts in 30 mins. Yesterday it worked fine, no changes were made. I need help in investigation. I am even not able to delete the file and launch it again.\n\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EA-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a122ee66-fd55-4e1b-b7b1-7677a4ab3932/resourceGroups/rg_azrbdcsdev/providers/Microsoft.HDInsight/clusters/azrhdieldev1\n- Location: northcentralus\n- Location: North Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster in Applying changes state for a long period of time,0.072646079,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Cluster deployment took longer than expected with deployment failure. ,"While installing the HDI components & registering the nodes in Ambari Server, ZKFC timed out and cluster did not achieve operational state because of it.",Transient issue & upon redeployment cluster deployment was successful.,,,,,,,,
1.20072E+14,11:35.6,DeploymentFailed in QA and Prod,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii} & {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: \n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://clicktime.symantec.com/3BrP3JLz2TtYqXRrftTKepT7Vc?u=https%3A%2F%2Faka.ms%2FDeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'FailedToValidateStorageAccountErrorCode\\',\\r\\n        \\'message\\': \\'Failed to validate the storage account.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii} & {alphanumericpii};\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - \n  'code': 'DeploymentFailed',\n  'message': 'At least one resource deployment operation failed. Please list deployment operations for details. Please see https://clicktime.symantec.com/3BrP3JLz2TtYqXRrftTKepT7Vc?u=https%3A%2F%2Faka.ms%2FDeployOperations for usage details.',\n  'details': [\n    {\n      'code': 'Conflict',\n      'message': '{{uncpii}\n  \\'status\\': \\'Failed\\',\\r\\n  \\'error\\': {{uncpii}\n    \\'code\\': \\'ResourceDeploymentFailure\\',\\r\\n    \\'message\\': \\'The resource operation completed with terminal provisioning state 'Failed'.{Uncpii}\r{uncpii}    \\'details\\': [{uncpii}\n      {{uncpii}\n        \\'code\\': \\'FailedToValidateStorageAccountErrorCode\\',\\r\\n        \\'message\\': \\'Failed to validate the storage account.\\'\\r{uncpii}      }{uncpii}\n    ]{uncpii}\n  }{uncpii}\n}'\n    }\n  ]\n}\n;\n\n- ProblemStartTime: 07/08/2020 18:30:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: QA Test 01 (S08)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",DeploymentFailed in QA and Prod,0.223071236,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,HDInsight deployment failures,DeploymentFailed in QA and Prod,"GZRS and RA-GZRS SKUs are not supported for HDI. And supported SKUs are - StandardLRS , StandardGRS , StandardRAGRS, StandardZRS, PremiumLRS, PremiumZRS.",196857407,,,,,,,
1.20072E+14,58:40.0,Hive Permission error on ADLS while creating the external tables,"Question: What time did the problem begin?\nAnswer: Wed, Jul 15, 2020, 4:00 PM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: set tez.queue.name=rdlcore;\n\nCREATE EXTERNAL TABLE rx_rtl_stg.rxp_wf_audit_palantir(                                                                       \n   rxc_wkflw_audt_seq_id string,                                                                                        \n   ref_id string,                                                                                                       \n   wkflw_typ_cd string,                                                                                                 \n   wkflw_step_cd string,                                                                                                \n   {alphanumericpii} string,                                                                                                    \n   {alphanumericpii} string,                                                                                                    \n   {alphanumericpii} string,                                                                                                    \n   crte_dt string,                                                                                                      \n   crte_by string)                                                                                                      \n PARTITIONED BY (                                                                                                         \n   extr_load_dt string)                                                                                                 \n ROW FORMAT DELIMITED                                                                                                     \n   FIELDS TERMINATED BY '|'                                                                                               \n STORED AS textfile                                                           \n LOCATION                                                                                                                 \n   'adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/palantirpoc/RXCWorkflow/RXP_WF_AUDIT';\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: Creating an external table since the location already exists and even the data also exists in that location.\n\nGetting the following error -\n\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [bat_hsxd] does not have [ALL] privilege on [adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/palantirpoc/RXCWorkflow/RXP_WF_AUDIT] ({alphanumericpii})\n\n\nFew things to {namepii} here -\n\ndoAs is set to false\nAll the folders and files inside parent folder (even the parent folder for that matter) is either owned by the user running the command or have an acl added with permission with full permissions on all the files (rwx). {Namepii} granted the full privilege on database to user in ranger\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - set tez.queue.name=rdlcore;\n\nCREATE EXTERNAL TABLE rx_rtl_stg.rxp_wf_audit_palantir(                                                                       \n   rxc_wkflw_audt_seq_id string,                                                                                        \n   ref_id string,                                                                                                       \n   wkflw_typ_cd string,                                                                                                 \n   wkflw_step_cd string,                                                                                                \n   {alphanumericpii} string,                                                                                                    \n   {alphanumericpii} string,                                                                                                    \n   {alphanumericpii} string,                                                                                                    \n   crte_dt string,                                                                                                      \n   crte_by string)                                                                                                      \n PARTITIONED BY (                                                                                                         \n   extr_load_dt string)                                                                                                 \n ROW FORMAT DELIMITED                                                                                                     \n   FIELDS TERMINATED BY '|'                                                                                               \n STORED AS textfile                                                           \n LOCATION                                                                                                                 \n   'adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/palantirpoc/RXCWorkflow/RXP_WF_AUDIT';;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Beeline;\nAdditional details about the issue - Creating an external table since the location already exists and even the data also exists in that location.\n\nGetting the following error -\n\nError: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: user [bat_hsxd] does not have [ALL] privilege on [adl://prodrxperso.azuredatalakestore.net/data/prod/rtl_pharmacy/archive/rxdw/palantirpoc/RXCWorkflow/RXP_WF_AUDIT] ({alphanumericpii})\n\n\nFew things to {namepii} here -\n\ndoAs is set to false\nAll the folders and files inside parent folder (even the parent folder for that matter) is either owned by the user running the command or have an acl added with permission with full permissions on all the files (rwx). {Namepii} granted the full privilege on database to user in ranger;\n\n- ProblemStartTime: 07/15/2020 21:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Hive Permission error on ADLS while creating the external tables,1.04509268,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive," Hive create table statements were failing on existing folders\files with error message “HiveAccessControlException"". While you were able to create tables on new directories.","We looked at the owner and permissions of the files\folders and found that there were some files\folders which were owned by different users. Upon updating the owner, you are able to create the tables successfully.","We looked at the owner and permissions of the files\folders and found that there were some files\folders which were owned by different users. Upon updating the owner, you are able to create the tables successfully.",,,,,,,,
1.20072E+14,40:16.3,Unable to provision new hdinsight cluster utilizing existing managed sql instance,"Question: What time did the problem begin?\nAnswer: ‎7‎/‎16‎/‎2020‎ ‎11‎:‎00‎:‎00‎ ‎AM\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: When provisioning of new HDI cluster, we are unable to locate Managed SQL Server {namepii} {alphanumericpii}) for external hive meta data store. \nProvisioning also failed while using Arm Template with {namepii} connection string.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - When provisioning of new HDI cluster, we are unable to locate Managed SQL Server {namepii} {alphanumericpii}) for external hive meta data store. \nProvisioning also failed while using Arm Template with {namepii} connection string.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/16/2020 18:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Analytics-and-{Namepii}-Science-DevTest\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to provision new hdinsight cluster utilizing existing managed sql instance,0.02497383,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to provision new hdinsight cluster utilizing existing managed sql instance,Not supported SQL MI in HDInsight clusters,Not supported SQL MI in HDInsight clusters,,,,,,,,
1.20072E+14,17:03.0,Unable to create HDI Cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 16, 2020, 3:30 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: prod-hdipacificapp\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Unable to select default storage account to create the cluster\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - prod-hdipacificapp;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Unable to select default storage account to create the cluster;\n\n- ProblemStartTime: 07/16/2020 10:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: RSI Production PayGo(Converted to EA)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to create HDI Cluster,0.103494934,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Unable to create HDI Cluster,Unable to create HDI Cluster,"Checked and found that this issue was due to Azure Storage outage in East US region impacting very few customers. Storage team had deployed the fix for the same. Customer was able to provision cluster successfully. RCA would be posted to Azure Monitor -> service health -> Health History, when it is available.",196857692,,,,,,,
1.20072E+14,11:48.4,I want to stop my HD Insight cluster for some time.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 16, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Hello,\n\nAs I don't see an option to select on how to stop an HD Insight cluster which is not in use, is there a script action to perform or is there an option to perform from the Ambari UI, please let me know.\n\nThanks,\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Hello,\n\nAs I don't see an option to select on how to stop an HD Insight cluster which is not in use, is there a script action to perform or is there an option to perform from the Ambari UI, please let me know.\n\nThanks,;\n\n- ProblemStartTime: 07/16/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/706cebd5-c5db-499d-aace-d5f558f61f9e/resourceGroups/dv-uat3-timeseries1.0-{namepii}/providers/Microsoft.HDInsight/clusters/dv-uat3-ts-spark\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I want to stop my HD Insight cluster for some time.,0.037391387,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,120071624005592- I want to stop my HD Insight cluster for some time.,Customer wants to save costs and save the customizations made to the cluster.,"•	Delete the current HDInsight cluster.•	Use the template that was used to deploy the current HDInsight cluster when you need to run the cluster again: Open the Azure Portal --> Resource Groups --> Deployments --> Select the cluster deployment.- --> Click Deploy.If you have made customizations to the cluster, they will not be saved. Consider creating a script action that does the customizations and pass that during cluster creation.Instructions:https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-cluster-linux",,,,,,,,
1.20072E+14,48:27.9,Observing issue while querying Hive 'Failed to execute tez graph',"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: New problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: {alphanumericpii}\n\nQuestion: Hive query if applicable\nAnswer: select count(*) from atn_ats_raw\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: How was the Hive query submitted?\nAnswer: ODBC\n\nQuestion: Additional details about the issue\nAnswer: INFO  : Executing {AlphanumericPII}): select count (*) from atn_ats\nINFO  : Query ID = {alphanumericpii}\nINFO  : Total jobs = 1\nINFO  : Launching {Namepii} 1 out of 1\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nINFO  : Subscribed to counters: [] for queryId: {alphanumericpii}\nINFO  : Tez session hasn't been created yet. Opening session\nERROR : Failed to execute tez graph.\njava.io.FileNotFoundException: wasbs://y4a8d1-metlloader-20200717-creg-prod-hdi@gmcloudregprodlogs.blob.core.windows.net/hps/3.1.2.7-1/tez/tez.tar.gz: No such file or directory.\n        at {AlphanumericPII}) ~[hadoore-3.1.1.3.1.2.7-1.jar:?]\n\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - New problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - {alphanumericpii};\nHive query if applicable - select count(*) from atn_ats_raw;\nHive query explain plan if available - ;\nHow was the Hive query submitted? - ODBC;\nAdditional details about the issue - INFO  : Executing {AlphanumericPII}): select count (*) from atn_ats\nINFO  : Query ID = {alphanumericpii}\nINFO  : Total jobs = 1\nINFO  : Launching {Namepii} 1 out of 1\nINFO  : Starting task [{AlphanumericPII}] in serial mode\nINFO  : Subscribed to counters: [] for queryId: {alphanumericpii}\nINFO  : Tez session hasn't been created yet. Opening session\nERROR : Failed to execute tez graph.\njava.io.FileNotFoundException: wasbs://y4a8d1-metlloader-20200717-creg-prod-hdi@gmcloudregprodlogs.blob.core.windows.net/hps/3.1.2.7-1/tez/tez.tar.gz: No such file or directory.\n        at {AlphanumericPII}) ~[hadoore-3.1.1.3.1.2.7-1.jar:?]\n;\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82df7a41-a89e-4f62-a5e1-c3a85166ae5a/resourceGroups/gm_cloudreg_prod-workload-rg/providers/Microsoft.HDInsight/clusters/y4a8d1-metlloader-20200717-creg-prod-hdi\n- Location: {alphanumericpii}\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Observing issue while querying Hive 'Failed to execute tez graph',0.108346471,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Hive,failed Tez jobs,Needed system files were deleted,recreate cluster ,"196,964,321,196,964,000",,,,,,,
1.20072E+14,04:20.3,MapReduce activity is hanged,"Question: Which {Namepii} of {Namepii} Factory are you using?\nAnswer: \n\nQuestion: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Name of the problem pipeline(s) (separate with commas)\nAnswer: \n\nQuestion: JSON code of the affected pipeline\nAnswer: \n\nQuestion: Sample problem pipeline RunIDs (separate with commas)\nAnswer: \n\nQuestion: Sample problem activity RunIDs (separate with commas)\nAnswer: \n\nQuestion: Please provide additional details about the issue\nAnswer: MapReduce activity is hanged and it has been running for more than 15 hrs. Usually it tasks 2 hrs to complete.\nWe can see below error message in the yarn logs:\n----------------\nApplication {alphanumericpii} failed 5 times due to AM Container for {alphanumericpii} exited with exitCode: -{AlphanumericPII} more detailed output, check the application tracking page: http://hn0-hdppro.ne0iohsnpmmupav3s5kmi5rxta.cx.internal.cloudapp.net:8088/cluster/app/application_1594916237538_0006\n Then click on links to logs of each attempt.Diagnostics: Error getting info for file /{AlphanumericPII} GETFILESTATUS failed with {ALPHANUMERICPII} : nullLast\n encountered exception thrown after 5 tries. [HTTP500(null),HTTP500(null),HTTP500(null),HTTP500(null),HTTP500(null)][ServerRequestId:9d19781a-7df3-4934-961d-acb6dea6a5f1]{namepii}.microsoft.azure.datalake.store.ADLException: Error getting info for file /{AlphanumericPII}\n----\nADF {Namepii} Id - {guidpii}\nYarn Application {namepii} - {alphanumericpii}\n{Namepii} name - hdpprodwkcchiqest\n---\nWE would like to know why the job failed and why the failure was not propagated back to the ADF.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for {Namepii} Factory:\nWhich {Namepii} of {Namepii} Factory are you using? - ;\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nName of the problem pipeline(s) (separate with commas) - ;\nJSON code of the affected pipeline - ;\nSample problem pipeline RunIDs (separate with commas) - ;\nSample problem activity RunIDs (separate with commas) - ;\nPlease provide additional details about the issue - MapReduce activity is hanged and it has been running for more than 15 hrs. Usually it tasks 2 hrs to complete.\nWe can see below error message in the yarn logs:\n----------------\nApplication {alphanumericpii} failed 5 times due to AM Container for {alphanumericpii} exited with exitCode: -{AlphanumericPII} more detailed output, check the application tracking page: http://hn0-hdppro.ne0iohsnpmmupav3s5kmi5rxta.cx.internal.cloudapp.net:8088/cluster/app/application_1594916237538_0006\n Then click on links to logs of each attempt.Diagnostics: Error getting info for file /{AlphanumericPII} GETFILESTATUS failed with {ALPHANUMERICPII} : nullLast\n encountered exception thrown after 5 tries. [HTTP500(null),HTTP500(null),HTTP500(null),HTTP500(null),HTTP500(null)][ServerRequestId:9d19781a-7df3-4934-961d-acb6dea6a5f1]{namepii}.microsoft.azure.datalake.store.ADLException: Error getting info for file /{AlphanumericPII}\n----\nADF {Namepii} Id - {guidpii}\nYarn Application {namepii} - {alphanumericpii}\n{Namepii} name - hdpprodwkcchiqest\n---\nWE would like to know why the job failed and why the failure was not propagated back to the ADF.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/beff9f43-72bb-4e21-8072-4ac7f2ae04ea/resourceGroups/{namepii}-prodwk-cchiq-est/providers/Microsoft.DataFactory/factories/adfprodwkcchiqest\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MapReduce activity is hanged,18.93749694,Root Cause : HDInsight Service\Azure platform issues\Storage,"Routing Azure Data Factory V2\Pipeline Activities\HDInsight (Hive, MapReduce, Pig, Spark, Streaming)",Unable to run Map Reduce jobs,ADLS Gen 1 had an outage,"ADLS Gen 1 patchedRCA: the OS upgrade was flighting in a small percentage machines at ~7/17. During the OS flighting, the certificate permission which used for AAD authentication was removed. In general cases, the permission would be reapplied by the init-script when starting the ADLS service.However the init-script to reapply the permission to the certificate does not work in this case. The init-script cannot find the corresponding certificate. After investigation, DRI found out the init-script cannot grant permission to multiple certificates within the single command line. The schema of the input params need update. The mitigation was to update the schema of init-script to be able to find the certificate.Impact: during the incident, customer can get random 500 Internal server errors when the requests be routed to the flighting machines. ","197,384,712,197,553,000",,,,,,,
1.20072E+14,58:51.0,Prdsup - kpps83sparkespprdsupwus201 - History server (not aggregating comleted jobs),"Question: What time did the problem begin?\nAnswer: Fri, Jul 17, 2020, 9:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: Prdsup - {alphanumericpii} - History serve issue \n \nLog aggration is not being done for  comleted jobs)\n\n\n\nQuestion: Additional details about the issue\nAnswer: \n1. No errors in the logs \n2. log aggregation is enabled\n3.  system is not doing log aggregation for completed jobs\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - Prdsup - {alphanumericpii} - History serve issue \n \nLog aggration is not being done for  comleted jobs)\n\n;\nAdditional details about the issue - \n1. No errors in the logs \n2. log aggregation is enabled\n3.  system is not doing log aggregation for completed jobs\n\n;\n\n- ProblemStartTime: 07/17/2020 16:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ae52fda0-5ee6-4569-8573-987ae62bb0ec/resourceGroups/kp-{namepii}-cto-adfcore-prdsup-01/providers/Microsoft.HDInsight/clusters/kpps83sparkespprdsupwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Prdsup - kpps83sparkespprdsupwus201 - History server (not aggregating comleted jobs),0.028946468,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Prdsup - kpps83sparkespprdsupwus201 - History server (not aggregating comleted jobs),Prdsup - kpps83sparkespprdsupwus201 - History server (not aggregating comleted jobs),Recommended to validate svcazadfidps permissions on https://kpadlsgen2prdsupwus201.dfs.core.windows.net/kpps83sparkespprdsupwus201-cluster/app-logs path and update as required.,,,,,,,,
1.20072E+14,21:34.0,"Yarn UI is not loading, Resource Manager is Not running ","Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 16, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Stopped all the services and started. But still not loadin.\n\nQuestion: Additional details about the issue\nAnswer: Ambari and Yarn UI are not loading. Resource manager is not running.\n\n\n\n <Start:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Stopped all the services and started. But still not loadin.;\nAdditional details about the issue - Ambari and Yarn UI are not loading. Resource manager is not running.;\n\n- ProblemStartTime: 07/16/2020 07:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-NonProd-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a8e7f59d-5877-4efb-843b-f1a909b1c137/resourceGroups/perf-hdinsight-westus-rg-01/providers/Microsoft.HDInsight/clusters/perf-hdinsight-spark-01\n- Location: westus\n- Location: West US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Yarn UI is not loading, Resource Manager is Not running ",0.042800982,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,both RM in standby state,"Yarn UI is not loading, Resource Manager is Not running",Ran the following command - hdfs fsck hdfs://mycluster/ -delete to mitigate both RM in standby state,,,,,,,,
1.20072E+14,40:34.9,[Azure Government] Jobs cannot be submitted,"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 16, 2020, 6:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {Namepii} submission {namepii} ADF fails with error below.  {Namepii} never appears in YARN.  Same behaviour is seen on at least 3 instances of ADF + Spark.\n\n{\n    'computeInformation': 'https://DeCoreSparkBatchPPE.azurehdinsight.us',\n    'batchId': 2656,\n    'ExecutionProgress': 'Failed',\n    'effectiveIntegrationRuntime': 'DefaultIntegrationRuntime (USGov {Namepii})',\n    'executionDuration': 136,\n    'durationInQueue': {\n        'integrationRuntimeQueue': 0\n    },\n    'billingReference': {\n        'activityType': 'ExternalActivity',\n        'billableDuration': [\n            {\n                'meterType': 'AzureIR',\n                'duration': {Alphanumericpii},\n                'unit': 'Hours'\n            }\n        ]\n    }\n}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - {Namepii} submission {namepii} ADF fails with error below.  {Namepii} never appears in YARN.  Same behaviour is seen on at least 3 instances of ADF + Spark.\n\n{\n    'computeInformation': 'https://DeCoreSparkBatchPPE.azurehdinsight.us',\n    'batchId': 2656,\n    'ExecutionProgress': 'Failed',\n    'effectiveIntegrationRuntime': 'DefaultIntegrationRuntime (USGov {Namepii})',\n    'executionDuration': 136,\n    'durationInQueue': {\n        'integrationRuntimeQueue': 0\n    },\n    'billingReference': {\n        'activityType': 'ExternalActivity',\n        'billableDuration': [\n            {\n                'meterType': 'AzureIR',\n                'duration': {Alphanumericpii},\n                'unit': 'Hours'\n            }\n        ]\n    }\n};\n\n- ProblemStartTime: 07/17/2020 01:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PPE – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - ProDirect\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7ab74e9d-5466-4955-b717-acf76d07a2ca/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchPPE\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Jobs cannot be submitted,21.0196545,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,120071724003515 - [Azure Government] Jobs cannot be submitted,"When the hotfix was deployed for Fairfax on 3rd Aug, our internal storage account key was rotated accidentally and that caused our API roles to fail. We have restored the key, patched impacted areas and redeployed code.","After a hot fix was applied by the Product Group, all clusters are up and able to run jobs, except one, which you have already deleted and recreated.",197394720,,,,,,,
1.20072E+14,20:53.9,"Cluster is performing extremely slow, even though all the nodes and services are up and running","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: All operations on the cluster are slow\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Beeline\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} is performing extremely slow, even when the services and nodes are up and running. Also, the head nodes are continuously coming down without any reason.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - All operations on the cluster are slow;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Beeline;\nAdditional details about the issue - {Namepii} is performing extremely slow, even when the services and nodes are up and running. Also, the head nodes are continuously coming down without any reason.;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Investment {Namepii} Strategic Services (IMSS)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/de7ea9e6-f432-431e-9179-679474bec993/resourceGroups/RGIMDATALAKEDEV/providers/Microsoft.HDInsight/clusters/ahd501dj\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Cluster is performing extremely slow, even though all the nodes and services are up and running",3.174873446,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Hive,"Cluster is performing extremely slow, even though all the nodes and services are up and running",NA,"1. Increased the metastore DTU size from 50 to 100 and have gathered stats and rebuilt indexes and then see that CPU reduced,cluster is in healthy state.2. Ambari UI shows stale alerts on Wn0. Restarted ambari-agent on Wn0, where it clears stale alerts.3. Regarding YARN issue Yarn admin acls were changed - only yarn was the yarn admin. Zookeeper acls were changed to the /hadoop-ha path. Gateway was unable to find out who the active resource manager was.Whenever the active RM is on hn1, Gateway kept routing them to hn0. We failed it over to hn0 and it started working. We fixed the zookeeper ACLs, fixed the yarn admin ACLs and they were back to the expected state.","197,808,414,198,288,000",,,,,,,
1.20072E+14,18:29.4,Ambari Server is in failed status on hn0 (non-active),"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 9, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}:~# {namepii} systemctl status ambari-server\n-- ambari-server.service - ambari-server\n   Loaded: loaded (/etc/systemd/system/ambari-server.service; disabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since {Namepii} 2020-07-09 12:27:17 UTC; 1 weeks 1 days ago\n {Namepii} PID: 16653 (code=exited, {alphanumericpii})\n\nWarning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - {alphanumericpii}:~# {namepii} systemctl status ambari-server\n-- ambari-server.service - ambari-server\n   Loaded: loaded (/etc/systemd/system/ambari-server.service; disabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since {Namepii} 2020-07-09 12:27:17 UTC; 1 weeks 1 days ago\n {Namepii} PID: 16653 (code=exited, {alphanumericpii})\n\nWarning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.;\n\n- ProblemStartTime: 07/09/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Demand-Forecast-Release/providers/Microsoft.HDInsight/clusters/reldfh-azwus-hbasecluster\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Ambari Server is in failed status on hn0 (non-active),0.688849463,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Alerts firing on Services\Hbase,"root@hn1-reldfh:~# sudo systemctl status ambari-server -- ambari-server.service - ambari-server    Loaded: loaded (/etc/systemd/system/ambari-server.service; disabled; vendor preset: enabled)    Active: failed (Result: exit-code) since Thu 2020-07-09 12:27:17 UTC; 1 weeks 1 days ago  Main PID: 16653 (code=exited, status=143)  Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.",Ambari Server is in failed  status on hn0 (non-active),"This behavior is OK and would not  impact it in future  failover(s). Below is the manual  failover of  Ambari Server,# You might need to manually stop  Ambari server on previous active head  node.sudo systemctl stop  ambari-server# On current active  headnode, run the following command to stop master failover  controllersudo systemctl stop  master-failover-controller# On another headnode, run the  following command to start master failover  controller.sudo systemctl start  master-failover-controller",,,,,,,,
1.20072E+14,36:28.0,one of the worker node went down in prod,"Question: What time did the problem begin?\nAnswer: Sat, Jul 18, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Tried to ssh the worker node\n\nQuestion: Additional details about the issue\nAnswer: Tried to SSH to worker node 16 and getting 'server unexpected closed network connection' error message.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Tried to ssh the worker node;\nAdditional details about the issue - Tried to SSH to worker node 16 and getting 'server unexpected closed network connection' error message.;\n\n- ProblemStartTime: 07/17/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",one of the worker node went down in prod,0.057476578,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Vm inaccessable ,Out of space on VM,Reboot of VM ,,,,,,,,
1.20072E+14,15:55.6,Spark Thrift server is not starting. It is trying to connect to hive for very long time and getting failed,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 20, 2020, 3:00 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Restarted hive,zookeeper and spark server. still no luck\n\nQuestion: Additional details about the issue\nAnswer: ExecutionFailed: Execution of '! /{alphanumericpii} -u 'jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http'  -e '' | awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL' -e 'Error: Could not open'' returned 1. Error: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http. HTTP Response code: 500 ({AlphanumericPII})\nError: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http. HTTP Response code: 500 ({AlphanumericPII})\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Restarted hive,zookeeper and spark server. still no luck;\nAdditional details about the issue - ExecutionFailed: Execution of '! /{alphanumericpii} -u 'jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http'  -e '' | awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL' -e 'Error: Could not open'' returned 1. Error: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http. HTTP Response code: 500 ({AlphanumericPII})\nError: Could not open client transport with JDBC {Namepii}: jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http: Could not create http connection to jdbc:hive2://hn0-spark.y2yjuqvjt2ie3kcgkwqs0tp1qb.cx.internal.cloudapp.net:10002/default;transportMode=http. HTTP Response code: 500 ({AlphanumericPII});\n\n- ProblemStartTime: 07/20/2020 09:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Optumera_SaaS_POC\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f0e800b9-b753-41d6-bc7a-f87b6084672c/resourceGroups/opt-pri-perf/providers/Microsoft.HDInsight/clusters/spark-pri-hbase\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Thrift server is not starting. It is trying to connect to hive for very long time and getting failed,13.99231978,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Service unhealthy\Spark,When trying to restart spark from ambari it kept saying it was not able to connect to JDBC url,"Some jars are being copied into location /usr/hdp/current/spark2-client/jars/, which could potentially cause this issue.",moved few potential jars that CX may copied to /home/sshuser/backup/ in hn0 and hn1. (The CX may have to copy back needed JARs),"197,489,921,197,906,000",,,,,,,
1.20072E+14,30:32.3,all nodes are unhealthy,"Question: What time did the problem begin?\nAnswer: Sat, Jul 18, 2020, 6:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: {Namepii} node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: I restarted yarnui service , but doesn't help\n\nQuestion: Additional details about the issue\nAnswer: NodeManager Health Summary\n17 NodeManagers are unhealthy.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - {Namepii} node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - I restarted yarnui service , but doesn't help;\nAdditional details about the issue - NodeManager Health Summary\n17 NodeManagers are unhealthy.;\n\n- ProblemStartTime: 07/18/2020 13:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6900704a-e368-4960-9a99-ee57384d17ea/resourceGroups/HDInsightClusterResources/providers/Microsoft.HDInsight/clusters/ensfeatureworkcluster\n- Location: westcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",all nodes are unhealthy,0.076247006,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,node manager unhealthy,hdfs disk usage high,Provided suggestion to cleanup the disk and in case if this occurs frequently user needs to consider scaling up the cluster.,,,,,,,,
1.20072E+14,18:38.5,unable to delete cluster,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 20, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: see case #{Phonenumberpii} and {alphanumericpii}. PG had to delete the HDI cluster.\n\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} SDK.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - Not new, happened before;\nPrevious solution if applicable - see case #{Phonenumberpii} and {alphanumericpii}. PG had to delete the HDI cluster.\n;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - {Namepii} SDK.;\n\n- ProblemStartTime: 07/20/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: aerserv-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9ef27971-25ed-4df5-9b7e-46cb50431641/resourceGroups/aerserv-prod-eastus-{namepii}/providers/Microsoft.HDInsight/clusters/daily-adurlsreport-cluster-20200719\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to delete cluster,0.090723598,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to delete cluster,By design behavior. The customer will be able to issue a delete for a cluster in Operational state after 60 minutes since the cluster was last updated.,Waited 60+ min you will be implementing logic to retry deletion after 60 min until it is completed.,197364265,,,,,,,
1.20072E+14,26:51.6,ADF QA - kpq063sparkespadfqawus201 - HiS2 Interactive down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 21, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Validate config \n2. Restart HS2\n\nQuestion: Additional details about the issue\nAnswer: HS2 is down.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - 1. Validate config \n2. Restart HS2;\nAdditional details about the issue - HS2 is down.;\n\n- ProblemStartTime: 07/21/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-{namepii}-cto-edpcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq063sparkespadfqawus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ADF QA - kpq063sparkespadfqawus201 - HiS2 Interactive down,3.531971967,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,LLAP service doesnt start,LLPA server stuck in log aggregation phase,Disabled yarn level log aggregation,197635144,,,,,,,
1.20072E+14,51:04.7,Sqoop as parquet not working on HDInsight,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of job that experienced the issue?\nAnswer: Sqoop\n\nQuestion: YARN Application ID for the job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are trying to extract data from AWS redshift and import into the Azure Datalake using sqoop provided on HDInsight. We are facing issues when trying to import the data and write it to parquet format. It give an error as 'org.kitesdk.data.DatasetNotFoundException' . Please help with a resolution. Attaching the sqoop statement along with the error.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of job that experienced the issue? - Sqoop;\nYARN Application ID for the job if known - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nAdditional details about the issue - We are trying to extract data from AWS redshift and import into the Azure Datalake using sqoop provided on HDInsight. We are facing issues when trying to import the data and write it to parquet format. It give an error as 'org.kitesdk.data.DatasetNotFoundException' . Please help with a resolution. Attaching the sqoop statement along with the error.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LXK.DigitalTransformation.BigDecisions.Non-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/27f2890d-6e16-464f-853b-ae7f681978d5/resourceGroups/dev_qa_resource_group/providers/Microsoft.HDInsight/clusters/deventanalyticshdinsight\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sqoop as parquet not working on HDInsight,0.190837313,Root Cause : HDInsight Service\By Design\HDInsight,"Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\MapReduce, Pig, Sqoop or Oozie","Import command failing when the argument ""--as-parquetfiles"" is on, getting the followed error:org.kitesdk.data.DatasetNotFoundException: Unknown dataset URI pattern: dataset:adl://deventanalyticsdatalake.azuredatalakestore.net/RAW/CODEBREAKER/error_code_lookupCheck that JARs for adl datasets are on the classpath","Sqoop import jobs fail when trying to import data into parquet files on any of the storage (WASB, ADL Gen1 / Gen2)Sqoop on HDInsight Linux cluster does not support writing parquet files (--as-parquetfile option)Sqoop import completes successfully when we don't use parquet format to the same storage path (adl),  the issue is observed Only with parquet format.Cloudera claims that didn't receive any requirement from Microsoft about Sqoop and parquet loading. We never supported Sqoop-Parquet before.                     Parquet loading/import in HDI environment is not supported and never was.",Currently using Sqoop to write parquet files is not supported for HDInsight linux.  Product group is currently investigating on any workarounds and working with Cloudera to implement this feature to HDInsight.  As of right now this is not supported.  https://msdata.visualstudio.com/HDInsight/_search?text=kite&type=workitem&pageSize=25&filters=Projects%7BHDInsight%7D,,,,,,,,
1.20072E+14,52:45.5,Cluster Headnode unhealthy,"Question: What time did the problem begin?\nAnswer: Fri, Jul 17, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Spark History Server cannot come online on HN0.    Error message I'm seeing is\n\nConnection failed: [Errno 111] Connection refused to {alphanumericpii}\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Spark History Server cannot come online on HN0.    Error message I'm seeing is\n\nConnection failed: [Errno 111] Connection refused to {alphanumericpii}\n\n;\n\n- ProblemStartTime: 07/17/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Flash\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/42498c60-cc00-45c4-8ae5-db64072b7418/resourceGroups/captain-{namepii}-flash/providers/Microsoft.HDInsight/clusters/captain-{namepii}-flash\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cluster Headnode unhealthy,1.130804487,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,"Cluster Headnode unhealthy.resource_management.core.exceptions.ExecutionFailed:  Execution of '/usr/bin/apt-get -q -o Dpkg::Options::=--force-confdef  --allow-unauthenticated --assume-yes install liblzo2-2' returned 100. E: dpkg  was interrupted, you must manually run 'dpkg --configure -a' to correct the  problem.Exception in thread ""main""  org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException: The entity for  application application_1584397808761_15233 doesn't exist in the timeline  store       at  org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerOnTimelineStore.getApplication(ApplicationHistoryManagerOnTimelineStore.java:678)",Cluster Headnode unhealthy,"dpkg was interrupted on HN1, you must manually run 'dpkg --configure -a' to correct the problem and also rebooted the headnodes.",,,,,,,,
1.20072E+14,42:36.5,HBase Service Down,"Question: What time did the problem begin?\nAnswer: ‎7‎/‎21‎/‎2020‎ ‎11‎:‎41‎:‎00‎ ‎PM\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after {alphanumericpii}, exceptions:\n{Namepii} Jul 21 11:41:04 CDT 2020, null, java.net.SocketTimeoutException: {AlphanumericPII}, {AlphanumericPII}: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server {alphanumericpii} is not running yet\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after {alphanumericpii}, exceptions:\n{Namepii} Jul 21 11:41:04 CDT 2020, null, java.net.SocketTimeoutException: {AlphanumericPII}, {AlphanumericPII}: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server {alphanumericpii} is not running yet;\n\n- ProblemStartTime: 07/22/2020 04:41:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: HCSC Azure Test - Infrastructure\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/b896c19d-3467-4c2d-9e46-d93bf2eccc41/resourceGroups/appsvc_rg_Linux_centralus/providers/Microsoft.HDInsight/clusters/tazhdiucr002\n- Location: northcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HBase Service Down,1.111672204,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Service unhealthy\Hbase,HBase Service Down,there is an issue accessing the key vault that contains the key to access the storage account.,CUstomer opend a seperate case with Keyvault teamhttps://servicedesk.microsoft.com/#/customer/cases?caseNumber=120072324002349,197663309,,,,,,,
1.20072E+14,30:30.8,Application log missing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Azure Data Factory\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: I want to get application final status of a job just sent  2 days ago (7/20 9~10 am PST), but cannot get through `yarn application -list -appStates ALL` command\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Azure Data Factory;\nWhat is the programming language used? - Scala;\nSpark configuration details - N/A;\nAdditional details about the issue - I want to get application final status of a job just sent  2 days ago (7/20 9~10 am PST), but cannot get through `yarn application -list -appStates ALL` command;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-NAM-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1cda42e6-a623-4800-abdf-431ef3ec65e5/resourceGroups/o365ipdinam06-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdinam06-sp-wu01\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Application log missing,0.389620545,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Application log missing,Customer was unable to check the logs  and where they can be retrieved in the Spark history,"To find the information about the job is persisted in the Spark History Server:- From the overview page, select Spark History server under cluster dashboards. You can see all the completed applications listed. Selected an application ID to drill down into an application to know more details.Please refer to this link for more details: https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-job-debugging ",,,,,,,,
1.20072E+14,03:47.7,I would like to automate deletion of cluster based on idle/inactivity time,"The scenario is related to the cluster deletion based on a condition. For example: In case the cluster has been idle for x hours, delete it.\n\nProblem start date and time\nWed, Jul 22, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 07/22/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",I would like to automate deletion of cluster based on idle/inactivity time,0.098266825,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Delete HDInsight cluster,Automate cluster deletion feature ,NA,"no such feature now available , reached out to the PMs for a feedback. ",,,,,,,,
1.20072E+14,09:17.8,Error : Connection reset by peer:socket write error,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Never fixed\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: No specific query\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We use some third party in order to execute some queries on Hive (DBeaver, Sisense).\n\nRegarding DBeaver : {Namepii} 'first' execution of a query after a certain delay, we get this error.\nRegarding Sisense : When we try to compile data, we have this trouble.\nPlease find the full error message in the screenshot.\n\nThis issue occurs since a {namepii} time. We wish to fix it definitively .\nThanks a lot for support\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Never fixed;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - No specific query;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We use some third party in order to execute some queries on Hive (DBeaver, Sisense).\n\nRegarding DBeaver : {Namepii} 'first' execution of a query after a certain delay, we get this error.\nRegarding Sisense : When we try to compile data, we have this trouble.\nPlease find the full error message in the screenshot.\n\nThis issue occurs since a {namepii} time. We wish to fix it definitively .\nThanks a lot for support;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Error : Connection reset by peer:socket write error,0.139064462,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,Issue: Error : Connection reset by peer:socket write error while connecting to HDInsight from third party clients such as Dbeaver and SiSense,Cause: Client idle timeout setting.,"Resolution: Client is disconnecting the connection if it is idle, and even though it throws this error message on the first attempt it still manages to connect fine on the second run. Change the Client level setting “Keep alive” on DBeaver and sisense is a third party application and you have reached out to their support team to help.",,,,,,,,
1.20072E+14,42:04.5,Problems to send email alerts in Ambari,We have problems trying to send email alerts using HDInsight. We enter the email address and the email isnt saved. What's the procedure to configure email alerts?\n\nWe tried to follow this doc but no luck: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-cluster-availability\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} OMEGA Non-Productive\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Problems to send email alerts in Ambari,0.250445501,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hadoop,Problems to send email alerts in Ambari,Needed to use Azure Send Grid email account as the mail server,Instructions sent out to set-up notifications via Send Grid email account as the mail server ,,,,,,,,
1.20072E+14,10:19.5,Unable ti publish messages from kafka to spark ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Unable to publish message on a topic\nCommand:\n/usr/hdp/3.1.2.7-1/kafka/bin/kafka-console-producer.sh --broker-list wn0-chkp22.domainservices.ncr.com:9092,wn1-chkp22.domainservices.ncr.com:9092,wn2-chkp22.domainservices.ncr.com:9092 --topic {ALPHANUMERICPII}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - Unable to publish message on a topic\nCommand:\n/usr/hdp/3.1.2.7-1/kafka/bin/kafka-console-producer.sh --broker-list wn0-chkp22.domainservices.ncr.com:9092,wn1-chkp22.domainservices.ncr.com:9092,wn2-chkp22.domainservices.ncr.com:9092 --topic {ALPHANUMERICPII};\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP25ADLSTREAM\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable ti publish messages from kafka to spark ,0.064508297,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Kafka,Unable ti publish messages from kafka to spark,Unable ti publish messages from kafka to spark ,"As recommended in the other case, decided to create a new Spark cluster under the Kafka cluster VNET\SUBNET similar to Prod environment",,,,,,,,
1.20072E+14,18:01.4,Problemas na Atualização do Certificado do Cluster hdinsights ,"Cliente: Telefonica S.A\nSubscription: Microsoft Azure 1\nRecurso: HDInsights\nGrupo {namepii} Recurso: pro-mls\nDescrição: Não estamos conseguindo atualizar o certificado do cluster hdinsights que expirou para o novo certificado.\nSeguimos a documentação {namepii} azure e rodamos o script para atualização do certificado, entretanto o mesmo está retornando {namepii} erro 500.\nSegue link {namepii} documentação: https://docs.microsoft.com/pt-br/azure/hdinsight/hdinsight-hadoop-use-data-lake-store\nSegue erro no cluster ao executar o comando hdfs: \n \nSegue novo certificado já configurado no service principal:\n \n\nSegue motivo do erro em anexo.\nSegue script usado para atualização do certificado em anexo.\nSegue erro do script:\nInvoke-AzResourceAction : {'code':'InternalServerError','message':'ErrorCode: Unexpected workflow execution exception;\nErrorDescription: Unexpected workflow execution exception'}\n\nConsegue nos ajudar com esta demanda?\n\nQualquer dúvida estou à disposição.\n\nAbraços,\n\n{Namepii} {Namepii}\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure 1\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: \n- SubscriptionType: CSP\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Provedor {namepii} Soluções {namepii} Nuvem\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: global\n- ResourceUri: /subscriptions/7b0bcc15-eef6-4181-b9fe-23bc213ce163/resourceGroups/AzureRM-telefonica/providers/Microsoft.CertificateRegistration/certificateOrders/certbigdatawild\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Problemas na Atualização do Certificado do Cluster hdinsights ,0.231118615,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure App Service Certs\Renewing/Rekeying,"Client was following instructions on the documentation () and during the script execution the got;Invoke-AzResourceAction : {'code':'InternalServerError','message':'ErrorCode: Unexpected workflow execution exception; ErrorDescription: Unexpected workflow execution exception'}",Known bug on the process to renew certificates for HDInsight clusters.,PG needs to do it manually,197913304,,,,,,,
1.20072E+14,34:20.4,Seeing -mv: Fatal internal error java.lang.NullPointerException.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 21, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: none\n\nQuestion: Additional details about the issue\nAnswer: Seeing -mv: Fatal internal error java.lang.NullPointerException while trying to move all files and directories in from one directory to another. Attached screenshot.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - none;\nAdditional details about the issue - Seeing -mv: Fatal internal error java.lang.NullPointerException while trying to move all files and directories in from one directory to another. Attached screenshot.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/21/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Demand-Forecast-Release/providers/Microsoft.HDInsight/clusters/reldfs-azwus-spark\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Seeing -mv: Fatal internal error java.lang.NullPointerException.,0.161292153,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\hdfs commands do not work\Azure Storage in standard cluster,Fatal internal error java.lang.NullPointerException.,Issue: Seeing -mv: Fatal internal error java.lang.NullPointerException.,"Resolution: Traditional copy to storage explorer would not include ""hadoop-azure"" module functionality and HDIsight carries it. So we would recommend you to use HDFS command way copy to avoid this issue. Link: https://hadoop.apache.org/docs/current/hadoop-azure/index.html",,,,,,,,
1.20072E+14,47:29.7,"Exception seen while running Spark job (Spark 2.4, HDI 4.0)","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: Exception details attached in text file with this ticket.\n\nQuestion: Additional details about the issue\nAnswer: Exception details attached in text file with this ticket.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - Scala;\nSpark configuration details - Exception details attached in text file with this ticket.;\nAdditional details about the issue - Exception details attached in text file with this ticket.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Pivotal-Stratus-Prod-Extra\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/135d2085-e95f-4550-b69c-4b5ec0c17f9a/resourceGroups/az-iauc-prod-westus-{namepii}-01/providers/Microsoft.HDInsight/clusters/iauc-prod-hdinsight-spark-01\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Exception seen while running Spark job (Spark 2.4, HDI 4.0)",0.093140374,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,below error while running your Spark job.java.lang.IllegalAccessError: class org.apache.hadoop.hdfs.web.HftpFileSystem cannot access its superinterface org.apache.hadoop.hdfs.web.TokenAspect$TokenManagementDelegator,Version mismatch for Hadoop\Spark,User rebuilt the application with Spark 2.4.4 and Hadoop client libraries version 3.1.1 and reported that the jobs are executing as expected.,,,,,,,,
1.20072E+14,04:55.8,Informatica BDM jobs failed on Azure cluster,"Question: What time did the problem begin?\nAnswer: Sat, Jul 18, 2020, 9:58 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: it is a Informatica BDM jobs\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Informatica BDM jobs submitted on Azure HDI cluster and it failed with {Namepii} transportatio error. when we checked the logs it shows job is running beyond physical memory limits. snippet from the logs '2020-07-18 {Alphanumericpii} AMRM Callback {Namepii} Thread INFO: Container completion status: \n{namepii} [{alphanumericpii}]; state [COMPLETE]; \ndiagnostics [Container [{AlphanumericPII}] is running beyond physical memory limits. \nCurrent usage: 8.1 GB of 8.0 GB physical memory used; 14.4 GB of 16.8 GB virtual memory used. Killing container'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - it is a Informatica BDM jobs;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Informatica BDM jobs submitted on Azure HDI cluster and it failed with {Namepii} transportatio error. when we checked the logs it shows job is running beyond physical memory limits. snippet from the logs '2020-07-18 {Alphanumericpii} AMRM Callback {Namepii} Thread INFO: Container completion status: \n{namepii} [{alphanumericpii}]; state [COMPLETE]; \ndiagnostics [Container [{AlphanumericPII}] is running beyond physical memory limits. \nCurrent usage: 8.1 GB of 8.0 GB physical memory used; 14.4 GB of 16.8 GB virtual memory used. Killing container';\n\n- ProblemStartTime: 07/18/2020 13:58:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii} BI PRD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /{AlphanumericPII}\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Informatica BDM jobs failed on Azure cluster,0.989076481,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Hive,Informatica BDM jobs failed on Azure cluster.,Job is intermittently failing because the YARN containers are running beyond physical memory limits.There is a check placed at Yarn level for Virtual and Physical memory usage ratio. Issue is not only that VM doesn't have sufficient physical memory. But it is because Virtual memory usage is more than expected for given physical memory.,"Increase VM:PM ratio by setting yarn.nodemanager.vmem-pmem-ratio to some higher value, by default it is 2.1.",,,,,,,,
1.20072E+14,42:48.9,[Azure Government] Confirm MSI certificate renewal,"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 23, 2020, 3:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Case {Phonenumberpii} tracks a certificate renewal issue on our PPE clusters.\n\nSupport requested a new case to track confirming whether our Prod clusters are at risk of failure for the same issue:\n- decoresparkbatchprod\n- decoresparkbatchsharedprod\n- desparkbatchprod\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Case {Phonenumberpii} tracks a certificate renewal issue on our PPE clusters.\n\nSupport requested a new case to track confirming whether our Prod clusters are at risk of failure for the same issue:\n- decoresparkbatchprod\n- decoresparkbatchsharedprod\n- desparkbatchprod\n;\n\n- ProblemStartTime: 07/23/2020 22:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PROD – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - ProDirect\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchProd\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Confirm MSI certificate renewal,0.890892865,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,MSI certificate renewals failing,Regression in certificate renewal workflow that required a bug fix.,PG deployed the fix to the FairFax region,,,,,,,,
1.20072E+14,02:40.3,Service Stuck registering/unregistering,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 23, 2020, 12:00 AM MDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: Microsoft.HDInsight\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We tried to register the Microsoft.HDInsight resource provider and it hung. We tried to unregister and that hung.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - Microsoft.HDInsight;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We tried to register the Microsoft.HDInsight resource provider and it hung. We tried to unregister and that hung.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/23/2020 06:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}'s sub\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: {Namepii}\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - {Namepii}\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Service Stuck registering/unregistering,21.60283265,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Customer is unable to Unregister the Resource Provider ""Microsoft.HDInsight""","The resource provider's unregistration endpoint is not returning success for the unregistration call from ARMNotes from the customer:""We hit an edge case that no one had not thought of.  Really long story short. We had a sponsored subscription. It ran out of money. We were given a new sponsored subscription. We moved the tenant to the new subscription. HDI could not register, because there was a registration left over from the original subscription in the tenant.""",Resolved by: https://portal.microsofticm.com/imp/v3/incidents/details/198342177/home,198342177,,,,,,,
1.20072E+14,45:44.4, The Number of nodes used by Hive's LLAP Config issue,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Interactive Query job if known\nAnswer: \n\nQuestion: Interactive query if applicable\nAnswer: The Number of nodes used by Hive's LLAP on the summary config  page on the Hive configuration not carried over to the Advanced configuration page.\n\nQuestion: Interactive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the interactive query submitted?\nAnswer: {Namepii}\n\nQuestion: Additional details about the issue\nAnswer: The Number of nodes used by Hive's LLAP on the summary config  page on the Hive configuration not carried over to the Advanced configuration page.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Interactive Query job if known - ;\nInteractive query if applicable - The Number of nodes used by Hive's LLAP on the summary config  page on the Hive configuration not carried over to the Advanced configuration page.;\nInteractive query explain plan if available - ;\n{Namepii} was the interactive query submitted? - {Namepii};\nAdditional details about the issue - The Number of nodes used by Hive's LLAP on the summary config  page on the Hive configuration not carried over to the Advanced configuration page.;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-{namepii}-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq101llapfdqawus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n", The Number of nodes used by Hive's LLAP Config issue,0.009590477,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Interactive Query,The Number of nodes used by Hive's LLAP Config issue,The Number of nodes used by Hive's LLAP Config issue,"Based on your configuration changes, Ambari is recommending the following dependent configuration changes. Ambari will update all checked configuration changes to the Recommended Value. Uncheck any configuration to retain the Current Value.",,,,,,,,
1.20072E+14,51:20.2,2.'NoneType' object has no attribute 'split' showing in alerts on wn404. ,"Question: What time did the problem begin?\nAnswer: Fri, Jul 24, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Microsoft fixed on back end.\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: I am working with {Namepii} {Namepii} {Namepii} at {emailpii}@microsoft.com.  Please assign this case to him.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Microsoft fixed on back end.;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - I am working with {Namepii} {Namepii} {Namepii} at {emailpii}@microsoft.com.  Please assign this case to him.;\n\n- ProblemStartTime: 07/24/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ba4526ea-6a69-40d2-8f7b-8f7a10dbafdf/resourceGroups/gehc-datasvc-spark-01/providers/Microsoft.HDInsight/clusters/dtspwsuwsparkcluster1a\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",2.'NoneType' object has no attribute 'split' showing in alerts on wn404. ,0.012289283,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling down,'NoneType' object has no attribute 'split' showing in alerts on wn404.,Issue: 2.'NoneType' object has no attribute 'split' showing in alerts on wn404.,"Resolution: Followed below steps to mitigate the issue,Restarted the ambari-agent on wn404 and it mitigated the issueIdentify process ID (pid) of ambari-agent:ps -ef | grep ambari_agentRestart ambari-agent to mitigate issue:service ambari-agent restartIf restart does not work, kill the ambari-agent process and then start it up:kill -9 <ambari-agent-pid>Service ambari-agent startAs discussed, if it happen again please run ""top"" command on the where you see this issue and share the usage with us. ",193201295,,,,,,,
1.20073E+14,27:47.1,Sandbox - kps050sparkadfsbwus201 - oozie can't  run spark submit,"Question: What time did the problem begin?\nAnswer: Fri, Jul 24, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: Not applicable.\n\nQuestion: Additional details about the issue\nAnswer: \nError invoking spark-submit through Oozie\n\n--- Invocation of {Namepii} class completed ---\n \nFailing Oozie Launcher, {Namepii} class [org.apache.oozie.action.hadoop.SparkMain], exception invoking main(), java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\njava.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\nCaused by: java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 9 more\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - Not applicable.;\nAdditional details about the issue - \nError invoking spark-submit through Oozie\n\n--- Invocation of {Namepii} class completed ---\n \nFailing Oozie Launcher, {Namepii} class [org.apache.oozie.action.hadoop.SparkMain], exception invoking main(), java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\njava.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\nCaused by: java.lang.ClassNotFoundException: Class org.apache.oozie.action.hadoop.SparkMain not found\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        ... 9 more\n;\n\n- ProblemStartTime: 07/24/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-{namepii}-cto-edpcore-sandbox-01/providers/Microsoft.HDInsight/clusters/kps050sparkadfsbwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sandbox - kps050sparkadfsbwus201 - oozie can't  run spark submit,0.342776608,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Spark,Sandbox - kps050sparkadfsbwus201 - oozie can't run spark submit,Sandbox - kps050sparkadfsbwus201 - oozie can't run spark submit,"o hdfs dfs -mkdir /user/oozie/share/lib/spark2o hdfs dfs -put  /usr/hdp/current/spark2-client/jars/* /user/oozie/share/lib/spark2o hdfs dfs  -cp /user/oozie/share/lib/spark/oozie-sharelib-spark-*.jar  /user/oozie/share/lib/spark2/o hdfs dfs -put  /usr/hdp/current/spark2-client/conf/hive-site.xml  /user/oozie/share/lib/spark2/o hdfs dfs -put  /usr/hdp/current/spark2-client/python/lib/py*  /user/oozie/share/lib/spark2/o oozie admin –sharelibupdate and oozie admin  –sharelibupdate spark2o oozie admin –shareliblist spark2o Spark job with  the spark2 ShareLib, add the action.sharelib.for.spark property to the  job.properties file, and set its value to spark2:             oozie.action.sharelib.for.spark=spark2o Also add “--conf  spark.executor.extraLibraryPath=/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64”  to Oozie spark action",198824981,,,,,,,
1.20073E+14,38:41.6,None of Azure HDInsight resource is having acceess in its underlying source. ie : ADLS Gen-1,"Question: What time did the problem begin?\nAnswer: Sat, 25 Jul, 2020, 9:00 am IST\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: On every cluster which is comes under prod subscription\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: We are usong OnDemand cluster and currently our hadoop SP certificate/thrumbprint got expired. After that we are unable to access the ADLS and some of the cluster is not able too up and running state.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: We are usong OnDemand cluster and currently our hadoop SP certificate/thrumbprint got expired. After that we are unable to access the ADLS and some of the cluster is not able too up and running state. We are trying to trigger it from ADF as well as from the {Namepii} Runbook.\n\n{Namepii}-AzureRmResourceGroupDeployment : 8:35:36 PM - Resource Microsoft.HDInsight/clusters '{alphanumericpii}' failed with message '{ 'code': 'BadRequest', 'message': 'DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Error while getting access to the datalake storage account {alphanumericpii}: The specified network password is not correct.{uncpii}\n.',DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Service Principal Details are invalid - The specified network password is not correct.{uncpii}\n'' }' At {alphanumericpii} {alphanumericpii} + {Namepii}-AzureRmResourceGroupDeployment -Name $DeploymentName -Res ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [{Namepii}-AzureRmResourceGroupDeployment], Exception + FullyQualifiedErrorId : Microsoft.{Namepii}.Commands.ResourceManager.Cmdlets.Implementation.NewAzureResourceGroupDeploymentCmdlet\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - On every cluster which is comes under prod subscription;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - We are usong OnDemand cluster and currently our hadoop SP certificate/thrumbprint got expired. After that we are unable to access the ADLS and some of the cluster is not able too up and running state.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - We are usong OnDemand cluster and currently our hadoop SP certificate/thrumbprint got expired. After that we are unable to access the ADLS and some of the cluster is not able too up and running state. We are trying to trigger it from ADF as well as from the {Namepii} Runbook.\n\n{Namepii}-AzureRmResourceGroupDeployment : 8:35:36 PM - Resource Microsoft.HDInsight/clusters '{alphanumericpii}' failed with message '{ 'code': 'BadRequest', 'message': 'DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Error while getting access to the datalake storage account {alphanumericpii}: The specified network password is not correct.{uncpii}\n.',DeploymentDocument '{AlphanumericPII}' failed the validation. Error: 'Service Principal Details are invalid - The specified network password is not correct.{uncpii}\n'' }' At {alphanumericpii} {alphanumericpii} + {Namepii}-AzureRmResourceGroupDeployment -Name $DeploymentName -Res ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [{Namepii}-AzureRmResourceGroupDeployment], Exception + FullyQualifiedErrorId : Microsoft.{Namepii}.Commands.ResourceManager.Cmdlets.Implementation.NewAzureResourceGroupDeploymentCmdlet;\n\n- ProblemStartTime: 07/25/2020 03:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: diageo-analytics-prod\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3a683d84-be08-4356-bb14-3b62df1bad55/resourceGroups/diageo-analytics-prod-{namepii}-depletion/providers/Microsoft.HDInsight/clusters/diageo-eun-analytics-prod-hdi-hd-depletion-prd01\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",None of Azure HDInsight resource is having acceess in its underlying source. ie : ADLS Gen-1,0.022169461,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,None of Azure HDInsight resource is having acceess in its underlying source. ie : ADLS Gen-1,None of Azure HDInsight resource is having acceess in its underlying source. ie : ADLS Gen-1,"Followed below steps, Next, convert the SecretValueText to a certificate. $certObject = New-Object System.Security.Cryptography.X509Certificates.X509Certificate2 -ArgumentList $certValue,$null,""Exportable, PersistKeySet""$certBytes = $certObject.Export([System.Security.Cryptography.X509Certificates.X509ContentType]::Pkcs12, $certPassword);   <<< Updated $certPassword.SecretValueText to $certPassword$identityCertificate = [System.Convert]::ToBase64String($certBytes)Then you can use the $identityCertificate to deploy a new cluster as in the following snippet:New-AzResourceGroupDeployment `    -ResourceGroupName $resourceGroupName `    -TemplateFile $pathToArmTemplate `    -identityCertificate $identityCertificate `    -identityCertificatePassword $certPassword `   <<<< Updated $certPassword.SecretValueText to $certPassword    -clusterName  $clusterName `    -clusterLoginPassword $SSHpassword `    -sshPassword $SSHpassword `    -servicePrincipalApplicationId $application.ApplicationId Link: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-use-data-lake-store#refresh-the-hdinsight-certificate-for-data-lake-storage-gen1-access",198058362,,,,,,,
1.20073E+14,48:33.7,delta as a format is not working in the cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: Starting the spark-shell using the delta jar and not able to read/write tin delta format.\n\nspark-shell --packages {alphanumericpii} --conf 'spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension' --conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog'\n\n val subDelta=spark.read.format('delta').load('wasbs://subscriptiondelta@airsteststorage.blob.core.windows.net/subscriptions/').cache()\n\n\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - N/A;\nAdditional details about the issue - Starting the spark-shell using the delta jar and not able to read/write tin delta format.\n\nspark-shell --packages {alphanumericpii} --conf 'spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension' --conf 'spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog'\n\n val subDelta=spark.read.format('delta').load('wasbs://subscriptiondelta@airsteststorage.blob.core.windows.net/subscriptions/').cache()\n\n\n\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: AIRS {Namepii} Services - DevTest\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: SpecialFree\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Special entitlement - Highest SLA\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1d597868-d7dd-4cf6-8374-af5ffc56a781/resourceGroups/airsteststreaming/providers/Microsoft.HDInsight/clusters/sponsorshipstreamingtest\n- Location: southcentralus\n- Location: South Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",delta as a format is not working in the cluster,0.355315487,Root Cause : HDInsight Service\User Subscription issues,Routing Azure HDInsight V5\Query or Job Failure\Spark,"When client wants to use the package io.delta:delta-core_2.11:0.6.1 to use the function:1) val someDF = Seq((8, ""bat""),(64, ""mouse""),(-27, ""horse"")).toDF(""number"", ""word"")2) someDF.write.format(""delta"").mode(""append"").save(""<path>"")Was getting; com.google.common.util.concurrent.ExecutionError: java.lang.NoSuchMethodError: com.fasterxml.jackson.module.scala.experimental.ScalaObjectMapper.com$fasterxml$jackson$module$scala$experimen                                                                  ... 49 elidedCaused by: java.lang.NoSuchMethodError:com.fasterxml.jackson.module.scala.experimental.ScalaObjectMapper.com$fasterxml$jackson$module$scala$experimental$ScalaObjectMapper$_setter_$com$fast                                                                erxml$jackson$module$scala$experimental$ScalaObjectMapper$$MAP_$eq(Ljava/lang/Class;)V",Every time client was creating a HDInsight Spark cluster it would created a HDI 4.0.1000 instead of the 4.0.2000 version.His code works fine on HDI 4.0.2 version,"The CX asked to use the distro version, which has the working Jackson JARs. FEATURE_DISTRO capability has been added via Jarivis action (HDInsight > Service Management > Update/Insert per subscription capability override) for the subscription 1d597868-d7dd-4cf6-8374-af5ffc56a781:Grant/Deny capability override operation completed successfully. SubscriptionId: 1d597868-d7dd-4cf6-8374-af5ffc56a781, CapabilityName: FEATURE_DISTRO, Grant/Deny: Grant",198201250,,,,,,,
1.20073E+14,41:23.8,Unpin request ,Unpin HDI cluster in Central US region from DEV Subscription\nUnpin HDI cluster in EAST US 2 region from DEV Subscription \nUnpin HDI cluster in Central US region from PROD Subscription\n\nPlease donot touch EAST US 2 region from PROD Subscription.\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_PROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,Unpin request ,0.490384085,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Unexpected result\Spark,Unpin Request ,Unpin Request ,PG team unpinned the requested Subscriptions,198211254,,,,,,,
1.20073E+14,33:45.7,Connection failure from kafka to spark cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We ran netstat and found that {ALPHANUMERICPII} and {ALPHANUMERICPII} kafka cluster brokers are not reachable by {Namepii} Spark {Namepii} {ALPHANUMERICPII}. We have contacted SOUP {Namepii} to publish messages \nAnalysis Stats on CERT:\nConnectivity  b/w new Spark {Namepii} & {Namepii} {Namepii} --Timed Out -- No Connectivity\nAnalysis Stats on PROD:\nConnectivity  b/w new Spark {Namepii} & {Namepii} {Namepii} -- Succeeded\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - We ran netstat and found that {ALPHANUMERICPII} and {ALPHANUMERICPII} kafka cluster brokers are not reachable by {Namepii} Spark {Namepii} {ALPHANUMERICPII}. We have contacted SOUP {Namepii} to publish messages \nAnalysis Stats on CERT:\nConnectivity  b/w new Spark {Namepii} & {Namepii} {Namepii} --Timed Out -- No Connectivity\nAnalysis Stats on PROD:\nConnectivity  b/w new Spark {Namepii} & {Namepii} {Namepii} -- Succeeded\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/CHKP25ADLSTREAM\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Connection failure from kafka to spark cluster,0.152770208,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Kafka,Unable to connect between kafka and spark clusters,Kafka and Spark clusters were in different VNET\SNET,Created a new Spark cluster in same vnet subnet,,,,,,,,
1.20073E+14,35:18.4,Receiving FailedToConnectWithClusterThroughGatewayErrorCode on deployment,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 27, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: No changes made to the VNet, route table, nsg, firewall or storage table.  The template used to deploy the cluster has been deployed consistently over the last 6 months.  {Namepii} change is that we are {namepii} new features in central us where this subscription was whitelisted.\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: Worked last week.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - No changes made to the VNet, route table, nsg, firewall or storage table.  The template used to deploy the cluster has been deployed consistently over the last 6 months.  {Namepii} change is that we are {namepii} new features in central us where this subscription was whitelisted.;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - Worked last week.;\n\n- ProblemStartTime: 07/27/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/66d6093c-2dac-4eaa-ae4f-fe18bcd3a6cd/resourceGroups/hdipoc-hdi002-{namepii}/providers/Microsoft.HDInsight/clusters/hdi201\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Receiving FailedToConnectWithClusterThroughGatewayErrorCode on deployment,0.066036521,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Cluster creation failing with : FailedToConnectWithClusterThroughGatewayErrorCode,Cause: Private Preview of HDInsight Azure Private link capabilities reset on the Test Subscription. ,Resolution : Help from Sathvik to enable the capability back. ,,,,,,,,
1.20073E+14,09:23.3,Plz delete all the resources from this subscription,"I remeber deleting everything, but can you plz delete all the resources from this subscription (if any)\n\nProblem start date and time\nWed, {Namepii} 10, 2020, 12:00 AM EDT\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 06/10/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Experiments - Microsoft Azure Internal Consumption\n- PUID: {Xuidpii}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Plz delete all the resources from this subscription,0.99520437,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Delete HDInsight cluster,Plz delete all the resources from this subscription,na,"The resource group ASI-RG shows up when you select ""all subscriptions"". The Resoruce group ASI-RG is under a different subscription 97227f43-3143-4d5f-921c-bc9de25314e2. Since the subcription ID belongs to someone else, you do not have the admin permissions to delete the resource group.  Therefore, when you select all-subscriptions it is showing under your resource groups because you might be tagged under that resource group. ",,,,,,,,
1.20073E+14,41:11.5,Anaconda installation failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: Anaconda installation failing on cluster:\n\n{namepii}  /usr/bin/anaconda/bin/conda  create  --prefix /{alphanumericpii}  python=3.7  anaconda  --yes\n\n\ngetting below error:\n\nanaconda-2020. 100% |####################################################################################################################################################| Time: {Alphanumericpii}  26.13 MB/s\n\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - NA;\nAdditional details about the issue - Anaconda installation failing on cluster:\n\n{namepii}  /usr/bin/anaconda/bin/conda  create  --prefix /{alphanumericpii}  python=3.7  anaconda  --yes\n\n\ngetting below error:\n\nanaconda-2020. 100% |####################################################################################################################################################| Time: {Alphanumericpii}  26.13 MB/s\n\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\nCondaError: UnicodeDecodeError('ascii', '/info/{namepii}/tests/data/{uncpii}\x94{uncpii}\xeb{uncpii}\x9c{uncpii}\xb7{uncpii}\xeb{uncpii}\xa8.README', 22, 23, 'ordinal not in {alphanumericpii})')\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GM_CLOUDREG_DEV\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/gm_cloudreg_qa-cat-csqa-{namepii}/providers/Microsoft.HDInsight/clusters/vc96ex-fbco-07272020-cat-qa-hdi\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Anaconda installation failing,0.355098312,Root Cause : HDInsight Service\Bug\Other,Routing Azure HDInsight V5\Unexpected result\Spark,Anaconda installation failing,"There's a known bug for Anaconda version 4.7.11, 4.7.12, and 4.8.0. If you see your script actions stops responding at ""Collecting package metadata (repodata.json): ...working..."" and failing with ""Python script has been killed due to timeout after waiting 3600 secs"". You can download this script and run it as script actions on all nodes to fix the issue.",To mitigate it please run the folowing ...please  run the following script action from the portal... on the Headnodes and Workernodes https://gregorysfixes.blob.core.windows.net/public/fix-conda.sh After that runs go ahead and run ...sudo  /usr/bin/anaconda/bin/conda  create  --prefix /usr/bin/anaconda/envs/py37  python=3.7  anaconda  --yes,198369479,,,,,,,
1.20073E+14,34:21.3,Spark2 is not starting,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are not able to start {alphanumericpii} even tried so many times to start it\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are not able to start {alphanumericpii} even tried so many times to start it;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: GBS_IoTPlatform\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/50456edb-757e-4cbc-94bb-44bf85acc96e/resourceGroups/SITGEN-SPARK/providers/Microsoft.HDInsight/clusters/gensitsparkhdidq\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark2 is not starting,1.475054062,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Spark,All job failures that was submitted to the cluster,Customer trying to start the HA services on both headnodes.The Bad Vm for hn1 is causing the cluster to unhealthy,The HA services should be only started in active headnodecx recreated a new cluster to resolve the issue ,198553956,,,,,,,
1.20073E+14,27:12.3,Kerbaroes TGT errors causing production jobs failing,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 28, 2020, 12:00 AM {NAMEPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 28, 2020, 12:00 AM {NAMEPII}\n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the {Namepii} node?\nAnswer: Yes\n\nQuestion: Does authentication fail even for the cluster {namepii} account?\nAnswer: No\n\nQuestion: Have you logged in to Ambari as local {namepii} and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: All our productions jobs are failing with the below token error eventhough service account has the valid TGT for the crontab session - Since it is production, please need help ASAP.\n\n20/07/28 11:44:16 ERROR secure.AbstractCredentialServiceCaller: Error while authenticating with endpoint: https://hn0-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM&requestid=04515d00-46bb-4642-b67b-24f9022f7083\norg.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: https://hn0-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM&requestid=04515d00-46bb-4642-b67b-24f9022f7083\n        at {namepii}.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at {namepii}.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at {namepii}.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(AbstractCredentialServiceCaller.java:116)\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.access$000(AbstractCredentialServiceCaller.java:27)\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller$1.run(AbstractCredentialServiceCaller.java:92)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(AbstractCredentialServiceCaller.java:88)\n        at {namepii}.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(CredentialServiceClientImpl.java:91)\n        at {namepii}.microsoft.azure.storage.oauth2.DelegationTokenManager.getDelegationToken(DelegationTokenManager.java:33)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the {Namepii} node? - Yes;\nDoes authentication fail even for the cluster {namepii} account? - No;\nHave you logged in to Ambari as local {namepii} and verified the users have been synced? - ;\nAdditional details about the issue - All our productions jobs are failing with the below token error eventhough service account has the valid TGT for the crontab session - Since it is production, please need help ASAP.\n\n20/07/28 11:44:16 ERROR secure.AbstractCredentialServiceCaller: Error while authenticating with endpoint: https://hn0-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM&requestid=04515d00-46bb-4642-b67b-24f9022f7083\norg.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: https://hn0-sprk01.petsmartazureds.com:50910/tokenmanager/v1/?op=GETDELEGATIONTOKEN&service=ABFS_DT_SERVICE&user.name=svc-hdi_azure_aa&renewer=rm%2Fhn0-sprk01.petsmartazureds.com%40PETSMARTAZUREDS.COM&requestid=04515d00-46bb-4642-b67b-24f9022f7083\n        at {namepii}.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at {namepii}.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at {namepii}.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.retryableCall(AbstractCredentialServiceCaller.java:116)\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.access$000(AbstractCredentialServiceCaller.java:27)\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller$1.run(AbstractCredentialServiceCaller.java:92)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n        at {namepii}.microsoft.azure.storage.secure.AbstractCredentialServiceCaller.call(AbstractCredentialServiceCaller.java:88)\n        at {namepii}.microsoft.azure.storage.secure.CredentialServiceClientImpl.getDelegationToken(CredentialServiceClientImpl.java:91)\n        at {namepii}.microsoft.azure.storage.oauth2.DelegationTokenManager.getDelegationToken(DelegationTokenManager.java:33)\n        at {AlphanumericPII})\n        at {AlphanumericPII})\n;\n\n- ProblemStartTime: 07/28/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Next {Namepii} Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/2d679cd1-d459-41f9-8d29-00e282a042f4/resourceGroups/RG-NGA-HDICluster/providers/Microsoft.HDInsight/clusters/sprk01-prod-eastus2\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Kerbaroes TGT errors causing production jobs failing,0.036084511,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,Kerbaroes TGT errors causing production jobs failing,Kerbaroes TGT errors causing production jobs failing,Worked with customer on this and advised customer that TGT do not span sessions and kinit would need to be done in scope of the current user context/session. Customer added kinit to individual cronjobs and that fixed the issue.,,,,,,,,
1.20073E+14,08:49.7,One of the nodes lost hearbeat,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I shutdown a worker node (wn2-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net) and tried to bring back up with the below sequence. But the node is not coming back up. It says 'Lost heartbeat' in the ambari portal. Can you please bring this back up.\n\n1. {alphanumericpii}:~$ {namepii} shutdown -h now\n\n2. Restart the node from powershell\n Restart-AzHDInsightHost -ClusterName adbeidxhbasestagenew -Name {alphanumericpii}\n\nWhat I was trying: I just wanted to test shutting down a {NAMEPII} and bringing it back.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - I shutdown a worker node (wn2-adbeid.k3jwb24zp1peppjrndygedoz0b.cx.internal.cloudapp.net) and tried to bring back up with the below sequence. But the node is not coming back up. It says 'Lost heartbeat' in the ambari portal. Can you please bring this back up.\n\n1. {alphanumericpii}:~$ {namepii} shutdown -h now\n\n2. Restart the node from powershell\n Restart-AzHDInsightHost -ClusterName adbeidxhbasestagenew -Name {alphanumericpii}\n\nWhat I was trying: I just wanted to test shutting down a {NAMEPII} and bringing it back.;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: CloudTech/Search STG ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0da20eb9-ec94-4b4a-b2fa-c06faa9acf3c/resourceGroups/adobeidx-stage-hbase/providers/Microsoft.HDInsight/clusters/adbeidxhbasestagenew\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",One of the nodes lost hearbeat,0.103024364,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,One of the nodes lost hearbeat,"Issue resolved, customer did a shutdown on the VM instead of a reboot. ",brought the node back up by a restart from ACIS. ,,,,,,,,
1.20073E+14,24:51.7,Clamav is using 100% cpu on edge nodes,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 28, 2020, 4:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Jul 28, 2020, 5:00 PM EDT\n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: Killed clamav service\n\nQuestion: Additional details about the issue\nAnswer: we noticed clamav service is constantily using 100% cpu in all 3 edge node.\n\nwe would like to know if it is expected behaviour?\n\nIf not what shuold be done to reolsve this issue?\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - Killed clamav service;\nAdditional details about the issue - we noticed clamav service is constantily using 100% cpu in all 3 edge node.\n\nwe would like to know if it is expected behaviour?\n\nIf not what shuold be done to reolsve this issue?\n\n;\n\n- ProblemStartTime: 07/28/2020 20:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: US_AUDIT_PREPROD\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d7ac9c0b-155b-42a8-9d7d-87e883f82d5d/resourceGroups/App-Cortex-AME-LRN-RG/providers/Microsoft.HDInsight/clusters/cortexaapslrnspark\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Clamav is using 100% cpu on edge nodes,0.04139249,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish,Clamav is using 100% cpu on edge nodes,Clamscan process that runs on the individual nodes is an open-source anti-virus software Clamav and if you notice the nice value for this process is set to 19 which is the lowest and is set in that way so it would yeild to any other process that has a higher value. So you would notice CPU spikes only when the system is idle. ,We would not recommend making any cnahges to the clamscan but you can disable the automatic execution as shown in the documentation. Hope this helps. https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-faq#can-i-disable-clamscan-on-my-cluster,,,,,,,,
1.20073E+14,49:33.9,Nonprod - kpq060sparkadfqawus201 - Node not responsive,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 28, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Reset password\n\nQuestion: Additional details about the issue\nAnswer: Node is not responsive , doesn't allow login\n\nEdge node {Ipaddresspii}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Reset password;\nAdditional details about the issue - Node is not responsive , doesn't allow login\n\nEdge node {Ipaddresspii};\n\n- ProblemStartTime: 07/28/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-{namepii}-cto-edpcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq060sparkadfqawus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Nonprod - kpq060sparkadfqawus201 - Node not responsive,0.041042705,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish, Nonprod - kpq060sparkadfqawus201 - Node not responsive, Nonprod - kpq060sparkadfqawus201 - Node not responsive,Reboot ED21 node is let the password update and all good after that,,,,,,,,
1.20073E+14,44:50.9,Huge Amount of logs are present in the '/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir' due to this header node running out of storage,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: NA\n\nQuestion: Additional details about the issue\nAnswer: /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir\n having huge amount of logs present\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - NA;\nAdditional details about the issue - /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir\n having huge amount of logs present;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EMEA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/31b2ba9a-0826-4a10-ab4e-f239517ec26f/resourceGroups/Mosaic-EMEA-STAGE-Primary/providers/Microsoft.HDInsight/clusters/omwseitcbmstagemea01\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Huge Amount of logs are present in the '/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir' due to this header node running out of storage,2.601181707,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Unexpected result\Spark,Large amount of logs being stored in hadoop_java_io_tmpdir,Logs were being stored on local disk instead of storage.,"Create /mnt/tmp in all nodes.  HN0, HN1, WN Yarn-env template in ambariChange export HADOOP_OPTS=""$HADOOP_OPTS -Djava.io.tmpdir={{hadoop_java_io_tmpdir}}"" à export HADOOP_OPTS=""$HADOOP_OPTS -Djava.io.tmpdir={{mnt/tmp}"" Mapred-env template in ambariChange export HADOOP_OPTS=""-Djava.io.tmpdir={{hadoop_java_io_tmpdir}} $HADOOP_OPTS""   à export HADOOP_OPTS=""-Djava.io.tmpdir={{mnt/tmp}} $HADOOP_OPTS"" Then restart both yarn and mapred components from ambari.",198669593,,,,,,,
1.20073E+14,29:31.4,Exception operation failed in logs and log files stay inprogress,"Question: What time did the problem begin?\nAnswer: Wed, Jul 1, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: {Namepii} with the default settings from cmd line with an example.  But with get the same issue with other jobs with different configs as well.\n\nQuestion: Additional details about the issue\nAnswer: This exception appears in the logs:\n\nOperation failed: 'This request is not authorized to perform this operation using this permission.', 403, PUT, https://gqjnooc2oz37jrhcontainer.dfs.core.windows.net/container/hdp/spark2-events/application_1595612739040_0069_1?timeout=90, AuthorizationPermissionMismatch, 'This request is not authorized to perform this operation using this permission. {AlphanumericPII} {AlphanumericPII}'\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.spark.examples.SparkPi.main(SparkPi.scala)\nat {namepii}.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat {namepii}.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/07/29 14:01:22 INFO YarnAllocator [{alphanumericpii}]: Driver requested a total number of 0 executor(s).\n20/07/29 14:01:22 INFO YarnClusterSchedulerBackend [Driver]: Shutting down all executors\n20/07/29 14:01:22 INFO YarnSchedulerBackend$YarnDriverEndpoint [{alphanumericpii}]: Asking each executor to shut down\n20/07/29 14:01:22 INFO SchedulerExtensionServices [Driver]: Stopping SchedulerExtensionServices\n(serviceOption=None,\n services={Namepii}(),\n started=false)\n20/07/29 14:01:22 INFO MapOutputTrackerMasterEndpoint [{alphanumericpii}]: MapOutputTrackerMasterEndpoint stopped!\n20/07/29 14:01:22 INFO MemoryStore [Driver]: MemoryStore cleared\n20/07/29 14:01:22 INFO BlockManager [Driver]: BlockManager stopped\n20/07/29 14:01:22 INFO BlockManagerMaster [Driver]: BlockManagerMaster stopped\n20/07/29 14:01:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [{alphanumericpii}]: OutputCommitCoordinator stopped!\n20/07/29 14:01:22 INFO SparkContext [Driver]: Successfully stopped SparkContext\n20/07/29 14:01:22 INFO ApplicationMaster [Driver]: Final app status: SUCCEEDED, exitCode: 0\n20/07/29 14:01:22 INFO ApplicationMaster [{alphanumericpii}]: Unregistering ApplicationMaster with SUCCEEDED\n20/07/29 14:01:22 INFO AMRMClientImpl [{alphanumericpii}]: Waiting for application to be successfully unregistered.\n20/07/29 14:01:23 INFO ApplicationMaster [{alphanumericpii}]: Deleting staging directory abfs://container@gqjnooc2oz37jrhcontainer.dfs.core.windows.net/user/az-1003161703/.sparkStaging/application_1595612739040_0069\n20/07/29 14:01:23 INFO ShutdownHookManager [{alphanumericpii}]: Shutdown hook called\n20/07/29 14:01:23 INFO ShutdownHookManager [{alphanumericpii}]: Deleting directory /mnt/resource/hadoop/yarn/local/usercache/az-1003161703/appcache/application_1595612739040_0069/spark-e52c6745-838f-4ac0-b507-bf1c81b160a2\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - {Namepii};\nSpark configuration details - {Namepii} with the default settings from cmd line with an example.  But with get the same issue with other jobs with different configs as well.;\nAdditional details about the issue - This exception appears in the logs:\n\nOperation failed: 'This request is not authorized to perform this operation using this permission.', 403, PUT, https://gqjnooc2oz37jrhcontainer.dfs.core.windows.net/container/hdp/spark2-events/application_1595612739040_0069_1?timeout=90, AuthorizationPermissionMismatch, 'This request is not authorized to perform this operation using this permission. {AlphanumericPII} {AlphanumericPII}'\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat {AlphanumericPII})\nat org.apache.spark.examples.SparkPi.main(SparkPi.scala)\nat {namepii}.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat {namepii}.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat {namepii}.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat {AlphanumericPII})\nat {AlphanumericPII})\n20/07/29 14:01:22 INFO YarnAllocator [{alphanumericpii}]: Driver requested a total number of 0 executor(s).\n20/07/29 14:01:22 INFO YarnClusterSchedulerBackend [Driver]: Shutting down all executors\n20/07/29 14:01:22 INFO YarnSchedulerBackend$YarnDriverEndpoint [{alphanumericpii}]: Asking each executor to shut down\n20/07/29 14:01:22 INFO SchedulerExtensionServices [Driver]: Stopping SchedulerExtensionServices\n(serviceOption=None,\n services={Namepii}(),\n started=false)\n20/07/29 14:01:22 INFO MapOutputTrackerMasterEndpoint [{alphanumericpii}]: MapOutputTrackerMasterEndpoint stopped!\n20/07/29 14:01:22 INFO MemoryStore [Driver]: MemoryStore cleared\n20/07/29 14:01:22 INFO BlockManager [Driver]: BlockManager stopped\n20/07/29 14:01:22 INFO BlockManagerMaster [Driver]: BlockManagerMaster stopped\n20/07/29 14:01:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [{alphanumericpii}]: OutputCommitCoordinator stopped!\n20/07/29 14:01:22 INFO SparkContext [Driver]: Successfully stopped SparkContext\n20/07/29 14:01:22 INFO ApplicationMaster [Driver]: Final app status: SUCCEEDED, exitCode: 0\n20/07/29 14:01:22 INFO ApplicationMaster [{alphanumericpii}]: Unregistering ApplicationMaster with SUCCEEDED\n20/07/29 14:01:22 INFO AMRMClientImpl [{alphanumericpii}]: Waiting for application to be successfully unregistered.\n20/07/29 14:01:23 INFO ApplicationMaster [{alphanumericpii}]: Deleting staging directory abfs://container@gqjnooc2oz37jrhcontainer.dfs.core.windows.net/user/az-1003161703/.sparkStaging/application_1595612739040_0069\n20/07/29 14:01:23 INFO ShutdownHookManager [{alphanumericpii}]: Shutdown hook called\n20/07/29 14:01:23 INFO ShutdownHookManager [{alphanumericpii}]: Deleting directory /mnt/resource/hadoop/yarn/local/usercache/az-1003161703/appcache/application_1595612739040_0069/spark-e52c6745-838f-4ac0-b507-bf1c81b160a2;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/01/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourceGroups/mlt-dar-pscdatahub-1-DEV-arc10-{Namepii}-HDI/providers/Microsoft.HDInsight/clusters/fyPEhG8OnY-ProjectSpark\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Exception operation failed in logs and log files stay inprogress,0.051453998,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,Issue: Exception(403) operation failed in logs and log files stay inprogress in Spark2 events logs.,Cause: User running the job does not have proper permission,Resolution: grant the user “storage blob data contributor” role on the Storage account.,,,,,,,,
1.20073E+14,26:41.6,Unable to Restart 'Cache Metadata Server' on one of the Node,"Question: What time did the problem begin?\nAnswer: Wed, Jul 22, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Tried restarting the services multipe times but its still under critical phase :\n\nTraceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/IOCACHE/0.1/package/scripts/bookkeeper_server.py', line 2, in (module)\n    from hdinsight_common.AmbariHelper import AmbariHelper\nImportError: No module named hdinsight_common.AmbariHelper\n\n\n\nQuestion: Additional details about the issue\nAnswer: 2020-07-29 {Alphanumericpii} - {Namepii} Feature {Namepii} Info: {Namepii} {Namepii}=2.6, Command {Namepii}=None, Command {Namepii}=2.6.5.3008-11 --- 2.6.5.3008-11\n2020-07-29 {Alphanumericpii} - Using hadoop conf dir: /{alphanumericpii}\n2020-07-29 {Alphanumericpii} - {Namepii} Feature {Namepii} Info: {Namepii} {Namepii}=2.6, Command {Namepii}=None, Command {Namepii}=2.6.5.3008-11 --- 2.6.5.3008-11\n2020-07-29 {Alphanumericpii} - Using hadoop conf dir: /{alphanumericpii}\n2020-07-29 {Alphanumericpii} - Skipping creation of {Namepii} and {Namepii} as host is sys prepped or ignore_groupsusers_create flag is on\n2020-07-29 {Alphanumericpii} - Skipping setting dfs cluster {namepii} and tez view acls as host is sys prepped\n2020-07-29 {Alphanumericpii} - FS Type: \n2020-07-29 {Alphanumericpii} - Directory['/etc/hadoop'] {'mode': 0755}\n2020-07-29 {Alphanumericpii} - File['/usr/hdp/2.6.5.3008-11/hadoop/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}\n2020-07-29 {Alphanumericpii} - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', '{namepii}': True, 'only_if': 'test -f /selinux/enforce'}\n2020-07-29 {Alphanumericpii} - Skipping Execute[('setenforce', '0')] due to not_if\n2020-07-29 {Alphanumericpii} - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}\n2020-07-29 {Alphanumericpii} - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}\n2020-07-29 {Alphanumericpii} - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}\nSkipping copying of fast-hdfs-resource.jar as host is sys prepped\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'owner': 'hdfs'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'owner': 'hdfs'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'mode': 0755}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': {AlphanumericPII}'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop', 'mode': 0644}\n2020-07-29 {Alphanumericpii} - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}\n2020-07-29 {Alphanumericpii} - Skipping unlimited key JCE policy check and setup since the host is sys prepped\n2020-07-29 {Alphanumericpii} - Skipping stack-select on IOCACHE because it does not exist in the stack-select package structure.\n\nCommand failed after 1 tries\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Tried restarting the services multipe times but its still under critical phase :\n\nTraceback (most recent call last):\n  File '/var/lib/ambari-agent/cache/common-services/IOCACHE/0.1/package/scripts/bookkeeper_server.py', line 2, in (module)\n    from hdinsight_common.AmbariHelper import AmbariHelper\nImportError: No module named hdinsight_common.AmbariHelper\n\n;\nAdditional details about the issue - 2020-07-29 {Alphanumericpii} - {Namepii} Feature {Namepii} Info: {Namepii} {Namepii}=2.6, Command {Namepii}=None, Command {Namepii}=2.6.5.3008-11 --- 2.6.5.3008-11\n2020-07-29 {Alphanumericpii} - Using hadoop conf dir: /{alphanumericpii}\n2020-07-29 {Alphanumericpii} - {Namepii} Feature {Namepii} Info: {Namepii} {Namepii}=2.6, Command {Namepii}=None, Command {Namepii}=2.6.5.3008-11 --- 2.6.5.3008-11\n2020-07-29 {Alphanumericpii} - Using hadoop conf dir: /{alphanumericpii}\n2020-07-29 {Alphanumericpii} - Skipping creation of {Namepii} and {Namepii} as host is sys prepped or ignore_groupsusers_create flag is on\n2020-07-29 {Alphanumericpii} - Skipping setting dfs cluster {namepii} and tez view acls as host is sys prepped\n2020-07-29 {Alphanumericpii} - FS Type: \n2020-07-29 {Alphanumericpii} - Directory['/etc/hadoop'] {'mode': 0755}\n2020-07-29 {Alphanumericpii} - File['/usr/hdp/2.6.5.3008-11/hadoop/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}\n2020-07-29 {Alphanumericpii} - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', '{namepii}': True, 'only_if': 'test -f /selinux/enforce'}\n2020-07-29 {Alphanumericpii} - Skipping Execute[('setenforce', '0')] due to not_if\n2020-07-29 {Alphanumericpii} - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}\n2020-07-29 {Alphanumericpii} - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}\n2020-07-29 {Alphanumericpii} - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}\nSkipping copying of fast-hdfs-resource.jar as host is sys prepped\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'owner': 'hdfs'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'owner': 'hdfs'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'content': {AlphanumericPII}'), 'mode': 0755}\n2020-07-29 {Alphanumericpii} - {AlphanumericPII}'] {'owner': 'hdfs', 'group': 'hadoop'}\n2020-07-29 {Alphanumericpii} - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': {AlphanumericPII}'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop', 'mode': 0644}\n2020-07-29 {Alphanumericpii} - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}\n2020-07-29 {Alphanumericpii} - Skipping unlimited key JCE policy check and setup since the host is sys prepped\n2020-07-29 {Alphanumericpii} - Skipping stack-select on IOCACHE because it does not exist in the stack-select package structure.\n\nCommand failed after 1 tries\n;\n\n- ProblemStartTime: 07/22/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Abs-ITDS-Prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6dfbe157-2219-4313-adfc-6df4829ab651/resourceGroups/itds-prod-wus-hdi-sprk01-{namepii}/providers/Microsoft.HDInsight/clusters/sprk01-itds-prod-wus-hdi\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to Restart 'Cache Metadata Server' on one of the Node,0.054506889,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Hadoop,Issue: IO cache not starting on hn1.,"Cause: A few vital libraries got removed from hn1 as we saw from the logs, especially IO cache was complaining about hdinsight-common library missing on it.“ImportError: No module named hdinsight_common.AmbariHelper”  User ERROR ",Resolution: We were able to manually restore the library and get IO cache back to running state on hn1. ,,,,,,,,
1.20073E+14,09:14.7,Connection failed to headnode,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Ambari Hive view\n\nQuestion: Additional details about the issue\nAnswer: Connection failed: [Errno 111] Connection refused to hn1-ana02h.ylrhihwg4sfetpxuxtrg5jyrma.gx.internal.cloudapp.net:8019\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Ambari Hive view;\nAdditional details about the issue - Connection failed: [Errno 111] Connection refused to hn1-ana02h.ylrhihwg4sfetpxuxtrg5jyrma.gx.internal.cloudapp.net:8019\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Predictive Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/10051b30-e5c6-487e-9133-8b1425b877a2/resourceGroups/HDISpark01-Prod-Predictive/providers/Microsoft.HDInsight/clusters/ana02hdi36sparkpa01\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Connection failed to headnode,0.062711276,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Hive,connection failed to headnode.,"AppTimeline serverHistory serverLivy is running on both the headnodesHive view was not accessible.Restart of all the components on standby namenode and that made ATS, History Server and Livy running on both the headnodes.","Turned down those three services on standby headnode and requested customer for a downtime for a hard reboot from jarvis for a proper failover of services.Rebooted the cluster node, services are up and running.Cleared the stale alerts on the cluster.shared the Ambari purge commands to purge the Ambari DB to enhance cluster performance.sudo service ambari-server stopsudo ambari-server db-purge-history --cluster-name=CLUSTERNAME --from-date=$(date +%Y-%m-%d -d ""15 day ago"")sudo service ambari-server startAfter the above steps cluster looks stable now. ",,,,,,,,
1.20073E+14,19:19.5,Zookeeper logs configuration.,"Question: What time did the problem begin?\nAnswer: Wed, Jul 29, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you kinited or logged in using AAD credential?\nAnswer: Yes\n\nQuestion: Does hdfs dfs -ls / work?\nAnswer: No\n\nQuestion: hdfs dfs -ls error message\nAnswer: 20/07/29 21:53:58 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404)\n\nQuestion: Have you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script?\nAnswer: Through Gateway\n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Primary storage account\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Logged in to Ambari to resolve the issue.\n\nQuestion: Additional details about the issue\nAnswer: Here was the error message in Credential service logs -\n\n\n2020-07-29 {Alphanumericpii} INFO {namepii}.microsoft.azure.datalake.store.security.AdlWebHdfsMethods: GETACCESSTOKEN request for the principal rtdsbatch\norg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /secretmanager/ZKDTSMRoot/refreshtokens/rtdsbatch\n{namepii}.microsoft.azure.datalake.store.security.exceptions.TokenNotFoundException: No persisted refresh token was found for the user: rtdsbatch. This can happen if a refresh token was never automatically generated for the user as MFA is enabled  or the previous token has expired or became invalid due to credential changes.\nCaused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /secretmanager/ZKDTSMRoot/refreshtokens/rtdsbatch\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you kinited or logged in using AAD credential? - Yes;\nDoes hdfs dfs -ls / work? - No;\nhdfs dfs -ls error message - 20/07/29 21:53:58 ERROR secure.AbstractCredentialServiceCaller: Token does not exist in TokenManager (Response Code: 404);\nHave you logged in to Ambari through the gateway or run the RegisterKerbTicketAndOAuth.sh script? - Through Gateway;\nIs storage affected the primary or secondary storage account - Primary storage account;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - Logged in to Ambari to resolve the issue.;\nAdditional details about the issue - Here was the error message in Credential service logs -\n\n\n2020-07-29 {Alphanumericpii} INFO {namepii}.microsoft.azure.datalake.store.security.AdlWebHdfsMethods: GETACCESSTOKEN request for the principal rtdsbatch\norg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /secretmanager/ZKDTSMRoot/refreshtokens/rtdsbatch\n{namepii}.microsoft.azure.datalake.store.security.exceptions.TokenNotFoundException: No persisted refresh token was found for the user: rtdsbatch. This can happen if a refresh token was never automatically generated for the user as MFA is enabled  or the previous token has expired or became invalid due to credential changes.\nCaused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /secretmanager/ZKDTSMRoot/refreshtokens/rtdsbatch;\n\n- ProblemStartTime: 07/29/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Data Analytics\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3e6a222a-e9a4-4a3a-bc52-ee646e2dcffd/resourceGroups/RxPersonalization-RG/providers/Microsoft.HDInsight/clusters/Prod05RxPerso\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zookeeper logs configuration.,13.90263333,Root Cause : HDInsight Service\Bug\HDInsight,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in cluster with Enterprise Security Package","In prod cluster “Prod05RxPerso”, Credential Service gets restarted every 6 hours multiple times spanning 2-3 minutes of total time and jobs running during this interval are failing due to that.","As this cluster image is old, this version of cluster had a known bug in credential_server_stagedrestart.py that it was reporting the status as failed. This has caused the RP repeatedly trying to run the same script. This version of the script will also restart credential service from every host that it runs on. This is the reason multiple cred service restarts were occurring in a matter of 2-3 minutes. While this was addressed in the newer version of the clusters, this particular cluster image continued to face this issue.","A fixed version of the script credential_server_stagedrestart.py was applied in both head nodes. Along with this, a fix to “update manifest” script to restart credential service only from head nodes. This will be useful for older clusters that still don't have the credential_server_stagedrestart.py fix to restart only from lowest order headnote. ",195416389,,,,,,,
1.20073E+14,48:29.1,We had an outage on our HDInsight cluster (message were lost) - Zookeeper node was unreachable (zk0,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 30, 2020, 11:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: Messages were lost; Ambari reported that a zookeeper node was unreachable\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None;\nAdditional details about the issue - Messages were lost; Ambari reported that a zookeeper node was unreachable;\n\n- ProblemStartTime: 07/30/2020 10:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Tyl UK Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/97ee98dc-adfe-449c-b260-00c3a7c15856/resourceGroups/produkshdirg0/providers/Microsoft.HDInsight/clusters/produkskafka0\n- Location: uksouth\n- Location: Uk South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",We had an outage on our HDInsight cluster (message were lost) - Zookeeper node was unreachable (zk0,0.2765149,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Kafka,We had an outage on our HDInsight cluster (message were lost) - Zookeeper node was unreachable (zk0,message header which was causing issue in down conversion,message header which was causing issue in down conversionResolution:We changed the zookeeper logger to write to RFA instead of console and restarted the zookeepers one at a time.We tried consuming messages from topic using console consumer and we found that there was no data loss and consumers were able to consume messages.You will investigate your consumer client code and change the message header which was causing issue in down conversion.Recommendation made: Change RF for few topics from 1 to 3 and change min insync replicas from 1 to 2 to avoid issues in future.,198646840,,,,,,,
1.20073E+14,43:36.7,Can't change version of Hadoop components,"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 28, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: devsparkrlrazstg\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is cluster created in a VNET?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: We use terraform for cloud resource management. Despite deploying exactly the same resource in rlr-az-dev and rlr-az-stg versioning of hadoop components differ in both environemnt cousing issues for our developers, mainly: dev has spark 2.4.0, stg has spark 2.4.4. We want both to be at 2.4.0. Ambari ui seems broken and doesn't allow custom created template to deploy on cluster.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - devsparkrlrazstg;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIs cluster created in a VNET? - No;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - We use terraform for cloud resource management. Despite deploying exactly the same resource in rlr-az-dev and rlr-az-stg versioning of hadoop components differ in both environemnt cousing issues for our developers, mainly: dev has spark 2.4.0, stg has spark 2.4.4. We want both to be at 2.4.0. Ambari ui seems broken and doesn't allow custom created template to deploy on cluster.;\n\n- ProblemStartTime: 07/27/2020 22:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: rlr-az-stg\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3f845378-c663-41f8-a52e-1229c3cf389b/resourceGroups/rlr-az-stg/providers/Microsoft.HDInsight/clusters/devsparkrlrazstg\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Can't change version of Hadoop components,0.114470527,Root Cause : HDInsight Service\By Design\Spark,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,Symptom: Spark application are crashing due to version compatibility.,Cause:  Due to some dependency need for the spark application the job is failing.,Resolution: Options that you can take.Adjust the dependencies needed for the application to be able to use 2.4.4Create an uber jar with spark 2.4.0 so that the application can use those instead of the cluster.(I haven’t tested this yet) create an edgenode and install 2.4.0 to run the application.  There may be some things that needs to be changed to run on the cluster.,,,,,,,,
1.20073E+14,04:40.2,INC04140006:  the cluster is down we have all jobs failing,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: {Namepii}\n\nQuestion: What is the programming language used?\nAnswer: {Namepii}\n\nQuestion: Spark configuration details\nAnswer: '{AlphanumericPII}\n\nQuestion: Additional details about the issue\nAnswer: {AlphanumericPII} ({guidpii})\nServiceHDInsight Service\n{AlphanumericPII}\nProblem typeService unhealthy / Spark\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - {Namepii};\nWhat is the programming language used? - {Namepii};\nSpark configuration details - '{AlphanumericPII};\nAdditional details about the issue - {AlphanumericPII} ({guidpii})\nServiceHDInsight Service\n{AlphanumericPII}\nProblem typeService unhealthy / Spark\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {AlphanumericPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/22818b25-a228-474d-9e11-a0d8a4afdb27/resourceGroups/MFC-USE2-BDSS-PROD-9690/providers/Microsoft.HDInsight/clusters/BDSS-PROD-MERKLE-SPARK-9690\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",INC04140006:  the cluster is down we have all jobs failing,0.124187424,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Spark,INC04140006: the cluster is down we have all jobs failing,INC04140006: the cluster is down we have all jobs failing,Worked with customer on this and found HDFS in safemode and dfs.replication set to 3. Customer has a practice to scale-down cluster to 1 node. Customer updated dfs.replication to 1 and cleared local hdfs and taken hdfs out of safemode. Customer monitored further scale-up/scale-down on the cluster and confirmed everything is working as expected and agreed to close the case.,,,,,,,,
1.20073E+14,20:04.4,MSI Certification renew workflow failed,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the {Namepii} node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster {namepii} account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local {namepii} and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: MSI Certificate renew failed\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the {Namepii} node? - ;\nDoes authentication fail even for the cluster {namepii} account? - ;\nHave you logged in to Ambari as local {namepii} and verified the users have been synced? - ;\nAdditional details about the issue - MSI Certificate renew failed;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MSI Certification renew workflow failed,0.087588055,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,MSI Certification renew workflow failed,HDI MSI renewal bug,PG applied fix manually,,,,,,,,
1.20073E+14,08:47.6,Problemas para conexão SSH,"não é possivel conectar no cluster {namepii} ssh. ao checar o cluster size, aparentemente {namepii} workers cairam.\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Azure Natura\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/82699d66-399b-4736-bc94-e0ccdc71a2d4/resourceGroups/PRD-Dir-BI-Analytics/providers/Microsoft.HDInsight/clusters/prd01ingestion-analytics\n- Location: brazilsouth\n- Location: {Namepii} South\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Problemas para conexão SSH,0.859842258,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unable to reset Cluster or ssh password,"hn lost heart beat, not able to SSH",transient/unknown,Head node is up and SSH was working now without reboot. May be auto healing action,198707549,,,,,,,
1.20073E+14,12:26.6,Jobs running in the cluster are stuck and not able to restart services of the cluster,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Hive job if known\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: NA\n\nQuestion: Hive query explain plan if available\nAnswer: \n\nQuestion: {Namepii} was the Hive query submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Jobs running in the cluster are stuck and not able to restart services of the cluster.\nRestart of Hivemetastore is failing \n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Hive job if known - ;\nHive query if applicable - NA;\nHive query explain plan if available - ;\n{Namepii} was the Hive query submitted? - Other, don't know or not applicable;\nAdditional details about the issue - Jobs running in the cluster are stuck and not able to restart services of the cluster.\nRestart of Hivemetastore is failing \n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f55d4ef9-4d7f-4763-8661-9b82de6c08c9/resourceGroups/zne-udl1-p-11-ust0-rsg/providers/Microsoft.HDInsight/clusters/bpapiobs\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Jobs running in the cluster are stuck and not able to restart services of the cluster,0.009009533,Root Cause : HDInsight Service\User Environment/Platforms\Networking configuration,Routing Azure HDInsight V5\Query or Job Failure\Hive,Issue: Unable to start hive metastore service on the cluster.,Cause: we noticed that the hive-metastore connected to the cluster is not coming up as it was unable to connect to the sql database because of a changed Firewall rule.,Resolution: Change made on the SQL server by the BP Infra team to allow HDInsight cluster’s connectivity to the Hive metastore DB.,198696404,,,,,,,
1.20073E+14,27:08.2,[Azure Government] Edge node cannot be reached,"[Azure Government] Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Edge node\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We found our udp requests cannot sent to edgen node, & we caannot ssh into edge node,\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Edge node;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We found our udp requests cannot sent to edgen node, & we caannot ssh into edge node,;\n\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-GCC-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/ad2a8933-826d-4752-88b0-9d4f59730f0b/resourceGroups/o365ipdigcc01-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdigcc01-sp-uv01\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Edge node cannot be reached,0.075992508,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Customer could not ssh to the edge node,"Unknown, because backend telemetry showed the edge node was up","Advised customer to reboot the edge node using the below PowerShell commands:Use the following command to list the names of the VMs in your HDInsight cluster:Get-AzHDInsightHost -ClusterName <yourclustername> Use the following command to try rebooting the edgenode:Restart-AzHDInsightHost -ClusterName myclustername -Name <nameOfedgnode>If the issue happens again, use the following to get the verbose ssh logs:ssh -vvv <sshusername>@ed10-o365ip",198851116,,,,,,,
1.20073E+14,52:53.6,HDI Spark is down and hn0 is unresponsive,"Question: What time did the problem begin?\nAnswer: Fri, Jul 31, 2020, 3:30 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: {alphanumericpii}\n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Scala\n\nQuestion: Spark configuration details\nAnswer: SPARK_MAJOR_VERSION is set to 2, using {Alphanumericpii}\n{ALPHANUMERICPII}: Class path contains multiple {ALPHANUMERICPII} bindings.\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/2.6.5.3008-11/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/2.6.5.3008-11/spark_llap/spark-llap-assembly-1.0.0.2.6.5.3008-11.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: {Namepii} http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n{ALPHANUMERICPII}: Actual binding is of type [{AlphanumericPII}]\n\nQuestion: Additional details about the issue\nAnswer: This issue started at about 3:30 AM {NAMEPII}.\n\nThese spark jobs process data for 6 countries to provide reports to executives.  The error seems to be that hn0 cannot connect or communicate with the rest of the cluster.\n\nWe were able to find error logs that identified a resource contention on the cluster.\n\nWe know that less load or scaling up the cluster is advised, but currently the cluster is in a bad state and we need assistance getting it back online asap.\n\nWe can provide more details, logs and configuration data on a bridge call when an engineer is available.\n\nThank you\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nYARN Application ID for the Spark job if known - {alphanumericpii};\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Scala;\nSpark configuration details - SPARK_MAJOR_VERSION is set to 2, using {Alphanumericpii}\n{ALPHANUMERICPII}: Class path contains multiple {ALPHANUMERICPII} bindings.\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/2.6.5.3008-11/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: Found binding in [jar:file:/usr/hdp/2.6.5.3008-11/spark_llap/spark-llap-assembly-1.0.0.2.6.5.3008-11.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n{ALPHANUMERICPII}: {Namepii} http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n{ALPHANUMERICPII}: Actual binding is of type [{AlphanumericPII}];\nAdditional details about the issue - This issue started at about 3:30 AM {NAMEPII}.\n\nThese spark jobs process data for 6 countries to provide reports to executives.  The error seems to be that hn0 cannot connect or communicate with the rest of the cluster.\n\nWe were able to find error logs that identified a resource contention on the cluster.\n\nWe know that less load or scaling up the cluster is advised, but currently the cluster is in a bad state and we need assistance getting it back online asap.\n\nWe can provide more details, logs and configuration data on a bridge call when an engineer is available.\n\nThank you;\n\n- ProblemStartTime: 07/31/2020 08:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support – Performance\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/48f10876-7183-46da-a5f7-33a9ce21f189/resourceGroups/RG-AP-SoutheastAsia-Prod-CEPA/providers/Microsoft.HDInsight/clusters/hdisomprod-ap-southeastasia-cepa\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",HDI Spark is down and hn0 is unresponsive,0.189356954,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Performance - queries or jobs running slower than before\Spark,HDI Spark is down and hn0 is unresponsive.,Increased load in the environment caused the firewalls to be the bottlenecks and caused Retransmits/Out of order packets and the like that significantly hindered the Spark clusters performance.,"Rebooting Hn0 and fixed HDFS checkpoint ERROR, Which brought the cluster back to healthy state.",,,,,,,,
1.20073E+14,23:43.6,test,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: test\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: test case\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - test;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Other, don't know or not applicable;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - test case;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Internal Consumption\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",test,0.012458481,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Test ticket,Test Ticket,Test Ticket,,,,,,,,
1.20073E+14,51:03.4,SQL Connectivity issues to metastore,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hello\n{Namepii} team and I are investigating since several months regarding Hive unstability.\nProduct {Namepii} that are helping us on this case ask us to create a ticket in order to go further about a SQL Connectivity issues to metastore.\nBelow are erros that PG noticed :\n{AlphanumericPII} - Failed to create/setup connection: The TCP/IP connection to the host azsbid01spark001.database.windows.net, port 1433 has failed. Error: 'null. Verify the connection properties. Make sure that an instance of sql server is running on the host and accepting TCP/IP connections at the port. Make sure that TCP connections to the port are not blocked by a firewall.'.”\n\no“Database 'hivedb' on server '{alphanumericpii}' is not currently available.  Please retry the connection later.  If the problem persists, contact customer support, and provide them the session tracing ID of '{{GUIDPII}}'. {AlphanumericPII}”\n\nPlease find attached a list of session IDs that were reported similar errors.\nThanks\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Hello\n{Namepii} team and I are investigating since several months regarding Hive unstability.\nProduct {Namepii} that are helping us on this case ask us to create a ticket in order to go further about a SQL Connectivity issues to metastore.\nBelow are erros that PG noticed :\n{AlphanumericPII} - Failed to create/setup connection: The TCP/IP connection to the host azsbid01spark001.database.windows.net, port 1433 has failed. Error: 'null. Verify the connection properties. Make sure that an instance of sql server is running on the host and accepting TCP/IP connections at the port. Make sure that TCP connections to the port are not blocked by a firewall.'.”\n\no“Database 'hivedb' on server '{alphanumericpii}' is not currently available.  Please retry the connection later.  If the problem persists, contact customer support, and provide them the session tracing ID of '{{GUIDPII}}'. {AlphanumericPII}”\n\nPlease find attached a list of session IDs that were reported similar errors.\nThanks\n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV04/providers/Microsoft.HDInsight/clusters/dsjd4llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",SQL Connectivity issues to metastore,0.149312876,Root Cause : HDInsight Service\Configuration\Other,Routing Azure HDInsight V5\Service unhealthy\Interactive Query,Intermittently SQL DB connectivity issues to metastore,Not related to HDInsight Hive Metastore,"Based on PG-Hive (Taylor) RCA, CX had opened a support case to SQL DB team for Intermittent SQL DB connectivity issue",199579074,,,,,,,
1.20073E+14,16:13.1,CRITSIT || PREM || Azure HDInsight Service || workernodes are being compromised (hdihdcatmanpsdev  and  hdihddemandforecastpsprod),"Question: Additional details\nAnswer: We want to know the below ips are useing by which servicess and why.?\nAttached To: {alphanumericpii}\nIP: {Ipaddresspii}\n{Namepii}: {alphanumericpii}\nSubNet: {alphanumericpii}\nNIC Nmae: {alphanumericpii}\n\n\nAttached to: {alphanumericpii}\nIP: {Ipaddresspii}\n{Namepii}: {alphanumericpii}\nSubnet: {alphanumericpii}\n\nRegards,\nSivasaikrishna.T\n\nQuestion: Problem start time\nAnswer: Fri, Jul 31, 2020, 12:00 AM {ALPHANUMERICPII}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for Virtual Network:\nAdditional details - We want to know the below ips are useing by which servicess and why.?\nAttached To: {alphanumericpii}\nIP: {Ipaddresspii}\n{Namepii}: {alphanumericpii}\nSubNet: {alphanumericpii}\nNIC Nmae: {alphanumericpii}\n\n\nAttached to: {alphanumericpii}\nIP: {Ipaddresspii}\n{Namepii}: {alphanumericpii}\nSubnet: {alphanumericpii}\n\nRegards,\nSivasaikrishna.T;\nProblem start time - {ALPHANUMERICPII};\n\n- ProblemStartTime: 07/30/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: {alphanumericpii}\n- ResourceUri: /subscriptions/64a50daa-16fd-48c0-95cd-5317e14fe14d/resourceGroups/{namepii}-network-prod-001/providers/Microsoft.Network/virtualNetworks/vnet-prod-001\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",CRITSIT || PREM || Azure HDInsight Service || workernodes are being compromised (hdihdcatmanpsdev  and  hdihddemandforecastpsprod),16.40646864,Root Cause : HDInsight Service\User Error,"Routing Azure Virtual Networks V3\VPN Gateway\Creating and managing VPN Gateway, connection, and routing",workernodes are being compromised (hdihdcatmanpsdev and hdihddemandforecastpsprod),"Securing inbound access to the cluster is customer's responsibility, there are two ways we think this cluster could have been compromised:NSG rules for this cluster were compromised and hackers got into the cluster directly.Network that has access to this cluster was compromised and hackers got access to the cluster through their other network.On such security incidents, the immediate recommendation is to get rid of the cluster and create a new one preferably with a new network configuration that is even more strict. Initially customer was not willing to get rid of the cluster but then they agreed to delete the cluster and create a new one.Important data points while discussing with the customer:Cluster is of 3.5 version which is out of supportOne of the following compromised the cluster and this was completely in customer's control:NSG of the existing cluster was too wide open and their passwords were susceptible to dictionary attackNetwork that has access to this cluster could have been compromisedWe still tried to help the customer by removing the existing workernodes and replacing them with new ones but that didn't work.",Final conclusion: customer has agreed to delete the compromised cluster and create a new 3.6 cluster to move the workload.,200571586,,,,,,,
1.20073E+14,01:50.5,[Azure Government] Deploying a new HDInsight Cluster and getting an error: Unable to connect to cluster management endpoint. Please retry later.,"[Azure Government] Question: What time did the problem begin?\nAnswer: Fri, Jul 31, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: hdi-ugv-dna-pd\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: CLUSTERNAME=$(hd_insights_name)\nRGNAME=$(dna_rg_name)\nCLUSTERTYPE=spark\nPASSWORD='$(head_password)'\nSTORAGE_ACCOUNT=$(hd_insights_str_name)\nSUBNET_RESOURCE_ID='/subscriptions/$(subscriptionid)/resourceGroups/$(spoke_vnet_rg_name)/providers/Microsoft.Network/virtualNetworks/$(spoke_vnet_name)/subnets/$(dna_hdi_subnet_name)'\nADDS_RESOURCE_ID='/subscriptions/$(core_subscription_id)/resourceGroups/$(core_rg_name)/providers/Microsoft.AAD/domainServices/$(domain_name)'\nMSI_RESOURCE_ID='/subscriptions/$(subscriptionid)/resourceGroups/$(dna_rg_name)/providers/Microsoft.ManagedIdentity/userAssignedIdentities/$(msi_hdi_dna_name)'\nDOMAIN_USER_ACCOUNT_ADMIN=$(dna_hdi_admin_domain_user) \nDOMAIN_USER_GROUP=$(dna_hdi_user_group)\nVM_SIZE_HEADNODE=$(head_vm_size)\nVM_SIZE_WORKERNODE=$(worker_vm_size)\nLOG_ANALYTICS_WORKSPACE=$(azurerm_spoke_log_analytics_workspace_name)\n\naz hdinsight create \\\n    --esp \\\n    --name $CLUSTERNAME \\\n    --resource-group $RGNAME \\\n    --type $CLUSTERTYPE \\\n    --http-password $PASSWORD \\\n    --storage-account $STORAGE_ACCOUNT \\\n    --subnet $SUBNET_RESOURCE_ID \\\n    --domain $ADDS_RESOURCE_ID \\\n    --assign-identity $MSI_RESOURCE_ID \\\n    --cluster-{namepii}-account $DOMAIN_USER_ACCOUNT_ADMIN \\\n    --cluster-users-group-dns $DOMAIN_USER_GROUP \\\n    --headnode-size $VM_SIZE_HEADNODE \\\n    --workernode-size $VM_SIZE_WORKERNODE\n\n# Enable the Azure Monitor logs integration on an HDInsight cluster.\naz hdinsight monitor enable --name $CLUSTERNAME --resource-group $RGNAME --workspace $LOG_ANALYTICS_WORKSPACE\n\n# Get the status of Azure Monitor logs integration on an HDInsight cluster.\naz hdinsight monitor show --name $CLUSTERNAME --resource-group $RGNAME\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - hdi-ugv-dna-pd;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - CLUSTERNAME=$(hd_insights_name)\nRGNAME=$(dna_rg_name)\nCLUSTERTYPE=spark\nPASSWORD='$(head_password)'\nSTORAGE_ACCOUNT=$(hd_insights_str_name)\nSUBNET_RESOURCE_ID='/subscriptions/$(subscriptionid)/resourceGroups/$(spoke_vnet_rg_name)/providers/Microsoft.Network/virtualNetworks/$(spoke_vnet_name)/subnets/$(dna_hdi_subnet_name)'\nADDS_RESOURCE_ID='/subscriptions/$(core_subscription_id)/resourceGroups/$(core_rg_name)/providers/Microsoft.AAD/domainServices/$(domain_name)'\nMSI_RESOURCE_ID='/subscriptions/$(subscriptionid)/resourceGroups/$(dna_rg_name)/providers/Microsoft.ManagedIdentity/userAssignedIdentities/$(msi_hdi_dna_name)'\nDOMAIN_USER_ACCOUNT_ADMIN=$(dna_hdi_admin_domain_user) \nDOMAIN_USER_GROUP=$(dna_hdi_user_group)\nVM_SIZE_HEADNODE=$(head_vm_size)\nVM_SIZE_WORKERNODE=$(worker_vm_size)\nLOG_ANALYTICS_WORKSPACE=$(azurerm_spoke_log_analytics_workspace_name)\n\naz hdinsight create \\\n    --esp \\\n    --name $CLUSTERNAME \\\n    --resource-group $RGNAME \\\n    --type $CLUSTERTYPE \\\n    --http-password $PASSWORD \\\n    --storage-account $STORAGE_ACCOUNT \\\n    --subnet $SUBNET_RESOURCE_ID \\\n    --domain $ADDS_RESOURCE_ID \\\n    --assign-identity $MSI_RESOURCE_ID \\\n    --cluster-{namepii}-account $DOMAIN_USER_ACCOUNT_ADMIN \\\n    --cluster-users-group-dns $DOMAIN_USER_GROUP \\\n    --headnode-size $VM_SIZE_HEADNODE \\\n    --workernode-size $VM_SIZE_WORKERNODE\n\n# Enable the Azure Monitor logs integration on an HDInsight cluster.\naz hdinsight monitor enable --name $CLUSTERNAME --resource-group $RGNAME --workspace $LOG_ANALYTICS_WORKSPACE\n\n# Get the status of Azure Monitor logs integration on an HDInsight cluster.\naz hdinsight monitor show --name $CLUSTERNAME --resource-group $RGNAME;\n\n- ProblemStartTime: 07/31/2020 04:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: prod-spoke-apps\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/d987258c-7c97-4c14-a1e0-983405b7a373/resourceGroups/RGP-UGV-DNA-{NAMEPII}/providers/Microsoft.HDInsight/clusters/hdi-ugv-dna-pd\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Deploying a new HDInsight Cluster and getting an error: Unable to connect to cluster management endpoint. Please retry later.,0.115364849,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,cannot deploy cluster,AD group is not present,created the AD group and deployed the cluster successfully,,,,,,,,
1.20073E+14,10:56.5,DatalakeCapabilityNotEnabledForAdlAdditionalFS error when creating HDI cluster with ADL gen1 access,"Question: What time did the problem begin?\nAnswer: Fri, Jul 31, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, Jul 31, 2020, 12:00 AM PDT\n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Hi -- I'm receiving the following error when attempting to create a HDI cluster with access to ADL {alphanumericpii}:\n\n{'code':'InvalidTemplateDeployment ','message':'{Namepii} creation request is invalid.','details':[{'code':'DatalakeCapabilityNotEnabledForAdlAdditionalFS','message':'Datalake capability to support ADL as Additional Storage is not enabled for subscription '{guidpii}'.'}]}\n\nCould you please point me to the setting that I need to tweak in order to enable ADL on this subscription?  I can't seem to find it anywhere.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Hi -- I'm receiving the following error when attempting to create a HDI cluster with access to ADL {alphanumericpii}:\n\n{'code':'InvalidTemplateDeployment ','message':'{Namepii} creation request is invalid.','details':[{'code':'DatalakeCapabilityNotEnabledForAdlAdditionalFS','message':'Datalake capability to support ADL as Additional Storage is not enabled for subscription '{guidpii}'.'}]}\n\nCould you please point me to the setting that I need to tweak in order to enable ADL on this subscription?  I can't seem to find it anywhere.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/31/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: GSL Research Subscription\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",DatalakeCapabilityNotEnabledForAdlAdditionalFS error when creating HDI cluster with ADL gen1 access,0.137922203,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure due to Azure Policy,DatalakeCapabilityNotEnabledForAdlAdditionalFS error when creating HDI cluster with ADL gen1 access,Customer chose HDI 3.6 as a version and chose ADLS Gen1 as additional storage which  didn't allow the cluster deployment.,The HDI Spark 2.4 (HDI 4.0) does not support ADLS Gen1 as primary or or as an additional storage account.,,,,,,,,
1.20073E+14,11:30.0,20 nodes on cluster is dead,"Question: What time did the problem begin?\nAnswer: Fri, Jul 31, 2020, 6:00 PM GMT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: cant conect {namepii} ssh to proplematics nodes\n\nQuestion: Additional details about the issue\nAnswer: Please reboot nodes:\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\nwn3\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\nwn7\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - cant conect {namepii} ssh to proplematics nodes;\nAdditional details about the issue - Please reboot nodes:\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\nwn3\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\n{alphanumericpii}\nwn7\n;\n\n- ProblemStartTime: 07/31/2020 18:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: WCD_MicroServices_Production_MBI\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e41925a3-ff07-4003-9fc5-4d68bb4ac45b/resourceGroups/wdatpsparkprd-eus2-{namepii}/providers/Microsoft.HDInsight/clusters/wdatp-spark-prd-eus2-1\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",20 nodes on cluster is dead,0.043900242,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Heart beat loss for multiple workernodes,Working on RCA with Alex in 120073025000649 in your TZ. Will inform Alex about this ticket. ,Rebooted worker nodes --> https://docs.microsoft.com/en-us/azure/hdinsight/cluster-reboot-vm,,,,,,,,
1.2008E+14,34:46.8,Unable to query Ambari server to retrieve the list of cluster hosts.,"Question: What time did the problem begin?\nAnswer: Sat, Aug 1, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Sat, Aug 1, 2020, 12:00 AM PDT\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: Unable to query Ambari server to retrieve the list of cluster hosts.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - Unable to query Ambari server to retrieve the list of cluster hosts.;\n\n- ProblemStartTime: 08/01/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DMa/DSNP ({ALPHANUMERICPII})\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/fb0e3da6-825c-4b83-a16d-bd78eb273ffd/resourceGroups/CCCM-PROD-CCCM-on-CAI-HDInsight24/providers/Microsoft.HDInsight/clusters/i24customeraiprod\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to query Ambari server to retrieve the list of cluster hosts.,0.155697101,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Unable to query Ambari server to retrieve the list of cluster hosts.,Unable to query Ambari server to retrieve the list of cluster hosts.,Make the cluster back to RUNNING state. The root cause is Gateway failed with 502 error when scale activity is going on. This is a known issue and fix ETA would be in 2 weeks.,"199,014,771,199,017,000,000,000,000,000,000,000,000,000,000",,,,,,,
1.2008E+14,16:02.6,The auto scale  is still in progress since Friday,"Question: What time did the problem begin?\nAnswer: Fri, Jul 31, 2020, 12:00 AM GMT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: The auto scale  is still in progress since {Namepii}\nThe cluster status from azure portal is showing “FailedToQueryAmbariServerErrorCode” error \nThe ambari interface is still working but we can’t stop the autoscale process from azure portal. \n\n \n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - Other, don't know or not applicable;\nAdditional details about the issue - The auto scale  is still in progress since {Namepii}\nThe cluster status from azure portal is showing “FailedToQueryAmbariServerErrorCode” error \nThe ambari interface is still working but we can’t stop the autoscale process from azure portal. \n\n \n;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 07/31/2020 00:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: BAT PaaS {Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/62139dec-4b9a-4661-8448-b84bf8cc354b/resourceGroups/RG-{NAMEPII}-NE-PetraAnalytics-uat-02/providers/Microsoft.HDInsight/clusters/bathdi-pd-{namepii}-petra-sparkhive-v4-uat-02\n- Location: northeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",The auto scale  is still in progress since Friday,0.426358283,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with Autoscaling,cluster stuck in error state,Ambari DB exhausted,Purged ambari DBDeleted the zombie nodes,"199,259,551,199,281,000",,,,,,,
1.2008E+14,32:07.0,Credential reset didn't take place,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 4, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Aug 4, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: HDInsight cluster configuration\n\nQuestion: Detail of the changes\nAnswer: I reset the ssh credentials from the portal but I still can't ssh into the node.\n\nHowever, I can login to ambari using the new credentials. \n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: Yes\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: I reset the ssh credentials from the portal but I still can't ssh into the node.\n\nHowever, I can login to ambari using the new credentials. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - HDInsight cluster configuration;\nDetail of the changes - I reset the ssh credentials from the portal but I still can't ssh into the node.\n\nHowever, I can login to ambari using the new credentials. ;\nHave you ever successfully connected to Ambari? - Yes;\nMitigating actions taken so far - ;\nAdditional details about the issue - I reset the ssh credentials from the portal but I still can't ssh into the node.\n\nHowever, I can login to ambari using the new credentials. ;\n\n- ProblemStartTime: 08/04/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}-As-You-{Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: {Namepii}\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - {Namepii}\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3a95e282-1525-4207-b1ad-2888e03d5f80/resourceGroups/{namepii}-westeurope/providers/Microsoft.HDInsight/clusters/soundhoundhdinsight\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Credential reset didn't take place,0.020659899,Root Cause : HDInsight Service\User Authentication and authorization issues,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,cannot ssh into cluster,SSH Password expired,"Change the SSH user password or public key1.    Using a text editor, save the following text as a file named changecredentials.sh. ImportantYou must use an editor that uses LF as the line ending. If the editor uses CRLF, then the script does not work.BashCopy#! /bin/bashUSER=$1PASS=$2usermod --password $(echo $PASS | openssl passwd -1 -stdin) $USER2.    Upload the file to a storage location that can be accessed from HDInsight using an HTTP or HTTPS address. For example, a public file store such as OneDrive or Azure Blob storage. Save the URI (HTTP or HTTPS address) to the file, as this URI is needed in the next step.3.    From the cluster home page, select Script actions under Settings.4.    From the Script actions page, select Submit new.5.    From the Submit script action page, enter the following information: NoteSSH passwords cannot contain the following characters:Copy"" ' ` / \ < % ~ | $ & ! CHANGE THE SSH USER PASSWORD OR PUBLIC KEYFieldValueScript typeSelect - Custom from the drop-down list.Name""Change ssh credentials""Bash script URIThe URI to the changecredentials.sh fileNode type(s): (Head, Worker, Nimbus, Supervisor, or Zookeeper.)✓ for all node types listedParametersEnter the SSH user name and then the new password. There should be one space between the user name and the password.Persist this script action ...Leave this field unchecked.6.    Select Create to apply the script. Once the script finishes, you're able to connect to the cluster using SSH with the new credentials.",,,,,,,,
1.2008E+14,04:18.9,Application stuck in Accepted statue with plenty of free memory & cores,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: All jobs stuck at ACCEPTED state, even restart YARN the issue soon comes back, related to ticket {Phonenumberpii}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - All jobs stuck at ACCEPTED state, even restart YARN the issue soon comes back, related to ticket {Phonenumberpii};\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe-sp-eu01\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Application stuck in Accepted statue with plenty of free memory & cores,0.886679011,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Service unhealthy\Spark,All jobs stuck at ACCEPTED state,"Apparently, another user during a configuration deployment changed the values for cluster o365ipdippe-sp-eu01 as well, ending in a resource reassignment for YARN queues.","Since this was a matter of resources allocation on YARN queues, the solution is to increase the resources for the ""Default"" queue from Ambari.Ambari -> YARN Queue Manager -> Edit Default queue.Restart YARN service.",199469978,,,,,,,
1.2008E+14,29:58.2,ACID Transaction Failing even after configuring hive,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Hive query if applicable\nAnswer: create table {alphanumericpii}\n ({namepii} int, phone int)\n clustered by ({namepii}) into 2 buckets stored as orc\n tblproperties('transactional'='true');\n \n \ninsert into table {alphanumericpii} values ​​(1,4);\ninsert into table {alphanumericpii} values ​​({Alphanumericpii});\n\nupdate {alphanumericpii} set {namepii}=20 where {alphanumericpii};\n\nwhen using update it is throwing error.\n\nQuestion: Does the same query work through Beeline from the Headnode?\nAnswer: Yes\n\nQuestion: Additional details about the issue\nAnswer: Enable {Namepii} Transactions and set threads to 1 in hive-site.xml still unable to upate table in hive\n\nError: Error while compiling statement: FAILED: SemanticException [Error 10302]: Updating values of bucketing columns is not supported.  Column {namepii}. ({alphanumericpii})\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nHive query if applicable - create table {alphanumericpii}\n ({namepii} int, phone int)\n clustered by ({namepii}) into 2 buckets stored as orc\n tblproperties('transactional'='true');\n \n \ninsert into table {alphanumericpii} values ​​(1,4);\ninsert into table {alphanumericpii} values ​​({Alphanumericpii});\n\nupdate {alphanumericpii} set {namepii}=20 where {alphanumericpii};\n\nwhen using update it is throwing error.;\nDoes the same query work through Beeline from the Headnode? - Yes;\nAdditional details about the issue - Enable {Namepii} Transactions and set threads to 1 in hive-site.xml still unable to upate table in hive\n\nError: Error while compiling statement: FAILED: SemanticException [Error 10302]: Updating values of bucketing columns is not supported.  Column {namepii}. ({alphanumericpii})\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/154431fe-c911-490e-87a0-c84ced2bee05/resourceGroups/pep-gdalatamrm-devhadoop-scus-01-{namepii}/providers/Microsoft.HDInsight/clusters/latamrmdevhadoop\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",ACID Transaction Failing even after configuring hive,0.733052944,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\Hive View,"Error: Error while compiling statement: FAILED: SemanticException [Error 10302]: Updating values of bucketing columns is not supported.  Column id. (state=42000,code=10302) ;",User was trying to update clustered field,Educated user that clustered fields cannot be updated in hive,,,,,,,,
1.2008E+14,36:25.7,Spark Applications failing in Cluster Mode,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Spark shell\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: spark-submit --files '/home/DOMAINSERVICES/sm185488/streaming/kafka_client_jaas#.conf,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVision_kafka.properties,/etc/krb5.conf,/etc/security/keytabs/application_keytabs/ca230558.keytab,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVisionlog4j.properties'  --conf 'spark.executor.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --conf 'spark.driver.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --class {namepii}.ncr.streams.SparkKafkaStreamNew --driver-memory 20g --executor-memory 15g --master yarn --deploy-mode cluster {alphanumericpii} aptraVision\n\nQuestion: Additional details about the issue\nAnswer: spark-submit --files '/home/DOMAINSERVICES/sm185488/streaming/kafka_client_jaas#.conf,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVision_kafka.properties,/etc/krb5.conf,/etc/security/keytabs/application_keytabs/ca230558.keytab,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVisionlog4j.properties'  --conf 'spark.executor.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --conf 'spark.driver.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --class {namepii}.ncr.streams.SparkKafkaStreamNew --driver-memory 20g --executor-memory 15g --master yarn --deploy-mode cluster {alphanumericpii} aptraVision\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Spark shell;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - spark-submit --files '/home/DOMAINSERVICES/sm185488/streaming/kafka_client_jaas#.conf,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVision_kafka.properties,/etc/krb5.conf,/etc/security/keytabs/application_keytabs/ca230558.keytab,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVisionlog4j.properties'  --conf 'spark.executor.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --conf 'spark.driver.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --class {namepii}.ncr.streams.SparkKafkaStreamNew --driver-memory 20g --executor-memory 15g --master yarn --deploy-mode cluster {alphanumericpii} aptraVision;\nAdditional details about the issue - spark-submit --files '/home/DOMAINSERVICES/sm185488/streaming/kafka_client_jaas#.conf,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVision_kafka.properties,/etc/krb5.conf,/etc/security/keytabs/application_keytabs/ca230558.keytab,/home/DOMAINSERVICES/sk185606/aptraVision/aptraVisionlog4j.properties'  --conf 'spark.executor.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --conf 'spark.driver.extraJavaOptions= -Djava.security.auth.login.config=kafka_client_jaas.conf' --class {namepii}.ncr.streams.SparkKafkaStreamNew --driver-memory 20g --executor-memory 15g --master yarn --deploy-mode cluster {alphanumericpii} aptraVision;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {ALPHANUMERICPII}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/67f94bee-2f3b-45d5-9940-b6473a58f2f2/resourceGroups/ITS-APPOPS-EDL-PREP-EUA01-STREAM01-RG/providers/Microsoft.HDInsight/clusters/chsp20adlspark\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Spark Applications failing in Cluster Mode,0.061010272,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Unexpected result\Spark,Spark Applications failing in Cluster Mode,Spark Applications failing in Cluster Mode,Worked with customer on this and found that the keytab required for the application is missing on worker nodes. Customer had copied the same to all worker nodes and taht fixed the issue.,,,,,,,,
1.20081E+14,21:03.1,Cannot access YARNUI,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: After {namepii} storage account thorugh script action,  yarn ui cannot be accessed:\n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - After {namepii} storage account thorugh script action,  yarn ui cannot be accessed:\n\n;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: DataInsights PPE\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cf9c99e1-cfef-4497-aeb9-6cabd61a0deb/resourceGroups/o365ipdippe01-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdippe01-sp-eu01\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot access YARNUI,0.568922708,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Service unhealthy\Spark,Cannot access YARNUI,We are seeing frequent CRITICAL alerts for the YARN service:Example Error:TIMESTAMP Label State Text2020-08-10 16:45:00.0000000 ResourceManager Web UI CRITICAL Connection failed to http://hn0-o365ip.d03pewby5tcerh35vwg0l4oncf.bx.internal.cloudapp.net:8088 (<urlopen error [Errno 111] Connection refused>)2020-08-10 16:45:00.0000000 ResourceManager Web UI CRITICAL Connection failed to http://hn1-o365ip.d03pewby5tcerh35vwg0l4oncf.bx.internal.cloudapp.net:8088 (<urlopen error [Errno 111] Connection refused>)The following warnings happen before the resource manager service gets stopped:PreciseTimeStamp Message2020-08-10 16:43:53.4010600 Large response size 3552214 for call Call#230664 Retry#0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getApplications from 10.0.0.24:38796,Asked the customer to try adding the following in the custom hdfs-site.xml:ipc.server.max.response.size=6000000Doc reference:https://issues.apache.org/jira/browse/HADOOP-6577Customer is unresponsive. Unsure if this fixed the issue.,,,,,,,,
1.20081E+14,04:39.0,folders in head node disappeared,"Question: What time did the problem begin?\nAnswer: Wed, Aug 5, 2020, 11:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: Other, don't know or not applicable\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: I had some files saved to the headnode of the Spark cluster. {Namepii} of the folders suddenly disapeared. Is there any way to retrieve the files? What is the reason cause this happened?\n\nQuestion: Additional details about the issue\nAnswer: I had some files saved to the headnode of the Spark cluster. {Namepii} of the folders suddenly disapeared. Is there any way to retrieve the files? What is the reason cause this happened?\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - Other, don't know or not applicable;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - I had some files saved to the headnode of the Spark cluster. {Namepii} of the folders suddenly disapeared. Is there any way to retrieve the files? What is the reason cause this happened?;\nAdditional details about the issue - I had some files saved to the headnode of the Spark cluster. {Namepii} of the folders suddenly disapeared. Is there any way to retrieve the files? What is the reason cause this happened?;\n\n- ProblemStartTime: 08/05/2020 16:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-{namepii}/providers/Microsoft.HDInsight/clusters/p02-las-as\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",folders in head node disappeared,0.033703541,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,folders in head node disappeared,Client tool issue. SSH/SFTP -- Mobaxterm,We noticed that the files and folders on the headnode were in place as they should have been and the issue was with the MabaXterm’s SFTP client that was not showing some directories. In the future we recommend using the azure storage account or datalake to save your data instead of the cluster nodes as the data on the cluster is not resilient as the storage accounts.,,,,,,,,
1.20081E+14,22:54.6,Need to access the HDI cluster through WVD (Windows virtual desktop),"Question: What time did the problem begin?\nAnswer: {Namepii}, Jul 14, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Not able to create HDI with express route \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - No;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Not able to create HDI with express route ;\n\n- ProblemStartTime: 07/14/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EnS-{Namepii}-DL-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a04d1510-3444-42bc-9ce1-41b3c9a9c558/resourceGroups/hdi-expresssroute-{namepii}/providers/Microsoft.HDInsight/clusters/hdi-expresssroute-test1\n- Location: westcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need to access the HDI cluster through WVD (Windows virtual desktop),0.250131986,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure within a VNET,Need to access the HDI cluster through WVD (Windows virtual desktop),Not able to access the cluster using MSFT VPN  ,"Steps to create create the WVD  Add the Selfhost ring registry value: Download from here: \\redmond\wsscfs\CowBell\Public_Tools\MSRDC_Config.exe     When you launch select ""Set Selfhost"" Install the client from: X64: https://aka.ms/wvd/clients/windows/x64 X86: https://aka.ms/wvd/clients/windows/x86Launch the client from the Start Menu by looking for the Remote Desktop(SelfHost)app if it didn't launch automatically after the install. If you receive a prompt to update to the latest version, please do so. Once the client window opens, click on Subscribe to get started. Sign in with your work account to automatically enable the selfhost subscription.  Using WVD we confirm that all the team member can able to access the HDI cluster",,,,,,,,
1.20081E+14,09:03.8,Heartbeat lost,"Question: What time did the problem begin?\nAnswer: Wed, Aug 5, 2020, 8:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Several cluster services have the Hearbet lost issue related to Ambari Server alert (hn0).\nI would like to know how to fix it (I am not able to connect ssh to hn0, so I couldn't execute the following steps https://docs.microsoft.com/fr-fr/azure/hdinsight/hadoop/apache-ambari-troubleshoot-heartbeat-issues).\nThanks a lot\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Several cluster services have the Hearbet lost issue related to Ambari Server alert (hn0).\nI would like to know how to fix it (I am not able to connect ssh to hn0, so I couldn't execute the following steps https://docs.microsoft.com/fr-fr/azure/hdinsight/hadoop/apache-ambari-troubleshoot-heartbeat-issues).\nThanks a lot;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/05/2020 12:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV01/providers/Microsoft.HDInsight/clusters/dsjd1llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Heartbeat lost,1.044794504,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Heart beat lost and head node (hn0) was un accessible .Several cluster services have the Heartbeat lost issue related to Ambari Server alert (hn0).,Headnode was down and stop sending heart beat.,Restarted the headnode-0-vm-0 and started all the hive services.,,,,,,,,
1.20081E+14,48:43.4,How to prevent HMaster process run? We found HMaster process uses lot of CPU,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We found CPU high on hn0, checked HMaster consume much CPU  resource, how to prevent it run?\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We found CPU high on hn0, checked HMaster consume much CPU  resource, how to prevent it run?;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-FRA-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/31cf52ce-3c6d-4759-b1a9-1daac64e8064/resourceGroups/o365ipdifra01-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdifra01-sp-fc01\n- Location: francecentral\n- Location: {Namepii} Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",How to prevent HMaster process run? We found HMaster process uses lot of CPU,0.153467148,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,The other jobs are taking more time than usual ,Process on head node are using a lot of resources (CPU),Kill the non-job related processSchedule the heavy jobs on a different time frameInvestigate the jobs using more resources by using the jstack command;jstak -l <PID>,,,,,,,,
1.20081E+14,14:39.6,spark history server takes too much of cpu consumtpion,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: kill Spark History server\n\nWe know it may be hard to get root cause since it is being killed, now we want to know what steps should we do before kill it to easier for you to find out root cause?\n\nQuestion: Additional details about the issue\nAnswer: We found History server takes a lot of CPU consumption\n\n{alphanumericpii}$ {namepii} jps -lm | grep 18576\n18576 org.apache.spark.deploy.history.HistoryServer\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - kill Spark History server\n\nWe know it may be hard to get root cause since it is being killed, now we want to know what steps should we do before kill it to easier for you to find out root cause?;\nAdditional details about the issue - We found History server takes a lot of CPU consumption\n\n{alphanumericpii}$ {namepii} jps -lm | grep 18576\n18576 org.apache.spark.deploy.history.HistoryServer;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EOP-DataInsights-FRA-Public\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/31cf52ce-3c6d-4759-b1a9-1daac64e8064/resourceGroups/o365ipdifra01-{namepii}-spark/providers/Microsoft.HDInsight/clusters/o365ipdifra01-sp-fc01\n- Location: francecentral\n- Location: {Namepii} Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",spark history server takes too much of cpu consumtpion,0.106057373,Root Cause : HDInsight Service\Configuration\Spark,Routing Azure HDInsight V5\Service unhealthy\Spark,Customer wanted the root cause and to know what steps to take before killing the spark history server,spark history server takes too much of cpu consumtpion,"Sent customer this recommendation:Before killing the Spark history server:1. Sudo to the spark user2. Execute the following command:  jstack -l <pid> > hsi_jstack_$(date +""%Y_%m_%d_%I_%M_%S"").out  3. Send the file to me for further analysisCustomer shared that they will try this steps if the issue reoccurs ",,,,,,,,
1.20081E+14,42:20.0,User is not able to run SPARK job with Livy Interpreter ,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: YARN Application ID for the Spark job if known\nAnswer: \n\nQuestion: {Namepii} was the Spark job submitted?\nAnswer: {Namepii} Notebook\n\nQuestion: What is the programming language used?\nAnswer: Other, don't know or not applicable\n\nQuestion: Spark configuration details\nAnswer: org.apache.zeppelin.livy.LivyException: Session 141 is finished, appId: null, log: [ at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala), 20/07/14 17:39:54 INFO ShutdownHookManager: Shutdown hook called, 20/07/14 17:39:54 INFO ShutdownHookManager: Deleting directory /{alphanumericpii}, 20/07/14 17:39:54 INFO MetricsSystemImpl: Stopping azure-file-system metrics system..., 20/07/14 17:39:54 INFO MetricsSinkAdapter: {alphanumericpii} thread interrupted., 20/07/14 17:39:54 INFO MetricsSystemImpl: azure-file-system metrics system stopped., 20/07/14 17:39:54 INFO MetricsSystemImpl: azure-file-system metrics system shutdown complete.,\n\nYARN Diagnostics: , java.lang.Exception: No YARN application is found with tag {alphanumericpii} in 120 seconds. Please check your cluster status, it is may be very busy., {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII})]\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat org.apache.zeppelin.scheduler.{Namepii}.run({Namepii}.java:175)\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\n \n\nQuestion: Additional details about the issue\nAnswer: Impacting all users.\n\nManual execution of SPARK {Namepii} job from CLI is failing and investigating the same .\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - Other, don't know or not applicable;\nIncrease in load? - ;\nYARN Application ID for the Spark job if known - ;\n{Namepii} was the Spark job submitted? - {Namepii} Notebook;\nWhat is the programming language used? - Other, don't know or not applicable;\nSpark configuration details - org.apache.zeppelin.livy.LivyException: Session 141 is finished, appId: null, log: [ at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala), 20/07/14 17:39:54 INFO ShutdownHookManager: Shutdown hook called, 20/07/14 17:39:54 INFO ShutdownHookManager: Deleting directory /{alphanumericpii}, 20/07/14 17:39:54 INFO MetricsSystemImpl: Stopping azure-file-system metrics system..., 20/07/14 17:39:54 INFO MetricsSinkAdapter: {alphanumericpii} thread interrupted., 20/07/14 17:39:54 INFO MetricsSystemImpl: azure-file-system metrics system stopped., 20/07/14 17:39:54 INFO MetricsSystemImpl: azure-file-system metrics system shutdown complete.,\n\nYARN Diagnostics: , java.lang.Exception: No YARN application is found with tag {alphanumericpii} in 120 seconds. Please check your cluster status, it is may be very busy., {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII}) {AlphanumericPII})]\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat org.apache.zeppelin.scheduler.{Namepii}.run({Namepii}.java:175)\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\nat {AlphanumericPII})\n\n ;\nAdditional details about the issue - Impacting all users.\n\nManual execution of SPARK {Namepii} job from CLI is failing and investigating the same .;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/0d749f68-ee04-4891-886c-0af14d9f80a8/resourceGroups/hdi-{namepii}-main01-prod/providers/Microsoft.HDInsight/clusters/prod-hdi-main01\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",User is not able to run SPARK job with Livy Interpreter ,0.362465151,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Query or Job Failure\Spark,Users are unable to run zeppelin commands,"Container was deleted and restored a couple of weeks back by the customer. There were access issues to /hdp/spark2_events folder. After enabling inherittance property on this folder, users are able to run zeppelin commands","Container was deleted and restored a couple of weeks back by the customer. There were access issues to /hdp/spark2_events folder. After enabling inherittance property on this folder, users are able to run zeppelin commands",199287463,,,,,,,
1.20081E+14,31:16.9,FD QA - kpq101llapfdqawus201 - Node unresponsive,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 6, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Not applicable. \n\n\n\nQuestion: Additional details about the issue\nAnswer: {alphanumericpii}\n{Ipaddresspii} - {alphanumericpii} node not reachable\n\nNode is not reachable. please reboot node and bring it back. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Not applicable. \n\n;\nAdditional details about the issue - {alphanumericpii}\n{Ipaddresspii} - {alphanumericpii} node not reachable\n\nNode is not reachable. please reboot node and bring it back. ;\n\n- ProblemStartTime: 08/06/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/3cd32f54-48bb-46d9-b679-00c40023eac0/resourceGroups/kp-{namepii}-cto-adfcore-qa-01/providers/Microsoft.HDInsight/clusters/kpq101llapfdqawus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",FD QA - kpq101llapfdqawus201 - Node unresponsive,0.038704388,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\VM or Node unhealthy\Node unresponsive or sluggish, FD QA - kpq101llapfdqawus201 - Node unresponsive, FD QA - kpq101llapfdqawus201 - Node unresponsive,Rebooted the WN25 node to mitigate the issue,,,,,,,,
1.20081E+14,42:39.3,[Azure Government] Jobs cannot be submitted,"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 6, 2020, 5:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Related incidents -- {Phonenumberpii} and {Phonenumberpii}\n\nAttached curl oathtoken response appears to indicate that this is the same expired certificate issue as we expreienced with our Spark clusters in {Phonenumberpii}.\n\nOddly, the resolution to {Phonenumberpii} confirmed the certificate renewal process had been fixed and that our Prod clusters -- which are now failing to accept jobs -- should not have been at immenent risk of failure.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - Related incidents -- {Phonenumberpii} and {Phonenumberpii}\n\nAttached curl oathtoken response appears to indicate that this is the same expired certificate issue as we expreienced with our Spark clusters in {Phonenumberpii}.\n\nOddly, the resolution to {Phonenumberpii} confirmed the certificate renewal process had been fixed and that our Prod clusters -- which are now failing to accept jobs -- should not have been at immenent risk of failure.;\n\n- ProblemStartTime: 08/07/2020 00:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PROD – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-{namepii}-{namepii}/providers/Microsoft.HDInsight/clusters/DeSparkBatchProd\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Jobs cannot be submitted,0.694510813,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Spark,120080724000334 - [Azure Government] Jobs cannot be submitted,"When the hotfix was deployed for Fairfax on 3rd Aug, our internal storage account key was rotated accidentally and that caused our API roles to fail. We have restored the key, patched impacted areas and redeployed code.","After a hot fix was applied by the Product Group, all clusters are up and able to run jobs, except one, which you have already deleted and recreated.",197394720,,,,,,,
1.20081E+14,22:39.0,Sandbox - kps126llaphpbiosbwus201,"Question: What time did the problem begin?\nAnswer: Fri, Aug 7, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {alphanumericpii}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: No\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: SecureHadoopWaitForOuContainerCreationActivityTimedOut\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {alphanumericpii};\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - No;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - SecureHadoopWaitForOuContainerCreationActivityTimedOut;\n\n- ProblemStartTime: 08/07/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-{namepii}-hpbio-ingest-dev-01/providers/Microsoft.HDInsight/clusters/kps126llaphpbiosbwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Sandbox - kps126llaphpbiosbwus201,0.314791849,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,SecureHadoopWaitForOuContainerCreationActivityTimedOut error while cluster creation,Transient issue,Delete and recreate cluster,,,,,,,,
1.20081E+14,47:03.2,unable to create cluster,"Question: What time did the problem begin?\nAnswer: Fri, Aug 7, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {AlphanumericPII} \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Yes\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: ARM Template\n\nQuestion: Additional details about the issue\nAnswer: {namepii}.azure.cli.core.util : Deployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'SecureHadoopWaitForOuContainerCreationActivityTimedOut',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}\nDeployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {AlphanumericPII} ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Yes;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - ARM Template;\nAdditional details about the issue - {namepii}.azure.cli.core.util : Deployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [\n      {\n        'code': 'SecureHadoopWaitForOuContainerCreationActivityTimedOut',\n        'message': 'Internal server error occurred while processing the request. Please retry the request or contact support.'\n      }\n    ]\n  }\n}\nDeployment failed. Correlation ID: {guidpii}. {\n  'status': 'Failed',\n  'error': {\n    'code': 'ResourceDeploymentFailure',\n    'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n    'details': [;\n\n- ProblemStartTime: 08/07/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Rx Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/e33df5d1-ae22-417d-b794-8d9b6f338409/resourceGroups/{namepii}-rtl-use2-cdp-dev/providers/Microsoft.HDInsight/clusters/hcdpd1-HDI-RTL-USE2-CDP-DEV-1\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",unable to create cluster,3.990066596,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,unable to create cluster,unable to create cluster,"Worked with customer on this and found that peering from ADDS to HDInsight VNET disabled and customer had enabled it successfully, that fixed the issue",199876180,,,,,,,
1.20081E+14,30:18.4,"[Azure Government] Status=---, Cannot delete clusters","[Azure Government] Question: What time did the problem begin?\nAnswer: Fri, Jul 17, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: {Phonenumberpii} - The internal certificates had expired and are not able to be rotated. To get our environments running again, we wish to delete the clusters, but because of the current state it is in, we cannot take any actions. \n\nQuestion: Additional details about the issue\nAnswer: Executed delete command on 1 selected items\nSucceeded: 0, Failed: 1, Canceled: 0.\nError details\ndecoresparkbatchprod: Encountered internal server error for batch API request '/subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchProd?api-version=2015-03-01-preview'. Tracking {namepii} '{guidpii}'. (Code: InternalServerError)\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - {Phonenumberpii} - The internal certificates had expired and are not able to be rotated. To get our environments running again, we wish to delete the clusters, but because of the current state it is in, we cannot take any actions. ;\nAdditional details about the issue - Executed delete command on 1 selected items\nSucceeded: 0, Failed: 1, Canceled: 0.\nError details\ndecoresparkbatchprod: Encountered internal server error for batch API request '/subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchProd?api-version=2015-03-01-preview'. Tracking {namepii} '{guidpii}'. (Code: InternalServerError);\n\n- ProblemStartTime: 07/17/2020 07:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PROD – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - ProDirect\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- Location: usgovvirginia\n- ResourceUri: /subscriptions/17a93c64-c0dc-47bb-98cd-26b687b0a68a/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchProd\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","[Azure Government] Status=---, Cannot delete clusters",0.874243279,Root Cause : HDInsight Service\Azure platform issues\Storage,Routing Azure HDInsight V5\Service unhealthy\Spark,"Not able to renew adls cert. Therefore, tried deleting clusters & re-creating to keep the environement running. But stuck in delete error state. ", Platform issue: storage account key was rotated accidentally and that caused our API roles to fail.  ,"Restored the key, patched impacted areas and redeployed code. Clusters are running now. Able to delete/create clusters. ",199877190,,,,,,,
1.20081E+14,30:44.0,Unable to delete resource group,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or it has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: No\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Automation runbook\n\nQuestion: Additional details about the issue\nAnswer: Stuck in Deleting but will not delete it states failed in the activity log. Please delete this resource group ASAP so we are not charged for the cluster\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or it has happened before? - {Namepii} problem, worked before;\nAny changes made? - No;\n{Namepii} was the CRUD request submitted? - Azure Automation runbook;\nAdditional details about the issue - Stuck in Deleting but will not delete it states failed in the activity log. Please delete this resource group ASAP so we are not charged for the cluster;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Clinical Network - Fuse - Stage Classic (DevTest)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/543c0572-d153-4029-b134-dae30593657e/resourceGroups/chc-dp-6b300000-ffac-0003-cc82-08d83af0e63a-stage-{namepii}/providers/Microsoft.HDInsight/clusters/f-wldu-chc-dp-6b300000-ffac-0003-cc82-08d83af0e63a\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Unable to delete resource group,0.027569623,Root Cause : HDInsight Service\HDInsight Custom configuration,Routing Azure HDInsight V5\Delete HDInsight cluster,Unable to delete resource group,unknown,VM reboot and deleted a cluster in backend,199891332,,,,,,,
1.20081E+14,40:45.1,[Azure Government] Cant publish in kafka,"[Azure Government] Question: What time did the problem begin?\nAnswer: Fri, Aug 7, 2020, 1:00 PM GMT-5\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: Fri, Aug 7, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None\n\nQuestion: Additional details about the issue\nAnswer: Topic ###### not present in metadata after 60000 ms.\n Cnat publish into {Namepii}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None;\nAdditional details about the issue - Topic ###### not present in metadata after 60000 ms.\n Cnat publish into {Namepii};\n\n- ProblemStartTime: 08/07/2020 18:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: pre-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n- Location: usgovvirginia\n- ResourceUri: /subscriptions/817cf623-d40e-4196-8261-736e3bffed3a/resourceGroups/pre-prod-kafka-{namepii}/providers/Microsoft.HDInsight/clusters/pre-prod-hdikafka-kafka\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] Cant publish in kafka,3.705878541,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Service unhealthy\Kafka,Unable to publish topic,Unable to publish topic,Issue with customer config,"199,877,190,199,899,000",,,,,,,
1.20081E+14,56:00.8,Not able to open ambari page,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: We are not able to open Ambari page for cluster {alphanumericpii}. Getting\n'502 - Web server received an invalid response while acting as a gateway or proxy server.\nThere is a problem with the page you are looking for, and it cannot be displayed. When the Web server (while acting as a gateway or proxy) contacted the upstream content server, it received an invalid response from the content server.'\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - We are not able to open Ambari page for cluster {alphanumericpii}. Getting\n'502 - Web server received an invalid response while acting as a gateway or proxy server.\nThere is a problem with the page you are looking for, and it cannot be displayed. When the Web server (while acting as a gateway or proxy) contacted the upstream content server, it received an invalid response from the content server.';\n\n- Cloud: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: NAA IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/bade91ba-b918-4ebc-b7ac-cb06dc6b1655/resourceGroups/Mosaic-NAA-Prod-Primary/providers/Microsoft.HDInsight/clusters/omeunitcbmprodnaa01a\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Not able to open ambari page,0.175175384,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Unable to login Ambari Portal,"Bad Gateway 502.It usually related with the active headnodehost didn’t run the ambari-server correctly and the 8080 port is not listening.Also, ambari server was running on both active namenode and standby namenode.This could cause the HDinsigtht HA fail to work as expected while there is HA active/standby headnode switch. In addition, we need to make sure the correct headnode ambari-server is running as a service. That is to say, we should generally use the command  “sudo systemctl restart ambari-server” when we are going to restart the ambari-server.","Check which is the active headnode:from hn0, grep ""headnodehost"" /etc/hostsUse the below commands as a fix for the clusterps -ef|grep ambari-server  to check if multiple ambari-server processessudo systemctl stop ambari-serversudo systemctl start ambari-server",,,,,,,,
1.20081E+14,23:31.4,[Azure Government] The Yarn UI for the cluster is not available.,"[Azure Government] Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 6, 2020, 4:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: No\n\nQuestion: Any change made to any of these components?\nAnswer: Password, access key, or certificate rotation\n\nQuestion: Detail of the changes\nAnswer: The MSI internal certificates were rotated thursday.\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: This page isn’t working right now\n\ndecoresparkbatchsharedppe.azurehdinsight.us redirected you too many times.\nERR_TOO_MANY_REDIRECTS\n\nIt also looks like the {Alphanumericpii} {Namepii} server is down.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - No;\nAny change made to any of these components? - Password, access key, or certificate rotation;\nDetail of the changes - The MSI internal certificates were rotated thursday.;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - ;\nAdditional details about the issue - This page isn’t working right now\n\ndecoresparkbatchsharedppe.azurehdinsight.us redirected you too many times.\nERR_TOO_MANY_REDIRECTS\n\nIt also looks like the {Alphanumericpii} {Namepii} server is down.;\n\n- ProblemStartTime: 08/06/2020 23:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Delaware – EDP PPE – Yes ITAR – No Classified\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: SpecialFree\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Special entitlement - Highest SLA\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/7ab74e9d-5466-4955-b717-acf76d07a2ca/resourceGroups/spark-p-{namepii}-core-{namepii}/providers/Microsoft.HDInsight/clusters/DeCoreSparkBatchSharedPPE\n- Location: usgovvirginia\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] The Yarn UI for the cluster is not available.,0.101824627,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Ambari UI is not loading,The Yarn UI for the cluster is not available.,Customer deleted the cluster & re-created a new one. ,Customer deleted the cluster & re-created a new one. Did not require RCA.,,,,,,,,
1.20081E+14,41:09.0,Cannot Authenticate to YARN,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Have you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication?\nAnswer: \n\nQuestion: Are the accounts federated?\nAnswer: \n\nQuestion: Does the issue affect all users or a few users?\nAnswer: All users\n\nQuestion: Does the user account work with other Azure services?\nAnswer: Yes\n\nQuestion: Does kinit for some or all users work from the {Namepii} node?\nAnswer: \n\nQuestion: Does authentication fail even for the cluster {namepii} account?\nAnswer: \n\nQuestion: Have you logged in to Ambari as local {namepii} and verified the users have been synced?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: All logins work across ambari except I cannot get to the YARN UI.  It throws authentication errors.\n\nPlease email for a MS Teams meeting time if you need more information than the attached image.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nHave you configured conditional access policy to be bypassed for the cluster login? Have you disabled Multi-Factor Authentication? - ;\nAre the accounts federated? - ;\nDoes the issue affect all users or a few users? - All users;\nDoes the user account work with other Azure services? - Yes;\nDoes kinit for some or all users work from the {Namepii} node? - ;\nDoes authentication fail even for the cluster {namepii} account? - ;\nHave you logged in to Ambari as local {namepii} and verified the users have been synced? - ;\nAdditional details about the issue - All logins work across ambari except I cannot get to the YARN UI.  It throws authentication errors.\n\nPlease email for a MS Teams meeting time if you need more information than the attached image.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: KONZA BIA {Namepii}\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: ProDirect\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan – ProDirect\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/74b150a9-e4c1-449e-96f8-f22cdc1fd7a6/resourceGroups/BIA_HD_Insight/providers/Microsoft.HDInsight/clusters/konzaanalytics\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Cannot Authenticate to YARN,1.316146029,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in cluster with Enterprise Security Package,cannot aauthenticate with yarn UI,customer did not use domain credentials,asked cx to use domain credentials,,,,,,,,
1.20081E+14,53:58.9,"Heartbeat lost, headnode down","Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Ticket related from the ticket {Phonenumberpii}\n\nSeveral cluster services have the Hearbeat lost issue related to Ambari Server alert (hn0).\nI would like to know how to fix it (I am not able to connect ssh to hn0, so I couldn't execute the following steps https://docs.microsoft.com/fr-fr/azure/hdinsight/hadoop/apache-ambari-troubleshoot-heartbeat-issues).\n\nI need to change some Hive parameters that I suspect to be the root issue of the problem.\nThanks a lot\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nMitigating actions taken so far - ;\nAdditional details about the issue - Ticket related from the ticket {Phonenumberpii}\n\nSeveral cluster services have the Hearbeat lost issue related to Ambari Server alert (hn0).\nI would like to know how to fix it (I am not able to connect ssh to hn0, so I couldn't execute the following steps https://docs.microsoft.com/fr-fr/azure/hdinsight/hadoop/apache-ambari-troubleshoot-heartbeat-issues).\n\nI need to change some Hive parameters that I suspect to be the root issue of the problem.\nThanks a lot;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9fea1672-7f6b-4f49-b341-53e307ebb4db/resourceGroups/NPD05-RGP-BI-DEV01/providers/Microsoft.HDInsight/clusters/dsjd1llapbi\n- Location: canadaeast\n- Location: Canada {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","Heartbeat lost, headnode down",2.384549795,Root Cause : HDInsight Service\By Design\Hadoop - HDP,Routing Azure HDInsight V5\Alerts firing on Services\Hive,Symptom: Heart beat lost and head node (hn0) was un accessible .Several cluster services have the Heartbeat lost issue related to Ambari Server alert (hn0).Manually not able to restart Ambari Server and Ambari Agent.,Cause:  Head node was down and stops sending heartbeat. Process ID – ambari-agent.pid  for Ambari Agent was not running and missing under /var/run which caused ambari agent to stop sending heartbeat,"Restarted the headnode-0-vm-0 and started all the hive services. Kill the ambari-agent process ID and restarting ambari-agent , ambari server helped fixed the issue.",,,,,,,,
1.20081E+14,55:53.6,Unable to create Spark cluster with ADLS Gen2 Storage Account ,"Question: What time did the problem begin?\nAnswer: Sun, Aug 9, 2020, 12:00 AM CDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Cluster name\nAnswer: adlsgen2poc-cloudregdev\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: Other, don't know or not applicable\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: No\n\nQuestion: How was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: No Title \nNo Title \n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'StoragePermissionsBlockedForMsi',\n                'message': 'The Managed Identity does not have permissions on the storage account. Please verify that 'Storage Blob Data Owner' role is assigned to the Managed Identity for the storage account. Storage: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/cr-workload-dev-rg/providers/Microsoft.Storage/storageAccounts/gmcloudregdevdatalake, Managed Identity: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourcegroups/gm_cloudreg_dev-cat-workload-rg/providers/Microsoft.ManagedIdentity/userAssignedIdentities/cat-dev-admin-msi, Missing permissions: Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/write,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/delete,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/add/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/deleteAutomaticSnapshot/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/runAsSuperUser/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/filter/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/tags/read,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/tags/write'\n            }\n        ]\n    }\n} \n\n\n\n\n<Start:Agent_Additional_Properties_Do_Not_Edit>\nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - 2020-08-09T05:00:00.000Z;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nCluster name - adlsgen2poc-cloudregdev;\nIs this a new problem, or the problem has happened before? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - Other, don't know or not applicable;\nIs Azure Active Directory Domain Services Integration involved? - No;\nHow was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - No Title \nNo Title \n{\n    'status': 'Failed',\n    'error': {\n        'code': 'ResourceDeploymentFailure',\n        'message': 'The resource operation completed with terminal provisioning state 'Failed'.',\n        'details': [\n            {\n                'code': 'StoragePermissionsBlockedForMsi',\n                'message': 'The Managed Identity does not have permissions on the storage account. Please verify that 'Storage Blob Data Owner' role is assigned to the Managed Identity for the storage account. Storage: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/cr-workload-dev-rg/providers/Microsoft.Storage/storageAccounts/gmcloudregdevdatalake, Managed Identity: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourcegroups/gm_cloudreg_dev-cat-workload-rg/providers/Microsoft.ManagedIdentity/userAssignedIdentities/cat-dev-admin-msi, Missing permissions: Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/write,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/delete,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/add/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/deleteAutomaticSnapshot/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/runAsSuperUser/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/filter/action,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/tags/read,Microsoft.Storage/storageAccounts/blobServices/containers/blobs/tags/write'\n            }\n        ]\n    }\n} \n;\n\n- ProblemStartTime: 08/09/2020 05:00:00\n- Cloud: Azure\n- AzureProductSubscriptionID: f1bb12fd-25a4-443f-97c4-c6ede704ec4b\n- AzureProductSubscriptionName: GM_CLOUDREG_DEV\n- PUID: 100320009C885346\n- Tenant Id: d0df3d96-c065-41c3-8c0b-5dcaa460ec33\n- Object Id: 7cf7a01a-e71a-4ec8-adf0-5249e004a084\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***Start: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/f1bb12fd-25a4-443f-97c4-c6ede704ec4b/resourceGroups/cr-workload-dev-rg/providers/Microsoft.HDInsight/clusters/adlsgen2poc-cloudregdev\n- Location: eastus2\n- Location: East US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: See External Reference in Admin Tab for full details.\n\n\n<End:Agent_Additional_Properties_Do_Not_Edit>\n",Unable to create Spark cluster with ADLS Gen2 Storage Account ,0.004090403,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure with Azure Data Lake Storage Gen2,Unable to create Spark cluster with ADLS Gen2 Storage Account,By design ,we noticed that the Managed Identity does not have proper permissions on the storage account the MSI should have “Storage blob data owner” role on the storage account to be able to successfully deploy the cluster while we only had a contributor role on it. ,,,,,,,,
1.20081E+14,56:32.1,"The previous problem has reoccured, previous support id: 120070723000968","Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 12:00 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Not new, happened before\n\nQuestion: Previous solution if applicable\nAnswer: Previous support ticket: {Phonenumberpii}\nPreviously resolved by patching the kafka brokers but the problem has re-occured\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: Following error is shown:\nUncaught error in kafka producer I/O thread: \njava.util.ConcurrentModificationException: null\n\nThis is a known bug of kafka 2.1.0 and is fixed in 2.1.1\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Not new, happened before;\nPrevious solution if applicable - Previous support ticket: {Phonenumberpii}\nPreviously resolved by patching the kafka brokers but the problem has re-occured;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - Following error is shown:\nUncaught error in kafka producer I/O thread: \njava.util.ConcurrentModificationException: null\n\nThis is a known bug of kafka 2.1.0 and is fixed in 2.1.1;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/10/2020 18:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}-Saavn\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Unified\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Unified Support - Advanced\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/570aed54-4a70-43cf-b092-1da587e063e1/resourceGroups/data-prod-sgp-{namepii}/providers/Microsoft.HDInsight/clusters/prodkafka\n- Location: southeastasia\n- Location: Southeast {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","The previous problem has reoccured, previous support id: 120070723000968",0.688193841,Root Cause : HDInsight Service\Bug\HDInsight,Routing Azure HDInsight V5\Query or Job Failure\Kafka,Followed error: Uncaught error in kafka producer I/O thread: java.util.ConcurrentModificationException: null,"ConcurrentModificationException occurs when iterating through multiple partitions in Sender.getExpiredInflightBatches (https://issues.apache.org/jira/browse/KAFKA-7709"" )","Client need to look at their producer code and update their app with newer version of kafka library (using whatever build/dependency system they use), to use 2.1.1 or 2.2.0. Therefore, there’s no change need to be made on the Kafka broker side.",200355019,,,,,,,
1.20081E+14,20:47.6,General Question related to the HDI ESP clusters,Certificate for the secure LDAPS (AAD DS) is expiring next month and we are planning to get it rotated.. Can you please advise on the impact to the existing HDInsight ESP clusters(azure manged service).\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: False\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n,General Question related to the HDI ESP clusters,0.670004246,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Spark,General question about LDAP certificate renewal,General question about LDAP certificate renewal,Provided information that HDI automatically updates ldap cert every 2 hours and normally no action is needed after cert renewal. Also provided a script which will manually update the cert in case of any issues.,,,,,,,,
1.20081E+14,39:37.6,Scale up cluster failed and cluster is not in running state.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 4:30 PM GMT+5:30\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Scale up cluster failed and cluster is not in running state.\n\n\nScale cluster failed with 'Gateway timeout' after that cluster not coming to 'running' status more that 2 hours. It is in 'accepted' status.\n\n\n{Namepii} Name : {alphanumericpii}\nSubscription  Name : {alphanumericpii}\nSubscription ID: {guidpii}\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Scale up cluster failed and cluster is not in running state.\n\n\nScale cluster failed with 'Gateway timeout' after that cluster not coming to 'running' status more that 2 hours. It is in 'accepted' status.\n\n\n{Namepii} Name : {alphanumericpii}\nSubscription  Name : {alphanumericpii}\nSubscription ID: {guidpii}\n;\n\n- ProblemStartTime: 08/11/2020 11:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-{namepii}-ingest1/providers/Microsoft.HDInsight/clusters/eds5prd-ingest-cluster\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Scale up cluster failed and cluster is not in running state.,0.276127083,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Scale up cluster failed and cluster is not in running state.,system was stuck with unknown reason,System backup and run with scale-up 36 nodes,,,,,,,,
1.20081E+14,01:34.0,Scale up cluster failed and cluster is not in running state.,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 4:30 AM {ALPHANUMERICPII}\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: \n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: Scale up cluster failed and cluster is not in running state.\n\nScale cluster failed with 'Gateway timeout' after that cluster not coming to 'running' status more that 2 hours. It is in 'accepted' status.\n\n{Namepii} Name : {alphanumericpii}\nSubscription  Name : {alphanumericpii}\nSubscription ID: {guidpii}\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs this a new problem, or the problem has happened before? - ;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - Scale up cluster failed and cluster is not in running state.\n\nScale cluster failed with 'Gateway timeout' after that cluster not coming to 'running' status more that 2 hours. It is in 'accepted' status.\n\n{Namepii} Name : {alphanumericpii}\nSubscription  Name : {alphanumericpii}\nSubscription ID: {guidpii};\n\n- ProblemStartTime: 08/10/2020 23:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ae3f03c-98cb-400c-bcd5-92d72c8efb8b/resourceGroups/xlc-azu-eus2-prd-edsprd-{namepii}-ingest1/providers/Microsoft.HDInsight/clusters/eds5prd-ingest-cluster\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Scale up cluster failed and cluster is not in running state.,0.321296227,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Scale HDInsight cluster\Issue with scaling up,Cluster stuck in accepting state ,"Cause:The scaling request has been received and it was getting processed by the API role but the DB call took almost 1 min. Since ARM is expecting for the API to return a response in less than 20 seconds, you would see the GatewayTimeout exception. The DB call returned with the exception below but the state was updated to Accepted. Since it came back with exception, there was no message queued for processing the scale request which means the cluster would be stuck in Accepted until manual action by on-call is taken. We have updated the cluster state to Running and the retry of the scale operation succeeded Occasionally we see these kind of exceptions, likely because the DB could be under load but this is not something that regularly happens and is very unlikely to happen again. ",Resolution:The on-call engineering team has put the cluster back to running state manually.,"200,366,408,200,371,000",,,,,,,
1.20081E+14,12:23.0,NameNode Last Checkpoint,"Pregunta: ¿A qué hora comenzó {namepii} problema?\nRespuesta: mié., 5 ago. 2020 8:00 {ALPHANUMERICPII}\n\nPregunta: {Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco.\nRespuesta: \n\nPregunta: ¿{Namepii} {namepii} realizado cambios en cualquiera {namepii} estos componentes?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: ¿{Namepii} aumentado {namepii} carga?\nRespuesta: Otro, no lo sé o no {namepii} aplicable\n\nPregunta: Acciones {namepii} mitigación realizadas hasta ahora\nRespuesta: NameNode {Namepii} Checkpoint\n\nPregunta: Detalles adicionales acerca del problema\nRespuesta: dos alertas criticas {namepii} los namenodes, como puedo solucionar esta alerta {namepii} raiz o como mitigarla.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight:\n¿A qué hora comenzó {namepii} problema? - {ALPHANUMERICPII};\n{Namepii} aproximada a {namepii} que {namepii} problema dejó {namepii} ocurrir. {Namepii} {namepii} problema está en curso, deje este campo en blanco. - ;\n¿{Namepii} {namepii} realizado cambios en cualquiera {namepii} estos componentes? - Otro, no lo sé o no {namepii} aplicable;\n¿{Namepii} aumentado {namepii} carga? - Otro, no lo sé o no {namepii} aplicable;\nAcciones {namepii} mitigación realizadas hasta ahora - NameNode {Namepii} Checkpoint;\nDetalles adicionales acerca del problema - dos alertas criticas {namepii} los namenodes, como puedo solucionar esta alerta {namepii} raiz o como mitigarla.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/05/2020 13:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Microsoft Azure Enterprise\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Plan {namepii} soporte técnico {namepii} Azure - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/678db644-8433-4ce4-96d7-c3d616140a2c/resourceGroups/GRPBigData/providers/Microsoft.HDInsight/clusters/bigdatasatrack02\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",NameNode Last Checkpoint,0.113437149,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Alerts firing on Services\Hbase,NameNode Last Checkpoint HDInsight Service,Critical alerts on both the headnodes hn0 and hn1,"Log onto your HDInsight cluster:Restart Ambari service on the nodes listed below, using sudo service ambari-agent restart Note: If the following list is empty, this step can be skipped: [listhosts]Once both Namenodes are running, please run the following commands to reset the checkpoint: hdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode enterhdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -saveNamespacehdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode leave",,,,,,,,
1.20081E+14,58:42.4,Use public IP for KAfka worker node for bootstrap servers,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Additional details about the issue\nAnswer: I would like to use the public IP of kafka brokers to send to topic instead of sending data to internal bootstrap servers {Alphanumericpii} \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - Never worked;\nIncrease in load? - Other, don't know or not applicable;\nAdditional details about the issue - I would like to use the public IP of kafka brokers to send to topic instead of sending data to internal bootstrap servers {Alphanumericpii} ;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: PepSecEngLongTermRetention\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/763b090e-4e6c-4c88-8b09-1c68c1e8578e/resourceGroups/pep-dap-p02-cus-{namepii}/providers/Microsoft.HDInsight/clusters/pep-kafka-ssl\n- Location: centralus\n- Location: Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Use public IP for KAfka worker node for bootstrap servers,0.033386199,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Kafka,Use public IP for KAfka worker node for bootstrap servers,"Not supported, By design ",I was able to find a documentation on what we discussed of using a vpn gateway to connect to the brokers using their private IPs.https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-connect-vpn-gateway This doc has a step by step guidance on how we can achieve this. Hope this helps.,,,,,,,,
1.20081E+14,55:28.6,adf sandbox - kps121sparkhpbiosbwus201 - adls access,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is storage affected the primary or secondary storage account\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Adding RBAC access with Storage blob data owner for MSI\n\nQuestion: Additional details about the issue\nAnswer: Unable to access additional ADLS from cluster even when RBAC 'Storage BLOB {Namepii} owner' permisisons granted . \n\n\n{Namepii}                           : {alphanumericpii} \nPrimary ADLS {Alphanumericpii}       :   {alphanumericpii}\nADLS MI {Namepii}         :   {alphanumericpii}\n\n{Namepii} ADLS where RBAC was provided for above MSI  {alphanumericpii}\n\nHDFS commands work on '{alphanumericpii}'\n\nHDFS commands not working on '{alphanumericpii}'. RBAC was provided for MSI. \n\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs storage affected the primary or secondary storage account - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nMitigating actions taken so far - Adding RBAC access with Storage blob data owner for MSI;\nAdditional details about the issue - Unable to access additional ADLS from cluster even when RBAC 'Storage BLOB {Namepii} owner' permisisons granted . \n\n\n{Namepii}                           : {alphanumericpii} \nPrimary ADLS {Alphanumericpii}       :   {alphanumericpii}\nADLS MI {Namepii}         :   {alphanumericpii}\n\n{Namepii} ADLS where RBAC was provided for above MSI  {alphanumericpii}\n\nHDFS commands work on '{alphanumericpii}'\n\nHDFS commands not working on '{alphanumericpii}'. RBAC was provided for MSI. \n\n;\n\n- ProblemStartTime: 08/11/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-DevTest-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/9622ce38-027e-46af-9ae6-5734056435fa/resourceGroups/kp-{namepii}-hpbio-ingest-dev-01/providers/Microsoft.HDInsight/clusters/kps121sparkhpbiosbwus201\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",adf sandbox - kps121sparkhpbiosbwus201 - adls access,0.069009369,Root Cause : HDInsight Service\User Error,"Routing Azure HDInsight V5\hdfs commands do not work\ADLS Gen1, ADLS Gen2 in standard cluster",adf sandbox - kps121sparkhpbiosbwus201 - adls access,adf sandbox - kps121sparkhpbiosbwus201 - adls access,Checked and found that secondary ADL Gen2 account has firewall rules enabled and source HDInsight VNET/Subnet is not whitelisted. Customer had fixed firewall rules and able to browse ADL Gen2 account successfully,,,,,,,,
1.20081E+14,58:56.0,hn0-omeaci.geragnkkulle1co3drhsk3ky0b.hx.internal.cloudapp.net is down,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 6:00 PM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: Nothing has been done as it should be started by MS.\n\nQuestion: Additional details about the issue\nAnswer: hn0-omeaci.geragnkkulle1co3drhsk3ky0b.hx.internal.cloudapp.net is down and restart it ASAP. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - Nothing has been done as it should be started by MS.;\nAdditional details about the issue - hn0-omeaci.geragnkkulle1co3drhsk3ky0b.hx.internal.cloudapp.net is down and restart it ASAP. ;\n\n- ProblemStartTime: 08/11/2020 22:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: APAC IoT\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/6ce0a038-2250-40fe-a3a1-1112c52dec0c/resourceGroups/Mosaic-APAC-STAGE-Primary/providers/Microsoft.HDInsight/clusters/omeacitdpstageapac02\n- Location: eastasia\n- Location: {Namepii} {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",hn0-omeaci.geragnkkulle1co3drhsk3ky0b.hx.internal.cloudapp.net is down,0.173807687,Root Cause : HDInsight Service\By Design\HBase,Routing Azure HDInsight V5\Service unhealthy\Hbase,hn0-omeaci.geragnkkulle1co3drhsk3ky0b.hx.internal.cloudapp.net is down,"Product group:  ""Such incidents can happen one off in cloud just like it can happen in on-prem for several reasons and are expected. The key takeaway is restarting the vm should fix this as it did in this case. If it's happening frequently, please reopen a ticket and the product group will collect more data.""",We help customer to reboot HN0 at 02:17 UTC 8/12,200445973,,,,,,,
1.20081E+14,32:11.3,Zeppelin not starting,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 11, 2020, 2:00 AM {ALPHANUMERICPII}\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Hi, yesterday, when opening the {Namepii} interface, we were greeted by an error 503 (Service Unavailable). We tried to restart the service from Ambari but without any luck as {Namepii} fails upon restart\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nAdditional details about the issue - Hi, yesterday, when opening the {Namepii} interface, we were greeted by an error 503 (Service Unavailable). We tried to restart the service from Ambari but without any luck as {Namepii} fails upon restart;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/11/2020 00:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {Namepii}., Platform & Solution Enablement (CZ)\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/cacc39b3-c703-4ddc-97a4-bfc9ccdb57aa/resourceGroups/DEV-MLAK-RESGROUP-SPARK-MDEEA/providers/Microsoft.HDInsight/clusters/{Namepii}-MLAK-HDI36-SPARK23-MDEEA\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Zeppelin not starting,0.422323078,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Client tool issue\Notebooks,Zeppelin not starting,Zeppelin not starting,Worked with customer and engaged product group on this. Product group suggested to set ZEPPELIN_MEM (as below) on Ambari UI -> Zeppelin notebook -> configs -> Advanced zeppelin-env.     export ZEPPELIN_MEM=-Xmx2048m -XX:MaxPermSize=1024mThis had fixed the issue and customer able to load Zeppelin UI and run commands.,"200,466,861,200,467,000,000,000,000",,,,,,,
1.20081E+14,22:31.8,[Azure Government] This resource won't create correctly,"[Azure Government] Question: What time did the problem begin?\nAnswer: Wed, Aug 12, 2020, 2:00 PM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: spark-lgrpt-tx-ppe\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: Never worked\n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: No\n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure Portal\n\nQuestion: Additional details about the issue\nAnswer: 'details': [\n            {\n                'code': 'InternalServerError',\n                'message': 'Fetching the customer's tenant {namepii} for subscription '{guidpii}'. Invalid Status Code or www-authenticate header is empty or invalid format: 'StatusCode = Forbidden{uncpii}\nHeaders{uncpii}\nPragma=no-cache{uncpii}\nx-ms-failure-cause=gateway{uncpii}\nx-ms-request-{namepii}=b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nx-ms-correlation-request-{namepii}=b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nx-ms-routing-request-{namepii}=USGOVTEXAS:20200812T221103Z:b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nStrict-Transport-Security=max-age=31536000; includeSubDomains{uncpii}\nX-Content-Type-Options=nosniff{uncpii}\nConnection=close{uncpii}\nCache-{Namepii}=no-cache{uncpii}\nDate=Wed, 12 Aug 2020 22:11:03 GMT''\n            }\n        ]\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - spark-lgrpt-tx-ppe;\nIs this a new problem, or the problem has happened before? - Never worked;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - No;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure Portal;\nAdditional details about the issue - 'details': [\n            {\n                'code': 'InternalServerError',\n                'message': 'Fetching the customer's tenant {namepii} for subscription '{guidpii}'. Invalid Status Code or www-authenticate header is empty or invalid format: 'StatusCode = Forbidden{uncpii}\nHeaders{uncpii}\nPragma=no-cache{uncpii}\nx-ms-failure-cause=gateway{uncpii}\nx-ms-request-{namepii}=b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nx-ms-correlation-request-{namepii}=b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nx-ms-routing-request-{namepii}=USGOVTEXAS:20200812T221103Z:b3514584-ce87-4b0e-b192-92fbc6b8be4e{uncpii}\nStrict-Transport-Security=max-age=31536000; includeSubDomains{uncpii}\nX-Content-Type-Options=nosniff{uncpii}\nConnection=close{uncpii}\nCache-{Namepii}=no-cache{uncpii}\nDate=Wed, 12 Aug 2020 22:11:03 GMT''\n            }\n        ];\n\n- ProblemStartTime: 08/12/2020 21:00:00\n- {Namepii}: Azure Government\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: MSF Datalake Prod sub\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {Guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5948035a-2b05-4ae0-adb1-95a3ca8807bb/resourceGroups/{namepii}-lgrpt-tx-ppe-compute/providers/Microsoft.HDInsight/clusters/spark-lgrpt-tx-ppe\n- Location: usgovtexas\n- Location: USGov {Namepii}\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",[Azure Government] This resource won't create correctly,1.668335326,Root Cause : HDInsight Service\By Design\Other,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,"Unable to deploy HDI cluster cluster creation fails with [{""ErrorCode"":""InternalServerError"",""ErrorDescription"":""Fetching the customer's tenant id for subscription '5948035a-2b05-4ae0-adb1-95a3ca8807bb'. Invalid Status Code or www-authenticate header is empty or invalid format:  'StatusCode = Forbidden\r\nHeaders\r\nPragma=no-cache\r\nx-ms-failure-cause=gateway\r\nx-ms-request-id=b77a8869-8913-4462-a015-f497eec14270\r\nx- ms-correlation-request-id=b77a8869-8913-4462-a015-f497eec14270\r\nx-ms-routing-request-id=USGOVTEXAS:20200812T215111Z:b77a8869-8913-4462-a015-f497eec14270 \r\nStrict-Transport-Security=max-age=31536000; includeSubDomains\r\nX-Content-Type-Options=nosniff\r\nConnection=close\r\nCache-Control=no-cache\r\nDate=Wed, 12 Aug 2020 21:51:10 GMT'""}]","Azure Databricks requires customer subscriptions to be managed by an Azure Databricks tenant. This is configured via the 'managedByTenantId' property on the customer subscription. The Azure Databricks tenant for these environments was being set to the MSFT CME tenant (for MC - a55a4d5b-9241-49b1-b4ff-befa8db00269), and MSFT FF tenant (for FF - 2f4a9838-26b7-47ee-be60-ccc1fdec5953) respectively instead of dedicated Azure Databricks tenants (as expected). This conflicted with tenant ID retrieval logic on HDI side where HDI was failing to retrieve the tenant id for customer subscriptions where the 'managedByTenantId' property includes the MSFT tenant for that cloud. This is HDI production impacting for the single subscription in MC. We haven't seen any issues in Fairfax, but its possible if the customer provisions Azure Databricks workspaces (to trigger setting the managedByTenantId property) along with HDI clusters in the same subscription."," delete Azure Databricks workspace so we can run Jarvis Action to unregister the Microsoft tenant ID as managedBy tenant to fix the issue. If they aren't able to delete the workspace, the team is currently working on migration of the current Fairfax workspaces which will take a few weeks (tentatively) to complete.","200,573,597,201,244,000",,,,,,,
1.20081E+14,09:23.5,Importing snapshot,"We are trying to export a snapshot from our on-prem HDI cluster to this Azure instance. Which is completed successfully but we are unable to find the same snapshot on this Azure cluster.\n\n\n\nProblem start date and time\n{Namepii}, Aug 11, 2020, 12:00 AM PDT\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 08/11/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/4a007414-fdfa-44a6-af25-b022ddda599a/resourceGroups/g-rsg-2s-commerce01-personalization-marketing-pas-01/providers/Microsoft.HDInsight/clusters/g-hdh-2s-personalization-marketing-pas-01\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Importing snapshot,0.157528622,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Client tool issue\HDInsight SDK,unable to export hbase snapshot from on-prem cluster to HDI cluster,  Storage account is not accessible from on-prem cluster,  Added the decrypted       key only to core-site.xml on edge node without any restart of      components and no config change on master/slave nodes still I was able to      successfully copy the snapshot to HSinsight clusterand restored the      snaphost as well.,200724987,,,,,,,
1.20081E+14,46:46.1,can not change the sshuser password throug Script action,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 13, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Have you ever successfully connected to Ambari?\nAnswer: No\n\nQuestion: Mitigating actions taken so far\nAnswer: followed the steps from the doucment to reset ssh user password \nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux\n\nOpen bridge for Microsoft SME to join teams call\n\n\nQuestion: Additional details about the issue\nAnswer: in Power BI the connection to the HIVE is not working and user {namepii} needs a reset. \n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nAny change made to any of these components? - Other, don't know or not applicable;\nHave you ever successfully connected to Ambari? - No;\nMitigating actions taken so far - followed the steps from the doucment to reset ssh user password \nhttps://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux\n\nOpen bridge for Microsoft SME to join teams call\n;\nAdditional details about the issue - in Power BI the connection to the HIVE is not working and user {namepii} needs a reset. ;\n\n- ProblemStartTime: 08/13/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: LCL_Production_PaaS\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1765302d-d48d-4bfd-bd2c-0f31b7653dba/resourceGroups/rg_FLIP3/providers/Microsoft.HDInsight/clusters/lcl-flip-hdi-apache\n- Location: canadacentral\n- Location: Canada Central\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",can not change the sshuser password throug Script action,0.072845952,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Authentication failure\Ambari in standard cluster,ssh user password change failed,Unsupported characters in the password,Removed unsupported characters in the password,,,,,,,,
1.20082E+14,40:33.6,compoments/service are not loading on Ambari UI,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 16, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Is issue intermittent?\nAnswer: Other, don't know or not applicable\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: I try to restart component but no response from UI\n\nQuestion: Additional details about the issue\nAnswer: see attached screen capture\nnone of component under\nhttps://catalysthive02.azurehdinsight.net/#/main\n\ncan be loaded\n\nPlease go ahead to do whatever needed to bring this cluster back to normal. reboot or restart service are fine\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nIs issue intermittent? - Other, don't know or not applicable;\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - I try to restart component but no response from UI;\nAdditional details about the issue - see attached screen capture\nnone of component under\nhttps://catalysthive02.azurehdinsight.net/#/main\n\ncan be loaded\n\nPlease go ahead to do whatever needed to bring this cluster back to normal. reboot or restart service are fine;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/16/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: EnS-{Namepii}-DL-Prod-01\n- PUID: {XUIDPII}\n- Tenant Id: {Guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Internal\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Internal\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a04d1510-3444-42bc-9ce1-41b3c9a9c558/resourceGroups/cat-operational-dl-{namepii}-01/providers/Microsoft.HDInsight/clusters/catalysthive02\n- Location: westcentralus\n- Location: {Namepii} Central US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",compoments/service are not loading on Ambari UI,0.243500218,Root Cause : HDInsight Service\Configuration\HDInsight,Routing Azure HDInsight V5\Ambari UI is not loading,Compoments/service are not loading on Ambari UI.,Upgrade to the next service tier or increase number of vCores. This is a hard limit based on the service tier or number of vCores.,Reboot the headnodes,,,,,,,,
1.20082E+14,31:41.9,"After a reboot, we are unable to SSH in.  'System is booting up. See pam_nologin(8)'","Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 17, 2020, 10:30 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: {Namepii} node\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: Rebooted at 9:30AM.\n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Mitigating actions taken so far\nAnswer: 1. Tried to SSH in.  Cannot.\n2. Script action to delete the following files:\nrm -f /var/run/nologin\nrm -f /etc/nologin\n\nScript action would not run with a status of 'aborted'\n\nQuestion: Additional details about the issue\nAnswer: {Namepii} with HN1 available, clients cannot connect to the cluster.\n\nHN1 is having Hive service issues.\n\nHN0 may have performed an UBUNTU udate upon reboot.  It did perform a filecheck.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - {Namepii} node;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - Rebooted at 9:30AM.;\nIncrease in load? - ;\nMitigating actions taken so far - 1. Tried to SSH in.  Cannot.\n2. Script action to delete the following files:\nrm -f /var/run/nologin\nrm -f /etc/nologin\n\nScript action would not run with a status of 'aborted';\nAdditional details about the issue - {Namepii} with HN1 available, clients cannot connect to the cluster.\n\nHN1 is having Hive service issues.\n\nHN0 may have performed an UBUNTU udate upon reboot.  It did perform a filecheck.;\n\n- ProblemStartTime: 08/17/2020 14:30:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Greenhouse\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Standard\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Azure Support Plan - Standard\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/5fcb9b33-e28e-4056-96dc-9ecc709cfd78/resourceGroups/ProductionCluster/providers/Microsoft.HDInsight/clusters/Greenhouse-Production\n- Location: {alphanumericpii}\n- Location: {Namepii} US 2\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n","After a reboot, we are unable to SSH in.  'System is booting up. See pam_nologin(8)'",0.051482465,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\VM or Node unhealthy\Unable to SSH,Getting the error “connect to host hn1-greenh port 22: Connection refused” when I attempt to SSH from HN0 to HN1.,SSH process needs time to be up and running,Waiting for some time after the cluster rebooted,,,,,,,,
1.20082E+14,38:23.8,Need help with vulnerability questions,"Does HDI need rabbitmq on edge node? If yes, what is the use of it? If no, can we remove it?\n\n\n\nProblem start date and time\n{Namepii}, Aug 17, 2020, 12:00 AM CDT\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \n- ProblemStartTime: 08/17/2020 05:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Retail Rx Data Analytics Non-Production\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Need help with vulnerability questions,0.265836219,Root Cause : HDInsight Service\By Design\HDInsight,Routing Azure HDInsight V5\Unexpected result\Hive,General question,General questions on rabbitmq and postgresql services,Checked with PG team and provided suggestion that these services are not needed for HDI,,,,,,,,
1.20082E+14,56:24.2,Getting list of hosts to be customized is empty,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 18, 2020, 9:40 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Aug 18, 2020, 12:00 AM PDT\n\nQuestion: YARN Application ID for the broker job if known\nAnswer: \n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any change made to any of these components?\nAnswer: \n\nQuestion: Increase in load?\nAnswer: \n\nQuestion: Additional details about the issue\nAnswer: Getting error message:\n\nDeployment failed. Correlation ID: {guidpii}. ErrorCode: ScriptExecutionFailed; ErrorDescription: List of hosts to be customized is empty for script action 'Reset Password'.\n\n\naz hdinsight script-action execute --resource-group helx-prod-dataingest-wds-hdi-eastus-{namepii} --cluster-name {alphanumericpii} --name 'Reset Password' --roles headnode workernode zookeepernode edgenode --script-uri 'https://helxpubgrsstadevwestus.blob.core.windows.net/scripts/changepassword.sh?se=2020-08-18T17%3A13Z&sp=r&spr=https&sv=2018-11-09&sr=b&sig=eSUMDmD88PS5uhOqIbA3PzPTAhw/3m84bwZZtoZqaPY%3D' --script-parameters 'helixuser xxxxxxxx' --subscription 'helix-prod'\n\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nYARN Application ID for the broker job if known - ;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny change made to any of these components? - ;\nIncrease in load? - ;\nAdditional details about the issue - Getting error message:\n\nDeployment failed. Correlation ID: {guidpii}. ErrorCode: ScriptExecutionFailed; ErrorDescription: List of hosts to be customized is empty for script action 'Reset Password'.\n\n\naz hdinsight script-action execute --resource-group helx-prod-dataingest-wds-hdi-eastus-{namepii} --cluster-name {alphanumericpii} --name 'Reset Password' --roles headnode workernode zookeepernode edgenode --script-uri 'https://helxpubgrsstadevwestus.blob.core.windows.net/scripts/changepassword.sh?se=2020-08-18T17%3A13Z&sp=r&spr=https&sv=2018-11-09&sr=b&sig=eSUMDmD88PS5uhOqIbA3PzPTAhw/3m84bwZZtoZqaPY%3D' --script-parameters 'helixuser xxxxxxxx' --subscription 'helix-prod'\n;\n\n- ProblemStartTime: 08/18/2020 16:40:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: helix-prod\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/a548e950-33a3-489b-94b3-29b5ad6030bc/resourceGroups/helx-prod-dataingest-wds-hdi-eastus-{namepii}/providers/Microsoft.HDInsight/clusters/helx2-prod-dataingest-wds-hdi-eastus-hdik\n- Location: eastus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Getting list of hosts to be customized is empty,0.040079045,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\Unexpected result\Kafka, Getting list of hosts to be customized is empty,Issue: Getting list of hosts to be customized is empty,Resolution: We see multiple PIDs related to AmbariServer process. So we killed those hung/Zombie PIDs to restart the ambari-server. After that everything started working fine and able to see hosts information in Ambari UI and able to update the SSH password,"201,342,589,201,343,000",,,,,,,
1.20082E+14,25:24.8,Connection failed: 'NoneType' object has no attribute 'split' to region server,"Question: What time did the problem begin?\nAnswer: Wed, Aug 19, 2020, 12:00 AM PDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: Type of node affected?\nAnswer: Workernode\n\nQuestion: Any change made to any of these components?\nAnswer: Node or service reboot\n\nQuestion: Detail of the changes\nAnswer: The ambari service auto restarted the head node hn0\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: None taken as of yet, unable to find information on this error: \n\nConnection failed: 'NoneType' object has no attribute 'split' to wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:16030\n\nQuestion: Additional details about the issue\nAnswer: This error happened after an autorestart of the head node.  Worker nodes affected numbers 11, 21, and 25.\n\nWorker Node Errors: \n- Connection failed to http://wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30075 ('NoneType' object has no attribute 'split')\n- Connection failed: 'NoneType' object has no attribute 'split' to wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:16030\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\nType of node affected? - Workernode;\nAny change made to any of these components? - Node or service reboot;\nDetail of the changes - The ambari service auto restarted the head node hn0;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - None taken as of yet, unable to find information on this error: \n\nConnection failed: 'NoneType' object has no attribute 'split' to wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:16030;\nAdditional details about the issue - This error happened after an autorestart of the head node.  Worker nodes affected numbers 11, 21, and 25.\n\nWorker Node Errors: \n- Connection failed to http://wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:30075 ('NoneType' object has no attribute 'split')\n- Connection failed: 'NoneType' object has no attribute 'split' to wn11-prdalh.meuoib51lmqezo25oxzugd5q2g.dx.internal.cloudapp.net:16030;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/19/2020 07:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: Plan\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier {Namepii} Critical\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/231ce626-a41d-4bb2-9bec-51ab394e76a6/resourceGroups/Allocation-Prod/providers/Microsoft.HDInsight/clusters/prdalh-azwus-prd-allocation-hdihbase001\n- Location: westus\n- Location: {Namepii} US\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Connection failed: 'NoneType' object has no attribute 'split' to region server,0.084342436,Root Cause : HDInsight Service\Transient error / Unknown,Routing Azure HDInsight V5\VM or Node unhealthy\Lost network connectivity between nodes,Connection failed: 'NoneType' object has no attribute 'split' to region server,Issue: Connection failed: 'NoneType' object has no attribute 'split' to region server,"Resolution: As a mitigation, we restarted the ambari agent service - systemctl restart ambari-agent",,,,,,,,
1.20082E+14,27:01.3,MDH Distribuition:  Problem with deploying the ESP clusters,"Question: What time did the problem begin?\nAnswer: \n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: \n\nQuestion: {Namepii} name\nAnswer: {Namepii} clusters\n\nQuestion: Is this a new problem, or the problem has happened before?\nAnswer: {Namepii} problem, worked before\n\nQuestion: Any changes made?\nAnswer: \n\nQuestion: Is cluster created in a VNET?\nAnswer: Yes\n\nQuestion: Is VNET peering involved?\nAnswer: \n\nQuestion: Is Azure Active Directory Domain Services Integration involved?\nAnswer: Yes\n\nQuestion: {Namepii} was the CRUD request submitted?\nAnswer: Azure CLI\n\nQuestion: Additional details about the issue\nAnswer: With the MDH distribution not able to create the ESP spark cluster.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - ;\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - ;\n{Namepii} name - {Namepii} clusters;\nIs this a new problem, or the problem has happened before? - {Namepii} problem, worked before;\nAny changes made? - ;\nIs cluster created in a VNET? - Yes;\nIs VNET peering involved? - ;\nIs Azure Active Directory Domain Services Integration involved? - Yes;\n{Namepii} was the CRUD request submitted? - Azure CLI;\nAdditional details about the issue - With the MDH distribution not able to create the ESP spark cluster.;\n\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {guidpii}\n- AzureProductSubscriptionName: {NAMEPII}-{Namepii}-NonProd-01\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: False\n- DatabricksConsent: False\n\n- ResourceUri: \n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",MDH Distribuition:  Problem with deploying the ESP clusters,0.006269918,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Create HDInsight cluster\Create failure - other,MDH Distribuition: Problem with deploying the ESP clusters,Issue: MDH Distribuition: Problem with deploying the ESP clusters,Resolution: Got the email from Ashish saying he has enabled again and retry helped to deploy the MDH cluster.,,,,,,,,
1.20082E+14,58:26.5,Memory and VCores available in a Cluster for Spark Jobs in Yarn,"Question: What time did the problem begin?\nAnswer: {Namepii}, Aug 20, 2020, 12:00 AM EDT\n\nQuestion: Approximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank\nAnswer: {Namepii}, Aug 20, 2020, 12:00 AM EDT\n\nQuestion: Any change made to any of these components?\nAnswer: Other, don't know or not applicable\n\nQuestion: Increase in load?\nAnswer: Other, don't know or not applicable\n\nQuestion: Mitigating actions taken so far\nAnswer: N/A\n\nQuestion: Additional details about the issue\nAnswer: Hi,\n\nI am trying to find out what is the available memory and vcores available in a cluster with the following:\n\nWorker Nodes 5, 10\n{NAMEPII} Types {Alphanumericpii} or {Alphanumericpii}.\n\nFrom YARN, I see {ALPHANUMERICPII} and 75 cores.  But when I run the multiple jobs with a total of these numbers, some of the jobs are in accepted state.  Is this memory used and vcores used instead of reserved?  {Alphanumericpii} -{Alphanumericpii} in this instance?  Also it the number same for a cluster of 10 nodes?\n\nIf there is a way to find out how much memory and cpu is reserved in the cluster, e.g. for LLAP, System, etc..\n\nThanks.\n\n\n\n <{Namepii}:Agent_Additional_Properties_Do_Not_Edit> \nCustomer answers to additional questions for HDInsight Service:\nWhat time did the problem begin? - {ALPHANUMERICPII};\nApproximate time when the problem stopped occurring. If the issue is ongoing, leave this field blank - {ALPHANUMERICPII};\nAny change made to any of these components? - Other, don't know or not applicable;\nIncrease in load? - Other, don't know or not applicable;\nMitigating actions taken so far - N/A;\nAdditional details about the issue - Hi,\n\nI am trying to find out what is the available memory and vcores available in a cluster with the following:\n\nWorker Nodes 5, 10\n{NAMEPII} Types {Alphanumericpii} or {Alphanumericpii}.\n\nFrom YARN, I see {ALPHANUMERICPII} and 75 cores.  But when I run the multiple jobs with a total of these numbers, some of the jobs are in accepted state.  Is this memory used and vcores used instead of reserved?  {Alphanumericpii} -{Alphanumericpii} in this instance?  Also it the number same for a cluster of 10 nodes?\n\nIf there is a way to find out how much memory and cpu is reserved in the cluster, e.g. for LLAP, System, etc..\n\nThanks.;\n\nCustomer has uploaded a file. /?{alphanumericpii}\n- ProblemStartTime: 08/20/2020 04:00:00\n- {Namepii}: Azure\n- AzureProductSubscriptionID: {Guidpii}\n- AzureProductSubscriptionName: {alphanumericpii}\n- PUID: {XUIDPII}\n- Tenant Id: {guidpii}\n- Object Id: {guidpii}\n- SubscriptionType: Premier\n- RequestTypeId: AZURE_TECHNICAL\n- SupportPlanDisplayName: Premier with Azure Rapid response\n- GrantPermission: True\n- ShareMemoryDump: False\n- HDInsightConsent: True\n- DatabricksConsent: False\n\n***{Namepii}: Additional properties for HDInsight***\n- ResourceInstanceId: /subscriptions/1efb937e-53fb-4d3f-9987-34362886acc2/resourceGroups/mlt-dar-pscdatahub-1-DEV-cluster5-{Namepii}-HDI/providers/Microsoft.HDInsight/clusters/QlcQFawGuC-ProjectSpark\n- Location: westeurope\n- Location: {Namepii} Europe\n- OsType: \n- ClusterVersion: \n***End: Additional properties for HDInsight***\n\n**Note: {Namepii} External Reference in {Namepii} {Namepii} for full details.\n\n\n <End:Agent_Additional_Properties_Do_Not_Edit> \n",Memory and VCores available in a Cluster for Spark Jobs in Yarn,0.040329413,Root Cause : HDInsight Service\User Error,Routing Azure HDInsight V5\Metrics are missing\Spark,Memory and VCores available in a Cluster for Spark Jobs in Yarn,Issue: Memory and VCores available in a Cluster for Spark Jobs in Yarn,Resolution: Recommend to use the YARN UI to check the usage details for memory and cores,,,,,,,,
